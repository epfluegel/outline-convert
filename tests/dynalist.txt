By My Novelty
     BY TAG
         #AI #productivity #VNM
             NOVELTY
                 DIGITAL PRODUCTIVITY -- KNOWLEDGE WORK + VNM
                 AI + DIGITAL PRODUCTIVITY -- KNOWLEDGE WORK + VNM
         #econ #security #VNM
             BACKGROUND
                 Mathematical Economics
                 Security Economics
                 Von Neumann Economic Model
             NOVELTY
                 MROI AND MROMI
         #LA
         #RA 
             MAEVA #slide 
                 __Motive__: the underlying reason for attacking the victim. 
                     This could be for the purposes of financial gains, revenge, personal satisfaction or thrill, or simply with the intention of creating damage. From a psychological point of view, the attacker's motive might affect the perceived gain, as well as the appreciation of the effort required.
                 __Ability__: the capability of the attacker to invest in resources for implementing the attack, as well as the technical knowledge available for breaching cyber security controls. 
                     A strong ability will make it easier to spend effort on the attack, and subjectively reducing the perceived value of $e$.
                 __Exploitability__: the ease by which the system can be penetrated, through exploiting a vulnerability. 
                     It would be reasonable to expect exploitability and effort to be inversely related in a proportional manner. This category could be explored similarly as in the CVSS exploitability score, taking into account possible attack vectors and attack complexities, as well as the required privileges and interaction with users, however, the discussion should not be restricted to software vulnerabilities alone.
                 __Visibility of target__: how prominent is the target, for example, does it have a popular website or brand name, does it have a large user base? 
                     Great visibility might promise a big gain, in the eyes of the attacker.
                 __Attractiveness of target__: from the point of view of the attacker, how attractive is the target? 
                     This is linked to how much gain the attacker would estimate from achieving through the attack, and will strongly depend on the specific motive, as discussed in the first category.
         #simplex #VNM 
             Background
             Simplex+Dual+MC2
                 Background and Context #slide 
                     The Dual Simplex Method 
                     MC2 Linear Programs
                 MC2 Linear Program Formulation #slide 
                     MC2 LP:
                         Consider
                             "$$\max C^\top y+d$$" subject to "$$Ay\le B$$" and $$y\ge 0$$ ($$d>0$$). 
                         This means
                             $$\exist\, x,y^0\ge 0:\; z=x(C^\top y + d)$$ maximal s.t. $$Ay \le By^o,\; y\ge 0$$.
                         Here:
                             Multiple objectives: $$C$$
                             Multiple constraints: $$B$$
                 Necessary Conditions: Augmented Form #slide 
                     We view the linear system of inequalities used in the MC2 LP as a system of linear matrix equations.
                     This can be written using non-basic and basic variables as
                         $$Ay+\hat{y}=By^o$$
                         $$x^o(C^\top y+d)=v$$
                     where $$y\ge 0,\hat{y}\ge 0,y^o\ge 0$$.
                 Constructing A Basic Solution #slide 
                     We can construct a basic solution that may be infeasible, or not even real, given as follows:
                         Let $$\lambda\neq 0$$ be an eigenvalue of $$D$$ with corresponding eigenvectors $$\hat{x}^\top, \hat{y}$$ and define $$\hat{v}=1/\lambda$$. 
                         Subject to the substitution $$A\leftarrow A+aD$$ for a suitable positive real number $$a$$ we can assume $$\Re(\hat{v})>0$$. 
                         Then $$(\hat{v},\hat{x}^\top, \hat{y})$$ is a generalised eigensystem of $$I-\lambda{D}$$. 
                         Set $$x^o=\hat{x}B$$, $$y=0$$, $$v=x^od$$ and $$y^o=C^\top \hat{y}$$.
                 Sufficient Conditions for Feasible Basic Solution #slide 
                 Tableau Notation #slide 
                     The classical compact tableau notation is expanded as follows:
                         $$\begin{array}{|c|c|c|} \hline A & I & B\\ \hline C^\top & 0 & V\\ \hline \end{array}$$
                     The dual tableau is:
                         $$\begin{array}{|c|c|} \hline A  & B\\ \hline I  & 0 \\ \hline C^\top  & V\\ \hline \end{array}$$
                 Pivot Step #slide 
             Simplex+Params
             Simplex+Pencils
                 A novel multi-criteria dual simplex method based on matrix pencils. #MPS #h #slide #novel:algorithm #novel:slow
                     The Method #h 
                         Background and Context #slide 
                             The Dual Simplex Method 
                         Intro #slide 
                             The algorithm views the linear system of equations used in the dual simplex method as a bilinear linear matrix pencil equation. 
                             This can be written using non-basic and basic variables as
                                 $$x^\top(A-vD)y+\hat{x}\hat{y}=0$$
                                     $$x^\top(A-vD)y+\hat{x}^\top(I-\hat{v}{D})\hat{y}=0$$ #wfe-ignore-item 
                             where $$x\ge 0,\hat{x}\ge 0,y\ge 0,\hat{y}\ge 0$$.
                         View as Linear Matrix Pencil Equation #slide 
                             Setting #simplex:augmented 
                                 Canonical form can be written as
                                     $$x^\top(A-vbc^\top)y+\hat{x}^\top(\alpha I-{\beta}{bc^\top})\hat{y}=0$$
                                 where $$x\ge 0,\hat{x}\ge 0,\hat{y}\ge 0$$.
                             Assumptions
                                 The matrix pencil $$A-\lambda {bc^\top}$$ is regular.
                                 The unique finite eigenvalue of this regular matrix pencil is positive. 
                                 Note: this excludes the case where $$bc^\top$$ is nilpotent.
                         Relationships and Assumptions #slide 
                             $$A$$ is invertible
                             $$D=BC^\top$$ rank-factorisation
                             $$A-\lambda D$$ is a regular matrix pencil
                             Assumption: $$D$$ is not nilpotent 
                             $$V=C^\top A^{-1}B$$
                         Tableau Notation #slide 
                             We extend the classical compact tableau notation as follows:
                                 $$\begin{array}{|c|c|} \hline A & B\\ \hline C^\top & V\\ \hline \end{array}$$
                             The expanded tableau is:
                                 $$\begin{array}{|c|c|c|} \hline A & I & B\\ \hline I & 0 & 0 \\ \hline C^\top & 0 & V\\ \hline \end{array}$$
                         Initialisation #slide #simplex:init 
                             We start with $$x=y=0$$, $$v=0$$ and a basic solution that may be infeasible, given as follows:
                                 Let $$\lambda\neq 0$$ be an eigenvalue of $$D$$ with corresponding eigenvectors $$\hat{x}^\top, \hat{y}$$ and define $$\hat{v}=1/\lambda$$. 
                                 Then $$(\hat{v},\hat{x}^\top, \hat{y})$$ is a generalised eigensystem of $$I-\lambda{D}$$. 
                                 Subject to the substitution $$A\leftarrow A+aD$$ for a suitable real number $$a$$ we can assume $$\hat{v}>0$$. 
                         Reduction Step (I) #slide #simplex:pivot 
                             We partition the matrix $$A$$ into $$rs$$ blocks ($$1\le r \le m$$, $$1\le s \le n$$), with matching row and column dimensions:
                                 $$A=\begin{pmatrix} A_{11} & \cdots & A_{1j} & \cdots & A_{1s} \\ \vdots &  & \vdots &  & \vdots \\ A_{i1} & \cdots & A_{ij} & \cdots & A_{is} \\ \vdots &  & \vdots &  & \vdots \\A_{r1} & \cdots & A_{rj} & \cdots & A_{rs} \\ \end{pmatrix}$$
                             Let $$B$$ and $$C^\top$$ be partitioned accordingly
                             We can pick a block-index pair $$(i,j)$$ as block-pivot, if $$A_{ij}$$ is square and $$A_{ij}-\lambda B_{ij}C_{ij}^\top$$ is a regular matrix pencil with at least one real, positive eigenvalue $$\mu$$ and corresponding eigenvectors $$x^\top_\mu, y_\mu$$ that are not both nonnegative
                         Reduction Step (II) #slide #simplex:pivot 
                             Primal (Row/Left-Multiplication)
                                 The new matrices $$\tilde{A}$$ and $$\tilde{B}$$ are obtained through left-multiplication of a suitable matrix $$P$$ and swapping basic and non-basic variables
                             Dual (Column/Row-Multiplication)
                                 The new matrices $$\tilde{A}$$ and $$\tilde{C}$$ are obtained through right-multiplication of a suitable matrix $$Q$$ and swapping basic and non-basic variables
                         Reduction Step (III) #slide #simplex:pivot 
                             One has
                                 $$\tilde{A}_{ij}=$$
                                 $$\tilde{R}_i=$$
                                 $$\tilde{C}^\top_j=$$
                                 $$\tilde{V}=V-Q^\top A^{-1}P$$
                         Normalisation Step #slide 
                             
                         Termination #slide 
                             $$D=LR^\top$$, $$L,R^\top\ge 0, A^{-1}L\ge 0, R^\top A^{-1}\ge 0 \Rightarrow A-vD$$ has a nonnegative eigenvalue and semipositive eigenvector. 
                         Theorem.
                         The following statements are equivalent:
                             $$A_{11}-\lambda B_{11}$$ is an active / Thompson-Weil sub-pencil
                             algebraic formulation
                             The block-pivot
                     The Algorithm #h 
                     Evaluation and Applications #h 
                         Matrix Games #h 
                             Use of regular matrix pencils is latent but not mentioned in algorithmic context
                             Use of sub matrices 
                         The problem of computing the maximal growth order of a rank-$$r$$ linear matrix pencil is equivalent to solving a dual rank-$$r$$ multiple-criteria multiple-constraints (MC$$^2$$) linear program. 
                         The problem of computing the maximal slope of a rank-1 linear matrix pencil is equivalent to solving a dual linear program. 
         #m-mat #VNM
         #VNM 
             A Complete Analysis of 2x2 Strategic VNM Model Solutions #h #novel 
                 $$(P,A)$$
                 $$A-\lambda P$$
                 CASE SINGULAR PENCIL
                     For $$P=E$$ this is the trivial case as referred to on Moulin
                 CASE REGULAR PENCIL
                     CASE DET P = 1
                     CASE DET P = 2
             NOVEL APPLICATIONS
                 CA
                 GT+Grey
                 GT+Stochastic
                 Markov+Bilinear+Security
                     State Transitions #slide 
                         ![Pasted image](https://dynalist.io/u/L7qeIgCxFCJEAsajwBc3QSsf) 
                     Transition Matrices #slide 
                         These are
                             $$D=\begin{pmatrix}  d_{11}&d_{12} \\ d_{21} &d_{22}  \\  \end{pmatrix}$$
                             $$A=\begin{pmatrix}  a_{11}&a_{12} \\ a_{21} &a_{22}  \\  \end{pmatrix}$$
                         Written as linear matrix pencil: $$D-\lambda A$$.
                 Risk+ROI
                     Background
             INBOX
                 Incomplete Algorithm #slide 
                     **algorithm** matrix_game_solve_incomplete$$(A)$$
                         **if** $$({e^T{\rm adj}( A)e}\neq 0)$$ **then**
                             $$v := \frac{\det(A)} {e^T{\rm adj}( A)e}$$;
                             **if** $$\neg (e^T{\rm adj}( A)= 0 \wedge {{\rm adj}( A)e}=0)$$ **then**  
                                 $$x:=\frac{e^T{\rm adj}(A)} {e^T{\rm adj}( A)e}$$
                                 $$y:=\frac{{\rm adj}(A)e} {e^T{\rm adj}( A)e}$$
                                 **if** $$x\ge 0$$ **and** $$y\ge 0$$ **then** **return**($$v$$, $$x$$, $$y$$);
                             **fi**; 
                         **fi**; 
                         **return**(FAIL);
                     **end**;
                 After studying the different definitions the author decided to focus on a geometric meaning that is easy to illustrate 
                 VON NEUMANN MODEL
                     #signpost
                     Yet another Matrix Determinant Lemma #novel:theorem 
                         It holds
                             $$(\det(A))^{r-1}\det(A+a LR^\top)=\det( \det(A)I_r+ aR^\top\text{adj}(A)L)$$ 
                             $$R^\top \;\text{adj}(A+a LR^\top)=R^\top\;\text{adj}(A)$$ 
                             $$\text{adj}(A+a LR^\top)L=\text{adj}(A)L$$ 
                     Even if $$L\;\text{adj}(A)R^\top= 0$$!
                     GAME THEORY
                         #signpost
                         #theorem If $$e\;\text{adj}(A)e^\top\neq  0$$, the following identities hold:
                             $$\det(A+a )=\det(A)+ ae^\top\text{adj}(A)e$$ #novel 
                             $$e^\top \;\text{adj}(A+a )=e^\top\;\text{adj}(A)$$ #novel 
                             $$\text{adj}(A+a )e=\text{adj}(A)e$$ #novel 
     BY TITLE
         A novel von Neumann model reduction algorithm based on linear matrix pencils. #MPS #h #slide #novel:algorithm #novel #novel:slow #VNM #simplex
             Pencil Perturbation Approach #slide 
                 Instead of submatrices, we can consider perturbations of the given matrix pencil
             Reduction Algorithm #h
                 
                 On the equivalence of rank-$$k$$ VN Models and MC2 optimisation. #h 
                     STATUS
                     Background
                         https://dynalist.io/d/gcskC8EanDTKsGE-U8yP7HPC#z=NtPJeQOOEbhDA2xgUzbz8UVK
                     LP Equivalence Theorem #slide 
                         Consider the model VNM($$D,A$$) where $$D=BC^\top \geqq 0$$.
                         We refer to this as a rank-1 VN model.
                         It is known in the literature \cite{Bidard2000-jr}, that such a model is equivalent to a linear program.
                         Theorem: the rank-one model VNM($$uv^\top,A$$) with maximal growth factor $$\lambda>0$$ is equivalent to the linear program LP($$v^\top, A, u$$) with optimal value $$\lambda^{-1}$$. #theorem 
                     Proof #slide 
                         $$\Longrightarrow$$" 
                             Let $$A=UV^\top$$ with $$U, V\in\R^{n\times k}$$ having full rank ($$k\le n$$).
                             We start with $$\lambda$$ maximal such that $$\exists x,y\in \R^{n}: x^\top(A-\lambda UV^\top)\geqq 0$$.
                             Define $$\tilde{X} := \lambda^{-1} {(X^\top U)}^{-1}X^\top$$.
                             Then $$\tilde{X}u=\frac{X^\top U}{\lambda X^\top U}=\lambda^{-1}$$ is minimal, such that $$\tilde{X}^\top(A-\lambda UV^\top)=\tilde{X}^\top A-V^\top \geqq 0$$.
                             This means that the multi-linear multi-criteria program MLC($$U, A, V^\top$$) is solved by $$\tilde{X}^\top$$ with value $$\lambda^{-1}$$.
                         "$$\Longleftarrow$$" 
                             Assume $${X}^\top$$ is a solution of the multi-linear multi-criteria program MLC($$U, A, V^\top$$) with value $$\mu^{}$$.
                             This means $$\mu := X^\top u$$ is minimal such that $$X^\top A-V^\top\geqq 0$$.
                             One has $$V^\top=(X^\top U)^{-1}X^\top UV^\top = \mu^{-1}X^\top UV^\top \geqq 0$$. 
                             Hence $$X^\top(A-\mu^{-1} UV^\top)\geqq 0$$ and $$\lambda:=\mu^{-1}$$ is a maximal growth factor for VNM($$UV^\top,A$$).
             SIMPLEX
         Novel Equilibrium Level Estimates for an Extended Von Neumann Growth Model #h #VNM 
             ESTIMATES FOR $$\rho$$
                 Known Estimates:
     BY TOPIC (SLOW RESEARCH)
         BC 
             BC+Crypto #hh
                 Description of Research Strand #h 
                     Introduction #slide
                         Background:
                             The concept of a Blockchain has experienced a tremendous interest, ever since the inception of Bitcoin as a pioneering Blockchain application
                         Context:
                             Kindly, there is a huge debate whether Blockchains will eventually become mainstream applications
                         Motivation:
                             There are some crucial aspects of mainstream Blockchain systems, that require addressing
                         Summary:
                             use of innovative cryptographic techniques with a focus on secret sharing and steganography
                     Aims and Research Questions #slide 
                         This line of research aims to improve the security and dependability of blockchain architectures by addressing scalability, storage requirements, performance and refinements of the mainstream security goals of confidentiality, integrity and availability. 
                         A central research question is how to use cryptographic techniques other than encryption, to add features and improve the above-mentioned aspects for blockchain architectures that are not met by mainstream implementations. 
                     Challenges #slide 
                         The main challenge in this research domain is creating practical impact based on implementations suitable for real-world deployment. 
                         Another challenge is to find poignant blockchain applications compatible with proposed prototype security architectures, offering functionality for novel use cases. 
                     Outlook #slide 
                         At this point, further diversification of additional cryptographic schemes proposed for the use for the blockchain is expected. 
                         However, it is unclear when these initiatives will substantially and positively impact current mainstream systems. 
                         Still, a clear potential exists, which will continue to motivate researchers in this area to put their efforts into ongoing projects.
                     Notations #slide 
                     Contributions/Novelty #slide 
             BC+SS #hh  
                 Introduction #slide
                     Background:
                     Context:
                     Motivation:
                 Contributions/Novelty #slide 
                 Notations #slide 
                 Bibtex
                     All [22]
                         \cite{noauthor_undated-tq}
                         \cite{Ra2020-gl}
                         \cite{Rajput2021-co}
                         \cite{Cha2021-ya}
                         \cite{Raman2018-dk}
                         \cite{Zheng2021-zi}
                         \cite{Han2021-gj}
                         \cite{Popovska-Mitrovikj2020-yn}
                         \cite{Latha2021-yp}
                         \cite{Chen2022-pn}
                         \cite{Mao2020-gp}
                         \cite{Fan2022-ru}
                         \cite{Guojia2021-nm}
                         \cite{Harris2019-ft}
                         \cite{Kripa2021-xx}
                         \cite{Chen2021-aq}
                         \cite{Kim2019-qc}
                         \cite{Fukumitsu2017-bc}
                         \cite{Lopp2019-fj}
                         \cite{Maram2019-jt}
                         \cite{Chen2019-hd}
                         \cite{Raman2018-nv}
                     By Cluster
                         \cite{noauthor_undated-tq}
                         \cite{Ra2020-gl}
                         \cite{Rajput2021-co}
                         \cite{Cha2021-ya}
                         \cite{Latha2021-yp}
                         \cite{Chen2022-pn}
                         \cite{Mao2020-gp}
                         \cite{Fan2022-ru}
                         \cite{Guojia2021-nm}
                         \cite{Harris2019-ft}
                         \cite{Lopp2019-fj}
                         EARLY & INDEPENDENT WORKS
                             \cite{Maram2019-jt}
                             \cite{Fukumitsu2017-bc}
                         SOLID
                             \cite{Popovska-Mitrovikj2020-yn}
                             \cite{Chen2019-hd}
                             \cite{Kim2019-qc}
                             \cite{Raman2018-dk}
                             \cite{Raman2018-nv}
                         RECENT
                             \cite{Kripa2021-xx}
                             \cite{Zheng2021-zi}
                             \cite{Han2021-gj}
                             \cite{Chen2021-aq}
                         WWW
                         Fan2022-ru
             BC+Stego #hh  
                 Introduction #slide
                     Background:
                     Context:
                     Motivation:
                 Contributions/Novelty #slide 
                 Notations #slide 
             Overlay+BCSecurity
                 Virtual Private Network Overlay Architectures and their Design \& Implementation #strand 
         CA
             CA+FR+Pseudo
                 Formal reduction of systems of linear functional equations #h 
                     Motivation #slide
                         Motivation: Similarities between linear differential, difference and $q$-difference equations and systems, e.g. Bronstein \& Petkovsek (1996)
                         Want to extend progress made in differential case (Barkatou 1997, Pfluegel 1998, 2000)
                         This talk: extend local analysis from regular (Barkatou \& Broughton \& Pfluegel 2010) to irregular singular case
                     Notations #slide 
                         $$\delta$$
                         $$\phi$$
                         $$\text{val}$$
                         $$\text{lc}$$
                         $$c$$
                         $$q$$
                     Pseudo-Linear Algebra #h
                         Introduction #slide 
                             Introduced by Jacobson (1937) as a unifying framework for linear differential and difference equations/systems 
                             Computer Algebra use by e.g. Bronstein \& Petkovsek (1996), Bronstein (2000), Barkatou (2006) and Barkatou, Broughton \& Pfluegel (2008, 2010)
                         Concepts #slide 
                             We need some notations:
                                 $$F$$ a field
                                 $$\phi$$ a $$K$$-automorphism of $$F$$
                                 $$\delta$$ a pseudo-derivation w.r.t. $$\phi$$, i.e.
                                     $$\delta(fg) = \delta f \phi g + f\delta g$$
                             One can show: if $$\phi \neq \text{id}$$, then $$\exists \gamma \in F: \delta = \gamma(\phi - \text{id})$$.
                                 
                     Systems of Pseudo-Linear Equations #h 
                         Introduction #slide 
                             System of Pseudo-Linear Equations:
                                 $$\delta Y(\tau) = A(\tau) \phi Y(\tau)$$
                             with $$A \in F^{n \times n}$$. This unifies common types of linear functional equations.
                             If $$\phi \neq \text{id}$$, the system can be represented in different formats:
                                 $$\phi Y(\tau) = A(\tau) Y(\tau)$$
                             or
                                 $$\delta Y(\tau) = A(\tau) Y(\tau)$$.
                             Conversions between formats can be done efficiently.
                         Local Solutions #h 
                             Aims and Objectives #slide 
                                 Ultimate aim: efficiently compute symbolic solutions of systems of linear functional equations.
                                 Objectives:
                                     To give a unifying theoretical framework for defining irregular parts of formal solutions.
                                     To provide a generic algorithm that can compute irregular parts efficiently.
                                 This is joint work with M. Barkatou and G. Broughton.
                             Formal Solutions of Pseudo-Linear Equations #h 
                                 Irregular Parts #h 
                                     Singular Systems of Pseudo-Linear Equations #slide 
                                         Additional notations:
                                             $$F = K((\tau))$$
                                             $$v: F\longrightarrow \Z\cup\{\infty\}$$ a valuation defined by
                                                 $$v(f) = \left \{\begin{array}{lcl} m & \mbox{if }& f=\tau^{m}(f_{0}+f_{1}\tau + \ldots), f_{0} \neq 0, \\ \infty & \mbox{if }& f = 0. \end{array}\right.$$
                                             $$\omega \in \Z$$ defined by $$\omega(\D) =v(\delta(\tau)) - v(\tau)$$.
                                         Also assume $$v(\phi(f)) = v(f) \;\;\;\forall f \in F$$. 
                                         A singular system of pseudo-linear equations is:
                                             $$\tau^{r-\omega}\delta Y(\tau) = A(\tau) \phi Y(\tau)$$
                                         with $$r \in \N$$ (the \emph{Poincar\'{e}-rank}) and $$A \in K[[\tau]]^{n \times n}$$.
                                     Local Characteristics #slide 
                                         We define the quantities $$c, q \in K^{\ast}$$ from the definition of $$\phi$$ and $$\delta$$:
                                             $$\phi(\tau) = q\tau + O(\tau^{2})$$
                                             $$\tau^{-\omega}\delta(\tau) = c\tau + O(\tau^{2})$$
                                         We then have inductively for $$h \in \N^{+}$$
                                             $$\phi(\tau^{h})  =  q^{h}\tau^{h} + O(\tau^{h+1})$$,
                                             $$\tau^{-\omega}\delta(\tau^{h}) = c [h]_{q}\tau^{h} + O(\tau^{h+1})$$
                                         where
                                             $$[\lambda]_q = \left \{\begin{array}{lcr} \frac{1-q^{\lambda}}{1-q} & \text{if}& q \neq 1, \\ \lambda & \text{if}& q = 1. \end{array}\right.$$
                                     Examples #slide 
                                         Linear Differential Systems:
                                             $$\phi = \text{id}, \; \delta = \frac{d}{d\tau}, \; \omega = -1, \; q=1, \; c=1$$
                                         Linear Difference Systems:
                                             $$\phi(\tau) = \frac{\tau}{\tau+1}, \; \delta = \phi - \text{id}, \; \omega = 1, \; q=1, \; c=-1$$
                                         Linear $$q$$-Difference Systems:
                                             $$\phi(\tau) = q\tau, \; \delta = \phi - \text{id}, \; \omega = 0, \; q \neq 1, \; c=q-1$$
                                     Classification of Singularities #slide
                                         %\begin{definition}
                                         %\label{first_kind} A local system of the form
                                         %(\ref{pseudo_lin_sys}) is said to be of the \emph{first kind}
                                         %if for its Poincar\'{e}-rank $$r$$, we have $$r=0$$.
                                         %\end{definition}
                                         Let $$ T \in \GLn{\F}$$. Change of variable
                                             $$Y=TZ$$
                                         leads to
                                         \emph{equivalent} system $$\tau^{-\omega} \D Z = B \Aut Z$$
                                         where
                                         $$B = T^{-1} (A \Aut T -\tau^{-\omega} \D T) =:T_{\delta,\phi}[A]$$
                                         #definition
                                             System (\ref{pseudo_lin_sys}) is called \emph{regular singular} if $$\exists$$ $$T_{\delta, \phi} $$ such that  $$T_{\delta , \phi}[A]$$ is of \emph{first kind}, i.e. $$r=0$$. Otherwise, it is called \emph{irregular singular}.
                                         Barkatou \& Broughton \& Pfluegel (2010): Regular Singular Case \& Incomplete FMS in Irregular Singular Case\    
                                         New Goal: find complete FMS of irregular system.
                                 Regular Solutions #h 
                             Formal Reduction #h 
                                 Formal Reduction #slide 
                                     Idea: transform into simpler system -- lower $$r$$, decrease $$n$$
                                     Originally established for differential systems
                                     Transformations:
                                         Changes of variable $$Y=TZ$$,
                                         Changes of variable $$Y = e_{r,\mu}Z$$ where $$e_{r,\mu}$$ is a suitable scalar function,
                                         Substituting $$\tau = \tilde{\tau}^{s}$$ with $$s\in \N$$, $$s>1$$.
                                     Problems:
                                         How to compute $$T$$?
                                         How to define $$e_{r,\mu}$$?
                                         How to find ramifications?
                                 Approaches -- Overview #slide 
                                     Approaches in the literature: 2 schools
                                          Traditional
                                             Use of Shearing transformations
                                         Algorithmic
                                             Use of Moser and/or super reduction
                                             Care about introducing algebraic extensions of ground field 
                                     Main differences:
                                 Basic Operations #h 
                                     Gauge-Transformation #slide
                                         Let $$T(x)$$ be invertible square matrix function. The change of variable
                                             $$y = Tz$$
                                         transforms system (\ref{system}) into
                                             $$x^{r+1}\frac{dz}{dx} = \tilde{A}z $$
                                         where
                                             $$ \tilde{A} = T[A] :=  T^{-1}AT - x^{r+1}T^{-1}\frac{dT}{dx}$$.
                                         We call (\ref{system}) and (\ref{tildesystem}) ($$A$$ and $$\tilde{A}$$ respectively) {\em equivalent}. 
                                     Exponential Shift #slide 
                                     Splitting Lemma #slide 
                                         Consider (\ref{system}) and assume that $$A_0$$ is block-diagonal 
                                             $$ A_0 = \left(\begin{array}{cc}  A_0^{11} & 0 \\  0 & A_0^{22} \\\end{array}\right)$$
                                         such that $$\rho(A_0^{11})\cap\rho(A_0^{22})=\emptyset.$$
                                         Then there exists a formal analytical transformation of the form
                                             $$T(x) = \sum_{j = 0}^{\infty}T_j x^{j}\quad (T_0 = I)$$
                                         such that the transformed system is block-diagonal with the same block partition as in $$A_0$$.
                                     Shearing Transformation #slide 
                                         Gauge-Transformation using diagonal matrix 
                                             $$S=\text{diag}(x^{s_1},\ldots,x^{s_n})$$ 
                                         where $$s_i\in\mathbb{Q}$$. The transformed system is 
                                             $$\delta(Y)=B\phi(Y)$$ 
                                         where
                                             $$B=S[A]=S^{-1}A\phi(S)-\delta(S)$$.
                                         This means $$b_{ij}=a_{ij}x^{s_i-s_j}-\text{diag}(\delta(x^{s_i})/\theta(x^{s_i})$$ and
                                             $$\text{val}(b_{ij})=$$
                                             $$\text{lc}(b_{ij})=$$
                                         In order to be useful for formal reduction, the new matrix needs to satisfy
                                             $$\text{val}(B)>\text{val}(A)$$. 
                                     Ramification #slide 
                                         This could introduce __ramifications__. 
                                 Advanced Operations #h 
                                     Moser-Reduction #h 
                                     Super-Reduction #h 
                                     Katz-Invariant #h
                                     Generalised Splitting Lemma #slide 
                                     Rational (Root-free) Splitting Lemma #h 
                                         Splitting Lemma for $$ (\omega, P)$$-Commutative  Systems #slide 
                                             #lemma:commutative_splitting 
                                                 Consider the system (\ref{qsystem}) and assume that $$\hat{A}$$ is $$(\omega, P)$$-commutative with $$\hat{A}_p$$ and $$P$$ block-diagonal with blocks of same dimension
                                                     $$\hat{A}_p = \left(\begin{array}{cc}\hat{A}_p^{11} & 0 \\0 & \hat{A}_p^{22} \\ \end{array}\right),\quad P =\left(\begin{array}{cc}P^{11} & 0 \\0 & P^{22}\\ \end{array}\right)$$
                                                 such that
                                                     $$\wpspec(\hat{A}_p^{11})\cap\wpspec(\hat{A}_p^{22})=\emptyset.$$
                                                 Then there exists a $$(\omega, P)$$-commutative $$q $$-meromorphic transformation of the form
                                                     $$\hat{T}(x) =\sum_{j=0}^{\infty}T_jx^{j/q}\quad (T_0 = I)$$ #equation 
                                                 such that the transformed system is $$(\omega, P)$$-commutative and block-diagonal with the same block partition as in $$\hat{A}_p $$ and $$P $$.
                                         Rational Splitting Lemma #slide 
                                             #proposition
                                                 Consider a system as in ( #qsystem) with leading matrix $$\hat{A}_p$$ and let $$q\geq 2$$. The following statements are equivalent:
                                                     There exists a system as in ( #qsystem) and a generalised Shearing-transformation $$\tilde{S}$$ of ramifications index $$q$$ such that $$\tilde{S}[A]=\hat{A}$$.
                                                     The system ( #qsystem) is $$(\omega, \tilde{P})$$-commutative, the matrix $$\tilde{P}$$ is similar to a diagonal matrix and $$\text{spec}(\tilde{P})\subseteq\{1,\omega,\omega^2,\ldots,\omega^{q-1}\} $$.
                                                 Furthermore, if $$\lambda$$ is an eigenvalue of $$\hat{A}_{p}$$ with multiplicity $$s$$, the numbers $$\omega\lambda,\ldots,\omega^{(q-1)}\lambda$$ are all eigenvalues of the same multiplicity $$s$$.
                             APPLICATIONS 
                                 Differential Case #h 
                                     Linear Differential Systems #slide 
                                         We consider
                                             $$x^{r+1}\frac{dy}{dx} = A(x)y$$
                                         with $$r\in\N$$ called the {\em Poincar\'{e}-rank} of the system, and
                                             $$A = \sum_{j=0}^\infty A_{j} x^j\quad(A_0 \neq 0)$$
                                         where $$A_\nu\in\mathbb{C}^{n\times n}$$. Distinguish between
                                             $$r=0$$: regular singular case
                                             $$r>0$$: irregular or regular singular case
                                 Difference Case #h 
                                 $$q$$-Difference Case #h 
                                 Difference Case #h
                                 $$q$$-Difference Case #h 
                         Global Solutions #h 
             CA+FR+Pseudo+DAE+VNM
                 Previous Work #slide 
                     Little is known
                     Analogy of generalised splitting was given by Pfluegel
                     Out of any algorithmic context
                     Poof of concept
                 Equilibrium Pole Order #slide 
                     We can reduce both either from the left (altering row valuations) or the right (changing valuations of the columns)
                     Idea: find a competing balance (equlibrium)
                     Definition.
                     We say that a generalised Shearing transformation $$(S^*,T^*)$$ is an __equilibrium Shearing transformation__ for the system $$\mathcal{D}= A\theta- B\delta$$ if it holds
                         (i) $$\text{val}(S^*\mathcal{D}T^*)\le\text{val} ({S}\mathcal{D}T^*)$$ for all left-shearing matrices $$S$$, 
                         (ii) $$\text{val}(S^*\mathcal{D}T^*)\ge\text{val}(S^*\mathcal{D}{T})$$ for all right-shearing matrices $$T$$. 
                     Then the rational number $$\rho=\text{val}(S^*\mathcal{D}T^*)$$ is called an __equilibrium pole order__ of the system.
                 Main Theorem #slide 
                 Connection to Game Theory #slide 
                 Connection to Volecic-Weight #slide 
         Edu
             Edu+Cyber+AI
             Edu+CyBOK
                 CyBOK+Map
                 CyBOK+ZOO
             Edu+ZOO
         GT
             DECONSTRUCTING
                 Equilibrium Concepts
                     ![Equilibria.png](https://dynalist.io/u/gqSUuOGOBYjmj1njYbjHUf-R)
                         
                 Block Pivot Steps
             GT Background #slide 
                 Linear Algebra
                 Security Games (Complete Information)
                 Stochastic Games
             GT+Bimatrix
                 Bimatrix Games and Generalised Eigensystems
                     #h #slide 
                     Relationship between Equilibrium Solutions and Eigensystems #h 
                         Sufficient Conditions for Equilibrium Solutions #slide #novel 
                             #theorem:bimatrix-regular-theorem 
                                 Given a square bimatrix game $$G(A,B)$$, assume the matrix pencils $$A-\lambda E$$  and $$B-\lambda E$$ are both regular, each with a real eigenvalue $$\mu_A$$ and $$\mu_B$$ respectively. Let $$x_{\mu_B}$$ be a nonnegative left eigenvector of $$B-\lambda E$$ with respect to $$\mu_B$$ and denote $$y_{\mu_A}$$ a nonnegative right eigenvector of $$A-\lambda E$$ with respect to $$\mu_A$$. Then $$(x^*,y^*) = (x_{\mu_B}$$, $$y_{\mu_A}$$) is a Nash Equilibrium strategy profile of the game $${G}$$ and $$(\mu_A, \mu_B)$$ is the corresponding game value pair. 
                         A Best Response Lemma #slide 
                             The proof of the theorem will be aided by the following lemma. 
                             It exhibits a special case arising where there exists a strategy of one player to which any strategy of the other player is a best response.
                             #lemma:best-response-eigen
                                 Following the notations as in the theorem, we have for a nonnegative left eigenvector $$x_{\mu_B}$$ that for all Player 2 strategies $$y$$ it holds $$x^\top_{\mu_B} B y = \mu_B $$. Similarly, a nonnegative right eigenvector $$y_{\mu_A}$$ satisfies $$x^\top A y_{\mu_A} = \mu_A$$ for all Player 1 strategies $$x$$.
                                 Using set notation, $$ \mathcal{BR}(y_{\mu_A})=X$$ and $$ \mathcal{BR}(x_{\mu_B})=Y$$.
                         Proof [of lemma] #slide 
                             #proof 
                                 Assume that $$x^{\top}_{\mu_A}\ge 0$$ is a left eigenvector, associated with the eigenvalue $${\mu_A}$$ of the regular matrix pencil $$A-\lambda E$$. This implies
                                 #equation:left-nullspace-eq
                                      $$ x^{\top}_{\mu_A}(A-{\mu_A} E)=0. $$
                                 Due to the normalisation property $$\sum x_{{\mu_A},i}=1$$ we have $$ x^{\top}_{\mu_A} E = x^{\top}_{\mu_A} ee^{\top}=e^{\top}$$ so that equation #ref:left-nullspace-eq implies 
                                     $$ x^{\top}_{\mu_A} A = {\mu_A} e^{\top}$$.  #displaymaths 
                                 The second property for a right eigenvector $$y_{\mu_B}$$ can be shown similarly. From this, the lemma follows. 
                         Proof [of Theorem #ref:bimatrix-regular-theorem ] #slide 
                             Let $$y_{\mu_A}$$ be nonnegative right eigenvector of $$A-\lambda E$$ with respect to the eigenvalue $$\mu_A$$. From Lemma #ref:best-response-lemma we deduce that $$y_{\mu_A}$$ is a best response to any Player 1 strategy $$x$$, in particular to  $$x=x_{\mu_B}$$. Likewise,  denote $$x_{\mu_B}$$ a nonnegative left eigenvector of $$B-\lambda E$$. We obtain that  $$x_{\mu_B}$$ is a best response to Player 2 strategy $$y=y_{\mu_A}$$. Hence these strategies are mutual best responses and by definition mixed Nash Equilibrium strategies with payoffs $$\mu_A$$ and $$\mu_B$$ as required. #proof 
                         Explicit Solution Formula #slide 
                             #proposition
                                 If the conditions of Theorem #ref:bimatrix-regular-theorem hold, we can compute the equilibrium solution $$(x^*, y^*)$$ as
                                     $$x^*=\frac{e^T{\rm adj}(B)} {e^T{\rm adj}( B)e}$$, $$y^*=\frac{{\rm adj}(A)e} {e^T{\rm adj}( A)e}$$ #displaymaths 
                                 generalising the result of Thompson et al in the matrix game case.
                     Completely Mixed Solutions #h 
                         Necessary and Sufficient Conditions for Weakly Completely Mixed Solutions #slide #novel
                             In the weakly completely mixed case, the use of eigensystems to characterise solutions turns out to be a natural approach. 
                             #theorem:bimatrix-weakly-mixed 
                                 A bimatrix game is weakly completely mixed if and only if both its associated generalised eigensystems are regular, with real eigenvalues and strictly positive left and right eigenvectors. 
                         Proof (Necessary Condition) #slide
                             #proof Follows from main theorem.  
                         Proof (Sufficient Condition) #h 
                             Step 1: Refinement of Raghavan's results #slide
                                 #lemma:cofactors 
                                     If a bimatrix game is completely mixed and $$v_A=0$$, the cofactors $$A_{i1},\ldots,A_{in}$$ of the matrix $$A$$ are either all zero or have the same sign, for all $$1\le i\le n$$. If $$v_B=0$$, the same property holds for the cofactors $$B_{1j},\ldots,B_{nj}$$ of the matrix $$B$$, for all $$1\le j\le n$$. 
                                 #proof 
                                     Based on [Raghavan, Theorem 1], using a technique similar to that in the proof for [Kaplanski, Theorem 4]
                                     Will prove for $$A$$ and $$v_A$$, statements for $$B$$ and $$v_B$$ can be done in analog fashion.. 
                                         Show that if value is zero, rank is $$n-1$$
                                         Use then adjoint formula
                                 Then show that for arbitrary value, sum of adjoins is not zero. 
                             Step 2: Structure of Characteristic Polynomial #slide 
                                 The characteristic polynomial is $$c_A(\lambda)=\det(A-\lambda E)$$. 
                                 #lemma:charpoly 
                                     We have $$c_A(\lambda)=c_1\lambda -c_0$$ where $$c_0=\det A$$ and $$c_1=\sum_{ij}A_{ij}$$ with $$A_{ij}$$ the cofactor of $$a_{ij}$$.  
                                 #proof 
                                     The degree of $$c_A$$ is bound by rank($$E)=1$$
                                     Formula for $$c_0$$ is clear (put $$\lambda=0$$)
                                     The remaining fact follows by considering the expansion of the determinant $$\det A'=\sum_{ij}a_{ij}A'_{ij}$$ in a sum of terms
                                     For each $$i,j$$, there is a $$\lambda$$ exactly once per term 
                             Step 3: Proof #slide 
                                 Follows directly from Lemma #lemma:cofactors:ref and #lemma:charpoly:ref .
                         Strictly Completely Mixed Case #slide 
                             #theorem:bimatrix-mixed
                                 A bimatrix game is completely mixed if and only if it is weakly completely mixed and the matrix pencils $$A-\lambda E$$ and $$B-\lambda E$$ are simultaneously equivalent to 
                     NON-SQUARE CASE
                     Limitations #slide 
                         Only sufficient algebraic conditions 
                         Difficult to exploit algorithmically
                     INBOX
                         Additional Uniqueness Result #slide 
                             Assume the bimatrix game $$\mathcal{G}(A,B)$$ is regular, with a value $$(v_A, v_B)$$ corresponding to real eigenvalues and nonnegative left and right eigenvectors $$x_\mu$$ and $$y_\mu$$, equilibrium solutions of the game. 
                             Then $$x_\mu$$ and $$y_\mu$$ are unique solutions if and only if $$\det(A'-\lambda E')= {c\neq 0}$$ where $$A'$$ and $$E'$$ are derived from $$A$$ and $$E$$ by replacing rows and columns with zeros at all inactive strategies $$i$$ of $$x$$ and $$j$$ of $$y$$.
                 Necessary and Sufficient Algebraic Conditions #h
                     In this section, it is shown how to extend work of @THOMPSON to a bimatrix game setting, refining results given by . Sufficient algebraic conditions for the existence of an equilibrium strategy of a bimatrix game are derived. It is then established that for games with completely mixed solutions, the sufficient conditions can be strengthened to also become necessary. Finally, #signpost
                     Notations and Terminology #h 
                     Generalised Eigensystems and Equilibrium Strategies #h 
                         The fundamental relationship between generalised eigensystems associated with a bimatrix game --- under the assumption of certain sufficient conditions --- and an equilibrium strategy of the game is established in this section. 
                         This extends results by @THOMPSON to bimatrix games. 
                         #theorem:bimatrix-regular-theorem
                             Given a square bimatrix game $$G=(A,B)$$, assume the matrix pencils $$A-\lambda E$$  and $$B-\lambda E$$ are both regular, each with a real generalised eigenvalue $$\mu_A$$ and $$\mu_B$$ respectively. Let $$x_{\mu_B}$$ be a nonnegative left generalised eigenvector of $$B-\lambda E$$ with respect to $$\mu_B$$ and denote $$y_{\mu_A}$$ a nonnegative right generalised eigenvector of $$A-\lambda E$$ with respect to $$\mu_A$$. Then $$(x^*,y^*) = (x_{\mu_B}$$, $$y_{\mu_A}$$) is a Nash Equilibrium strategy profile of the game $$G$$ and $$(\mu_A, \mu_B)$$ is the corresponding game value pair.
                         The proof of the theorem will be aided by the following lemma. It exhibits a special case arising where there exists a strategy of one player to which any strategy of the other player is a best response.
                         #lemma:best-response
                             Following the notations as in the theorem, we have for a nonnegative left generalised eigenvector $$x_{\mu_B}$$ that for all Player 2 strategies $$y$$ it holds $$x^\top_{\mu_B} B y = \mu_B $$. Similarly, a nonnegative right generalised eigenvector $$y_{\mu_A}$$ satisfies $$x^\top A y_{\mu_A} = \mu_A$$ for all Player 1 strategies $$x$$.
                         #proof 
                             Assume that $$x^{\top}_{\mu_A}\ge 0$$ is a left generalised eigenvector, associated with the generalised eigenvalue $${\mu_A}$$ of the regular matrix pencil $$A-\lambda E$$. This implies
                             #equation:left-nullspace-eq
                                  $$ x^{\top}_{\mu_A}(A-{\mu_A} E)=0. $$
                             Due to the normalisation property $$\sum x_{{\mu_A},i}=1$$ we have $$ x^{\top}_{\mu_A} E = x^{\top}_{\mu_A} ee^{\top}=e^{\top}$$ so that equation #ref:left-nullspace-eq implies 
                                 $$ x^{\top}_{\mu_A} A = {\mu_A} e^{\top}$$.  #displaymaths 
                             The second property for a right generalised eigenvector $$y_{\mu_B}$$ can be shown similarly. From this, the lemma follows. 
                         The proof of Theorem #bimatrix-regular-theorem.ref can now be stated as follows. 
                         #proof
                             Let $$y_{\mu_A}$$ be nonnegative right generalised eigenvector of $$A-\lambda E$$ with respect to the generalised eigenvalue $$\mu_A$$. From Lemma #ref:best-response-lemma we deduce that $$y_{\mu_A}$$ is a best response to any Player 1 strategy $$x$$, in particular to  $$x=x_{\mu_B}$$. Likewise,  denote $$x_{\mu_B}$$ a nonnegative left generalised eigenvector of $$B-\lambda E$$. We obtain that  $$x_{\mu_B}$$ is a best response to Player 2 strategy $$y=y_{\mu_A}$$. Hence these strategies are mutual best responses and by definition mixed Nash Equilibrium strategies with payoffs $$\mu_A$$ and $$\mu_B$$ as required. #proof 
                         This result can also be used in order to construct an explicite solution formula, generalising a result of Thompson et al in the matrix game case. Karlin
                         #proposition
                             If the conditions of Theorem #bimatrix-regular-theorem.ref hold, an equilibrium strategy $$(x^*, y^*)$$ can be computed as $$x^*=\frac{e^T{\rm adj}(B)} {e^T{\rm adj}( B)e}$$, $$y^*=\frac{{\rm adj}(A)e} {e^T{\rm adj}( A)e}$$.  #displaymaths 
                         #proof
                             These equations follow from
                         Milchtaich 
                     The Completely Mixed Case #h 
                         The use of generalised eigensystems to characterise a completely mixed equilibrium strategy turns out to be a natural approach, as suggested by the following
                         #theorem:bimatrix-weakly-mixed
                             A bimatrix game is weakly completely mixed iff its associated generalised eigensystems $$\mathcal{E}_A$$ and $$\mathcal{E}_B$$ are both regular, with corresponding real generalised eigenvalues $$\mu_A$$ and $$\mu_B$$ respectively, and strictly positive right generalised eigenvector $$y_{\mu_A}$$ (left generalised eigenvector $$x_{\mu_B}$$ respectively). 
                         #proof
                             __The conditions are necessary.__  This shall be proven in a number of steps. 
                                 The following theorem is a refinement of Raghavan's results, establish additional properties of the adjoints of the game matrices. 
                                     #theorem:cofactors 
                                         If a bimatrix game is completely mixed and $$v_A=0$$, the cofactors $$A_{i1},\ldots,A_{in}$$ of the matrix $$A$$ are either all zero or all have the same sign, for any $$1\le i\le n$$. If $$v_B=0$$, the same property holds for the cofactors $$B_{1j},\ldots,B_{nj}$$ of the matrix $$B$$, for all $$1\le j\le n$$. 
                                     #proof 
                                         The proof is based on [Raghavan, Theorem 4], using a technique similar to that in the proof for [Kaplanski, Theorem 4].
                                         The result will be proven for $$B$$ and $$v_B$$, the statements for $$A$$ and $$v_A$$ can be done in an analog fashion.
                                             Let $$x$$ be an equilibrium strategy for the second player and assume $$v_{B} = 0$$. Then for $$j\in 1\ldots n$$ one has
                                                 $$\sum_{i=1}^n x_ia_{ij}=0$$.
                                             On the other hand, expanding the determinant using column $$j$$ it holds
                                                 $$0=\det A=\sum_{i=1}^n a_{ij}A_{ij}$$.
                                             Raghavan has shown that a completely mixed bimatrix game with both values zero, the rank of the game matrices is $$n-1$$ and the equilibrium strategy is unique.
                                             Since the equilibrium strategy is unique and $$rank A = n-1$$, these two linear combinations must be unique up to multiplication with a constant. This yields
                                                 $$\frac{x_1}{A_{1j}} = \frac{x_2}{A_{2j}} = \cdots = \frac{x_n}{A_{nj}}$$
                                             So these cofactors have same sign or are all zero.
                                             Then show that sum of adjoints is not zero:
                                                 if it was zero, then $$c_A(\lambda)\equiv 0$$ 
                                                 for a unique completely mixed equilibrium solution $$(x,y)$$ 
                                                 Since $$rk(A)=n-1$$ it follows $$A^*=
                                 For a regular matrix pencil $$A-\lambda E$$, define the __generalised characteristic polynomial__ $$c_A(\lambda):=\det(A-\lambda E)$$. It will be shown to be a polynomial of degree at the most one. 
                                     #lemma:charpoly 
                                         The generalised characteristic polynomial is a linear function $$c_A(\lambda)=c_0-c_1\lambda$$ where $$c_0=\det A$$ and $$c_1=e^t A^*e = \sum_{ij}A_{ij}$$ with $$A_{ij}$$ denoting the cofactor of $$a_{ij}$$.  
                                     This identity has already been used but not proven in @KAPLANSKI. 
                                     A full proof can be found in @KARLIN [A.9], however for convenience to the reader a different and short elementary proof is given here, based on a generalisation to regular matrix pencils of @MILCHTAICH .
                                     #proof 
                                         Consider the square matrix pencil of order $$n+1$$
                                             $$\hat{A}=\begin{pmatrix} A &\lambda e\\- e^t &0\end{pmatrix} $$. 
                                         The determinant of $$\hat{A}$$ can be computed in two different ways. First, use Laplace expansion by the last row to obtain 
                                             $$\det \hat{A} =\sum_{j=1}^n(-1)^{n+j}\det \left( [A]_{j}|\lambda e\right) $$. 
                                         Applying one more Laplace expansion along column $$n$$ in the augmented matrices yields
                                             $$\det \left( [A]_{j}|\lambda e\right)=\sum_{i=1}^n(-1)^{i+n}\det {}_i[A]_{j}\cdot \lambda $$. 
                                         Combining these steps, one has
                                             $$\det \hat{A}= \sum_{i,j=1}^n(-1)^{i+j}\det {}_i[A]_{j}\cdot \lambda =\sum_{i,j} A_{ij}\cdot \lambda      $$. 
                                         On the other hand, rewriting the initial matrix as
                                             $$\hat{A} = \begin{pmatrix} A &0+\lambda e\\-e^t &1-1\end{pmatrix} $$
                                         and applying the linearity of the determinant w.r.t. the last column, it follows
                                             $$\det \hat{A} =\det \begin{pmatrix} A &0\\-e^t &1\end{pmatrix} -\det \begin{pmatrix} A &-\lambda e\\-e^t &1\end{pmatrix} =\det A-\det \begin{pmatrix} A-\lambda E &-\lambda e\\ 0 &1\end{pmatrix} =\det A-\det (A-\lambda E) $$.
                                         The second equality 
                                         Finally combining these results finishes the proof:
                                             $$\det (A-\lambda E) = \det A-\sum_{i,j} A_{ij}\cdot \lambda$$.
                                         PROOF ARCHIVE #wfe-ignore-outline 
                                             DING
                                                 @DING [Lemma 1.1], sometimes referred to as __matrix determinant lemma__ in the literature. 
                                                 The regular matrix pencil
                                                     $$C(\lambda) = \begin{pmatrix}  \det A\cdot I-\lambda A^*E & \lambda A^*e \\ 0 & 1 \end{pmatrix}$$ #displaymaths 
                                                 satisfies for any real square matrix $$A$$ of order $$n$$ [ #todo check]
                                                     $$\det A \det C(\lambda)=(\det A)^n\det (A-\lambda E)$$. #displaymaths 
                                                 Furthermore, using left and right multiplication with invertible matrices $$S$$ and $$T$$ respectively where
                                                     $$S=\begin{pmatrix} I & 0 \\ -e^t & \det A\end{pmatrix} , \quad T=\begin{pmatrix} I & 0 \\ e^t & 1 \end{pmatrix}$$ #displaymaths 
                                                 one obtains
                                                     $$SC(\lambda)T = \begin{pmatrix} \det A\cdot I &\lambda A^*e \\ 0 &\det A-\lambda e^t A^*e\end{pmatrix}$$. #displaymaths #equation:eq-det
                                                 The proof is finished by applying the determinant to the left and right handside of the previous equation #equation:eq-det:ref and comparing.
                                             INDUCTIVE
                                                 It can be easily verified that the lemma is valid for $$n=2$$, hence assume $$n>2$$. 
                                                 The formula for $$c_0$$ is easy to see by evaluating $$c_A(\lambda)$$ at $$\lambda=0$$. 
                                                 Furthermore, since the degree of $$c_A$$ is bound by rank($$E)=1$$, it is sufficient to consider a linear polynomial and one obtains $$c_A(\lambda)=\det A+ c_1\lambda$$.
                                                 Using a column $$j\in \{1,\ldots,n\}$$, and considering the Laplace expansion of the determinant 
                                                     $$\det (A-\lambda E)=\sum_{i = 1}^{n}(-1)^{i+j}(a_{ij}-\lambda)\det({[A]}_{i,j}-\lambda E).$$ #det-label #displaymath
                                                 the lemma can be applied inductively to the above matrix minor pencil of order $$n-1$$
                                                     $$\det([{A}]_{i,j}-\lambda E)=\det[{A}]_{i,j}-\sum_{k,l}^{n}A_{\{i,k\}\{j,l \}} \cdot \lambda$$.
                                                 Using this in #det-label:ref and expanding, one obtains a polynomial in $$\lambda$$ which is known to be linear, and by comparing coefficients one obtains
                                                     $$ c_1 = \sum_{i=1}^n(-1)^{i+j}\det[{A}]_{i,j} +\sum_{i=1}^n(-1)^{i+j}a_{ij}\det[{A}]_{i,j}=\sum_{i=1}^nA_{ij}+s_{j}$$.
                                                 It remains to show that the term $$s_j$$ consists of the remaining sum of cofactors $$A_{il}$$ for $$l\neq j$$.
                                                 This can be seen by exchanging the order of summation in
                                                     $$s_{j}= \sum_{i=1}^n(-1)^{i+j}a_{ij}\det([{A}]_{i,j})$$
                                                     $$=\sum_{i=1}^n\sum_{k=1}^n\sum_{l=1}^n (-1)^{i+j+\sigma_i(k)+\sigma_j(l)}a_{ij}\det([A]_{\{i,k \}\{j,l \}})  $$ ($$k\neq i,\; l\neq j$$)
                                                     $$=\sum_{i=1}^n\sum_{l=1}^n\sum_{k=1}^n (-1)^{i+j+\sigma_i(k)+\sigma_j(l)}a_{ij}\det(A_{\{i,k \}\{j,l \}})  $$ ($$k\neq i,\; l\neq j$$).
                                                 Swapping index notations $$i,k$$ and $$l,j$$ one obtains
                                                     $$s_l=\sum_{k=1}^n\sum_{l=1}^n\sum_{i=1}^{n}(-1)^{k+l+\sigma_k(i)+\sigma_l(j)}{a}_{ij}\det [A]_{\{k,i \}\{l,j \}}  $$ ($$i\neq k,\; j\neq l$$)
                                                     $$=\sum_{k=1}^n\sum_{l=1}^n(-1)^{k+l}\det [A]_{kl}  $$
                                                     $$=\sum_{k=1}^n\sum_{l=1}^n A_{kl}  $$.
                                             ARCHIVE
                                                 $$=\sum_{k=1}^n\sum_{l=1}^n\sum_{i=1}^n (-1)^{i+j+\sigma_i(k)+\sigma_j(l)}a_{ij}A_{\{i,k \}\{j,l \}}  $$ ($$i\neq k,\; l\neq j$$)
                                                 $$=\sum_{k=1}^n\sum_{l=1}^n\sum_{i=1}^n a_{ij}(-1)^{i+j}A_{\{k,i \}\{l,j \}}  $$
                                             TEMP
                                                 Let $$\tilde{A}=A-\lambda E$$ and $$A_{i,j}$$ be the matrix obtained from $$A$$ by deleting row $$i$$ and column $$j$$.
                                                 $$\sum_{i=1}^n(-1)^{i+j}a_{ij}  \det[{A}]_{i,j}-\left( \sum_{i=1}^n(-1)^{i+j}\det[{A}]_{i,j} +\sum_{i=1}^n(-1)^{i+j}a_{ij}\det[{A}]_{i,j}\right)\cdot\lambda+O(\lambda^2) =\det A-\left(\sum_{i=1}^nA_{ij}+s_{j}\right)\cdot \lambda$$.
                                 Finally, the proof follows directly from Lemma #lemma:cofactors:ref and #lemma:charpoly:ref as the regularity of the pencil and the properties of the generalised eigenvectors are established. 
                             __The conditions are sufficient.__ This follows directly from Theorem #theorem:bimatrix-regular-theorem:ref yielding a completely mixed equlibrium strategy pair from the strictly positive generalised eigenvectors.
                     Related Work #h 
                         In summary, the purely game-theoretical results of this paper show that the use of generalised eigensystems is a natural approach when focussing on completely mixed equilibrium solutions of bimatrix games. 
                         Adapting the work of @THOMPSON to bimatrix games, the line of research initiated by @RAMAGHAN is led to a satisfying next level. Furthermore, some closely related results of @MILCHTAICH can be stated more naturally. The results on the relationship between inactive strategies, generalised eigenvalues and strategic dominance, first given by @WEIL for matrix games, appear to be novel in the bimatrix game setting. 
                         LIMITATIONS
                             At first glance, a limitation of this work appears to be the restriction to square bimatrix games. On the other hand, as shown in [], any non-square bimatrix game has inactive strategies and hence does not have completely mixed equilibrium strategies. 
                             It would be interesting to combine existing methods for solving non-square bimatrix games with the approach of this section and to investigate resulting advantages.
                 Three-Action Attack-Defense Game (Completely Mixed Solutions)
                     Motivation #slide 
                         Context #h
                             Resouce Allocation Game #slide 
                                 Game $$\mathcal{G}(t_1, t_2)$$:
                                     $$\begin{array}{ c | c | c }  \mathcal{D} \downarrow \mathcal{A}\rightarrow & s^\mathcal{A}_{t_1} & s^\mathcal{A}_{t_2} \\ \hline s^\mathcal{D}_{t_1} &  - c^{\mathcal{D}}_{t_1}, - c^{\mathcal{A}}_{t_1}&  -c^{\mathcal{D}}_{t_1} -l^ \mathcal{D}_{t_2},  -c^{\mathcal{A}}_{t_2} +b^ \mathcal{A}_{t_2} \\   \hline s^\mathcal{D}_{t_2} &  -c^{\mathcal{D}}_{t_2} -l^ \mathcal{D}_{t_1},  - c^{\mathcal{A}}_{t_1} + b^{\mathcal{A}}_{t_1} &  -c^{\mathcal{D}}_{t_2},  -c^{\mathcal{A}}_{t_2} \end{array}$$
                                 Notations:
                                     $$c^\mathcal{D}_{t_1}, c^ \mathcal{D}_{t_2}$$ -- the defense cost
                                     $$c^\mathcal{A}_{t_1}, c^ \mathcal{A}_{t_2}$$ -- the attack cost
                                     $$l^\mathcal{D}_{t_1}, l^ \mathcal{D}_{t_2}$$  -- the defender's loss from an attack
                                     $$b^\mathcal{A}_{t_1}, b^ \mathcal{A}_{t_2}$$  -- the benefit of the attacker
                             Analysis #slide 
                                 Let $$0\leq {p}\leq{1}$$ and $$0\leq {q}\leq{1}$$ and
                                     $$p$$ and $$(1-p)$$ be the probability for the attack actions
                                     $$q$$ and $$ (1-q)$$ be those for the defense actions
                                 Each game possesses one unique mixed NE solution $$(p^{*},1-p^{*})$$ and $$(q^{*},1-q^{*})$$.
                                     IDS Game: 
                                         $${p}^{*}=\frac{\alpha_f}{\alpha_f+\alpha_c+\alpha_m}$$ 
                                         $${q}^{*}=\frac{\beta_s}{\beta_c+\beta_s}$$ 
                                     RA Game:
                                         $$p^{*} = \frac{l^\mathcal{D}_{t_1} + c^\mathcal{A}_{t_2} - c^\mathcal{A}_{t_1}}{l^\mathcal{D}_{t_1} + l^\mathcal{D}_{t_2}}$$
                                         $$q^{*} = \frac{l^\mathcal{D}_{t_2} + c^\mathcal{D}_{t_1} - c^\mathcal{D}_{t_2}}{l^\mathcal{D}_{t_1} + l^\mathcal{D}_{t_2}}$$
                                 Corresponding equilibrium values
                                     IDS Game: 
                                         $$\mathcal{p}^{*}\alpha_c +(1-\mathcal{p}^{*})(-\alpha_f) = - \mathcal{p}^{*}\alpha_m  =\frac{-\alpha_f\alpha_m}{\alpha_f+\alpha_c+\alpha_m}$$
                                         $$\mathcal{q}^{*}(-\beta_c) +(1-\mathcal{q}^{*})\beta_s =  \mathcal{q}^{*}(0) +(1-\mathcal{q}^{*})(0) = 0$$
                                     RA Game:
                                          $$s^{*}_d = \frac {l^\mathcal{D}_{t_1}   l^\mathcal{D}_{t_2} (c^\mathcal{D}_{t_1}+c^\mathcal{D}_{t_2} +l^\mathcal{D}_{t_1}+l^\mathcal{D}_{t_2}  ) + c^\mathcal{D}_{t_1}{l^\mathcal{D}_{t_1} }^2 +  c^\mathcal{D}_{t_2} {l^\mathcal{D}_{t_2} }^2}{-(l^\mathcal{D}_{t_1}+l^\mathcal{D}_{t_2})^2} $$
                                         $$s^{*}_a = \frac {l^\mathcal{D}_{t_1}  l^\mathcal{D}_{t_2} (c^\mathcal{A}_{t_1}+c^\mathcal{A}_{t_2} -l^\mathcal{D}_{t_1}-l^\mathcal{D}_{t_2}  ) + c^\mathcal{A}_{t_1}{l^\mathcal{D}_{t_2} }^2 +  c^\mathcal{A}_{t_2}{l^\mathcal{D}_{t_1} }^2}{-(l^\mathcal{D}_{t_1}+l^\mathcal{D}_{t_2})^2}  $$
                         Research Question
                             What are the relationships between the two attack/defence actions, so that the overall game has suitable properties?
                         Contributions
                             We define a security game with two actions for the attacker
                             When restricted to one attack, the resulting games are fulfilling the AD 
                         INBOX
                             RESOURCE ALLOCATION (SEARCH) GAME #h
                                 Motivation
                                     a game with a restricted budget
                                     the utility compagny want to decide where to spend it
                                     type of game that is more realistic nowadays
                                 Notations
                                     $$t_1, t_2$$ -- targets (asset $$a_1$$ and $$a_2$$)
                                     $$r$$ -- resource, covering either $$t_1$$ or $$t_2$$ 
                                     Strategies
                                         $$S_\mathcal{D} = \{{defend }\; t_1, {defend }\; t_2\} = \{s^\mathcal{D}_{t_1}, s^\mathcal{D}_{t_2}\}$$
                                          $$S_\mathcal{A} = \{{attack}\; t_1, {attack}\; t_2\} = \{s^\mathcal{A}_{t_1},s^\mathcal{A}_{t_2}\}$$
                                 References #slide 
                                     [1] - Gianini, G., Cremonini, M., Rainini, A., Cota, G. L., & Fossi, L. G. (2015). A game theoretic approach to vulnerability patching. In 2015 International Conference on Information and Communication Technology Research, ICTRC 2015 (pp. 8891). Institute of Electrical and Electronics Engineers Inc. https://doi.org/10.1109/ICTRC.2015.7156428
                     Refined AD Game
                         Game Notations 
                             With superscript: 
                                 $$\begin{array}{ c | c | c | c}  {\mathcal{D}} \downarrow {\mathcal{A}} \rightarrow & aa & a & -{a} \\ \hline dd &  - c_{dd}^{\mathcal{D}}, - c_{aa}^{\mathcal{A}} & -c_{dd}^{\mathcal{D}}, -\tilde{c}_a^{\mathcal{A}}&  -c_{dd}^{\mathcal{D}},  0 \\ \hline d & -\tilde{l}_{aa}^{\mathcal{D}} -c_d^{\mathcal{D}},\tilde{b}_{aa}^{\mathcal{A}}  - \tilde{c}_{aa}^{\mathcal{A}} & -c_d^{\mathcal{D}},  -c_a^{\mathcal{A}} &  -c_d^{\mathcal{D}},  0 \\ \hline -{d} & -l_{aa}^{\mathcal{D}}  , -b_{aa}^{\mathcal{A}}  - c_{aa}^{\mathcal{A}} & -l_a^{\mathcal{D}}, - b_a^{\mathcal{A}}- c_a^{\mathcal{A}} &  0,  0  \end{array}$$
                             Simplified (without):
                                 $$\begin{array}{ c | c | c | c}  {\mathcal{D}} \downarrow {\mathcal{A}} \rightarrow & aa & a & -{a} \\ \hline dd &  - c_{dd}, - c_{aa} & -c_{dd}, -\tilde{c}_a&  -c_{dd},  0 \\ \hline d & -\tilde{l}_{aa} -c_d,\tilde{b}_{aa}  - \tilde{c}_{aa} & -c_d,  -c_a &  -c_d,  0 \\ \hline -{d} & -l_{aa}  , b_{aa}  - c_{aa} & -l_a,  b_a- c_a &  0,  0  \end{array}$$
                             As Matrices:
                                 $$A=\begin{pmatrix}  - c_{dd} & -c_{dd}&  -c_{dd}\\ -\tilde{l}_{aa} -c_d & -c_d &  -c_d \\  -l_{aa}  & -l_a&  0 \end{pmatrix}$$
                                 $$B=\begin{pmatrix} - c_{aa} &-\tilde{c}_a& 0 \\\tilde{b}_{aa}  - \tilde{c}_{aa} &-c_a &   0 \\b_{aa}  - c_{aa} &  b_a- c_a & 0  \end{pmatrix}$$
                             Table
                                 $$\begin{array}{ c | cc | cc | cc }         \mathcal{U} \downarrow\  \mathcal{A}\rightarrow & {s^\mathcal{A}_{att\degree}} & {s^\mathcal{A}_{att}} & {s^{\mathcal{A}}_{- att}} \\\hline  s^{\mathcal{U}}_{mon} & -c^{\mathcal{U}}_{mon} - l^\mathcal{U}_{att\degree}, &l^\mathcal{U}_{att\degree} - c^\mathcal{A}_{att\degree} & -c^{\mathcal{U}}_{mon} -c^\mathcal{U}_{def}, &- c^{\mathcal{A}}_{att} & -c^\mathcal{U}_{mon}, &0\\\hline      s^{\mathcal{U}}_{-mon} & -l^\mathcal{U}_{att\degree}, &l^\mathcal{U}_{att\degree} - c^\mathcal{A}_{att\degree} & -l^{\mathcal{U}}_{att}, &l^{\mathcal{U}}_{att}- c^{\mathcal{A}}_{att} & 0, &0     \end{array}  $$
                             Simplified (loss = benefit):
                                 $$A=\begin{pmatrix}  - c_{dd} & -c_{dd}&  -c_{dd}\\ -\tilde{l}_{aa} -c_d & -c_d &  -c_d \\  -l_{aa}  & -l_a&  0 \end{pmatrix}$$
                                 $$B=\begin{pmatrix} - c_{aa} &-\tilde{c}_a& 0 \\\tilde{l}_{aa}  - \tilde{c}_{aa} &-c_a &   0 \\l_{aa}  - c_{aa} &  l_a- c_a & 0  \end{pmatrix}$$
                             Using scale-factors:
                         Assumptions 
                         Equilibrium Analysis 
                         Discussion
             GT+Cloud
             GT+CVSS
                 Vulnerability Patching Game and Application
                     Methodology #slide
                         1. Design suitable generic strategic complete-information game #h
                             Generic Patching Game #slide 
                                 Focusing on the single software asset that contains a vulnerability, we define a __single-target small security game__ in normal form through the following payoff matrix
                                 $$\begin{array}{ | c | c | c | }  \mathcal{D} \downarrow \mathcal{A}\rightarrow & s_a & s_{-{a}} \\ s_d &  - c^{\mathcal{D}}, - c^{\mathcal{A}}&  -c^{\mathcal{D}},  0 \\  s_{-{d}} &  -l^{\mathcal{D}},  l^{\mathcal{D}}- c^{\mathcal{A}} &  0,  0 \end{array}$$  #normal
                                 where the rows correspond to the pure strategies available to the defender $$\mathcal{D}$$ and the columns are the attacker's pure strategies. Here  we assume that the attacker's benefit equals the loss of the defender. 
                                 This game has been studied in the past (see e.g. \cite{@Samarji2015}) and is suitable for our scenario which is based on a single asset vulnerability assessment. It is not the specialisation of a big security game.
                                 The following assumption seem reasonable in a realistic setup: 
                             Small security games for application scenarios #h 
                                 CVSS GAMES
                                     Basic CVSS Game [Cyber Science 2017 Paper] #h
                                         ******Notations &amp; Definitions ****** 
                                             ******$$\kappa$$ -- defense cost (direct cost)****** 
                                             ******$$\bar{V} = \langle V_C, V_I, V_A \rangle$$ -- asset value vector****** 
                                             ******$$\alpha$$ -- relates to attacker's profile (strength)****** 
                                             ******$$\bar{\mu}_{Imp} = \langle \mu_{Imp, C}, \mu_{Imp, I}, \mu_{Imp, A}\rangle$$ -- CVSS Impact score in vector representation****** 
                                             ******$$\mu_{Exp}$$ -- CVSS Exploitability score****** 
                                         **Further Work**
                                             ******#todo Use more  sophisticated defender cost framework (consider indirect costs -- colateral damage?) ****** 
                                             ******#todo considerable novelty: expand to incomplete information game, using Bayesian framework, enabling the use of environmental CVSS scores****** 
                                             ******#todo include additional CVSS subscores (cf vulnerability factors in [Panaousus GameSec 14]****** 
                                             ******#todo Address issue with the ease of attacker acceptance****** 
                                         **Game Type**
                                             ******A 2-person static complete-information "security game"****** 
                                         ******Discussion****** 
                                             ******This is a very simple model, although similar to most of the other game models published in the  context of vulnerability patching  [#todo list other papers]. ****** 
                                             ******The idea of an attacker profile is a novelty, extending the idea of a organisational cyber security profile as presented in [Panaousis GameSec 14]. ****** 
                                             ******Attacker might not easily accept this model, as his expected utility is zero (note: not many papers talk about this!)****** 
                                         Utility Matrix $$\begin{array}{ | c | c | c | } \hline &amp; s^{a}_A &amp; s^{-a}_A \\ \hline s^{d}_D &amp;  - \kappa, - \alpha \cdot {\mu_{Exp}}^{-1} &amp;  -\kappa,  0 \\ \hline s^{-d}_D &amp;  -\bar{\mu}_{Imp} \cdot \bar{V},  \bar{\mu}_{Imp} \cdot \bar{V} - \alpha \cdot {\mu_{Exp}}^{-1}&amp;  0,  0 \\ \hline \end{array}$$  #normal
                                         ******Summary****** 
                                             ******Aim: improve vulnerability scoring through the use of game theory****** 
                                             **Main contributions:**
                                                 ******Design novel utility functions based on using CVSS metrics****** 
                                                 ******Report on application potential for a cyber tool (CAESAIR)****** 
                                         **Nash Equilibrium Analysis**
                                             ******There exists no pure NE (#todo add justification)****** 
                                             **Optimal Expected Utilities**
                                                 ******$$u_D|_{p=p^{*}}=-\kappa$$  ****** 
                                                 ******$$u_A|_{q=q^{*}} = 0$$****** 
                                             **Optimal Mixed NE Strategies**
                                                 ******$$p^{*} =  1 - \frac{\alpha \cdot {\mu_{Exp}}^{-1}}{\bar{\mu}_{Imp} \cdot \bar{V}}$$****** 
                                                 ******$$q^{*} = \frac{\kappa}{\bar{\mu}_{Imp} \cdot \bar{V}}$$****** 
                                     CVSS Game with Reward #h
                                         Utility Matrix
                                         $$\begin{array}{ | c | c | c | } \hline & s^{a}_A & s^{-a}_A \\ \hline s^{d}_D & - \kappa, - \alpha \cdot {\mu_{E}}^{-1}+r &  -\kappa,  r \\ \hline s^{-d}_D &  -\bar{\mu}_{Imp} \cdot \bar{V},  B - \alpha \cdot {\mu_{E}}^{-1}& 0,  0 \\ \hline \end{array}$$  #normal
                                             
                                         ******Optimal Mixed NE Strategies %****** 
                                         ******Optimal Expected Utilities %****** 
                                 CLOUD GAMES
                                     **Notations**
                                         **$$U$$ -- user (defender) #GT #security**
                                         **$$A$$ -- attacker #GT #security**
                                         **$$C$$ -- cloud provider #GT #security**
                                     IaaS -- CCRAM, Quanyan14 #small #cloud #GT #h
                                     StaaS -- Maghrabi et al, CyberSA 2015 #small #cloud #GT #h
                                         This is a small two-target resource allocation game #GT #security #small #two-target
                                         Utility Matrix
                                             **This gives us eight utility functions, arranged in a utility matrix as follows:** #AD****
                                                 **\begin{center}** #AD****
                                                     **\begin{tabular}{ |c|c|c| }**
                                                         **\caption{Generic One-Shot Single-Target Attacker-Defender Game}**
                                                         **\label{GenericMatrix}**
                                                         **\hline**
                                                         **&amp; $$s^{a}_A$$ &amp; $$s^{-a}_A$$ \\**
                                                         **\hline**
                                                         **$$s^{d}_U$$ &amp; $$u^{{11}}_U$$, $$u^{{11}}_A$$ &amp; $$u^{{12}}_U$$, $$u^{{12}}_A$$ \\**
                                                         **\hline**
                                                         **$$s^{-d}_U$$ &amp; $$u^{{21}}_U$$, $$u^{{21}}_A$$ &amp; $$u^{{22}}_U$$, $$u^{{22}}_A$$ \\**
                                                         **\hline**
                                                     **\end{tabular}**
                                                 **\end{center}**
                                         $$a$$ -- key critical asset
                                         $$a_1$$ -- container asset on user's system #GT #security #small #two-target
                                         Strategy spaces
                                             **$${\mathcal S}_U = \{ \mbox{put asset on cloud ($$t_2$$)}, \mbox{keep asset in-house ($$t_1$$)} \} = \{s^{c}_U, s^{h}_U\}$$**
                                             **$${\mathcal S}_A = \{ \mbox{attack asset on user system} , \mbox{attack asset on cloud} \} = \{s^{u}_A, s^{c}_A\}$$**
                                         $$a_2$$ -- container asset on cloud #GT #security #small #two-target
                                         $$t_2$$ -- target: the cloud #GT #security #small #two-target
                                         $$t_1$$ -- target: the user's host system #GT #security #small #two-target
                                     PaaS -- CCRAM #small #cloud #GT #h
                                     SaaS -- CCRAM, Quanyan15, Moving Target paper #small #cloud #GT #h
                                         **Can I trust the results that my SaaS cloud provider computes for me? #GT**
                                         **Research question: how can a cloud provider apply game theory to inform and enhance the use of software vulnerability metrics to better defend his system against external attacks? #security #scoring #GT**
                             Game Analysis #slide 
                                 The analysis of this presented security game is not difficult, it can be shown that there are no pure Nash equilibrium strategies as [..] and hence a closed-form expression exists \cite{} for determining the values $$p^{*} = \frac{c^{\mathcal{A}}}{l^{\mathcal{D}}} = 1 - \frac{c^{\mathcal{A}}}{l^{\mathcal{D}}}$$ and $$q^{*} = \frac{c^{\mathcal{D}}}{l^{\mathcal{D}}}$$ forming a mixed Nash equilibrium strategy $$(s_D^{*}, s_A^{*})$$ where $$p^*$$ and $$q^*$$ are the probability of defense and attack respectively. 
                                 This will be the underlying method to compute our attack likelihood in this scenario, based on $$q^*$$.
                                 One verifies that the expected utilities in this case are $$ u_D^{*} = -c^{\mathcal{D}} $$ and $$ u_A^{*} = 0 $$.
                                 [TODO: derive these results by applying the algebraic framework from the previous section]
                                 Issues: complete info problematic; attacker needs to know defense cost and loss; defender needs to know attack cost;
                         2. Add CVSS metrics to the utility functions #h
                             Move to CVSS #slide 
                                 We  now use CVSS to specify the payoff functions of the single-target security game of the previous section.  
                                 To achieve this aim, we will use the CVSS impact and exploitability sub-scores. 
                                 Our aim is only use this publicly available scoring data, as we are assuming a complete information game.
                             Approach #slide 
                                 The loss for the defender is due to the attack impact, which will be modelled as a function of the CVSS impact sub-score: $$l^{\mathcal{D}} =f({\mu}_{Imp})$$. 
                                 Furthermore we assume that the defender applies the principle of adequate protection [@pfleeger] by investing an amount for defence that is proportional to the loss: $$c^{\mathcal{D}} \sim f({\mu}_{Imp})$$ where $$f$$ is linear. 
                                 The attack cost depends on the CVSS exploitability subscore, taking into account that high score values indicate a vulnerability that is easy to exploit: $$c^{\mathcal{A}} = g({\mu_{Exp}})$$.
                             CVSS Game #slide 
                                 We start with the following game:
                                 $$\begin{array}{ | c | c | c | } \mathcal{D} \downarrow \mathcal{A}\rightarrow & a& \overline{a} \\ d &?,?& ?, 0 \\ \overline{d} &? ,?& 0, 0 \end{array}$$ #normal
                         3. Find normalised (strategically equivalent) game #h
                             Normalised CVSS Game #slide 
                                 We obtain the following game normal form:
                                 $$\begin{array}{ c | c | c } \mathcal{D} \downarrow \mathcal{A}\rightarrow & a& \overline{a} \\ \hline d & - \mu_{Imp},  {\mu}_{Exp}-10& -\mu_{Imp}, 0 \\ \hline\overline{d} & -{\mu}_{Imp}, {\mu}_{Imp}+10- {\mu}_{Exp} & 0, 0 \end{array}$$
                         4. Solve game and derive metrics #h
                         5. Analyse metrics, compare with existing ones #h
                     Notations and Terminology #slide 
                         Throughout this section we assume that there is a software asset $$s$$ with a vulnerability $$v$$. 
                         We denote by $$S_{\mathcal{D}}=\{d,\overline{d}\}$$ the strategy set of the Defender, where $$d$$ corresponds to the strategy that the Defender patches $$v$$ and $$\overline{d}$$ corresponds to the strategy that the Defender does not patch $$v$$. Likewise, the strategy set of the Attacker is given by $$S_{\mathcal{A}}=\{a,\overline{a}\}$$, where $$a$$ corresponds to the strategy of the Attacker to exploit $$v$$ and $$\overline{a}$$ that the Attacker does not attempt to exploit $$v$$) respectively, e.g. by running some malware. To patch the vulnerability, we assume that there is an associate cost, $$c^{\mathcal{D}}$$ for the Defender. To exploit vulnerability $$v$$, we assume that there is a cost $$c^{\mathcal{A}}$$ for the Attacker and a benefit $$b^{\mathcal{A}}$$. We assume that this benefit matches a loss $$l^{\mathcal{D}} = b^{\mathcal{A}}$$ for the Attacker. % #gamesec
                     CVSS Game
                         Example: Case Study 2 #slide 
                             The analysis of the previous game can be used for the vulnerability patching scenario.
                             The goal is to find realistic values for the game payoff parameters $$l^D$$ and $$c^A$$.
                             This could be done for example using the __Common Vulnerability Scoring System__ (CVSS).
                             Information about the severity of the vulnerability is publicly available online.
                         Case Study 2 (continued) #slide 
                             The attacker's cost $$c^A$$ is proportional to the inverse of the CVSS __exploitability subscore__:
                                 $$c^A = \alpha \cdot {\mu_{E}}^{-1} $$.
                                 Here, $$\alpha$$ is a constant that needs to be suitably defined.
                             The loss of the defender $$l^D$$ is due to a threat event impact, exploiting the vulnerability and affecting the asset's CIA security requirements.
                             Using the CVSS impact subscore, a vector $$V$$ with numerical components is defined, depending on the security criticality of the asset. 
                                 This yields $$l^D =   \mu_{Imp, C} \cdot V_C + \mu_{Imp, I} \cdot V_I + \mu_{Imp, A} \cdot V_A$$.
                             Finally, by plugging this into the game solutions, a recommendation can be made for the decision to patch the vulnerability.
                     Vulnerability patch Narrative #wfe-ignore-outline 
                         We denote by $$S_{\mathcal{D}}=\{d,\overline{d}\}$$ the strategy set of the Defender, where $$d$$ corresponds to the strategy that the Defender patches $$v$$ and $$\overline{d}$$ corresponds to the strategy that the Defender does not patch $$v$$. Likewise, the strategy set of the Attacker is given by $$S_{\mathcal{A}}=\{a,\overline{a}\}$$, where $$a$$ corresponds to the strategy of the Attacker to exploit $$v$$ and $$\overline{a}$$ that the Attacker does not attempt to exploit $$v$$) respectively, e.g. by running some malware. 
                         To patch the vulnerability, we assume that there is an associate cost, $$c^{\mathcal{D}}$$ for the Defender. To exploit vulnerability $$v$$, we assume that there is a cost $$c^{\mathcal{A}}$$ for the Attacker and a benefit $$b^{\mathcal{A}}$$. We assume that this benefit matches a loss $$l^{\mathcal{D}} = b^{\mathcal{A}}$$ for the Attacker. % #gamesec
                         This game has been studied in the past (see e.g. \cite{@Samarji2015}) and is suitable for our scenario which is based on a single asset vulnerability assessment. It is not the specialisation of a big security game. 
                         Focusing on the single software asset that contains a vulnerability, we define a \emph{single-target small security game}  in normal form through the following payoff matrix $$\begin{array}{ | c | c | c | } \hline {\mathcal{D}} \downarrow {\mathcal{A}} \rightarrow & a & \overline{a} \\ \hline d &  - c^{\mathcal{D}}, - c^{\mathcal{A}} &  -c^{\mathcal{D}},  0 \\ \hline \overline{d} &  -l^{\mathcal{D}},  l^{\mathcal{D}}- c^{\mathcal{A}} &  0,  0 \\ \hline \end{array}$$where the rows correspond to the pure strategies available to the defender $${\mathcal{D}}$$ and the columns are the attacker's $${\mathcal{A}}$$ pure strategies. Here  we assume that the attacker's benefit equals the loss of the defender.
             GT+Grey
                 Ethical Hacking Games
                     GT IS GOOD TO CAPTURE DILEMMAS
                         Ethical Hacking Games #slide 
                             Can we model the interactions between a defending organisation and a black, gray or white hat hacker?
                             Can we design a generic all-compassing game?
                         Issues #slide 
                             Difficulties:
                                 Nature of Game: proactive versus reactive
                                 Plausibility of model
                                 Existence of dilemmas - should reflect real world
                                     Dilemma: a potential deviation from NE equilibrium solutions by human players in real world
                                 Interpretation of mixed NE
                         Overview #slide 
                             Strategic goals:
                                 
                     GREY HAT HACKERS ARE PROBLEMATIC
                         Motivation #slide 
                             Slide Title: Black Hat Hackers
                                 Black hat hackers are criminals who act with malicious intent.
                                 Their motivation is often financial gain or revenge.
                                     They may also release malware that destroys files, holds computers hostage, or steals personal information.
                                     Black hats spread havoc wherever they go, often causing serious damage to individuals and organizations alike.
                                 Sometimes they target people they strongly disagree with for ideological reasons.
                             Slide Title: Gray Hat Hackers
                                 Gray hat hackers engage in a mix of both black and white hat activities.
                                 They may look for system vulnerabilities without permission or knowledge from the owner, and may report any issues found to the owner for a small fee.
                                 Gray hats may sometimes violate laws or ethical standards but usually lack the malicious intent of black hat hackers.
                                 They may believe they are doing good for companies by hacking into their systems, but owners rarely appreciate unauthorized access to their business information infrastructure.
                                 Often, the real intention of gray hats is to showcase their skills and gain publicity and recognition for contributing to cybersecurity.
                             Slide Title: Definition of a White Hat Hacker
                                 A white hat hacker is a computer security expert who specializes in finding vulnerabilities in systems and networks.
                                 Unlike black hat hackers, white hat hackers use their skills for ethical and lawful purposes, such as testing and improving the security of computer systems and networks.
                                 White hat hackers may be hired by organizations to conduct penetration testing or vulnerability assessments to identify potential weaknesses in their systems.
                                 They may also participate in bug bounty programs, where companies offer rewards to hackers who identify and report vulnerabilities in their systems.
                                 White hat hackers may also develop and promote security best practices, and may work with law enforcement or other organizations to help combat cybercrime.
                             __Black hat hacker definition__
                                 __Black hat hackers are criminals who break into computer networks with malicious intent. They may also release malware that destroys files, holds computers hostage, or steals passwords, credit card numbers, and other personal information.__
                                 __Black hats are motivated by self-serving reasons, such as financial gain, revenge, or simply to spread havoc. Sometimes their motivation might be ideological, by targeting people they strongly disagree with.__
                             __White hat hacker definition__
                                 __White hat hackers  sometimes also called ethical hackers or good hackers  are the antithesis of black hats. They exploit computer systems or networks to identify their security flaws so they can make recommendations for improvement__
                             __Gray hat hacker definition__
                                 __Somewhere between white and black are gray hat hackers. Gray hat hackers enact a blend of both black hat and white hat activities. Gray hat hackers often look for vulnerabilities in a system without the owner's permission or knowledge. If issues are found, they report them to the owner, sometimes requesting a small fee to fix the problem.__
                                 __A grey hat is a computer hacker or computer security expert who may sometimes violate laws or typical ethical standards, but usually does not have the malicious intent typical of a black hat hacker.__
                                 __Some gray hat hackers like to believe they are doing something good for companies by hacking their websites and invading their networks without permission. Still, company owners rarely appreciate unauthorized forays into their business information infrastructure.__
                                 __Often, a gray hat's real intention is to show off their skills and gain publicity  maybe even appreciation  for what they consider a contribution to cybersecurity.__
                             https://www.kaspersky.com/resource-center/definitions/hacker-hat-types
                     #RC1
                         LOOKING AT THE SHADES OF GREY: ONE-STAGE STRATEGIC GAMES
                             Motivation #slide 
                                 Previous work
                                 Why not inspection game?
                                 Presence of dilemmas
                             Strategic Characterisation #h 
                                 Game $$G_1$$: Black-Hat Hacker #slide 
                                     $$\begin{array}{ c | c | c }  \mathcal{D} \downarrow \mathcal{B}\rightarrow & \text{not cooperate (attack)} & \text{cooperate (not attack)}  \\\hline  \text{not trust (defend)} &  \;\cdot\;,\rightarrow  &  \downarrow\; ,\;\cdot\;\\\hline   \text{trust (not defend)}  &  \uparrow\; ,\;\cdot\;  &  \;\;\cdot\;,\leftarrow \end{array}$$ #eyo-style:Normal 
                                     There is no pure NE but one mixed NE.
                                     No dilemma is present.
                                     This is a standard security game.
                                 Game $$G_2$$: Grey-Hat Hacker #slide 
                                     $$\begin{array}{ c | c | c }  \mathcal{D} \downarrow \mathcal{G}\rightarrow & \text{not cooperate (betray)} & \text{cooperate (not betray)}  \\\hline  \text{not trust (not employ)} & { \;\cdot\;, \;\cdot\;\;}& \; \downarrow\; ,\;\leftarrow\;\\\hline   \text{trust (employ)}  &  \uparrow\; ,\;\rightarrow\;  &  \;\cdot\;, \; \cdot \;\end{array}$$ #eyo-style:Normal 
                                     There are two pure NEs: (not trust, betray) and (trust, not betray).
                                     There is also one mixed NE.
                                     There are several dilemmas present.
                                 Game $$G_3$$: White-Hat Hacker #slide 
                                     $$\begin{array}{ c | c | c }  \mathcal{D} \downarrow \mathcal{W}\rightarrow & \text{not cooperate (betray)} & \text{cooperate (not betray)} \\\hline  \text{not trust (not employ)} &  \;\cdot\;, \;\rightarrow\;\;& \; \downarrow\; ,\;\cdot\;\\\hline   \text{trust (employ)}  &  \uparrow\; ,\;\rightarrow \;  &  \;\cdot\;, \; \cdot\;\end{array}$$ #eyo-style:Normal 
                                     There is one pure NE (trust, high effort). 
                                     There is no dilemma present.
                                 Discussion #slide 
                                     GT seems very fitting
                                     Justification 
                                         Number of dilemmas fits well
                                         Literature: inspection game
                             Games Details #h 
                                 Game $$G_1$$: Black-Hat Hacker #slide 
                                     $$\begin{array}{ c | c | c }  \mathcal{D} \downarrow \mathcal{B}\rightarrow & \text{not cooperate (attack)} & \text{cooperate (not attack)}  \\\hline  \text{not trust (defend)} &  - c_d, - c_a&  -c_d,  0 \\\hline   \text{trust (not defend)}  &  -c_l,  r_a- c_a &  0,  0 \end{array}$$ #eyo-style:Normal 
                                     Utilities
                                         $$c_{d}$$ -- the defense cost
                                         $$c_{a}$$ -- the attacker's cost
                                         $$c_{l}$$ -- the defender's loss from an attack
                                         $$b_{r}$$ -- the reward (benefit) of the attacker from an attack.
                                     Assumptions (\cite{Pfleeger2007-qm})
                                         __Principle of Adequate Protection__: $$c_{d} <c_{l}$$
                                         __Principle of Easiest Attack__: $$c_{a} < c_{l}$$
                                 Game $$G_2$$: Grey-Hat Hacker #h 
                                     Strategic normal form #slide 
                                         $$\begin{array}{ c | c | c }  \mathcal{D} \downarrow \mathcal{G}\rightarrow & \text{not cooperate (betray)} & \text{cooperate (not betray)}  \\\hline  \text{not trust (not employ)} &  \;-c_l\;, \;b_a\;\;& \; 0\; ,\;0\;\\\hline   \text{trust (employ)}  &  -c_f-c_l\; ,\;b_f+b_a-c_r\;  &  \;b_p-c_f\; ,\;b_f \;\end{array}$$ #eyo-style:Normal 
                                         Roles
                                     Utilities #slide 
                                         $$c_l$$ -- organisation's loss cost due to exploited vulnerability
                                         $$b_a$$ -- black-hat hacker benefit arising from exploiting the vulnerability
                                         $$c_f$$ -- organisation's cost of paying a fee for white-hat hacking role
                                         $$b_f$$ -- grey-hat hacker's remuneration from obtaining fee from organisation
                                         $$c_r$$ -- remorse (psychological) cost to the grey-hat hacker
                                         $$b_p$$ -- benefit of increased security for the organisation, due to patched vulnerability
                                     Assumptions #slide 
                                         All parameters are nonnegative, $$b_a$$, $$b_p$$, $$c_r$$ and $$c_f$$ are positive
                                         $$b_p>c_f$$: white-hat hacker is trusted to achieve better security
                                         $$c_r>b_a$$: trusted grey-hat hacker strives to cooperate based on psychological motivation 
                                             rewards the trust in them: remorse cost is greater than betrayal benefit #wfe-ignore-item 
                                         NE Solutions #slide 
                                             The game has three NE strategies: the pure strategy profiles $$s_1^*=((1,0),\begin{pmatrix} 1 \\ 0\\ \end{pmatrix})$$ and $$s_2^*=((0,1),\begin{pmatrix} 0 \\ 1\\ \end{pmatrix})$$ and the mixed strategy profile $$s_3^*=(x^*,y^*)$$ where $$x^*=(1-b_a/c_r,b_a/c_r)$$ and $$y^*=\begin{pmatrix} 1-c_f/b_p \\ c_f/b_p\\ \end{pmatrix}$$.
                                             The corresponding game value pairs are $$v_{1}=(-c_l,b_a)$$, $$v_{2}=(b_p-c_f,b_f)$$ and $$v_{3}=(c_l(c_f-b_p)/b_p,b_ab_f/c_r)$$.
                                     Equilibrium Analysis (I) #slide 
                                         $$v_B \prec_{\mathcal{D}} v_G \prec_{\mathcal{D}} v_W$$
                                         if $$b_a \neq b_f$$:
                                             $$v_G \prec_{\mathcal{H}} v_W$$
                                             $$\Rightarrow v_G \prec v_W$$
                                             if $$b_a < b_f$$:
                                                 $$v_B \prec_{\mathcal{H}} v_W$$
                                                 $$\Rightarrow v_B \prec v_W$$
                                             if $$b_a > b_f$$:
                                                 $$v_W \prec_{\mathcal{H}} v_B$$
                                         if $$b_a=b_f$$:
                                             $$v_G \prec_{\mathcal{H}} v_W$$
                                             $$v_G \prec_{\mathcal{H}} v_B$$
                                             $$\Rightarrow v_G \prec v_W$$
                                     Equilibrium Analysis (II) #slide 
                                         Proposition
                                         Given the generic utility functions and their assumptions (A1)-(A3), the following statements hold:
                                             $$v_G \prec v_W$$, so $$v_W$$ is Pareto-optimal.
                                             If $$b_a < b_f$$ then $$v_B \prec v_W$$.
                                 Game $$G_3$$: White-Hat Hacker #slide 
                                     $$\begin{array}{ c | c | c }  \mathcal{D} \downarrow \mathcal{B}\rightarrow & \text{not cooperate (betray)} & \text{cooperate (not betray)} \\\hline  \text{not trust (not employ)} &  \;\cdot\;, \;\rightarrow\;\;& \; \downarrow\; ,\;\cdot\;\\\hline   \text{trust (employ)}  &  \uparrow\; ,\;\rightarrow \;  &  \;\cdot\;, \; \cdot\;\end{array}$$ #eyo-style:Normal 
                                     Utilities
                                          
                                          
                                          
                                         
                                     Assumptions 
                             Unifying Approach #h 
                                 Burden Game #h 
                                     Unconditionally un-cooperative case #h  
                                         Notations #slide
                                             $$B$$: Burden to carry (joint burden)
                                             $$p$$: reward (pride) for sole carrying of honorable duty
                                             $$d$$: Sole punishment from defecting (system damage due to neglecting honorable duty)
                                             $$r$$: relief from sole defecting of criminal duty
                                             $$g$$: reward (gain from attack) for sole carrying of criminal duty
                                         Game #slide
                                             $$\begin{array}{ c | c | c }  S \downarrow W\rightarrow & \text{carry (attack)} & \text{defect (not attack)}  \\\hline  \text{carry (defend)} &  -B\;,\;-B\rightarrow  &  \downarrow\;-B+p ,\;-B+r\;\\\hline   \text{defect(not defend)}  &  \uparrow\; -d,\;g\;  &  0\;,\;0\leftarrow \end{array}$$ #eyo-style:Normal 
                                         New Game #slide
                                             $$\begin{array}{ c | c | c }  S \downarrow W\rightarrow & \text{carry (attack)} & \text{defect (not attack)}  \\\hline  \text{carry (defend)} &  -B\;,\;-B\rightarrow  &  \downarrow\;-B+p ,\;-B+r\;\\\hline   \text{defect(not defend)}  &  \uparrow\; -d,\;g\;  &  0\;,\;0\leftarrow \end{array}$$ #eyo-style:Normal 
                             Payoff Design #slide 
                             INVESTIGATION
                                 D: matrix([-c[l],0],[-c[f]-c[l],b[p]-c[f]]);
                                 G: matrix([b[r],0],[b[r]+b[f]-c[r],b[f]]);
                     #RC2
                         Background #slide 
                             Bimatrix Games
                             Stochastic Games
                         Bimatrix Games with Rational Payoff Functions #h 
                             Game and NE Equilibrium Strategy Definitions #slide 
                                 Denote $${\mathcal{G}}(A,B,C)$$ bimatrix game with rational payoff functions
                                 The corresponding payoffs to Player 1 and Player 2 are $$\frac{^\top{\!}xAy}{^\mathsf{T}{\!}xCy}$$ and $$\frac{^\top{\!}xBy}{^\top{\!}xCy}$$ respectively. 
                                 An __equilibrium strategy__ $$(x^*,y^*)$$ satisfies $$x^*Cy^*\neq 0$$ and
                                     $$ \frac{x^*Ay^*}{x^*Cy^*} \ge  \frac{xAy^*}{xCy^*} \quad\forall x: xCy^*\neq 0$$
                                     $$ \frac{x^*By^*}{x^*Cy^*} \ge  \frac{x^*By}{x^*Cy} \quad\forall y: x^*Cy\neq 0$$
                                 We say that $$s^*=(x^*,y^*)$$ is an __NE strategy profile__ and that $$v=(v_A,v_B)$$ is the corresponding __NE equilibrium value pair__. 
                                 Need to assume $$C>0$$ #wfe-ignore-item 
                             Generalised Eigensystem Theorem #slide 
                                 The following theorem gives a sufficient condition for the existence of an NE of the form (\ref{eq:NE-bimatrix). 
                                 Given the game $$\mathcal{G}(A,B,C)$$, assume the matrix pencils $$A-\lambda C$$  and $$B-\lambda C$$ are both regular, each with a real eigenvalue $$\mu_A$$ and $$\mu_B$$ respectively. Let $$x_{\mu_B}$$ be a nonnegative left eigenvector of $$B-\lambda C$$ with respect to $$\mu_B$$ and denote $$y_{\mu_A}$$ a nonnegative right eigenvector of $$B-\lambda C$$ with respect to $$\mu_A$$. Then $$(x^*,y^*) = (x_{\mu_B}$$, $$y_{\mu_A}$$) is an NE strategy profile of the game $$\mathcal{G}$$ and $$(\mu_A, \mu_B)$$ is the corresponding game value pair.
                             Proof #slide 
                                 We have for a nonnegative left eigenvector $$x_{\mu_B}$$ satisfying $$x^\top_{\mu_B} B = \mu_B x^\top_{\mu_B} C$$ that for any Player 2 strategy $$y$$ it holds $$\frac{x^\top_{\mu_B} B y}{x^\top_{\mu_B} C y} = \mu_B $$. 
                                 This trivially implies $$\frac{x^\top_{\mu_B} B y_{\mu_A}}{x^\top_{\mu_B} C y_{\mu_A}} \ge \frac{x^\top_{\mu_B} B y}{x^\top_{\mu_B} C y} $$. 
                                 Similarly, we can show for a nonnegative right eigenvector $$y_{\mu_A}$$ that $$\frac{x^\top_{\mu_B} Ay_{\mu_A}}{x^\top_{\mu_B} C y_{\mu_A}} \ge \frac{x Ay_{\mu_A}}{x C y_{\mu_A}} $$ for any Player 1 strategy $$x$$.
                                 Hence these strategies are mutual best responses and by definition NE strategies with payoffs $$\mu_A$$ and $$\mu_B$$ as required.  
                                 From this, the theorem follows. 
                             Remarks #slide 
                                 If $$C=E$$, this yields a linear algebra characterisation for NE solutions for standard bimatrix games.
                                 If eigenvectors are positive, we obtain completely mixed solutions
                                 Compare with Milchtaich \cite{Milchtaich2006-ro,Milchtaich2008-ny}, w/o LA
                                 If $$C=E$$ and $$B=-A$$, c.f. Weil 
                                 If $$B=-A$$, one obtains the work by Thomson et al.~\cite{} on the von Neumann model for game theory.
                                 A mixed solution is a generalised eigensystem. 
                             Lag-free Equilibrium Solutions #slide 
                                 Define a particular type of NE solutions: lag-free solutions
                                 Definition: a NE solution satisfying
                                     $$\frac{x^\top_{\mu_B} B y_{\mu_A}}{x^\top_{\mu_B} C y_{\mu_A}} \ge \frac{x^\top_{\mu_B} B y}{x^\top_{\mu_B} C y} $$. 
                                     $$\frac{x^\top_{\mu_B} Ay_{\mu_A}}{x^\top_{\mu_B} C y_{\mu_A}} \ge \frac{x Ay_{\mu_A}}{x C y_{\mu_A}}$$
                                 is called a __lag-free__ solution.
                             Necessary and Sufficient Conditon #slide 
                             A Specific Pencil #slide 
                                 Consider a regular matrix pencil of the form $$A-\lambda B$$ where $$A$$ is invertible and $$\text{rank}(B)=1$$. 
                                 We call this a __rank-1 pencil__. 
                                 We can write $$B=uv^\top$$ where $$u,v\in {\R}^n$$ nonnegative. 
                                 We define normalised left and right eigenvectors w.r.t. the factorisation of $$B$$ as eigenvectors satisfying $$x^\top u = 1$$ and $$y v^\top = 1$$. 
                             Eigenspace Structure rank-1 regular pencil Result #slide 
                                 If $$v^\top \text{adj}(A) u=0$$, the pencil has no finite eigenvalues. 
                                 Otherwise, the pencil has a single finite eigenvalue $$c=\frac{\det(A)}{v^\top \text{adj}(A) u}$$.
                                 The associated left and right normalised eigenvectors $$x,y$$ can be determined as follows:
                                     $$x^\top=\frac{v^\top\text{adj}(A)}{v^\top \text{adj}(A) u}$$,
                                     $$y=\frac{\text{adj}(A)u}{v^\top \text{adj}(A) u}$$.
                             Proof #slide #proof
                                 It can directly be verified that, based on the definitions of $$c$$, $$x$$ and $$y$$ as in the theorem, that it holds $$Ay=cuv^\top y$$ and $$x^\top A=cx^\top uv^\top$$. 
                                 So $$c$$ is an eigenvalue, and this must be the only one as the degree of the characteristic polynomial $$\det(A-\lambda B)$$ is one. 
                                 Furthermore, it can be seen that $$x^\top$$ and $$y$$ are normalised eigenvectors.
                             Rank-1 Bimatrix Games #h 
                                 \subsection{Rank-1 Bimatrix Games}
                                 This section considers the case where $$C\ge 0$$, $${\rm rank}(C)=1$$, and the implications on the existence of NE solutions of the game $${\mathcal{G}}(A,B,C)$$.
                                 
                                 We refer to a matrix pencil of the form $$A-\lambda B$$ and $${\rm rank}(C)=1$$ as a rank-1 pencil. We can then use rank-factorisation to write $$C={p}{q}$$ where $${p},{q}\in \mathbb{R}^n$$ are nonnegative row and column vectors.
                                 We define normalised left and right eigenvectors w.r.t. the representation $$C=pq$$ as eigenvectors satisfying $$x {p} = 1$$ and $$y {q} = 1$$.
                                 
                                 The following proposition provides an eigenspace structure result for rank-1 regular matrix pencils, which will be required when analysing the Shades of Grey game in Section \ref{sec:shades-of-grey}.
                                 \begin{proposition}
                                     The rank-1 pencil $$A-\lambda pq$$ has no finite eigenvalues if $${q}\,{\rm adj}(A) {p}=0$$. Otherwise, the pencil has the single finite eigenvalue $$c=\frac{\det(A)}{{q} \,\,{\rm adj}(A) {p}}$$.
                                     The associated left and right normalised eigenvectors $$x,y$$ can be determined explicitly using the formulae $$x=\frac{{q}\,{\rm adj}(A)}{{q} \,{\rm adj}(A) {p}}$$ and $$y=\frac{\,{\rm adj}(A){p}}{{q} \,{\rm adj}(A) {p}}$$.
                                 \end{proposition}
                                 \begin{proof}
                                     Based on the definitions of $$c$$, $$x$$ and $$y$$ as in the proposition, it can be directly verified that $$Ay=c{p}{q} y$$ and $$x A=cx {p}{q}$$.
                                     So $$c$$ is a finite eigenvalue of $$A-\lambda pq$$ with left and right eigenvectors $$x$$ and $$y$$. This must be the only eigenvalue as the degree of the characteristic polynomial $$\det(A-\lambda pq)$$ is bound by $${\rm rank}(pq)$$, which is one. Furthermore, it is straightforward to see that $$x$$ and $$y$$ are normalised eigenvectors.
                                 \end{proof}
                         Bimatrix Stochastic Stopping Games #h 
                             Introduction #slide 
                                 In this game model, we have $$N=1$$ using the notations of \cite{Shapley1953-hi}. 
                                 Using modern terminology, we would say we have a 2-state Markov-game with a transient state $$s_0$$ ``play" and an absorbing state $$s_1$$ ``stop''. 
                                 State transition probabilities depend on the current state and chosen strategies. 
                             Research Questions #slide 
                                 Natural questions to ask are then:
                                     What is the expected number of steps for the game to finish?
                                     How can we define a value and optimal solutions to this repeated zero-sum game?
                                     How it might these relate to the value and optimal solutions of the stage game?
                                 Let us fix a strategy profile $$(x^\top,y)$$.
                             Value of Stochastic Matrix Game #slide 
                                 The following well-known lemma summarises answers:
                                 \begin{lemma}[\cite{Shapley1953-hi}]
                                     The expected number of steps required for the game $$\mathcal{G}(A,S)$$ to stop when using the stationary strategy $$(x^\top,y)$$ is $$1/x^\top Sy$$. The expected resulting payoff  is $$u=\frac{x^\top Ay}{x^\top Sy}.$$ The value $$v$$ of the game is well-defined by
                                     $$ v=\max_x\min_y \frac{x^\top Ay}{x^\top Sy} = \min_y\max_x \frac{x^\top Ay}{x^\top Sy}. $$
                                     In general, $$v$$ is hence different from the value of the stage game.
                                 \end{lemma}
                             Bimatrix Version #slide 
                                 A partial extension is:
                                 \begin{lemma}
                                     Assume the stationary strategy $$(x^\top,y)$$ satisfies $$x^\top Sy<1$$.
                                     Then the expected number of steps required for the game $$\mathcal{G}(A,B,S)$$ to stop when the players are using $$(x^\top,y)$$ is $$1/x^\top Sy$$. The expected resulting payoff is $$u=(\frac{x^\top Ay}{x^\top Sy},\frac{x^\top By}{x^\top Sy}).$$ 
                                 \end{lemma}
                             Proof #slide 
                                 After $$k$$ iterations the accumulated payoff of the game when playing the same strategy $$(x^\top,y)$$ in each round is $$u_{A,k}(x,y)=x^\top Ay\sum_{i=0}^{k-1}(1-x^\top Sy)^i$$ and $$u_{B,k}(x,y)=x^\top By\sum_{i=0}^{k-1}(1-x^\top Sy)^i$$. 
                                 Since $$s:=1-x^\top Sy<1$$, the game finishes with probability one and $$ \sum_{i=0}^\infty s^i = \frac{1}{1-s}$$.
                                 The expected game payoff pair is $$u = (u_{A},u_{B}) = \lim_{k\to \infty}(u_{A,k},u_{B,k})=(\frac{x^\top Ay}{x^\top Sy},\frac{x^\top By}{x^\top Sy})$$.
                             More #slide 
                                 We would like to maximise $$u$$
                                 This leads to $$ u=(\max_x\max_y \frac{x^\top Ay}{x^\top Sy},\max_y\max_x \frac{x^\top By}{x^\top Sy}).$$
                                 This value might not be specific to $$u$$, and not unique
                                 Further theoretical characterisations are not in the scope of this outline
                     #RC3
                         REPEATED GAMES ARE MORE REALISTIC
                             Grey-Hat Stochastic Stopping Game #h 
                                 Repeated Grey-Hat Game #h 
                                     Generic Game Design #slide 
                                         Game $$\mathcal{G}(D,G,S)$$:
                                             $$D=\begin{pmatrix}  -c_l&0 \\ -c_f-c_l & b_p-c_f \\  \end{pmatrix}$$
                                             $$G=\begin{pmatrix}  b_r&0 \\ b_f+b_r-c_r &b_f  \\  \end{pmatrix}$$
                                             $$S=\begin{pmatrix}  s_0&s_1\\ s_2 &s_3  \\  \end{pmatrix}$$ $$(0<s_i\le 1)$$
                                     Specific Game Instances #slide 
                                         Rank-1 Games:
                                             Tints of Black: a grey-hat hacker, determined to turn into black-hat hacker: $$S=\begin{pmatrix}  1&s_B\\ 1&s_B\\  \end{pmatrix}$$
                                             Tints of White: a grey-hat hacker, striving to become white-hat hacker: $$S=\begin{pmatrix}  s_W&1\\ s_W&1\\  \end{pmatrix}$$
                                             Self-Absorbed Syndicate: an egoistic organisation, on a mission to detect unethical hacking: $$S=\begin{pmatrix}  1&1\\ s_E&s_E \\  \end{pmatrix}$$
                                             Selfless Syndicate: an altruistic organisation, believing in ethical hacking: $$S=\begin{pmatrix}  s_A&s_A\\1&1 \\  \end{pmatrix}$$
                                         Rank-2 Game:
                                             Black or White Thinking: both $$S=\begin{pmatrix}  1&0\\ 0&1  \\  \end{pmatrix}$$
                                     Stationary Equilibrium Solutions #slide 
                                         Consider the stochastic non-zero sum game $$\mathcal{G}(D,G,S)$$. If $$\text{rank}(S)=1$$, the game has two pure and one mixed stationary NE.
                                 Discussion #slide 
                                     Rank-condition
                                 INBOX #later
                                     Otherwise, $$\text{rank}(S)=2$$, and:
                                         If $$-c_l/s_0>-(c_l+c_f)/s_2 \Longleftrightarrow s_0/c_l>s_2/(c_l+c_f)$$ then $$((1,0),\begin{pmatrix} 1 \\ 0 \\  \end{pmatrix})$$ is a pure NE with $$\lambda^*=-c_l/s_0$$.
                                         If $$b_p>c_f$$ then $$((0,1),\begin{pmatrix} 0\\ 1\\  \end{pmatrix})$$ is a pure NE with $$\lambda^*=0$$.
                                         GRANULARITY I
                                             RESULT
                                                 If $$D-\lambda S$$  and $$A-\lambda S$$ are both regular, each with a real eigenvalue $$\mu_D$$ and $$\mu_A$$ respectively. Let $$x_{\mu_A}$$ be a nonnegative left eigenvector of $$B-\lambda S$$ with respect to $$\mu_A$$ and denote $$y_{\mu_D}$$ a nonnegative right eigenvector of $$A-\lambda S$$ with respect to $$\mu_D$$. Then $$(x^*,y^*) = (x_{\mu_A}$$, $$y_{\mu_D}$$) is a stationary equilibrium strategy profile of the game $$\mathcal{G}$$ and $$(\mu_D, \mu_A)$$ is the corresponding game value pair.
                                             GRANULARITY II
                                     PROOFS
                                         Proof -- Case $$\text{rank}(S)=1$$ #slide 
                                             Let $$S=lr^\top$$ where $$l,r \in \R^n$$ are nonnegative vectors
                                             The stage game $$G_2$$ has two pure and one mixed stationary NE.
                                             Let $$(^\top x^\ast,y^\ast)$$ be such an NE solution.
                                             Then $$^\top x^\ast S y^\ast>0$$ and with $$\alpha=^\top x^\ast l$$, $$\beta=r^\top y^\ast$$
                                                 $$ \frac{x^*Dy^*}{x^*Sy^*} \ge  \frac{xDy^*}{xSy^*} \quad\forall x: xCy^*\neq 0$$
                                                 $$ \frac{x^*By^*}{x^*Cy^*} \ge  \frac{x^*By}{x^*Cy} \quad\forall y: x^*Cy\neq 0$$
                                                 $$ x^*Ay^* \ge  xAy^* \quad\forall x$$
                                                 $$ x^*By^*\ge x^*By \quad\forall y$$
                                         Proof -- Case $$\text{rank}(S)=2$$ #slide 
                                     Shades of Grey: $$S=\begin{pmatrix}  1&s_B\\ s_W&1  \\  \end{pmatrix}$$
                                     Best Response #slide 
                                         $$\mathcal{BR}(y)$$ -- the set of __best responses__ to a strategy $$y$$ (the set of all strategies $$x$$ of Player 1 maximizing his expected payoff $$x^\top Ay/x^\top Cy$$).
                                         Similarly a best response to $$x$$ is a strategy $$y\in \mathcal{BR}(x)$$ of Player 2 that maximizing her expected payoff $$x^\top By/x^\top Cy$$. 
                                         #definition
                                             A Player 2 strategy $$y^*$$ is a __Nash equilibrium best response__ to a Player 1 strategy $$x$$ (denoted $$y^* \in \mathcal{BR}(x)$$ in the sequel) is a strategy $$y^*$$ satisfying $$ xBy^* \ge    xBy$$ for all other Player 2 strategy $$y$$.
                                         An equilibrium strategy is hence a strategy pair $$(x^*,y^*)$$ of mutual best responses: $$ x^* \in \mathcal{BR}(y^*) $$ and $$ y^* \in \mathcal{BR}(x^*) $$.
                                     A Best Response Lemma #slide #CYENS 
                                         #lemma:best-response 
                                             If Player 1's mixed strategy $$x^*$$ is a best response to the (mixed) strategy $$y$$ of the other player, then, for each pure strategy $$e_i$$ such that $$x_i > 0$$, it must be the case that $$e_i$$ is itself a best response.  In particular, the payoff $$e_i Ay$$ must be the same for all such strategies.
                                         Note: an analogous lemma can be stated for Player 2, $$y^*$$ and $$x$$.
                                     Proof (I) #slide #CYENS 
                                         Recap: due to $$x^* \in \mathcal{BR}(y^*)$$ we have $${}^t \!x^*Ay^*=v_{A}$$ and $${}^t \!xAy^*\le v_{A}$$ for all $$x$$. 
                                         Let us write $${}^t \!x^*= (x^*_{1},\ldots ,x^*_{i},\ldots ,x^*_{n})$$ and assume $$x^*_{i}\neq 0$$.
                                         Furthermore, denote $${}^t \!e_{i}= (\underbrace{0,\ldots ,0}_{i-1}, 1, 0,\ldots , 0)$$.
                                         It is clear that $${}^t \!e_{i}Ay^*\le v_{A}$$ (why?).
                                     Proof (II) #slide #CYENS 
                                         Now assume $${}^t \!e_{i}Ay^*< v_{A}$$, minimal for all pure strategies. 
                                         Find $$j\neq i$$, $$x_{j}^*\neq 0$$ (such $$j$$ exists since $$x^*$$ is not pure) and define ("falling from the sky"):
                                             $${}^t \!\hat{x}={}^t \!x^*-x_i^* {\;}^t\! e_i+x_i^* {\;}^t\! e_j$$.
                                         It follows
                                             $$^t\!\hat{x}Ay^*={}^t\!x^*Ay^*+x_{i}^*\overbrace{(^t\!e_{j}Ay^*-{}^t\!e_{i}Ay^*)}^{>0}>\,{}^t\! x^*Ay^*$$
                                         which is a contradiction. Hence we must have $${}^t \!e_{i}Ay^*= v_{A}$$. 
                                         An additional consequence is $${}^t \!x^*Ay^*= v_{A}{}^t\!e$$. 
                                     The Rank-2 Case
                                         The generalised eigensystems are
                                             $$\mathcal{E}_D=\left\{\left[ -c_l, \left\{ \begin{pmatrix}  1&0  \\ \end{pmatrix},\begin{pmatrix}  c_l+b_p-c_f\\c_l+c_f  \\ \end{pmatrix}  \right\}\right],\left[b_p-c_f,\left\{ \begin{pmatrix}  c_l+c_f & c_f-c_l-b_p \\ \end{pmatrix} \begin{pmatrix}  0\\1  \\ \end{pmatrix}  \right\}\right]\right\}$$
                                         and
                                             $$\mathcal{E}_G=\left\{\left[b_a,\left\{ \begin{pmatrix}  b_a-b_f & b_a+b_f-c_r \\ \end{pmatrix}, \begin{pmatrix}  1\\0  \\ \end{pmatrix}  \right\}\right],\left[ b_f, \left\{ \begin{pmatrix}  0&1  \\ \end{pmatrix},\begin{pmatrix}  c_r-b_f-b_a\\b_a-b_f  \\ \end{pmatrix}  \right\}\right]\right\}$$.
                                         Potentially large number of combinations
                                         discuss cases
                                         positive eigenvectors
                                         $$\mathcal{E}_D$$: selecting $$y_D$$
                                             both eigenvectors of $$\mathcal{E}_D$$ are nonnegative
                                             Note however: interchangeable
                                             This means:
                                                 We only need to consider one element of the set $$\mathcal{E}_D$$: 
                                                 this will be preferred by the defending organisation.
                                                 this is $$y_D^{(2)}$$ since $$b_p-c_f>0>-c_l$$.
                                                 need to pair this up with either (or both) $$x_G^{(1)},x_G^{(2)}$$
                                                 equilibrium solutions are obtained after normalising
                                         Selecting $$x$$:
                                             Case $$b_a < b_f$$:
                                                 choose $$x_G^{(2)}$$ as better game value (and anyway since $$b_a-b_f<0$$ and $$b_a+b_f-c_r>0$$)
                                             Case $$b_a > b_f$$:
                                                 
                                             Case $$b_a = b_f$$:
                                                 both $$x$$ yield the same strategy $$(0,1)$$
                                                 there is no second EV? dimension is one as $$G$$ is not diagonalisable
                                         Theorem #slide 
                                             The rank-2 Black or White game has precisely one Pareto-optimal Nash equilibrium $$(x^*,y^*)$$ with associated game value profile $$(v^*_D,v^*_G)$$. Depending on the comparative relationship between $$b_a$$ and $$b_f$$, it holds:
                                                 If $$b_a \le b_f$$, then the equilibrium is pure with $${}^tx^*=(0,1),y^*=\begin{pmatrix}  0\\1  \\ \end{pmatrix}$$ and $$v^*_D=b_p-c_f,v^*_G=b_f$$.
                                                 If $$b_a > b_f$$, then there is an equilibrium with one mixed and one pure strategy: $${}^tx^*=\begin{pmatrix}  \frac{b_a-b_f}{2b_a-c_r},&\frac{b_a+b_f-c_r}{2b_a-c_r}  \\ \end{pmatrix},y^*=\begin{pmatrix}  0\\1  \\ \end{pmatrix}$$ and $$v^*_D=b_p-c_f,v^*_G=b_a$$.
                                         Proof #h 
                                             The pencils $$D-\lambda S=D-\lambda I$$ and $$G-\lambda S=G-\lambda I$$ are trivially regular. 
                                             One finds for $$G-\lambda I$$
                                             $$\mathcal{E}_G=\left\{\left[ \mu_G^{(1)}, x_G^{(1)}, y_G^{(1)}\right],\left[\mu_G^{(2)}, x_G^{(2)}, y_G^{(2)}\right]\right\}$$
                                             where
                                             $$\mu_G^{(1)}=b_a,\;x_G^{(1)}=\begin{pmatrix}  b_a-b_f, & b_a+b_f-c_r \\ \end{pmatrix},\;y_G^{(1)}=\begin{pmatrix}  1 \\ 0  \\ \end{pmatrix}$$
                                             and
                                             $$\mu_G^{(2)}=b_f,\;x_G^{(2)}=\begin{pmatrix}  0,&1  \\ \end{pmatrix},\;x_D^{(2)}= \begin{pmatrix}  c_r-b_f-b_a\\b_a-b_f  \\ \end{pmatrix}.$$
                                             We now distinguish three cases:
                                                 Based on assumptions (A1)-(A3), both eigenvectors can be normalised to be nonnegative, and we can again use the interchangeable property to choose a suitable one 
                                                 If $$b_a<b_f$$, then 
                                         INBOX
                                             The pencils $$D-\lambda S=D-\lambda I$$ and $$G-\lambda S=G-\lambda I$$ are trivially regular. 
                                             In fact, the generalised eigensystems of the pencil in question coincide with ordinary eigensystems.
                                             $$\mathcal{E}_D=\left\{\left[ \mu_D^{(1)}, x_D^{(1)}, y_D^{(1)}\right],\left[\mu_D^{(2)}, x_D^{(2)}, y_D^{(2)}\right]\right\}$$
                                             where
                                             $$\mu_D^{(1)}=-c_l,\;x_D^{(1)}=\begin{pmatrix}  1,&0  \\ \end{pmatrix},\;y_D^{(1)}=\begin{pmatrix}  c_l+b_p-c_f\\c_l+c_f  \\ \end{pmatrix}$$
                                             and
                                             $$\mu_D^{(2)}=b_p-c_f,\;x_D^{(2)}=\begin{pmatrix}  c_l+c_f, & c_f-c_l-b_p \\ \end{pmatrix},\;x_D^{(2)}= \begin{pmatrix}  0\\1  \\ \end{pmatrix} .$$
                                             One finds for $$G-\lambda I$$
                                             $$\mathcal{E}_G=\left\{\left[ \mu_G^{(1)}, x_G^{(1)}, y_G^{(1)}\right],\left[\mu_G^{(2)}, x_G^{(2)}, y_G^{(2)}\right]\right\}$$
                                             where
                                             $$\mu_G^{(1)}=b_a,\;x_G^{(1)}=\begin{pmatrix}  b_a-b_f, & b_a+b_f-c_r \\ \end{pmatrix},\;y_G^{(1)}=\begin{pmatrix}  1 \\ 0  \\ \end{pmatrix}$$
                                             and
                                             $$\mu_G^{(2)}=b_f,\;x_G^{(2)}=\begin{pmatrix}  0,&1  \\ \end{pmatrix},\;x_D^{(2)}= \begin{pmatrix}  c_r-b_f-b_a\\b_a-b_f  \\ \end{pmatrix}.$$
                 INBOX
                     Game $$G_3$$: Untrusted White-Hat Hacker #slide 
                         $$\begin{array}{ c | c | c }  S \downarrow W\rightarrow & \text{not cooperate (low effort)} & \text{cooperate (high effort)}  \\\hline  \text{not trust} &  \;\cdot\;, \;\cdot\;\;& \; \downarrow\; ,\;\leftarrow\;\\\hline   \text{trust}  &  \uparrow\; ,\;\cdot \;  &  \;\cdot\;, \; \leftarrow\;\end{array}$$ #eyo-style:Normal 
                         There is one pure NE (not trust, low effort). 
                         One dilemma is present.
             GT+Matrix
                 @KAPLANSKI #wfe-ignore-item 
                     One of the early works which was a source of inspiration for this present paper is @KAPLANSKI. In his article, the value $$v$$ of a zero-sum game is determined from its coefficient matrix, although the algorithm is not efficient. The uniqueness property of completely mixed solutions is established and their presence detected based on necessary and sufficient conditions involving order, rank and adjoint properties of the game matrix $$A$$, after reducing $$v$$ to zero using a substitution.
                     Theorem #theorem:bimatrix-mixed:ref of this paper, when specialised to matrix games, generalises Kaplanski's result as the  necessary and sufficient conditions stated in the theorem are valid for any value $$v$$. 
                 @WEIL #wfe-ignore-item 
                 @THOMPSON #wfe-ignore-item 
                     In a series of papers ( @THOMPSON-a, @THOMPSON-b) work on the relationship between matrix games and generalised eigensystems, later extended to a more general problem (the Von Neumann economic model) in @THOMPSON-c, was undertaken. 
                     These results failed to achieve great  attention in the wider game theory research community apart from the niche specialist area due to their "lack of parsimony" (as quoted from @THOMPSON-a) and inability of leading to significant algorithmic improvements. 
                     One of the game theoretical insights gained in this paper is the fact that for restricted types of equilibrium solutions --- that of completely mixed ones --- the view of equilibrium solutions as solutions of associated generalised eigensystems is in fact very natural and useful, as will be demonstrated in the application section of this paper.
                 @RAGHAVAN #wfe-ignore-item 
                     More recently, @RAGHAVAN revisits @KAPLANSKI and initiates an extension to bimatrix games. 
                     In his work, Raghavan shows that important properties of completely mixed solutions known for matrix games also are valid for bimatrix games. His main result is that completely mixed equilibrium strategies are unique and require the game matrices to be square. 
                     However Theorem xxx is not stated for bimatrix games. A necessary condition is given, on the other hand, the result is not constructive, as supportive of Theorem 4 in \cite{} requires the knowledge of the game's value pair.
                     His work does not use the notion of generalised eigensystems. 
                 @MILCHTAICH #wfe-ignore-item 
                     In two consecutive papers ( @MILCHTAICH2006, @MILCHTAICH200x ), the authors present work which is closely related to the results of this section, although they do not use the language of generalised eigensystems. In the first paper, a formula is developed for determining an equilibrium value of a bimatrix game if the support of the corresponding solution is known in advance. This is extended in the second paper where necessary and sufficient conditions for the existence of completely mixed solutions are given, and an explicit solution formula is constructed for this case. 
                     Using the linear algebra concepts of this paper, their results can be viewed as stating necessary and sufficient conditions for the existence of non-negative (strictly positive in the completely mixed case) left and right generalised eigenvectors of the game matrices, with respect to real generalised eigenvalues, as well as the explicit construction of these. Their solution formula, necessary and sufficient conditions for completely mixed solutions are algebraically equivalent to the ones developed in this paper. 
                 @HEUER
             GT+HiTL
                 HaaS Game
                     HAAS INTRO #wfe-ignore-item 
                         Background  #slide 
                             Recent technological advances have made communication more affordable and computation faster.
                             The change in norms regarding the use of technology have enabled a range of new applications and systems that collect data from humans.
                             The concept of Human-as-a-Sensor (HaaS) formalises a methodology where instead of automated sensors, humans are the primary source of information. 
                         HaaS Examples #slide 
                             Non-cyber applications
                                 commuters to report suspicious luggage 
                                 residents participating in neighbourhood watch schemes
                                 emergency response (report quakes, search and rescue)
                                 participants on the road reporting traffic congestion
                                 proposals for teachers to spot tendency to criminal behaviour of pupils 
                             Cyber applications
                                 social media users reporting security threats
                                 employees to report spam or phishing emails
                                 more??
                     RESEARCH QUESTION & CONTRIBUTION #wfe-ignore-item 
                         Relevant Research #slide 
                             Research Strand: Incomplete information game theoretic approaches for modelling wireless sensor network and client-server architecture scenarios. 
                             Research Question: How can we model a human sensor using non-cooperative game theory, and what are pertinent insights can one gain when analysing the game?
                         Research Contributions #slide
                             The formulation of a generic Sensor Reference Game, of which all previously published Sensor games are special cases.  
                                 using the language of security and dependability. #wfe-ignore-item 
                                 Helps other researchers with defining games for new application areas
                                 It also aids in understanding the additional features required to model human sensors, and the novelty of our game 
                                 Furthermore it promotes the acceptance of game theory as a tool for analysing security Scenario is. 
                             The first GT model of HaaS, taking into account a rich type profile of typical human sensor nodes
                                 Based on expanding previous work on Sensor Games
                                 Solving the game 
                                 Devise repeated game
                     === #wfe-ignore-item 
                     SYSTEM SETUP #wfe-ignore-item 
                         Secure and Dependable Systems #slide 
                             Idea of system analysis: use security and dependability framework (A. Avizienis et al, Basic concepts and taxonomy of dependable and secure computing, IEEE Transactions on Dependable and Secure Computing, vol. 1, no. 1, pp. 1133, Jan. 2004).
                             Security = CIA
                                 (Confidentiality)
                                 Integrity 
                                 Availability
                             Dependability = AMRIS
                                 Availability
                                 (Maintainability)
                                 Reliability
                                 Integrity
                                 (Safety)
                         System Model #slide 
                             Sensor System
                                 Sensor $$S$$: collects data and sends to receiver $$R$$, via a Communication Channel $$C$$
                             A sensor system can have faults and security vulnerabilities
                                 $$f$$ -- fault (deviation of system from correct state)
                                 $$v$$ -- vulnerability = internal fault that enables an external fault to harm the system (exploitable by an attacker)
                             Another issue is that the entire system could be compromised and turned into a hostile system/threat.
                             We require $$S$$ to be free of faults, of system alterations or interruption by an attacker, and $$C$$ to be secure 
                         System Model -- Illustration #slide 
                             ![](https://dynalist.io/u/RLJxRXEazablAgnCy5ttM5Ci)( sensor_1.png) #eyo-style:Normal
                     GT QUICKIE #wfe-ignore-outline 
                         GT Terminology #slide 
                             Non-cooperative game theory for security
                             Complete versus incomplete information games
                             Bayesian games -- turned into imperfect information games
                             Static versus dynamic games
                             Signalling games
                             Zero-sum versus nonzero-sum
                             Solving games
                         Notations #slide 
                             In this paper, $$x$$ and $$y$$ denote a pure or mixed strategy of the first and second player in a two-player game, and $$x^*$$ and $$y^*$$ are used for optimal strategies of these players. A __strategy profile__ $$s=(x, y)$$ groups strategies of each player together. If the grouped strategies are optimal, the optimal strategy profile is written as $$s^*$$. A two-player non-zero sum game can be represented in normal form, based on the players' payoff matrices $$A$$ and $$B$$, and it is common in the literature and also in this paper to use a table to present the same information.
                             An __optimal Nash Equilibrium strategy profile __ is a strategy profile $$s^*=(x^*,y^*)$$ satisfying  
                                 $$ x^*Ay^* \ge  xAy^* \;\;\forall x,\quad x^*By^* \ge    x^*By\;\;\forall y$$. #wfe-style:Equation
                             Here, the strategies may be pure or mixed, and the corresponding NE is referred to as pure or mixed NE. Furthermore, if all of the inequalities in the above definition are strict, one has a __strict__ NE. Otherwise, the NE is __non-strict__.
                         INBOX  #wfe-ignore-outline 
                             , for a broad range of  scenarios such as intrusion detection in network security \cite{Alpcan2010}, managing the security of information in an organisation \cite{Panaousis2014CybersecurityApproach} and predicting the likelihood of cyber attacks \cite{Bao2017HowGames}.
                             Concept #h3
                                 The principal idea of non-cooperative game theory is to consider rational players, choosing between actions that entail payoffs consisting of gains (benefits) and losses (costs), in order to form __optimal strategies__ seeking to maximise their payoffs
                                 A game is solved using the fundamental concept of the Nash Equilibrium, as described in Section \ref{sec:scheduling_game}.
                                 An optimal Nash Equilibrium (NE) strategy has a local maximum property: any single player deviating from a NE strategy will suffer a reduced payoff
                                 It is important to note that only unilateral strategy changes are considered in this concept
                                 Hence applying game theory for real-life scenarios is only a valid and useful tool if all participants agree to adopt it as a rule for strategic decision-making, in the modelled scenario
                                 #wfe-ignore-item 
                                 __Zero-sum__ games are used for simple scenarios where it can be assumed that the gains or losses of one player are balanced out by those for the remaining ones
                                 . For more complex scenarios, __nonzero-sum__ games may be requir
                                 ed. A nonzero-sum game may not have any clear winner or looser, and its NE strategies may not necessarily be unique, implying that different optimal strategies with different payoffs e
                                 xist. An NE strategy whose payoff is largest amongst all other optimal solutions, is referred to as __globally optimal solution__.
                             Mixed strategies extend pure strategies by introducing probability distributionsAn arbitrary game need not always have to have optimal solutions following the above definition, and this can be resolved using the more general idea of mixed strategies
                             Nash's theorem then states that any $$n$$-player non-cooperative game not possessing a pure NE admits a mixed NE
                             Mixed strategies are very relevant in the context of security games, as most of these games do not have pure NEs
                             On the other hand, the practical interpretation of mixed NES remains controversial  \cite{} \Eckhard{Fariborz, could ypu please add this reference: Aumann, R (1985) What Is Game Theory Trying to Accomplish In: Arrow, K and Honkapohja, S., Eds., Frontiers of Economics, Basil Blackwell, Oxford, 5-46.} and for this reason, for the game introduced in this paper, the focus is on pure NEs.
                     === #wfe-ignore-item 
                     SIMPLE GAME #wfe-ignore-item 
                         Part I -- Designing The Game  #eyo-style:Section #wfe-ignore-item 
                             HaaS Scenario #slide 
                                 Employees in an organisation are used as human sensors 
                                 They report on cyber security incidents they encounter 
                                 Organisation needs to decide whether they can trust an incoming report $$r$$ (or its absence)
                                 Reports have the following properties:
                                     Could report incidents only, or also their absence
                                     For the most general scenario: they could be externally attacked (modified, delayed or fabricated)
                                     Could be synchronous or asynchronous
                             Reports -- Examples #slide
                                 Alice reports:
                                     "I have received a spam email at 8:10h, which was not detected by the spam filter"
                                     "While browsing the web for free tools that could be used for our project, I have discovered a freeware website that contains links to some malware"
                                     "Within the last seven days of the reporting period, there were three replies to the company's Twitter feed that appear to mislead potential customers"
                             Human Sensor System #slide 
                                 Human sensor has internal fault $$f$$ and/or external fault (vulnerability) $$v$$
                                     Faults = human lack of willingness to contribute to the security of the organisation 
                                     Vulnerabilities = Weaknesses in personality traits leading to exploitation by social engineering attacks
                                 Here $$f$$ has fault mode: Byzantine rather than fault-stop #wfe-ignore-item 
                                 Blurring traditional boundaries: fault can be deliberate
                             Human-made Faults #slide 
                                 ![](https://dynalist.io/u/YvZWuj6z_yyqithSACMX1tw_)( human-made-faults.png) #eyo-style:Normal 
                             Assumptions #slide 
                                 Public information, known to all players:
                                     Specific game theoretic model, comprising of game type and payoff  functions, including solution algorithm 
                                 Private information:
                                     The human sensor knows his own type (based on previous experience, appraisal or self observation/reflection).
                                     The report receiver does not know the human sensor's type.
                                 The reports are sent through a secure channel.
                                 The users are competent in their non-security related job tasks
                             HaaS Sensor Types #slide 
                                 Human sensor is not necessarily competent in security. 
                                 The human sensor could be cooperative or uncooperative.
                                 Using formal terminology: human sensor might have faults and/or vulnerabilities
                                     have a vulnerability (unknowingly -- socially engineered)
                                     a fault (deliberately)
                                 Human sensor could also turn malicious. 
                                 We obtain 3 different types. 
                             Type 1: Cooperative Human Sensor #slide
                                  Is willing to help with security but potentially lacking in precision/reliability 
                                     Could be socially engineered (externally attacked)
                                     Could have insufficient cyber skills to recognise security anomalies
                             Type 2 and 3: Uncooperative Human Sensor #slide 
                                 Type 2: Could be deliberately unreliable and apply minimal effort in contribution to overall security 
                                     lazy -- give it low priority
                                     distracted -- too focused on non-security job aspects
                                 Type 3: Could be malicious  (internal threat/attacker), wanting to create harm.
                                     disgruntled (seeking emotional reward), 
                                     greedy (seeking financial reward)
                             GAME #wfe-ignore-item 
                                 Scenario -- Sensor #slide 
                                     Player: Human Sensor $$H$$ ($$S$$ in reference game)
                                     Strategies: Human sensor $$\mathcal{H}$$ has three pure strategies $$s^\mathcal{H}\in \{c, a, n\}$$:
                                         $$c$$ -- cooperate and to send the perceived correct report (and to benefit from increased esteem, or being paid a bounty)
                                         $$a$$ -- perform an attack by giving misleading reports(in order to get a psychological "kick" or some other financial reward from a cyber criminal)
                                         $$n$$ -- not sending a report at all (as too lazy and preferring to "get on with the job")
                                 Scenario -- Report Receiver #slide 
                                     Player: Report Receiving Organisation $$R$$ ($$R$$ in reference game)
                                     Strategies: Report receiver $$\mathcal{R}$$ has two pure strategies $$s^\mathcal{R}\in \{t_r,\overline{t}_r\}$$ : 
                                         $$t_r$$ -- to trust the received report (and to benefit from its content to improve national security)
                                         $$\overline{t}_r$$ -- to not trust (to prevent damage, either by recognising the reporting node as malicious or as unreliable)
                                 Cost Benefit Model -- Human Sensor #slide 
                                     Benefit
                                         $$b_{rew}$$ -- reward (operational gain), threatened by operational punishment
                                         $$b_{est}$$ -- esteem (reputation), threatened by reputational punishment
                                     Cost
                                         $$c_{op}$$ -- operational (data collection, message creation)
                                         $$c_{att}$$ -- Message attack (data modification, deletion or fabrication)
                                         $$c_{comm}$$ -- Message sending (communication cost)
                                         $$c_{pun}$$ -- Punishment: operational and reputational
                                 Cost Benefit Model -- Receiving Organisation #slide 
                                     Benefit
                                         $$b_{sec}$$ -- System security, threatened by direct costs
                                         $$b_{rep}$$ -- Good reputation, threatened by indirect costs
                                     Cost
                                         $$c_{def}$$ -- Defence costs: verifying correctness of data
                                         $$c_{dir}$$ -- Direct costs: operational losses due to 
                                             false positives/alarm (wrongly mistrust)
                                             false negatives (missed alarm -- wrongly trust)
                                         $$c_{ind}$$ -- Indirect costs: loss of reputation
                             INBOX #wfe-ignore-outline 
                                 Organisation can run training/tests to assess the types
                                 Employee Properties
                                     cyber-unwise
                                         deliberate/knowingly
                                             uncommitted
                                             lazy
                                         unknowingly 
                                             distracted
                                             incompetent
                                             irresponsible
                                             negligent
                                             ? uncareful
                                             unskilled
                                             uncooperative
                                             unprofessional
                                             untrained
                                             unreliable
                                     malicious
                                         disgruntled
                                         greedy
                                 Employee Properties
                                     cyber-unwise, cyber-wise
                                     disgruntled, loyal
                                     distracted, focused 
                                     greedy, selfless ?
                                     incompetent, competent
                                     irresponsible, responsible
                                     lazy, hard-working
                                     malicious, honest
                                     negligent, thorough
                                     ? uncareful, diligent
                                     uncommitted, committed
                                     uncooperative, cooperative
                                     unskilled, skilled
                                     unprofessional, professional
                                     untrained, trained
                                     unreliable, reliable
                                 An honest human sensor does not know whether she is reliable or not, or socially engineered (stochastic element)
                                 HONEST
                                     The honest human sensor will always cooperate, so has no choice of actions per se
                                     But honesty does not always imply correctness 
                                     We want to model the fact that they could unknowingly create false reports
                                 Malicious Human Sensor Game #slide 
                                     The malicious reporter sends a fake report
                                     She can also decide to deceive the recipient, by sending a correct report
                                     Generally, she will try to optimise the rewards from the attack or deception versus potential punishment such as loss of reputation or prosecution
                                     This can be modelled as an IDS game where the defence action of the report receiver is to not trust the report
                                 Cyber-Untrained Honest Human Sensor Game #slide 
                                 Cyber-Trained Honest Human Sensor Game #slide 
                                 INBOX
                                     Report receiver
                                         Can use statistics to
                                             Estimate reliability of human sensor $$p_{\mathcal{R}}$$
                                             Compute expected frequency of reportable cyber incidents $$p_{F}$$
                                         Unknown information 
                                             Types -- whether human sensor is malicious $$p_{M}$$ or honest $$p_{H}$$
                                     Human sensor:
                                         Knows whether malicious or not
                                         Could get feedback to know whether reliable or not (useful for training purposes)
                                     Likelihood of attack on reporting channel is not known by anyone 
                         Next Steps #slide 
                             Continue Literature Review 
                             Review threat taxonomy and adapt our terminology if appropriate 
                             Design game payoff  functions and game
                             Solve it!
                             Design and solve repeated game
                         Part II -- Solving It #eyo-style:Section #wfe-ignore-outline 
                             INBOX - NE ANALYSIS #wfe-ignore-outline 
                                 Game 1 -- cont. #slide 
                                     Strategies
                                         Strategies:
                                             $$S_{SP} = (R_1, R_2, \ldots, R_N)$$
                                             $$S_A = (R_1, R_2, \ldots, R_N)$$
                                     Analysis of Game
                                         Static complete information parametric normal form game
                                         There is no pure strategy Nash equilibrium
                                         They compute the mixed Nash equilibrium for the cases $$N = 2$$ and the general case for the assumption that the attacker only chooses one resource to attack.
                                 Game Analysis #slide 
                                     Result: conditions under which a pure strategy BNE exists for the signalling game
                                 Bayesian Nash Equilibrium (BNE) #slide 
                                     Non-Bayesian game: strategy profile is a NE iff every strategy in that profile is a best response to every other strategy
                                     Bayesian Games: Players maximise their expected payoffs
                                         __Pooling Equilibrium__: if the first player sends the same signal, regardless of his type.
                                         __Separating Equilibrium__: if the first player sends different signals, depending on his type.
                     REPEATED GAME #wfe-ignore-outline 
                     === #wfe-ignore-item 
                     EVALUATION & DISCUSSION #wfe-ignore-outline 
                         Conclusion #slide #wfe-ignore-outline 
                     REFERENCES #slide 
                         Paper 0: Maryam Mohi, Ali Movaghar, and Pooya Moradian Zadeh. 2009. __A Bayesian Game Approach for Preventing DoS Attacks in Wireless Sensor Networks__. In Proceedings of the 2009 WRI International Conference on Communications and Mobile Computing - Volume 03 (CMC '09), Vol. 3. IEEE Computer Society, Washington, DC, USA, 507-511. DOI: https://doi.org/10.1109/CMC.2009.325 (http://www.sciencedirect.com/science/article/pii/S0898122111005815)]
                         Paper 1: Shigen Shen et al, Signaling game based strategy of intrusion detection in wireless sensor networks, __Computers & Mathematics with Applications__, Volume 62, Issue 6, 2011, Pages 2404-2416, [cited: 53]
                         Paper 2: M. Estiri and A. Khademzadeh, "A theoretical signaling game model for intrusion detection in wireless sensor networks," 2010 14th International Telecommunications Network Strategy and Planning Symposium [cited: 15]
                         Paper 3: Mohebbi Moghaddam M., Manshaei M.H., Zhu Q. (2015) To Trust or Not: A Security Signaling Game Between Service Provider and Client. In: Panaousis E. et al ed., Decision and Game Theory for Security. GameSec 2015. [cited: 6]
                     INBOX #wfe-ignore-outline 
                         Systems, Sensors and Human actors #slide 
                             Human actors may operate the sensor, interfere and/or interpret the results:
                 Human-in-the-Loop Games #h 
                 Complete Information Human-in-the-Loop Games #h
                     Motivation #slide 
                         Classification of 2x2 bimatrix games due to (Moulin, )
                             based on concept of strategic equivalence
                             there are three categories of games
                         In order to demonstrate the use of the generalised eigensystem approach, we exemplify an analysis of the classification of 2x2 non-zero-sum security games.
                         Give unifying framework how to express solutions algebraically from the game matrices 
                         We exclude Type 0 (cooperative, reliable)
                     The Human-in-the-Loop Principle #slide 
                         Definition: Human-in-the-Loop (HITL) is a design pattern that integrates human expertise into the automated process of a system.
                         Explanation: This means that humans are involved in the loop of a system to make critical decisions, improve the system's performance, and ensure accountability.
                         Benefits: HITL systems are more flexible, adaptable, and can handle edge cases better than purely automated systems. They can improve the accuracy and efficiency of the system, while also providing a means of accountability for actions taken.
                         Example: HITL is often used in cybersecurity, where automated systems are combined with human expertise to detect and respond to security threats. For example, security analysts can be alerted to potential attacks and then investigate to determine the validity of the threat and decide on the appropriate response.
                         Challenges: Implementing HITL systems can be challenging because it requires the integration of human expertise with automated processes. It also requires proper training, clear communication, and well-defined roles and responsibilities to ensure that the human-in-the-loop system functions effectively.
                     Moulin #slide 
                          ![Pasted image](https://dynalist.io/u/Ep39jjvZnnZiG0sSoAwSJjm4) 
                     Game $$G_1$$: Malicious Wizard #slide 
                         $$\begin{array}{ c | c | c }  S \downarrow W\rightarrow & \text{not cooperate} & \text{cooperate}  \\\hline  \text{not trust} &  \;\cdot\;,\rightarrow  &  \downarrow\; ,\;\cdot\;\\\hline   \text{trust}  &  \uparrow\; ,\;\cdot\;  &  \;\;\cdot\;,\leftarrow \end{array}$$ #eyo-style:Normal 
                         There is no pure NE but one mixed NE.
                     Game $$G_2$$: Impulsive Wizard #slide 
                         $$\begin{array}{ c | c | c }  S \downarrow W\rightarrow & \text{quick} & \text{slow}  \\\hline  \text{not trust} &  \;\cdot\;, \;\cdot\;\;& \; \downarrow\; ,\;\leftarrow\;\\\hline   \text{trust}  &  \uparrow\; ,\;\cdot \;  &  \;\cdot\;, \; \leftarrow\;\end{array}$$ #eyo-style:Normal 
                         There is one pure NE (not trust, quick). 
                     Game $$G_3$$: Selfish Wizard #slide 
                         $$\begin{array}{ c | c | c }  S \downarrow W\rightarrow & \text{low effort} & \text{high effort}  \\\hline  \text{not trust} &  \;\cdot\;, \;\cdot\;\;& \; \downarrow\; ,\;\leftarrow\;\\\hline   \text{trust}  &  \uparrow\; ,\;\rightarrow\;  &  \;\cdot\;, \; \cdot \;\end{array}$$ #eyo-style:Normal 
                         There are two pure NEs: (not trust, low effort) and (trust, high effort).
                         There is also one mixed NE.
                     Discussion #h 
                         Additional Assumptions #slide 
                              Selfish Wizard:
                         Classification of 2x2 Security Games #slide 
                             Game $$G_1$$:
                                 Typical example of a __security game__ (more generally: __search game__). Classical game: __Chicken__.
                                 Hawk-Dove Game
                                 Literature: IDS Game (Alpcan & Bazar, 2011).
                                 Game is strategically zero-sum.
                             Game $$G_2$$:
                                 Strategically equivalent to:
                                     The famous __Prisoner Dilemma__. 
                                     
                                 Has strong dilemma.
                                 Two-player version of Public Goods Game.
                                 Game is strategically zero-sum.
                             Game $$G_3$$:
                                 Strategically equivalent to:
                                      __The Battle of the Sexes__. 
                                     Stag-Hunt
                                 Game is not strategically zero-sum.
                                 Can we use mechanism design to achieve a preferred NE in this case?
                     Conclusion #slide 
                     
             GT+OaG
                 Chen2021-td
                 Cui2020-vg
                     Cui, Y., Quddus, N. and Mashuga, C.V. (2020) Bayesian network and game theory risk assessment model for third-party damage to oil and gas pipelines, __Process Safety and Environmental Protection__, 134, pp. 178188.
                         Tremendous amounts of oil and gas products are transported in pipelines worldwide resulting in increasing interest to identify the hazards and evaluate the associated risks associated with this critical infrastructure. Third-party intrusion is one of the least quantifiable factors being considered during the pipeline hazard assessment stage despite the substantial contributing to the total number of oil and gas pipeline incidents. This is because a probabilistic risk assessment cannot reliably model human actions and be applied to intentional acts. Due to the distinctive motivations of third-party damage, an unintentional third-party damage Bayesian Network model and a game-theoretic model on malicious intrusion will therefore be built, to examine the mechanism of pipeline failure caused by this mode. This study is conducted aiming at investigating pipeline risk resulting from third-party damage, and will formulate risk assessment models to identify threats, prioritize risks and determine which integrity plan should apply to different pipeline segments given the condition of third-party interference (both the accidental damage and malicious acts).
                 Hawash2020-yt
                 Rezazadeh2019-sz
                 Araujo2018-ng
                 Wadhawan2016-sf
                 Bucelli2018-vd
                 noauthor_undated-ow
                 Vieira2014-rr
                 Peskir2008-rz
             GT+RA
                 Game theory applications to security Risk Assessment #GTSec #h 
                     Complete Information Security Assessment Game #h #single-target 
                         Introduction #slide 
                             SA game is a __proactive__ security game (actions are non-observable, this is a static game)
                             Single-target game: we only consider one target. The focus is on the single asset that has a vulnerability.
                             Most simple attacker defender scenario.
                                 Rows corresponds to the strategies available to the defender.
                                 Columns are the attacker's strategies.
                             Strategies:
                                 $$S_\mathcal{D} = \{$$defend, not defend$$\} = \{s_d, s_{-d}\}$$ 
                                 $$S_\mathcal{A} = \{$$ attack, not attack $$\} = \{s_a, s_{-a}\}$$ 
                         Payoff Notations #slide 
                             $$c_{\mathcal{D}}$$ -- the defense cost
                             $$I$$ -- the defender's cost due to the impact of an attack
                             $$c_{\mathcal{A}}$$ -- the attacker's cost
                             $$G$$ -- the gain (benefit) of the attacker from an attack.
                             Assumptions:
                                 __Principle of Adequate Protection__: $$c_{\mathcal{D}} <I$$
                                 __Principle of Easiest Attack__: $$c_{\mathcal{A}} < G$$
                         Game Description  #slide 
                             $$\mathcal{G}(\mathcal{D},\mathcal{A})$$  Payoff Matrix:
                                 $$\begin{array}{  c | c | c }  \mathcal{D} \downarrow \mathcal{A}\rightarrow & s_a & s_{-{a}} \\ \hline s_d &  - c_{\mathcal{D}}, - c_{\mathcal{A}}&  -c_{\mathcal{D}},  0 \\ \hline s_{-{d}} &  -I,  G- c_{\mathcal{A}} &  0,  0 \\ \end{array}$$ #eyo-style:Normal 
                             We will also use bimatrix notation $$\mathcal{G}(A,B)$$.
                         Game Equilibrium Analysis #slide 
                             There is a unique mixed NE solution pair with
                                 $$x^{*} = \frac{G-c_{\mathcal{A}}}{G} = 1 - \frac{c_{\mathcal{A}}}{G}$$
                                 $$y^{*} = \frac{c_{\mathcal{D}}}{I}$$
                             The corresponding optimal expected payoffs are:
                                  $$s^{*}_d = -c_{\mathcal{D}} $$
                                 $$s^{*}_a =  0 $$ 
                             The game is strategically zero-sum. 
                         Game Analysis Summary #slide
                             In order to slightly simplify the game, we assume "the winner gets it all": $$G = I$$
                             **Theorem 1**. The security game $$\mathcal{G}(\mathcal{D},\mathcal{A})$$ has no pure Nash Equilibrium. A mixed Nash Equilibrium strategy pair $$(x_\mathcal{D}^,y_\mathcal{A}^)$$ is obtained, where $$x_\mathcal{D}^=1-c_\mathcal{A}/G$$ and $$y_\mathcal{A}^=c_\mathcal{D}/I$$ are the probability of defense and attack respectively. The resulting expected payoffs, in this case, are $$u_\mathcal{D}^=c_\mathcal{D}$$ and $$u_\mathcal{A}^=0$$.
                             **Proof**: The proof of this theorem will be obtained as a special case for that of Theorem 2.
                         Discussion #slide 
                             Main problem: $$u_\mathcal{A}^=0$$.
                                 Would this be desirable for attacker?
                                 GT needs to be accepted by all real-world players.
                             Solution: reward scheme.
                                 If outcomes of security assessment match observed reality, there will be a reward $$r_{\mathcal{D}}$$ for the defender
                                 Otherwise, the attacker will benefit from a reward $$r_{\mathcal{A}}$$.
                         Extended Game  #slide 
                             $$\mathcal{G}_r(\mathcal{D},\mathcal{A})$$  Payoff Matrix:
                                 $$\begin{array}{  c | c | c }  \mathcal{D} \downarrow \mathcal{A}\rightarrow & s_a & s_{-{a}} \\ \hline s_d &  - c_{\mathcal{D}}+r_{\mathcal{D}}, - c_{\mathcal{A}}&  -c_{\mathcal{D}},  r_{\mathcal{A}} \\ \hline s_{-{d}} &  -I,  G- c_{\mathcal{A}}+r_{\mathcal{A}} &  r_{\mathcal{D}},  0 \\ \end{array}$$ #eyo-style:Normal 
                         Solving the Extended Game #slide #wfe-ignore-outline 
                             Using the free CAS Maxima:
                                 A: matrix([-c["D"]+r["D"], -c["D"]],[-I,r["D"]]);
                                 B: matrix([-c["A"], r["A"]],[G+r["A"]-c["A"],0]);
                                 EA: gen_eigen_sys(A,u);
                                 EB: gen_eigen_sys(B,u);
                             Screenshot
                                 ![Screenshot 2021-05-26 18.13.54.png](https://dynalist.io/u/y11Djt9bZbZTxH9tJxK01XLC)
                         Extended Game Equilibrium Analysis #slide 
                             **Theorem 2**. The security game $$\mathcal{G}_r(A, B, \mathcal{D},\mathcal{A})$$ has no pure Nash Equilibrium. A mixed Nash Equilibrium strategy pair $$(x_\mathcal{D}^,y_\mathcal{A}^)$$ is obtained, where $$x_\mathcal{D}^=1 - \frac{r_{\mathcal{A}}+c_{\mathcal{A}}}{G+2r_{\mathcal{A}}}$$ and $$y_\mathcal{A}^=\frac{c_{\mathcal{D}}+r_{\mathcal{D}}}{2r_{\mathcal{D}}+I}$$ are the probability of defense and attack respectively. The resulting expected payoffs, in this case, are $$u_\mathcal{D}^=\frac{r_{\mathcal{D}}^2c_\mathcal{D}(I+r_{\mathcal{D}})}{I+2r_{\mathcal{D}}}$$ and $$u_\mathcal{A}^=\frac{r_{\mathcal{A}}^2+r_\mathcal{A}(G-c_{\mathcal{A}})}{G+2r_{\mathcal{A}}}$$. Furthermore, if $$r_{\mathcal{A}}>0$$ then it holds $$u_\mathcal{A}^>0$$.
                             INBOX
                                 $$r_{\mathcal{D}}>0$$ then $$u_\mathcal{D}^>0$$ and if 
                                 RESULTS
                                     There is a unique mixed NE solution pair with
                                         $$x^{*} =  1 - \frac{r_{\mathcal{A}}+c_{\mathcal{A}}}{I+2r_{\mathcal{A}}}$$
                                         $$y^{*} = \frac{c_{\mathcal{D}}+r_{\mathcal{D}}}{2r_{\mathcal{D}}+I}$$
                                     The corresponding optimal expected payoffs are:
                                          $$s^{*}_d  \neq 0  $$ if $$ r_\mathcal{D}\neq 0$$
                                         $$s^{*}_a \neq 0  $$ if $$ r_\mathcal{A}\neq 0$$
                         References #slide #wfe-ignore-outline 
                             __Strategically zero-sum games: The class of games whose completely mixed equilibria cannot be improved upon__ - International Journal of Game Theory, 1978, Volume 7, Number 3-4, Page 201 - H. Moulin, J. -P. Vial #wfe-ignore-item 
                             Maghrabi, L., Pfluegel, E., Al-Fagih, L., Graf, R., Settanni, G., & Skopik, F. (2017). Improved software vulnerability patching techniques using CVSS and game theory. In 2017 International Conference on Cyber Security and Protection of Digital Services, Cyber Security 2017. Institute of Electrical and Electronics Engineering, https://doi.org/10.1109/CyberSecPODS.2017.8074856
                     TEMP
                         Introduction #slide 
                             Motivation 
                                 The budget source for rewards
                                 We are interested in capturing realistic assumptions 
                             Contributions  
                                 A systematic, complete analysis of 2x2 bimatrix games capturing  
                                 A formulation and analysis of a Bayesian non-zero sum 2-player game, informed by this analysis.
                         Motivation #slide 
                         Assumptions #slide 
                             Defender does not know about attacker reward and assumes 
                             
                         Moulin #slide 
                              ![Pasted image](https://dynalist.io/u/Ep39jjvZnnZiG0sSoAwSJjm4) 
                         Budget Game $$G_B(\mathcal{D},\mathcal{A})$$: #slide   
                             Payoff Matrix:
                                 $$\begin{array}{  c | c | c }  \mathcal{D} \downarrow \mathcal{A}\rightarrow & s_a & s_{-{a}} \\ \hline s_d &  - c_{\mathcal{D}}-r_{\mathcal{D}}, - c_{\mathcal{A}}&  -c_{\mathcal{D}},  0 \\ \hline s_{-{d}} &  -I,  g- c_{\mathcal{A}} &  -r_{\mathcal{D}},  0 \\ \end{array}$$ #eyo-style:Normal 
                             Classification of 2x2 bimatrix games due to (Moulin, )
                                 based on concept of strategic equivalence
                                 there are three categories of games
                             Depending on the value of $$r_{\mathcal{D}}$$, there could be no, one or two pure NEs.
                             In the latter case, there will also be one mixed NE equilibrium. 
                         Budget Game $$G_2$$: Selfless RA Team #slide 
                             $$ $$ 
                             
                             
                             There is one pure NE (not trust, quick). 
                         External Budget Game $$G_1$$: Selfish RA Team #slide 
                             There is no pure NE but one mixed NE.
                         Internal Budget Game $$G_2$$: Selfless RA Team #slide 
                             There are two pure NEs: (not trust, low effort) and (trust, high effort).
                             There is also one mixed NE.
                         Discussion #h 
                             Additional Assumptions #slide 
                                  Selfish Wizard:
                             Classification of 2x2 Security Games #slide 
                                 Game $$G_1$$:
                                     Typical example of a __security game__ (more generally: __search game__). Classical game: __Chicken__.
                                     Hawk-Dove Game
                                     Literature: IDS Game (Alpcan & Bazar, 2011).
                                     Game is strategically zero-sum.
                                 Game $$G_2$$:
                                     Strategically equivalent to:
                                         The famous __Prisoner Dilemma__. 
                                         
                                     Has strong dilemma.
                                     Two-player version of Public Goods Game.
                                     Game is strategically zero-sum.
                                 Game $$G_3$$:
                                     Strategically equivalent to:
                                          __The Battle of the Sexes__. 
                                         Stag-Hunt
                                     Game is not strategically zero-sum.
                                     Can we use mechanism design to achieve a preferred NE in this case?
                     Game Analysis #h 
                         Motivation #slide 
                             Main interest: compute closed form solutions for mixed equilibrium. 
                         Analysis Approach  #slide 
                             Degeneracy conditions ( @Moulin): $$a_1\neq a_3$$, $$a_2\neq a_4$$ and $$b_1\neq b_2$$, $$b_3\neq b_4$$.
                             Consequence: together with additional assumptions, might be shown either $$\mu$$ is well-defined, or does not exist.
                             Does it imply $$\det(A-\lambda E)= c_0-c_1\lambda$$ with $$c_0, c_1 \neq 0$$?
                             Are EVs non-negative?
                             This will be used in the different cases, to detail the solutions in closed-form expression. 
                         Equations for Generic Generalised Eigensystem #slide 
                             For a generic matrix $$A$$, the components of a generalised eigensystem $$\mathcal{E}_A=\left(\mu, x^t, y\right)$$ are determined as follows:
                                 The eigenvalue is the real number $$\mu = {{a_{1}\,a_{4}-a_{2}\,a_{3}}\over{a_{1}+a_{4}-a_{2}-a_{3}}}$$, assuming that the denominator in this expression does not vanish. 
                                 The corresponding left eigenvector  is $$x^t=\left(a_{3}-a_{1}\right)\,\begin{pmatrix}a_{4}-a_{3}&a_{1}-a_{2}\end{pmatrix}$$ and $$y=\left(a_{1}-a_{2}\right)\begin{pmatrix}a_{2}-a_{4}\cr a_{3}-a_{1}\end{pmatrix}$$ is the right eigenvector. 
                         Aggregated Generalised Eigensystem for Bimatrix Games #slide 
                             For a bimatrix game $$G(A,B)$$, the following aggregated generalised eigensystem is of interest: $$\mathcal{E}_{A,B} = \left(\mu_A, y_A,\mu_B, x_B^t\right)$$
                             We have
                                 $$\mu_A = {{a_{1}\,a_{4}-a_{2}\,a_{3}}\over{a_{1}+a_{4}-a_{2}-a_{3}}}$$
                                 $$y_A=\left(a_{1}-a_{2}\right)\begin{pmatrix}a_{2}-a_{4}\cr a_{3}-a_{1}\end{pmatrix}$$
                                 $$\mu_B = {{b_{1}\,b_{4}-b_{2}\,b_{3}}\over{b_{1}+b_{4}-b_{2}-b_{3}}}$$
                                 $$x_B^t=\left(b_{1}-b_{3}\right)\,\begin{pmatrix}b_{3}-b_{4}&b_{2}-b_{1}\end{pmatrix}$$
                         Fundamental Theorem #slide 
                             Specialising the work of (Thompson et al) to matrix games, we extend their main fundamental theorem to bimatrix games as follows: 
                             Given a square bimatrix game $$G(A,B)$$, assume the matrix pencils $$A-\lambda E$$  and $$B-\lambda E$$ are both regular, each with a real eigenvalue $$\mu_A$$ and $$\mu_B$$ respectively. Let $$x_{\mu_B}$$ be a nonnegative left eigenvector of $$B-\lambda E$$ with respect to $$\mu_B$$ and denote $$y_{\mu_A}$$ a nonnegative right eigenvector of $$A-\lambda E$$ with respect to $$\mu_A$$. Then $$(x^*,y^*) = (x_{\mu_B}$$, $$y_{\mu_A}$$) is a Nash Equilibrium strategy profile of the game $$G$$ and $$(\mu_A, \mu_B)$$ is the corresponding game value pair. #eyo-style:Theorem  #theorem:bimatrix-regular-theorem 
                         A Best Response Lemma #slide 
                             The proof of the theorem will be aided by the following lemma. 
                             It exhibits a special case arising where there exists a strategy of one player to which any strategy of the other player is a best response.
                             Following the notations as in the theorem, we have for a nonnegative left generalised eigenvector $$x_{\mu_B}$$ that for all Player 2 strategies $$y$$ it holds $$x^\top_{\mu_B} B y = \mu_B $$. Similarly, a nonnegative right eigenvector $$y_{\mu_A}$$ satisfies $$x^\top A y_{\mu_A} = \mu_A$$ for all Player 1 strategies $$x$$. #eyo-style:Lemma  #lemma:best-response-eigen
                         Proof [of lemma] #slide #wfe-ignore-outline 
                             #eyo-style:Proof 
                                 Assume that $$x^{\top}_{\mu_A}\ge 0$$ is a left eigenvector, associated with the eigenvalue $${\mu_A}$$ of the regular matrix pencil $$A-\lambda E$$. This implies
                                 #equation:left-nullspace-eq
                                      $$ x^{\top}_{\mu_A}(A-{\mu_A} E)=0. $$
                                 Due to the normalisation property $$\sum x_{{\mu_A},i}=1$$ we have $$ x^{\top}_{\mu_A} E = x^{\top}_{\mu_A} ee^{\top}=e^{\top}$$ so that equation #ref:left-nullspace-eq implies 
                                     $$ x^{\top}_{\mu_A} A = {\mu_A} e^{\top}$$.  #displaymaths 
                                 The second property for a right eigenvector $$y_{\mu_B}$$ can be shown similarly. From this, the lemma follows. 
                         Proof [of Theorem #ref:bimatrix-regular-theorem ] #slide #wfe-ignore-outline 
                             Let $$y_{\mu_A}$$ be nonnegative right eigenvector of $$A-\lambda E$$ with respect to the eigenvalue $$\mu_A$$. From Lemma #ref:best-response-lemma we deduce that $$y_{\mu_A}$$ is a best response to any Player 1 strategy $$x$$, in particular to  $$x=x_{\mu_B}$$. Likewise,  denote $$x_{\mu_B}$$ a nonnegative left generalised eigenvector of $$B-\lambda E$$. We obtain that  $$x_{\mu_B}$$ is a best response to Player 2 strategy $$y=y_{\mu_A}$$. Hence these strategies are mutual best responses and by definition mixed Nash Equilibrium strategies with payoffs $$\mu_A$$ and $$\mu_B$$ as required. #proof 
                         Case 1 #slide 
                             The non-existence of a pure NE leads to the following conditions, up to permution: $$a_1>a_3$$, $$a_4>a_2$$, $$b_2>b_1$$ and $$b_3>b_4$$.
                             We deduce that both eigenvalues $$\mu_A$$ and $$\mu_B$$ are well defined. 
                             The vectors $$x_B^t$$ and $$y_A$$ are non-zero. 
                             Furthermore each vector has entries having the same sign. 
                                 Define $$\text{sign}(v)$$ as the sign of #wfe-ignore-item 
                             Apply Theorem #theorem:bimatrix-regular-theorem to obtain the unique mixed NE solution pair. 
                         Case 2 #slide 
                             With two pure NEs one obtains $$a_1>a_3$$, $$a_4>a_2$$, $$b_1>b_2$$ and $$b_4>b_3$$.
                             As in Case 1, both vectors are non-zero and all entries have the same sign. 
                             Same approach to obtain the unique mixed NE solution pair by applying Theorem #theorem:bimatrix-regular-theorem . 
                         Case 3 #slide 
                             In this case, a single pure NE implies either 
                             Case (i): $$a_1>a_3$$, $$a_4>a_2$$, $$b_1>b_2$$ and $$b_3>b_4$$; or
                             Case (ii): $$a_1>a_3$$, $$a_2>a_4$$, $$b_1>b_2$$ and $$b_3>b_4$$.
                             There is dominance
                                 In both case (i) and (ii): column 2 of $$B$$ is dominated by column 1
                                 In the case of (ii): row 2 of $$A$$ is also dominated by row 1
                             The game is trivial for at least one of the players.
                             Algebraic property: empty generalised eigensystem.
                             This implies $$\det(A-\lambda E)\equiv c\neq 0$$ or the existence of not nonnegative eigenvectors. 
                             Proof:
                         Conclusion #slide 
                             Summarising theorem:
                             This is exhaustive result, completely covering all security game types. 
                             Preparation for Bayesian game analysis. 
                     Bayesian Game #h 
                         Motivation #slide 
                             Focus on first and second game
                             This avoids third, which is less interesting from GT point of view and also could be avoided through proper vetting 
                             Strategies are effectively: cooperate, not cooperate and trust, not trust
                             Denoted as $$\{C, \bar{C}\}$$ and  $$\{T, \bar{T}\}$$. 
                         Wizard Types #slide 
                             Type 1: Malicious
                                 deliberately wanting to reduce accuracy of system
                                  seeking emotional or financial reward
                             Type 2: Selfish
                                 knowingly/deliberately unreliable -- apply minimal effort in contribution to overall system accuracy, if possible 
                                 lazy (give it low priority, too focused on other job aspects)
                             Type 3: Incompetent
                                 unknowingly unreliable
                                 Impulsive 
                         A Bayesian Game #slide
                             This will lead to a Bayesian game $$G_B$$ with three Wizard types $$\Theta=\{m, s, i\}$$
                             Formally, game is a tuple $$(N, A,\Theta, p, u)$$ where:
                                 $$N$$ is a set of agents
                                 $$A = A_1 \times A_2 $$ where $$A_i$$ is the set of actions available to player $$i$$
                                 $$\Theta$$ is the type space of player $$W$$
                                 $$p : \Theta \rightarrow [0, 1]$$ is a common prior over types
                                 $$u = (u_1 , u_2)$$, where $$u_i : A \times \Theta \rightarrow R$$ is the utility function for player $$i$$
                             Static vs dynamic game
                         Game $$G_1(A,B)$$: 
                             $$ A=\begin{pmatrix} a_{1} &a_{2}\\a_{3} &a_{4}\end{pmatrix} $$, $$ B=\begin{pmatrix} b_{1} &b_{2}\\b_{3} &b_{4}\end{pmatrix} $$ and $$a_{1}>a_{3};a_{4}>a_{2};$$ $$b_{2}>b_{1 };b_{3}>b_{4};$$
                         Game $$G_2(\hat{A},\hat{B})$$: 
                             $$ \hat{A}=\begin{pmatrix} \hat{a}_{1} &\hat{a}_{2}\\\hat{a}_{3} &\hat{a}_{4}\end{pmatrix} $$, $$ \hat{B}=\begin{pmatrix} \hat{b}_{1} &\hat{b}_{2}\\\hat{b}_{3} &\hat{b}_{4}\end{pmatrix} $$ and $$\hat{a}_{1}>\hat{a}_{3};\hat{a}_{4}>\hat{a}_{2};$$ $$\hat{b}_{1}>\hat{b}_{2};\hat{b}_{4}>\hat{b}_{3};$$
                     Game Analysis #h 
                         Overview #slide 
                             Non-Bayesian game: strategy profile is a NE iff every strategy in that profile is a best response to every other strategy
                             Our game: find Bayesian Nash Equilibria (BNE) 
                             Bayesian Games: Players maximise their expected payoffs
                         BNE Types #slide 
                             __Pooling Equilibrium__: if the first player's best response remains the same, regardless of his belief in the type of Player 2.
                             __Separating Equilibrium__: if best response is different, depending on the type.
                         Harsani-Transformation #slide 
                             Idea: convert game with uncertainty over strategies (types) into game with payoff uncertainty. 
                             Assume knowledge of probability distribution for types. 
                             Consider 2 types.
                         The Imperfect Information Game #slide 
                             Denote
                             We have $$\tilde{A}=P_1A+P_2\hat{A}$$ and  $$\tilde{B}=P_1B+P_2\hat{B}$$ where 
                                 $$P_1 = \begin{pmatrix}  p&0 \\ p &0 \\ 0 &p  \\ 0 &p \\  \end{pmatrix}$$.
                                 $$P_2 = \begin{pmatrix}  1-p&0 \\ 0 &1-p  \\ 1-p &0  \\ 0 &1 -p \\  \end{pmatrix}$$.
                         The Imperfect Information Game (cont.) #slide 
                         Pure NE Analysis #h 
                             Pure NE Result #slide 
                                 Let $$\epsilon_1=\frac{b_{1}-\hat{b}_{2}}{b_{2}-\hat{b}_{2}}$$ and $${\epsilon_2}=\frac{b_{4}-\hat{b}_{3}}{b_{3}-\hat{b}_{3}}$$. Then it holds $$0<\epsilon_1<1$$ and $$0<{\epsilon_2}<1$$. Then if $$p<\epsilon_1$$, the game admits a Pooling BNE $$(\bar{T}\bar{T},\bar{C})$$. Furthermore, if $$p<\epsilon_2$$, there is a Pooling BNE $$(TT,C)$$. #eyo-style:Proposition
                             Proof #h 
                                 Step 1 #slide 
                                     First we show that Player 1's best responses to pure strategies of Player 2 are independent of the value of $$p$$. 
                                     For this, we establish $$\alpha_1>\alpha_5$$ and the chain of unequalities $$\alpha_1>\alpha_3>\alpha_7$$.
                                     Proving $$\alpha_1>\alpha_5$$:
                                     Proving $$\alpha_1>\alpha_3>\alpha_7$$:
                                 Step 2 #slide 
                                     If $$\beta_1>\beta_2$$, the game admits a Pooling BNE $$(\bar{T}\bar{T},\bar{C})$$. 
                                     If $$\beta_4>\beta_3$$, there is a Pooling BNE $$(TT,C)$$.
                                 Step 3 #slide 
                         Mixed NE Analysis #h 
                             Analysing Rectangular Games #slide 
                                 We need an extension of theorem #theorem:bimatrix-regular-theorem 
                         Discussion #slide 
                     Conclusion #slide 
             GT+SA
                 Louis_Anthony_Tony_Cox2009-fo
             GT+Stego
                 Game-Theoretic Adaptive Hybrid Steganography #h 
                     Stego Games
                         Introduction #slide
                             Background:
                             Context:
                             Motivation:
                         Contributions/Novelty #slide 
                         Notations #slide 
                         Terminology for Steganography #slide 
                             Cover-medium + payload = carrier-medium
                                 Cover-medium (cover object, cover) -- e.g. text, image, audio or video file
                                 Secret payload -- e.g. image, document, audio, video file
                                 Carrier-medium (stego-object) -- usually same as cover-object 
                             Stego-key: method or key required to access the payload from the carrier-medium 
                                 E.g. instructions, algorithm, tool with key or password
                         Simple Stego-Game #h 
                             Scenario #slide 
                                 An entity $$\mathcal U$$ wants to transmit a secret message to a friend. 
                                 The entity $$\mathcal U$$ decides to transmit the secret message $$m$$ as an email through a home internet connection
                                 However, $$\mathcal U$$ is in an environment where all email and internet communications are monitored by the intelligence agencies and the government, they are not to be trusted
                                 The current security techniques used for e-mail security are complicated
                                 PGP (Pretty Good Privacy) and GPG (GNU Privacy Guard) can used but in practice, the setup can be complicated and confusing.
                             Motivation for Security Game Model #slide 
                                 Furthermore, $$\mathcal U$$ decides to apply a game theoritcal approach to formalize decision making processess and predict the adversary behaviour
                                 $$\mathcal U$$ aims to implement an afforable and simple steganographic technique with hope that the secret message will be transmitted securly
                                 The simple stego game presented in this section adopts formost a more defense oriented perspective and focus more on defense rather than the adversary strategies.
                             Simple Stego-Game #slide 
                                 Aim: to decide when we should use expensive steganography, rather than cheap plaintext message sending.
                                 Players:
                                     $$\mathcal U$$ -- User
                                     $$\mathcal S$$ -- Steganalyst
                                 They can choose strategies:
                                     $$\mathcal U$$:
                                         $$hide, \lnot hide$$
                                     $$\mathcal S$$:
                                         $$look, \lnot look$$
                             Payoffs #slide 
                                 $$\mathcal U$$:
                                     $$b_{hide}$$ -- benefit of hiding (secrecy): assume = 0
                                     $$c_{hide}$$ -- cost of hiding 
                                     $$c_{leak}$$ -- cost arising from payload leaking
                                 $$\mathcal S$$:
                                     $$b_{leak}$$ -- reward of accessing leaked payload 
                                     $$c_{look}$$ -- cost of looking at carrier-object 
                             Game Strategic Normal Form #slide
                                 $$\begin{array}{c|c|c} \mathcal{U} \downarrow \mathcal{S} \rightarrow & look &\lnot look \\ \hline  hide & -c_{hide}, -c_{look}& -c_{hide}, 0\\ \hline  \lnot{hide}  &-c_{leak},b_{leak}-c_{look}&0, 0\end{array}$$ #eyo-style:Normal 
                                 Assumptions
                                     Principle of Adequate Protection : $$c_{leak} > c_{hide}$$
                                     Principle of Easiest Attack : $$b_{leak} >c_{look}$$
                             Game Analysis #slide
                                 Relationship with AD-Game
                                     $$\mathcal{U} \hat{=} \mathcal{D} $$
                                     $$\mathcal{S} \hat{=} \mathcal{A} $$
                                     Direct mapping between payoffs
                                 NE Solutions:
                                     Theorem 1. The security game has no pure Nash Equilibrium strategy.
                                     Proof: By inspecting the game.
                                     Theorem 2. A mixed Nash Equilibrium strategy $$(s_{\mathcal U}^*,s^*_{\mathcal S})$$ is obtained, where $$p^*=\dfrac{b_{leak}-c_{look}}{b_{leak}}$$ and $$q^*=\dfrac{c_{hide}}{c_{leak}}$$ are the probability of hiding and looking respectively. The resulting expected utilities in this case are $$u_{\mathcal U}^*=-c_{hide}$$ and $$u_{\mathcal S}^*=0$$.
                                     Proof: Following Nash.
                                         [https://dynalist.io/d/LEdIn-fQiooRnQn8D-7fFHVC#z=MtWHZzltzod30Ojb2lEysQxX](https://dynalist.io/d/LEdIn-fQiooRnQn8D-7fFHVC#z=MtWHZzltzod30Ojb2lEysQxX)
                                     $$\Longrightarrow p^*=\dfrac{b_{leak}-c_{look}}{b_{leak}-c_{look}+c_{look}}=\dfrac{b_{leak}-c_{look}}{b_{leak}}$$
                                     $$\Longrightarrow q^*=\dfrac{c_{hide}}{c_{leak}}$$
                             Discussion #slide 
                                 Find good example illustrating solution properties (low attack cost and high reward)
                                 Extend game for low- and high entropy steganography
                         Entropy-Game #h 
                             Entropy-Game #slide 
                             Payoffs #slide 
                                 $$\mathcal U$$:
                                     [$$b_{hide}$$ -- benefit of hiding (secrecy): assume = 0]
                                     $$c_{hide}$$ -- cost of hiding 
                                     $$c_{leak}$$ -- cost arising from payload leaking
                                 $$\mathcal S$$:
                                     $$b_{leak}$$ -- reward of accessing leaked payload 
                                     $$c_{look}$$ -- cost of looking at carrier-object 
                             Game Strategic Normal Form #slide 
                                 $$\begin{array}{c|c|c|c} \mathcal{U} \downarrow \mathcal{S} \rightarrow & scan^+ & scan & look\\ \hline  low & -c_{low}, -c_{scan^+}& -c_{low}, -c_{scan}& -c_{low}, -c_{look}\\ \hline  high  &-c_{leak},-c_{scan^+}&-c_{leak},-c_{scan}&-c_{leak}, -c_{look}\end{array}$$ #eyo-style:Normal 
                             Game Analysis #slide
                             Discussion #slide 
             GT+Stochastic+Stopping
                 MATRIX GAMES & GENERALISED EIGENSYSTEMS
                     CONCEPTS
                         SUPPORT, DEFECT, SLACK, LABELS
                     SUFFICIENCY FOR VALUE AND OPTIMAL SOLUTIONS
                         Fundamental Theorem (Linking Generalised Eigensystem and Value and Optimal Solutions of Game) #slide
                         #theorem:zero-sum-regular-pencil 
                             Assume the matrix game $$G(A)$$ is regular, with a real generalised eigenvalue $$\mu$$ corresponding to nonnegative left and right generalised (normalised) eigenvectors $$x_\mu$$ and $$y_\mu$$. Then the generalised eigenvalue and the value of the game coincide: $$v(A)=\mu$$. Furthermore, $$x_\mu$$ and $$y_\mu$$ are optimal solutions of the game with maximal support. #novel 
                                 Assume the matrix pencil $$A-\lambda E$$ is regular, with a real eigenvalue $$\mu$$ corresponding to nonnegative left and right normalised eigenvectors $$x_\mu$$ and $$y_\mu$$. Then the value of the game $$G(A)$$ is $$v(A)=\mu$$ and $$(x_\mu$$, $$y_\mu$$) is an optimal strategy profile.  #novel 
                         #proof:zero-sum-regular-pencil
                             We have $$v\le x^* Ay_\mu=\mu ex^*=\mu$$ for any optimal solution $$x^*$$. Furthermore it also holds $$v\ge x_\mu Ay^*=\mu ^\top\! ey^*=\mu$$ for any optimal solution $$y^*$$.
                             From this we obtain $$v=\mu$$ and $$x_\mu Ay_\mu=\mu$$ from which the theorem follows.
                         Proof (Alternatives) #slide
                             Alternative proof: use strategy transformation
                             $$^\top\! e$$
                             The proof of this theorem can also be obtained as a special case of our proof for Theorem #ref:non-zero-sum-regular-theorem. 
                         Lower and Upper Value Lemma #slide 
                             #lemma
                                 Assume the matrix pencil $$A-\lambda E$$ is regular, with a real eigenvalue $$\mu$$. Then the following holds:
                                     There is an associated generalised nonnegative left eigenvector $$x_\mu ^t\Longrightarrow \underline{v} \ge \mu$$. 
                                     There is an associated generalised nonnegative right eigenvector $$y_\mu \Longrightarrow  \overline{v} \le \mu$$.
                                 In particular, if both generalised eigenvectors are nonnegative, $$v=\mu$$.
                         Proof #slide 
                             #proof
                                 We have $$\underline{v} = \min_y \max_x xAy \ge \min_y \mu e^\top y = \mu$$ by choosing $$x=x_\mu$$ to derive the lower estimate of the maximum. 
                                 On the other hand, $$\overline{v}=\max_x \min_y xAy \le \max_x \mu xe = \mu$$. 
                     INACTIVE STRATEGIES
                         SUFFICIENT CONDITIONS
                             #lemma 
                                 If the game has an associated matrix pencil that is singular, there exist inactive strategies. #novel 
                             #lemma 
                                 If the game has an associated regular matrix pencil without positive eigenvectors, there exist inactive strategies. #novel 
                             #lemma 
                                 If the game has an associated regular matrix pencil with non-negative eigenvectors, there exists at the most one inactive strategy. #novel 
                     DOMINANCE
                     COMPLETELY MIXED CASE
                         #theorem:zero-sum-mixed-result
                             A matrix game is completely mixed if and only if its associated generalised eigensystem is regular, with a real eigenvalue and strictly positive left and right eigenvectors. #novel 
                     UNIQUENESS OF SOLUTIONS
                         Canonical Case: Unique Solutions #h 
                             Uniqueness Result #slide 
                             Necessary Conditions for Inactive Strategies #slide 
                             Solutions with Maximal Support #slide
                                 #lemma 
                                     A solution with maximal support has the same number of active strategies for each player. #novel 
                                      and is unique solution with that support. #novel 
                     PERTURBATIONS
                         REDUCTION
                     ARCHIVE
                         #theorem @zero-sum-regular-theorem-old
         LA #LA 
             Background #slide 
                 Matrix pencils
                 Matrix rank factorisations
             LA+Pencil+RFactor
                 Eigenspace characterisations of regular matrix pencils through rank factorisations. #EigenRankFactor
                     Introduction #slide
                         Background:
                             Matrix pencils
                             Matrix factorisations
                         Context:
                             To determine the structure of eigenspace of a regular matrix pencil 
                             To achieve this through matrix (full-) rank factorisation. 
                         Motivation:
                             To benefit from low-rank situations of the matrix $$B$$. 
                     Contributions/Novelty #slide 
                         Reduction of the pencil eigenspace problem to a matrix eigenspace problem, based on rank-factorisation of the matrix $$B$$. #novel:contribution
                         Novelty relation to previous work:
                             relation pencil to matrix: numerical maths
                             matrix determinant lemma
                             Italian guy 
                     Notations #slide 
                         Regular Matrix Pencils
                         Matrix Rank Factorisation
                         Normalised eigenvectors 
                     Characteristic Polynomial Lemma #slide #novel:lemma
                         The following lemma relates the characteristic polynomial of the matrix pencil $$P(\lambda)$$ to that of a pencil of smaller size, if $$r<n$$. 
                         #lemma Assume that $$A$$ is invertible. Then $$\det(\beta A-\alpha LR^\top)=\beta^{n-r}\det(A)\det(\beta I_r-\alpha R^\top A^{-1}L)$$. 
                             Proof: based on block-determinant identity (see e.g.~ \cite{Bernstein2018-bj}).
                                 Proof of Lemma #slide #proof
                                     Define the matrix
                                         $$M=\begin{pmatrix}  I_r&R^\top \\ \alpha L & \beta A  \\  \end{pmatrix}$$.
                                     Applying the block-determinant identity to the submatrix $$I_r$$, we obtain
                                         $$\det(M)=\det(\beta A- \alpha B)$$.
                                     On the other hand, we can swap rows and columns block-wise while preserving the determinant of the block-matrix, and apply the same identity to the top left block of
                                         $$\tilde{M}=\begin{pmatrix}  \beta A & \alpha L  \\ R^\top & I_r\\   \end{pmatrix}$$.
                                     Collecting powers of $$\beta$$, this yields
                                         $$\det(\tilde{M})=\beta^{n-r}\det(A)\det(\beta I_r-\alpha R^\top A^{-1}L)$$.
                                     This proves the lemma.
                     Reduction of Matrix Pencil Eigenspace to Matrix Eigenspace #slide #novel:proposition 
                         #proposition Given the regular matrix pencil $$A-\lambda LR^\top$$ and $$\det(A)\neq 0$$, define the matrix $$C=R^\top A^{-1}L$$. Then the following statements hold: 
                             If $$y\not\in \text{ker}\; L$$ is a right eigenvector of $$C$$ with eigenvalue $$\mu$$, $$A^{-1}Ly$$ is a right eigenvector of $$A-\lambda LR^\top$$ with eigenvalue $$[ \mu,1]_{\sim}$$.
                             If $$y$$ is a right eigenvector of $$A-\lambda LR^\top$$ with eigenvalue $$[\mu_2, \mu_1]_{\sim}$$ ($$\mu_1\neq 0$$), $$L^{-1}_RAy$$ is a right eigenvector of $$C$$ with eigenvalue $${\mu}_2/{\mu}_1$$. 
                     Proof of Proposition #slide 
                         The assertions can be verified by direct calculations. 
                     Results for Left Eigenvectors #slide #novel:proof 
                         Similarly, for left eigenvectors it holds:
                             If $$x_\mu^\top \not\in \text{ker}\; R^\top$$ is a left eigenvector of $$C$$ with eigenvalue $$\mu$$, $$x^\top R^\top A^{-1}$$ is a left eigenvector of $$A-\lambda LR^\top$$ with eigenvalue $$[1, \mu]_{\sim}$$. 
                             If $$y_\mu\not\in \text{ker}\; L$$ is a right eigenvector of $$A-\lambda LR^\top$$ with eigenvalue $$[\mu_2, \mu_1]_{\sim}$$ ($$\mu_2\neq 0$$), $$L^{-1}_RAy_\mu$$ is a right eigenvector of $$C$$ with eigenvalue $$\mu_1/\mu_2$$.  
                     On the Infinite Eigenvalue #slide #novel 
                         The algebraic multiplicity of the infinite eigenvalue of $$P(\lambda)$$ is $$m_\infty=r-\text{rank}(B)+m_0$$ where $$m_0$$ is the algebraic multiplicity of the eigenvalue $$\mu=0$$ of $$C$$. #lemma 
                         Proof:
                     Summary #slide 
                         The complete set of eigenvalues and corresponding eigenvectors of a regular matrix pencil $$A-\lambda B$$ can be determined as follows:
                             Assume $$B=LR^\top$$ is a full rank factorisation. 
                             Let $$k\in\R$$ such that $$A+kB$$ is invertible. 
                             Define the matrix $$C=R^\top (A+kB)^{-1}L$$. 
                         The eigensystem can then be derived from that of $$C$$:
                             The finite, nonzero eigenvalues of $$C$$ can be mapped into the finite eigenvalues of $$A-\lambda B$$,
                             The matrix eigenvalue zero corresponds to the infinite eigenvalue of the pencil.
                     Summarising Theorem #slide  #novel 
                         If $$B=LR^\top$$ is a full-rank factorisation and $$k\in \R$$ such that $$A+kB$$ is nonsingular, there is a one-to-one correspondence between eigenvalues and eigenvectors of $$A-\lambda B$$ and those of $$C=R^\top (A+kB)^{-1}L$$. For each right eigenvector $$y_\mu$$ of $$C$$ associated with an eigenvalue $$\mu$$ (left eigenvector $$x^\top_\mu$$ respectively), if $$A^{-1}Ly_\mu\neq 0$$, this vector is a right eigenvector (the vector $$x^\top_\mu R^\top A^{-1}\neq 0$$ is a left eigenvector respectively) of $$P(\lambda)$$ with finite eigenvalue $$\lambda=\mu^{-1}-k$$ if $$\mu\neq 0$$, and the infinite eigenvalue otherwise. #theorem
                     On Rank-1 Regular Matrix Pencils #h
                         Introduction #slide 
                             Consider a regular matrix pencil of the form $$A-\lambda B$$ where $$\text{rank}(B)=1$$. 
                             We call this a __rank-1 pencil__. 
                             We can write $$B=uv^\top$$ where $$u,v\in {\R_{\neq 0}}^n$$. 
                             Note that then $$\text{rank}(A) \ge n-1$$ (as otherwise $$\text{rank}(A-\mu B) < n-1+1 =n$$ for all $$\mu \in \R$$ and the pencil would not be regular).
                         Remarks #slide 
                             It is clear that the pencil has an eigenvalue at infinity with algebraic multiplicity $$m_\infty=n-1$$. 
                             The corresponding left and right eigenvectors are the elements of $$\text{ker}(B^\top)$$ and $$\text{ker}(B)$$.
                             Now the goal is to find the structure of the finite eigenspaces.
                         Eigenspace Structure Result #slide 
                             We define normalised left and right eigenvectors w.r.t. the factorisation of $$B$$ as eigenvectors satisfying $$x^\top u = 1$$ and $$y v^\top = 1$$. 
                             Structure theorem for finite eigenspace of rank-1 regular pencil:  #novel:theorem
                                 If $$v^\top \text{adj}(A) u=0$$, the pencil has no finite eigenvalues. 
                                 Otherwise, the pencil has a single finite eigenvalue $$c=\frac{\det(A)}{v^\top \text{adj}(A) u}$$.
                                 The associated left and right normalised eigenvectors $$x,y$$ can be determined as follows:
                                     $$x^\top=\frac{v^\top\text{adj}(A)}{v^\top \text{adj}(A) u}$$,
                                     $$y=\frac{\text{adj}(A)u}{v^\top \text{adj}(A) u}$$.
                         Proof of Theorem #slide #proof
                             It can directly be verified that, based on the definitions of $$c$$, $$x$$ and $$y$$ as in the theorem, that it holds $$Ay=cuv^\top y$$ and $$x^\top A=cx^\top uv^\top$$. 
                             So $$c$$ is an eigenvalue, and this must be the only one as the degree of the characteristic polynomial is one. 
                             Furthermore, it can be seen that $$x^\top$$ and $$y$$ are normalised eigenvectors.
                         Some Matrix-Adjoint Identities #slide #novel:proposition 
                             The previous results allow proving the following identities:
                             #proposition For $$a\in \R$$, the following holds:
                                 $$\det(A+a uv^\top)=\det(A)+ av^\top\text{adj}(A)u$$
                                 $$v^\top \;\text{adj}(A+a uv^\top)=v^\top\;\text{adj}(A)$$
                                 $$\text{adj}(A+a uv^\top)u=\text{adj}(A)u$$
                         Proof of Identities #slide 
                             Note that if $$v^\top\;\text{adj}(A)u= 0$$, it follows $$\det(A+a uv^\top)=\det(A)$$ and hence the identities are trivially fulfilled in this case.
                             Otherwise:
                                 It must hold $$\det(A+\lambda uv^\top)=b\lambda +\det(A)$$. 
                                 This is the characteristic polynomial. 
                                 Then we can solve for $$\lambda = -\frac{\det(A)}{b}$$. 
                                 Since $$-\lambda$$ is an eigenvalue, the previous theorem yields $$b=v^\top \text{adj}(A) u$$.
                             The other identities are immediate consequences of the fact that $$A-\lambda uv^\top$$ and $$(A+a uv^\top)-\lambda uv^\top$$ have the same eigenvectors for all real numbers $$a$$.
                         Remarks #slide 
                             The first identity is also known as __matrix determinant lemma__ in the literature \cite{}. 
                             The three identities generalise Karlin's well-known identities for computing optimal solutions of matrix games.
                             This is a pencil with $$B=E$$.
                     Irreducible Pencil #slide 
                         #proposition If the pencil is irreducible, the formulae as in Proposition \ref{} still apply.  
                         Proof
                             Being irreducible, the pencil is similar to either $$I-\lambda N$$ or $$J-\lambda I$$ where $$N$$ is a single nilpotent Jordan block and $$J$$ a single Jordan block with eigenvalue $$\mu\in\R$$. 
                             The case that needs examining is if $$A$$ singular, which corresponds to the latter with $$\mu=0$$. 
                             But then $$\text{rank}(A)=n-1$$, and there exist $$\tilde{u},\tilde{v}\in\R^n$$ such that $$\text{adj}(A)=\tilde{u}\tilde{v}^\top$$. 
                             Then $$x^\top=\tilde{v}^\top L$$, $$y=R\tilde{u}$$.
                         INBOX #h
                             The substitution $$\lambda \leftarrow \lambda+a$$ where $$a\in \R$$ adds $$a$$ to all finite eigenvalues and leaves their eigenvectors invariant. Without loss of generality, it can thus be assumed that $$\det(A)=f(0)=a\neq 0$$ and that $$A$$ be invertible. 
                             SPECIAL CASE #hh
                                 If the matrix $$A$$ is singular the previous results still hold subject to a rank condition. 
                                 #lemma The following identity holds for a square $$n \times n$$ matrix $$A$$ and $$n \times r$$ $$(r\le n)$$ matrices $$L$$, $$R$$: 
                                     $$(\det(A))^{r-1}\det(A+a LR^\top)=\det( \det(A)I_r+ aR^\top\text{adj}(A)L)$$ #novel 
                                     $$R^\top \;\text{adj}(A+a LR^\top)=R^\top\;\text{adj}(A)$$ #novel 
                                     $$\text{adj}(A+a LR^\top)L=\text{adj}(A)L$$ #novel 
                                         #proof 
                                     (ii) 
                                     #proof 
                                 #remark 
                                     Can be seen as a generalisation of the matrix determinant lemma in [,] to a singular matrix $$A$$.
                                     This is more compact than the result in [].
                                     In a simple form, it has already been stated in [] in the context of game theory.
                                 RANK A IS N-2 AND LESS #hh 
                                     #novel 
                             define the matrix $$C$$ as $$C=R^\top \text{adj}(A)L$$.
                             $$\text{rank}(A)=n$$ and $$x^\top=v^\top A^{-1}$$, $$y=A^{-1}u$$.
                     Conclusion #slide 
                     INBOX
                         #lemma The matrix $$uv^\top$$ has $$v^\top u$$ as an eigenvalue, with corresponding left and right eigenvectors $$v^\top$$ and $$u$$. If $$v^\top u=0$$, then $$uv^\top$$ is nilpotent. #novel 
                             #proof 
                         #theorem #novel Given the regular matrix pencil $$P(\lambda)= A-\lambda B$$ where $$B=LR^\top$$ and $$\det(A)\neq 0$$, define the matrix $$C=R^\top A^{-1}L$$. Then the following statements hold:
                             FINITE
                                 For each right eigenvector $$y_\mu$$ of $$C$$ associated with an eigenvalue $$\mu\neq 0$$ (left eigenvector $$x^\top_\mu$$ respectively), the vector $$A^{-1}Ly_\mu\neq 0$$ is a right eigenvector (the vector $$x^\top_\mu R^\top A^{-1}\neq 0$$ is a left eigenvector respectively) of $$P(\lambda)$$ with eigenvalue $$\lambda=\mu^{-1}$$.
                             INFINITE
                                 If the factorisation of $$B$$ is full-rank, the geometric multiplicity of the infinite eigenvalue of $$P(\lambda)$$ and that of $$\mu=0$$ as an eigenvalue of $$C$$ coincide. 
                         CASE A INVERTIBLE #hh 
                         #theorem 
                             The matrix pencil $$P(\lambda)$$ is irreducible iff the matrix $$C$$ is irreducible. 
                                 infty
                                     For corresponding unique eigenvectors y,z it holds #novel 
                     ARCHIVE
                         $$\deg(\det(I-\lambda LR^\top))\le \text{rank}(LR^\top)\le r$$
                         FINITE #hh 
                             In this case there is a one-to-one correspondence between finite eigenvalues and eigenvectors of the pencil, and that of a matrix of size $$r$$.
                             #proposition The finite eigenvalues of the regular matrix pencil $$P(\lambda)= A-\lambda B$$ where $$B=LR^\top$$ and $$\det(A)\neq 0$$ are the reciprocals of the non-zero eigenvalues of the matrix $$C=R^\top A^{-1}L$$. For each right eigenvector $$y_\mu$$ of $$C$$ associated with an eigenvalue $$\mu\neq 0$$ (left eigenvector $$x^\top_\mu$$ respectively), the vector $$A^{-1}Ly_\mu\neq 0$$ is a right eigenvector (the vector $$x^\top_\mu R^\top A^{-1}\neq 0$$ is a left eigenvector respectively) of $$P(\lambda)$$. #novel 
                                 #proof 
                                     The proof is constructive.
                                     Note that vectors $$A^{-1}Ly_\mu\neq 0$$ and $$x^\top_\mu R^\top A^{-1}\neq 0$$ as otherwise we would have $$\mu=0$$. 
                                     The set of finite eigenvalues can be seen to coincide with the reciprocals of the non-zero eigenvalues of $$C$$ using Lemma #ref:lemma:C-matrix
                         INFINITE #hh 
                             Note that if $$\deg(f)=0$$, since $$P(\lambda)$$ is a regular matrix pencil, we can see from its Weierstrass normal form that $$\det(A)\neq 0$$.
                             #proposition #label:infty If the regular matrix pencil $$P(\lambda)$$ as in the previous proposition has an infinite eigenvalue of multiplicity $$k$$, then zero is an eigenvalue of $$C$$ of multiplicity at least $$k$$. Corresponding eigenvectors can be computed from a suitable subset of $$k$$ eigenvectors of $$C$$, in a similar manner as in Proposition #ref:infty. #novel 
                                 #proof 
                             #proposition  If the factorisation of $$B$$ is full-rank, the multiplicity of the infinite eigenvalue of $$P(\lambda)$$ and that of 0 as an eigenvalue of $$C$$ coincide. #novel
                                 #proof 
                             #example Not full rank factorisation...
                         ARCHIVE #wfe-ignore-outline 
                             (i) $$(\det(A))^{r-1}\det(A-\lambda LR^\top)=\det( \det(A)I_r-\lambda R^\top\text{adj}(A)L)$$. #novel 
                 RFactor
                     (Franchi & Paruolo, 2011)
                         Achieves calculation of matrix invariants such as Jordan and Smith normal forms
                         Done through the computation of sequences of local rank factorisations 
                         Does apply to linear matrix pencils, where the Kronecker normal form is determined, and the Weierstra{\ss} normal form in the case of regular pencils.  
                         Local analysis requires the prior knowledge of eigenvalues 
             LA+EPF
                 Extended Perron-Frobenius Theory #EPF
                     Introduction #slide 
                         Background 
                         Context
                         Extended Perron-Frobenius Theory #slide #EPF 
                             Extended Perron-Frobenius Theory:
                                 Defining pertinent classes of matrices with spectral positivity and nonnegativity properties
                                 Find [necessary and] sufficient conditions for these properties to hold, based on inspecting matrix coefficients and performing elementary matrix operations
                             Recently:
                                 Generalising the theory to linear matrix pencils
                     TAXONOMY: EPF [NECESSARY & SUFFICIENT] CONDITIONS FOR SPECTRAL POSITIVITY PROPERTIES
                         Studied Matrix Pencils #slide 
                             $$A-\lambda I$$ #EPF:FMat #EPF:P #EPF:M #EPF:PF 
                             $$A-\lambda B$$ #EPF:FTrans #EPF:Mehr
                             $$A-\lambda E$$ #EPF:M 
                         Considered Properties of Interest #h 
                             General Matrix Properties #slide 
                                 Multiplicity of eigenvalue
                                     Simple eigenvalue #EPF:P #EPF:FTrans #Irr 
                                     Unique eigenvalue #EPF:FTrans #EPF:FMat
                                 Irreducibility #EPF:F #Irr 
                                 Nilpotency 
                             Spectral Positivity Properties #slide 
                                 Eigenvalues
                                     Positive eigenvalue #EPF:P #EPF:FTrans #EPF:FMat 
                                     Nonnegative eigenvalue #EPF:F 
                                     Dominant eigenvalue #EPF:P #EPF:F #EPF:PF 
                                         Strictly dominant eigenvalue #EPF:S 
                                     Eigenvalue(s) with positive real part #EPF 
                                     Eigenvalue(s) with dominant real part #EPF 
                                 Eigenvectors 
                                     Positive (right) eigenvector #EPF:P #EPF:F #EPF:FTrans #EPF:S #EPF:FMat #Irr 
                                         Unique
                                     Positive left eigenvector #EPF:FTrans #EPF:S #EPF:FMat 
                                         Unique
                                     Nonnegative (right) eigenvector #EPF:F #EPF:PF 
                                     Nonnegative left eigenvector
                             Published Named Properties
                                 Perron #EPF:P
                                 Frobenius #EPF:F
                                 PerronFrobenius Property #EPF:PF
                                 Weak Frobenius #EPF:W
                                 Strong Frobenius #EPF:S
                                 Left/Right PF #EPF
                                 Eventually PF #EPF
                                 PFn #EPF:PFn
                                     Following [16], we let PFn denote the collection ofnnreal matrices whose spectral radius is a simple positive and strictly dominant eigenvalue having positive left and right eigenvectors. 
                                     $$A$$ and $$A^\top$$ are Strong PF. #EPF:S  
                                     Equivalently, we can say that PFn is the collection of matrices such that bothAandATpossess the strong Perron-Frobenius property.
                                 WPFn #EPF:WPFn
                                     $$A$$ and $$A^\top$$ are PF. #EPF:WPFn 
                                     Following [16], Similarly, WPFn denotes the collection ofnnreal matrices whose spectral ra-dius is an eigenvalue having nonnegative left and right eigenvectors. 
                                     Equivalently,WPFn is the collection of matricesAsuch that bothAandATpossess the Perron-Frobenius property.
                         Published Sufficient Conditions #h 
                             Concepts #slide 
                                 Positive matrix #EPF:P 
                                 Nonnegative matrix #EPF:F 
                                 Eventually positive matrix
                                 Eventually nonnegative matrix
                                 Nilpotent matrix
                                 Irreducible matrix
                             Results in the Literature #h
                                 PERRON
                                     #theorem (Perrons Theorem). Let $$A$$ be a real positive square matrix. Then its spectral radius $$r=\rho(A)$$ is a simple, positive eigenvalue of $$A$$, and there is no other eigenvalue of the same modulus. Furthermore, there exists a corresponding positive right eigenvector $$y_r$$. #EPF:P
                                 FROBENIUS
                                     #theorem (Frobenius' Theorem). Let $$A$$ be a real nonnegative square matrix. Then $$r=\rho(A)\ge 0$$ is an eigenvalue of $$A$$, with a corresponding nonnegative right eigenvector $$y_r$$. If $$A$$ is an irreducible matrix, then $$y_r$$ is positive. #EPF:F #EPF:PF SIMPLE?? #todo 
                                 MINKOWSKI & RAGHAVAN
                                     M-MATRIX
                                         #theorem Let $$A$$ be an invertible $$M$$-Matrix. Then it holds #EPF:M 
                                             The matrix $$A^{-1}$$ has the Frobenius property. 
                                             Assume the pencil $$A-\lambda E$$ is regular. Then it has the Frobenius property. 
                                             The matrix game $$G(A)$$ is completely mixed. 
                                 UZAWA
                                     F-MATRIX 
                                         #EPF:FMat
                                 ELHASHASH & SZYLD
                                     #theorem Eventually nonnegative matrix #EPF:EV
                                 DRANDAKIS 
                                     F-TRANSFORMATIONS #EPF:FTrans
                                 MEHRMANN
                                     #EPF:Mehr
                     AUTHORS/REFERENCES
                         GENERAL PROPERTIES OF EVENTUALLY NONNEGATIVE MATRICES
                             Zaslavsky, McDonald, and Tam [31], [32] studied the Jordan form of eventuallynonnegative matrices. 
                             Carnochan Naqvi and McDonald [5] studied combinatorialproperties of eventually nonnegative matrices whose index is 0 or 1 by consideringtheir Frobenius normal forms. 
                         DOMINANT EV
                             Friedland [8] showed that for eventually nonnegative matrices the spectral radius is an eigenvalue. 
                                 Such an eigenvalue and any other eigenvalue whose modulus is equalto the spectral radius is called adominanteigenvalue. Furthermore, if a matrix hasonly one dominant eigenvalue (regardless of its multiplicity), then we call such aneigenvaluestrictly dominant.
                                 Eschenbach and Johnson [7] studied sign patterns of a matrix requiring the spectral radius to be an eigenvalue. They called such a propertythePerron property. 
                             We mention in passing the work of Rump [23], [24], who generalized the conceptof a positive dominant eigenvalue, but this is not related to the questions addressedin this paper.
                         EARLIER
                             Other earlier papers looking at issues relating to the spectralradius being an eigenvalue, at positive or nonnegative corresponding eigenvector, orat matrices with these properties,
                                  include [11], [12], [13], [16], [17], [19], [26], [27], [29].
                         EXTENDED PERRON PROPERTIES 
                             Different nomenclature for different Perron properties appear in the literature.In [7], as we already mentioned, thePerron propertystands for having the spectralradius as an eigenvalue, whereas, in [11] theweak Perron propertystands for havingthe spectral radius as a simple positive and strictly dominant eigenvalue. 
                             In [19],thePerron-Frobenius  propertystands for having the spectral radius as a positiveeigenvalue with a nonnegative eigenvector; this is also the definition used in [6].
                              Onthe other hand, in this paper we say that a real matrixApossesses thePerron-Frobenius propertyif(A) (whether it is zero or positive) is an eigenvalue ofAhavinga nonnegative eigenvector (which is the same as the definition introduced in [29]).
                                 Moreover, we say thatApossesses thestrong Perron-Frobenius propertyifAhas asimple, positive, and strictly dominant eigenvalue with a positive eigenvector (whichis the same as the definition introduced in [19]).
                 Extensions of the Perron-Frobenius theory to regular matrix pencils. #strand #EPF #novel:slow 
                     Introduction #slide
                         Background:
                         Context:
                         Motivation:
                     Contributions/Novelty #slide 
                     Notations #slide 
                     Perron-Frobenius Properties #slide 
                         Definition
                         Definition
                     Definition of Lambda-Matrix #slide #novel:definition 
                         For a regular matrix pencil $$A-\lambda B$$ with a rank-factorisation $$B=LR^\top$$ we define the $$r\times r$$ matrix $$\Lambda:=R^\top \text{adj}(A)L$$. #definition 
                     Well-Defined Lemma #novel:lemma 
                         Lemma.
                         The $$\Lambda$$-matrices obtained from different rank-factorisations of the same matrix $$B$$ are related to each other through application of suitable similarity transformations. 
                         Proof.
                         If $$B=L_1 R_1^\top =L_2 R_2^\top$$, then $$\Lambda_1\sim \Lambda_2$$.
                             \cite{Piziak1999-iu}
                         Lemma.
                         Two equivalent regular matrix pencils have all their associated $$\Lambda$$-matrices being similar.  
                         Proof.
                             If $$A-\lambda B \sim \tilde{A}-\lambda \tilde{B} $$, then $$\Lambda=\tilde{\Lambda}$$.
                                 $$\tilde{A}=SAT$$
                                 $$\tilde{B}=SBT=SLR^\top T=\tilde{L}\tilde{R}^\top$$
                                 $$\tilde{\Lambda}:=R^\top T \text{adj}(SAT)SL = R^\top T T^{-1}\text{adj}(A)S^{-1}SL=R^\top \text{adj}(A)L=\Lambda$$
                         SCREENSHOT
                             ![Lambda-Mat.png](https://dynalist.io/u/8KZtLlw6t7Ml6N_uyxIQTMvE)
                     Strong EPF Theorem #slide #novel:theorem 
                         If $$[A^{-1}?],L, R > 0$$ and $$\Lambda$$ has the strong PF property, then the regular matrix pencil $$A-\lambda LR^\top$$ has the strong PF property. 
                         If $$A,L_R^{-1}, R_R^{-1} > 0$$ and the regular matrix pencil $$A-\lambda LR^\top$$ has the strong PF property, then $$\Lambda$$ has the strong PF property.
                         If $$A,L,R>0$$ are inverse positive, then: the pencil has the strong PF property iff $$\Lambda$$ has the strong PF property. 
                             #theorem 
                     Proof of Theorem #slide 
                         Due to the definition of the $$\Lambda$$-matrix, we have
                             $$R^\top \text{adj}(A)L\cdot\Lambda=\det(R\top \text{adj}(A)L)\cdot I_r$$ #label:Lambda
                         We will denote $$\mu := \det(R^\top \text{adj}(A)L)$$ for ease of notation.
                         Let $$y>0$$ such that $$\Lambda y=\lambda y$$. We will assert that from this, we can derive a positive eigenvector for the pencil #label:the-pencil, for a suitable eigenvalue.
                          Define $$\tilde{y}= \text{adj}(A)Ly$$. Then we obtain
                             $$A \tilde{y}=A\; \text{adj}(A)Ly=\det(A)Ly$$. 
                         Furthermore, using #label:Lambda 
                             $$\mu y=R^\top \text{adj}(A)L\cdot \Lambda y=R^\top \text{adj}(A)L\cdot \lambda y$$.
                         Hence, putting this together, 
                             $$\mu A \tilde{y}=\det(A)LR^\top \text{adj}(A)L\cdot \lambda y=\det(A)\lambda B\tilde{y}\Longleftrightarrow (\mu A-\det(A)\lambda B)\tilde{y}=0$$.
                         We now distinguish three cases:
                             (i) Case $$\mu\neq 0, \det(A) \neq 0$$:
                                 We can see that $$\frac{\det(A)\lambda}{\mu}$$ is a finite nonzero eigenvalue, with positive eigenvector $$\tilde{y}$$.
                             (ii) Case $$\mu = 0, \det(A) \neq 0$$:
                                 In this case, we can see that $$\tilde{y}$$ is a positive eigenvector for an infinite eigenvalue. 
                             (iii) Case $$\mu \neq 0, \det(A) = 0$$:
                                 Consider $$a \neq 0$$ chosen so that $$\det(A + aLR^\top) \neq 0$$. 
                                 [..]
                                 This can be treated by Case (i) for the pencil $$A+ aLR^\top-\lambda LR^\top$$.
                                 Finally, we obtain that $$\tilde{y}$$ is a positive eigenvector for the eigenvalue $$0$$.
                             (iv) Case $$\mu = 0, \det(A) = 0$$:
                     Weak EPF Theorem #slide #novel:theorem 
                         [If $$A, L, R \ge 0$$, $$A$$ is irreducible and $$\Lambda$$ has the weak PF property, then the regular matrix pencil $$A-\lambda LR^\top$$ has the weak PF property.]
                     Proof of Theorem #slide 
                     Application: Game Theory #slide #novel:application 
                         The pencil is $$A-\lambda E$$.
                         Strong EPF => cm
                         Weak EPF => lag-free sols
                         Raghavaran
                     Application: Optimisation #slide #novel:application 
                         MC2 
                     Application: Economics #slide #novel:application 
                         Von Neumann Economical Growth Model
                             The pencil is $$A-\lambda E$$.
                             Strong EPF => cm
                             Weak EPF => lag-free sols
                             Giorgi
                     INBOX
                         The pencil is PF in the sense of Mehrmann et al if and only  it is..
                         Totally Positive Theorem #slide 
                             Let $$A-\lambda B$$ be totally positive. The it has the PF-property. #theorem 
             LA+M-Mat #m-mat 
                 Background
                     M-Matrices and other special nonnegative matrices
                 Generalisations of the notion of M- [Minkowski-Leontief-] matrices, based on matrix pencils #GMP #novel:slow 
                     Introduction #slide
                         Context:
                         Motivation:
                             Has not been done for pencils yet
                     Contributions/Novelty #slide 
                     Notations #slide 
                     Motivation
                     MP-Matrix Definition #slide #novel:definition add infinite EV
                         A square matrix $$A$$ admitting a splitting of the form $$A=sC-tB$$ where $$B,C>0$$ is called an $$MP$$-Matrix, if it is an $$MP$$-Matrix of the finite type, or an $$MP$$-Matrix of the infinite type.
                         $$A$$ is called an $$MP$$-Matrix of the finite type, if $$s\ge 0$$, $$t>0$$ such that 
                             $$B-\lambda C$$ is a regular matrix pencil which has the finite PF property,
                             $$\frac{s}{t}\ge \rho_0(B-\lambda C)$$.
                         If $$\frac{s}{t}> \rho(B-\lambda C)$$, then $$A$$ is called a non-singular $$MP$$-Matrix. Otherwise, it is referred to as a singular $$MP$$-Matrix.
                     Interpretation as Pencils #slide 
                         Interpret as matrix pencil
                             $$(B-sI)-\lambda I=:P(\lambda)$$
                         This can be defined for a general regular matrix pencil $$P(\lambda)=B-\lambda C$$ 
                             Non-singular $$M$$-Pencil: $$(sC-tB)-\lambda C$$ where $${s}/{t}>\rho(B-\lambda C)$$ 
                                 and $$B-\lambda C$$ has the strong Perron-Frobenius property.
                     MP-Matrix Properties #slide #novel 
                         totally positive
                         positive principal minors
                         all eigenvalues have positive real part
                     MP-Matrix and M-Matrix Relationship #slide #novel 
                         The matrix $$sA-tLR^\top$$ where $$A$$ is non-singular and $$L,R>0$$ are full rank matrices is an ML-matrix iff the matrix $$st^{-1} I-R^\top A^{-1}L$$ is an M-Matrix. 
                     Assume $$A$$ is an $$M$$-Matrix. Then $$A-\lambda B$$ has the XYZ-property for all $$B$$. 
                     Assume $$L,R>0$$. Then the pencil $$A-\lambda LR^\top$$ is an $$F$$-pencil iff the matrix $$R^\top A^{-1}L$$ is an $$F$$-matrix. 
                     GM-Matrix
                 Estimate for eigenvalues of $M$-Matrices #m-mat 
                 Further characterisations of F-Transformations based on M-Matrices
                     The Easy Result #slide #m-mat #VNM #eigen
                         Suppose the matrix $$A/B$$ ($$A \ge 0, B>0$$) is an $$M$$-Matrix. Then the pencil $$A-\lambda B$$ is an $$F$$-pencil and its nonnegative left (right resp.) generalised eigenvector is positive. #proposition 
                     Proof #slide 
                     Example #slide 
                     The Hard Result #slide #m-mat #VNM #eigen
                         Suppose the matrix $$A/B$$ ($$A \ge 0, B \ge 0$$, we define $$\infty:=a/0$$, 0/0 not allowed) is an $$M$$-Matrix. Then the pencil $$A-\lambda B$$ is an $$F$$-pencil and its nonnegative left- and right generalised eigenvectors are positive. #proposition 
                             0/0?
                             
         Prob
             Background
             Markov+Bilinear
         Risk
             Notations -- Linear #slide 
                 DEFENDED ASSET
                     $$a$$: asset
                     $$v$$: vulnerability
                     $$e$$: exploitability of vulnerability [MAEVA]
                 RISK
                     $$R=p\cdot I$$
                         $$R$$: risk
                         $$p$$: attack likelihood
                         $$I$$: impact
                 ATTACKER
                     $$S$$: Risk source
                     $$\theta$$: threat 
                     $$E$$: event 
                 ATTACK INCENTIVE
                     $$A=\nu\cdot V$$
                         $$A$$: attack incentive
                         $$\nu$$: visibility of asset [MAEVA]
                         $$V$$: value of asset
             Notations - Hierarchical #slide 
                 DEFENDER
                     HAS
                         $$a$$: asset
                             $$v$$: vulnerability
                                 [$$e$$: exploitability of vulnerability [MAEVA]]
                     RISK
                         $$R=p\cdot I$$
                             $$R$$: risk
                             $$p$$: attack likelihood
                             $$I$$: impact
                 ATTACKER
                     IS
                         $$\theta$$: threat 
                         $$S$$: Risk source
                             $$E$$: event 
                     ATTACK INCENTIVE
                         $$A=\nu\cdot V$$
                             $$A$$: attack incentive
                             $$\nu$$: visibility of asset [MAEVA]
                             $$V$$: value of asset
             VA
                 CVSS+DREAD #slide 
                     BASE
                         $$\mu_{Base} = M_{Base}(\mu_{Imp},\mu_{Exp},\mu_{Dis})$$
                             IMPACT
                                 $$\mu_{Imp} = M_{Imp}(\mu_{CIA},\mu_{\overline{CIA}})$$
                             EXPLOITABILITY
                                 $$\mu_{Exp}(v_i) = M_{Exp}(\mu_{Exp}(v_i),\mu_{Exp}(v_{i+1}))$$
                             DISCOVERY
                                 $$\mu_{Dis}(v_i) = M_{Dis}(\mu_{Dis}(v_i),\mu_{Dis}(v_{i+1}))$$
                         ASSET PAIR $$a=(a_i,a_{i+1})$$
                             INDEPENDENT
                             DEPENDENT (CHAIN) , v=(v_i,v_{i+1})$$
                                 DEPENDEND/DIRECT/INTERNAL/SERIES
                                     IMPACT
                                         $$\mu_{Imp}(v) = \mu_{Imp}(v_i)$$
                                         $$\mu_{\overline{CIA}}(v_i)=\mu_{Imp}(v_{i+1})$$
                                         $$\mu_{Imp}(v_i) = M_{Imp}(\mu_{CIA}(v_i),\mu_{Imp}(v_{i+1}))$$
                                     EXPLOITABILITY
                                     DISCOVERY
                                 INDEPENDENT/INDIRECT/EXTERNAL/PARALLELL
                                     IMPACT
                                         [$$\mu_{\overline{CIA}}(v_i)=0$$]
                                         $$\mu_{Imp}(v) = \mu_{Imp}(v_i)+\mu_{Imp}(v_{i+1})$$
                                     EXPLOITABILITY
                                         $$\mu_{Exp}(v) < \mu_{Exp}(v_i)+\mu_{Exp}(v_{i+1})$$
                                     DISCOVERY
                 Open Data Framework
                     Risk -- Equations #slide 
                         $$R=p\cdot I$$
                         $$p=p(e,\nu,V)$$
                         $$I = I(v,V)$$
                         Open Data 
                             $$o$$: Open Data (primary) asset
                         IMAGE
                              ![Pasted image](https://dynalist.io/u/5F6uC_TtvqWeCZsljZYnPvzx) 
             RA
         SS
             SS+Matrix
                 Matrix-based Space-Efficient Online Secret Sharing: A Contribution
                     Introduction #slide
                         Background:
                         Context:
                         Motivation:
                     Contributions/Novelty #slide 
                     Notations #slide 
                     Background #slide 
                         The probabilistic algorithm for secret matrix share size reduction by \cite{Pfluegel2013-as}:
                             Inspired by previous matrix-based work, but avoid Jordan normal form
                             Propose a probabilistic algorithm, based on using companion form
                             We achieve similarly short shares as Yang and Zhao, but are more efficient
                             This yields a probabilistic online secret sharing scheme with small expected share size
                     Linear Algebra Concepts #slide 
                         Let us review some linear algebra concepts that will be used in the sequel.
                         Let $$A \in \mathbbm{F}_p^{t \times t}$$. The matrix $$A$$ is \emph{cyclic} iff it is similar to matrix in {\em companion form}
                             $$C =\left(\begin{array}{ccccc}0 & 1 & 0 & \ldots & 0 \\0 & 0 & 1 & \ddots & \vdots \\\vdots & \vdots & \ddots & \ddots & 0 \\0 & 0 & \ldots & 0 & 1 \\c_{0} & c_{1} & \ldots & c_{t-2} & c_{t-1} \\\end{array}\right)$$.
                         Here, we have that
                             $$f (\lambda) = \lambda^{t} - c_{t-1} \lambda^{t-1} - \cdots- c_{1} \lambda - c_{0}$$
                         is the characteristic polynomial of $$C$$. 
                         For a cyclic matrix, we have that 
                             $$f(\lambda) = \det(C- \lambda I) = \det(A- \lambda I) = m(\lambda)$$ 
                         where $$m(\lambda)$$ is the minimal polynomial of $$A$$.
                     Cyclic Vectors and a Probability Result #slide 
                         If $$A$$ is cyclic, we can use standard linear algebra techniques  to compute $$C$$
                         Algorithm Cyclic\_Vector($$A$$)
                             [(1)] $$v_0:=$$ random vector
                             [(2)] {\bf for} $$i=1$$ {\bf to} $$t-1$$: compute $$v_i:=v_{i-1}A$$
                             [(3)] {\bf if} $$v_0, \ldots, v_{t-1}$$ are linearly independent {\bf then return} \emph{$$v_0$$} {\bf else return} {\em FAIL}
                     Research Question #slide 
                         Question: given a secret $$s$$, and a randomly chosen prime number $$p$$, we can convert $$s$$ to a matrix. How likely is this to induce a random cyclic matrix?
                         \begin{proposition}[Neumann et al., 1994]
                         If a matrix $$A$$ and a vector $$v$$ are chosen at random, then the probability that $$A$$ is cyclic and $$v$$ is a cyclic vector for $$A$$ is $$(1-p^{-1})(1-p^{-2})\cdots(1-p^{-t}) $$ .
                         \end{proposition}
                     Matrix Share Size Reduction Algorithm #slide 
                         This probabilistic algorithm splits secret $$s$$ into public part $$P$$ and (short) secret part $$Q$$
                         We use repeated matrix conversion, with increasing prime numbers
                         Algorithm MSSR($$s$$)
                             [(1)] $$p:=2$$
                             [(2)] /* Conversion of secret */
                                 [(a)] $$p:=$$ next\_prime$$(p)$$
                                 [(b)] Compute the base-$$p$$ digits of $$s$$
                                 [(c)] Convert secret $$s$$ into a $$t \times t$$ matrix $$S$$ by using these digits (padding with 0 if necessary)
                             [(3)] /* Size reduction step */
                                 [(a)] Attempt to compute cyclic vector $$v$$
                                 [(b)] If not successful, go to Step (2)
                                 [(c)] Construct similarity transformation $$T$$ such that $$C := T^{-1}S T$$ is a companion matrix
                             [(4)] Put $$P := T$$ and $$Q := [c_0, c_1, \ldots, c_{t-1}, p]$$
                     An Online Secret Sharing Scheme #slide 
                         We use the MSSR algorithm for an online secret sharing scheme with public and secret data
                         {Share creation}:
                             Compute $$P$$ and $$Q$$ using MSSR algorithm
                             Publish $$P$$
                             Share $$Q$$, using any space efficient secret sharing scheme
                         {Reconstruction of secret}:
                             Reconstruct the characteristic polynomial $$f$$ and the value of $$p$$ by acquiring at least $$k$$ shares
                             Build $$C$$ from the $$t$$ coefficients of $$f$$
                             Compute $$S$$ from $$C$$, by using the public transformation $$T$$ as $$S = T C T ^{-1}$$
                             Reconstruct $$s$$ from $$S$$ and $$p$$
             SS+Pre
             SS+Space
                 Space-efficient Secret Sharing for Constrained Channels #h 
                     Introduction #slide
                         Background:
                         Context:
                         Motivation:
                     Contributions/Novelty #slide 
                     Notations #slide 
                     Basic Idea #slide 
                     Simplified Version of \cite{CMI} #slide 
                     Closer to \cite{CMI} #slide 
                     Pertinent Points of \cite{CMI} #slide 
             SS+Stego
         Stego
             Background 
             Stego+Security
                 Litmap
                      ![Pasted image](https://dynalist.io/u/EXmYFHEDRMLNe7QoVtiO1z6K) 
                      ![Pasted image](https://dynalist.io/u/3Wv-ZAM5q7AKaArI314FVZFq) 
                     
             Stego+GT
             Stego+Adaptive
         Tropical Reduction
         Von Neumann Model Theory (VNM)
     BY DOMAIN
         Strand 0
             LA
             Simplex
             Nonnegative Matrices
             Formal Reduction
         Strand 1
             VNM
             GT
             CA
             Risk
             OaG
         Strand 2
             BC
             SS
             Stego
         Strand 3
             Edu
                 NCSC
                 ACE
                 NIS
                 CyBOK
                     Mapping
                 ZOOs