Knowledge
     By My Novelty
     BY TAG
         #AI #productivity #VNM
             NOVELTY
                 DIGITAL PRODUCTIVITY -- KNOWLEDGE WORK + VNM
                 AI + DIGITAL PRODUCTIVITY -- KNOWLEDGE WORK + VNM
         #econ #security #VNM
             BACKGROUND
                 Mathematical Economics
                 Security Economics
                 Von Neumann Economic Model
             NOVELTY
                 MROI AND MROMI
         #LA
         #RA 
             MAEVA #slide 
                 __Motive__: the underlying reason for attacking the victim. 
                     This could be for the purposes of financial gains, revenge, personal satisfaction or thrill, or simply with the intention of creating damage. From a psychological point of view, the attacker's motive might affect the perceived gain, as well as the appreciation of the effort required.
                 __Ability__: the capability of the attacker to invest in resources for implementing the attack, as well as the technical knowledge available for breaching cyber security controls. 
                     A strong ability will make it easier to spend effort on the attack, and subjectively reducing the perceived value of $e$.
                 __Exploitability__: the ease by which the system can be penetrated, through exploiting a vulnerability. 
                     It would be reasonable to expect exploitability and effort to be inversely related in a proportional manner. This category could be explored similarly as in the CVSS exploitability score, taking into account possible attack vectors and attack complexities, as well as the required privileges and interaction with users, however, the discussion should not be restricted to software vulnerabilities alone.
                 __Visibility of target__: how prominent is the target, for example, does it have a popular website or brand name, does it have a large user base? 
                     Great visibility might promise a big gain, in the eyes of the attacker.
                 __Attractiveness of target__: from the point of view of the attacker, how attractive is the target? 
                     This is linked to how much gain the attacker would estimate from achieving through the attack, and will strongly depend on the specific motive, as discussed in the first category.
         #simplex #VNM 
             Background
             Simplex+Dual+MC2
                 Background and Context #slide 
                     The Dual Simplex Method 
                     MC2 Linear Programs
                 MC2 Linear Program Formulation #slide 
                     MC2 LP:
                         Consider
                             "$$\max C^\top y+d$$" subject to "$$Ay\le B$$" and $$y\ge 0$$ ($$d>0$$). 
                         This means
                             $$\exist\, x,y^0\ge 0:\; z=x(C^\top y + d)$$ maximal s.t. $$Ay \le By^o,\; y\ge 0$$.
                         Here:
                             Multiple objectives: $$C$$
                             Multiple constraints: $$B$$
                 Necessary Conditions: Augmented Form #slide 
                     We view the linear system of inequalities used in the MC2 LP as a system of linear matrix equations.
                     This can be written using non-basic and basic variables as
                         $$Ay+\hat{y}=By^o$$
                         $$x^o(C^\top y+d)=v$$
                     where $$y\ge 0,\hat{y}\ge 0,y^o\ge 0$$.
                 Constructing A Basic Solution #slide 
                     We can construct a basic solution that may be infeasible, or not even real, given as follows:
                         Let $$\lambda\neq 0$$ be an eigenvalue of $$D$$ with corresponding eigenvectors $$\hat{x}^\top, \hat{y}$$ and define $$\hat{v}=1/\lambda$$. 
                         Subject to the substitution $$A\leftarrow A+aD$$ for a suitable positive real number $$a$$ we can assume $$\Re(\hat{v})>0$$. 
                         Then $$(\hat{v},\hat{x}^\top, \hat{y})$$ is a generalised eigensystem of $$I-\lambda{D}$$. 
                         Set $$x^o=\hat{x}B$$, $$y=0$$, $$v=x^od$$ and $$y^o=C^\top \hat{y}$$.
                 Sufficient Conditions for Feasible Basic Solution #slide 
                 Tableau Notation #slide 
                     The classical compact tableau notation is expanded as follows:
                         $$\begin{array}{|c|c|c|} \hline A & I & B\\ \hline C^\top & 0 & V\\ \hline \end{array}$$
                     The dual tableau is:
                         $$\begin{array}{|c|c|} \hline A  & B\\ \hline I  & 0 \\ \hline C^\top  & V\\ \hline \end{array}$$
                 Pivot Step #slide 
             Simplex+Params
             Simplex+Pencils
                 A novel multi-criteria dual simplex method based on matrix pencils. #MPS #h #slide #novel:algorithm #novel:slow
                     The Method #h 
                         Background and Context #slide 
                             The Dual Simplex Method 
                         Intro #slide 
                             The algorithm views the linear system of equations used in the dual simplex method as a bilinear linear matrix pencil equation. 
                             This can be written using non-basic and basic variables as
                                 $$x^\top(A-vD)y+\hat{x}\hat{y}=0$$
                                     $$x^\top(A-vD)y+\hat{x}^\top(I-\hat{v}{D})\hat{y}=0$$ #wfe-ignore-item 
                             where $$x\ge 0,\hat{x}\ge 0,y\ge 0,\hat{y}\ge 0$$.
                         View as Linear Matrix Pencil Equation #slide 
                             Setting #simplex:augmented 
                                 Canonical form can be written as
                                     $$x^\top(A-vbc^\top)y+\hat{x}^\top(\alpha I-{\beta}{bc^\top})\hat{y}=0$$
                                 where $$x\ge 0,\hat{x}\ge 0,\hat{y}\ge 0$$.
                             Assumptions
                                 The matrix pencil $$A-\lambda {bc^\top}$$ is regular.
                                 The unique finite eigenvalue of this regular matrix pencil is positive. 
                                 Note: this excludes the case where $$bc^\top$$ is nilpotent.
                         Relationships and Assumptions #slide 
                             $$A$$ is invertible
                             $$D=BC^\top$$ rank-factorisation
                             $$A-\lambda D$$ is a regular matrix pencil
                             Assumption: $$D$$ is not nilpotent 
                             $$V=C^\top A^{-1}B$$
                         Tableau Notation #slide 
                             We extend the classical compact tableau notation as follows:
                                 $$\begin{array}{|c|c|} \hline A & B\\ \hline C^\top & V\\ \hline \end{array}$$
                             The expanded tableau is:
                                 $$\begin{array}{|c|c|c|} \hline A & I & B\\ \hline I & 0 & 0 \\ \hline C^\top & 0 & V\\ \hline \end{array}$$
                         Initialisation #slide #simplex:init 
                             We start with $$x=y=0$$, $$v=0$$ and a basic solution that may be infeasible, given as follows:
                                 Let $$\lambda\neq 0$$ be an eigenvalue of $$D$$ with corresponding eigenvectors $$\hat{x}^\top, \hat{y}$$ and define $$\hat{v}=1/\lambda$$. 
                                 Then $$(\hat{v},\hat{x}^\top, \hat{y})$$ is a generalised eigensystem of $$I-\lambda{D}$$. 
                                 Subject to the substitution $$A\leftarrow A+aD$$ for a suitable real number $$a$$ we can assume $$\hat{v}>0$$. 
                         Reduction Step (I) #slide #simplex:pivot 
                             We partition the matrix $$A$$ into $$rs$$ blocks ($$1\le r \le m$$, $$1\le s \le n$$), with matching row and column dimensions:
                                 $$A=\begin{pmatrix} A_{11} & \cdots & A_{1j} & \cdots & A_{1s} \\ \vdots &  & \vdots &  & \vdots \\ A_{i1} & \cdots & A_{ij} & \cdots & A_{is} \\ \vdots &  & \vdots &  & \vdots \\A_{r1} & \cdots & A_{rj} & \cdots & A_{rs} \\ \end{pmatrix}$$
                             Let $$B$$ and $$C^\top$$ be partitioned accordingly
                             We can pick a block-index pair $$(i,j)$$ as block-pivot, if $$A_{ij}$$ is square and $$A_{ij}-\lambda B_{ij}C_{ij}^\top$$ is a regular matrix pencil with at least one real, positive eigenvalue $$\mu$$ and corresponding eigenvectors $$x^\top_\mu, y_\mu$$ that are not both nonnegative
                         Reduction Step (II) #slide #simplex:pivot 
                             Primal (Row/Left-Multiplication)
                                 The new matrices $$\tilde{A}$$ and $$\tilde{B}$$ are obtained through left-multiplication of a suitable matrix $$P$$ and swapping basic and non-basic variables
                             Dual (Column/Row-Multiplication)
                                 The new matrices $$\tilde{A}$$ and $$\tilde{C}$$ are obtained through right-multiplication of a suitable matrix $$Q$$ and swapping basic and non-basic variables
                         Reduction Step (III) #slide #simplex:pivot 
                             One has
                                 $$\tilde{A}_{ij}=$$
                                 $$\tilde{R}_i=$$
                                 $$\tilde{C}^\top_j=$$
                                 $$\tilde{V}=V-Q^\top A^{-1}P$$
                         Normalisation Step #slide 
                             
                         Termination #slide 
                             $$D=LR^\top$$, $$L,R^\top\ge 0, A^{-1}L\ge 0, R^\top A^{-1}\ge 0 \Rightarrow A-vD$$ has a nonnegative eigenvalue and semipositive eigenvector. 
                         Theorem.
                         The following statements are equivalent:
                             $$A_{11}-\lambda B_{11}$$ is an active / Thompson-Weil sub-pencil
                             algebraic formulation
                             The block-pivot
                     The Algorithm #h 
                     Evaluation and Applications #h 
                         Matrix Games #h 
                             Use of regular matrix pencils is latent but not mentioned in algorithmic context
                             Use of sub matrices 
                         The problem of computing the maximal growth order of a rank-$$r$$ linear matrix pencil is equivalent to solving a dual rank-$$r$$ multiple-criteria multiple-constraints (MC$$^2$$) linear program. 
                         The problem of computing the maximal slope of a rank-1 linear matrix pencil is equivalent to solving a dual linear program. 
         #m-mat #VNM
         #VNM 
             A Complete Analysis of 2x2 Strategic VNM Model Solutions #h #novel 
                 $$(P,A)$$
                 $$A-\lambda P$$
                 CASE SINGULAR PENCIL
                     For $$P=E$$ this is the trivial case as referred to on Moulin
                 CASE REGULAR PENCIL
                     CASE DET P = 1
                     CASE DET P = 2
             NOVEL APPLICATIONS
                 CA
                 GT+Grey
                 GT+Stochastic
                 Markov+Bilinear+Security
                     State Transitions #slide 
                         ![Pasted image](https://dynalist.io/u/L7qeIgCxFCJEAsajwBc3QSsf) 
                     Transition Matrices #slide 
                         These are
                             $$D=\begin{pmatrix}  d_{11}&d_{12} \\ d_{21} &d_{22}  \\  \end{pmatrix}$$
                             $$A=\begin{pmatrix}  a_{11}&a_{12} \\ a_{21} &a_{22}  \\  \end{pmatrix}$$
                         Written as linear matrix pencil: $$D-\lambda A$$.
                 Risk+ROI
                     Background
             INBOX
                 Incomplete Algorithm #slide 
                     **algorithm** matrix_game_solve_incomplete$$(A)$$
                         **if** $$({e^T{\rm adj}( A)e}\neq 0)$$ **then**
                             $$v := \frac{\det(A)} {e^T{\rm adj}( A)e}$$;
                             **if** $$\neg (e^T{\rm adj}( A)= 0 \wedge {{\rm adj}( A)e}=0)$$ **then**  
                                 $$x:=\frac{e^T{\rm adj}(A)} {e^T{\rm adj}( A)e}$$
                                 $$y:=\frac{{\rm adj}(A)e} {e^T{\rm adj}( A)e}$$
                                 **if** $$x\ge 0$$ **and** $$y\ge 0$$ **then** **return**($$v$$, $$x$$, $$y$$);
                             **fi**; 
                         **fi**; 
                         **return**(FAIL);
                     **end**;
                 After studying the different definitions the author decided to focus on a geometric meaning that is easy to illustrate 
                 VON NEUMANN MODEL
                     #signpost
                     Yet another Matrix Determinant Lemma #novel:theorem 
                         It holds
                             $$(\det(A))^{r-1}\det(A+a LR^\top)=\det( \det(A)I_r+ aR^\top\text{adj}(A)L)$$ 
                             $$R^\top \;\text{adj}(A+a LR^\top)=R^\top\;\text{adj}(A)$$ 
                             $$\text{adj}(A+a LR^\top)L=\text{adj}(A)L$$ 
                     Even if $$L\;\text{adj}(A)R^\top= 0$$!
                     GAME THEORY
                         #signpost
                         #theorem If $$e\;\text{adj}(A)e^\top\neq  0$$, the following identities hold:
                             $$\det(A+a )=\det(A)+ ae^\top\text{adj}(A)e$$ #novel 
                             $$e^\top \;\text{adj}(A+a )=e^\top\;\text{adj}(A)$$ #novel 
                             $$\text{adj}(A+a )e=\text{adj}(A)e$$ #novel 
     BY TITLE
         A novel von Neumann model reduction algorithm based on linear matrix pencils. #MPS #h #slide #novel:algorithm #novel #novel:slow #VNM #simplex
             Pencil Perturbation Approach #slide 
                 Instead of submatrices, we can consider perturbations of the given matrix pencil
             Reduction Algorithm #h
                 
                 On the equivalence of rank-$$k$$ VN Models and MC2 optimisation. #h 
                     STATUS
                     Background
                         https://dynalist.io/d/gcskC8EanDTKsGE-U8yP7HPC#z=NtPJeQOOEbhDA2xgUzbz8UVK
                     LP Equivalence Theorem #slide 
                         Consider the model VNM($$D,A$$) where $$D=BC^\top \geqq 0$$.
                         We refer to this as a rank-1 VN model.
                         It is known in the literature \cite{Bidard2000-jr}, that such a model is equivalent to a linear program.
                         Theorem: the rank-one model VNM($$uv^\top,A$$) with maximal growth factor $$\lambda>0$$ is equivalent to the linear program LP($$v^\top, A, u$$) with optimal value $$\lambda^{-1}$$. #theorem 
                     Proof #slide 
                         $$\Longrightarrow$$" 
                             Let $$A=UV^\top$$ with $$U, V\in\R^{n\times k}$$ having full rank ($$k\le n$$).
                             We start with $$\lambda$$ maximal such that $$\exists x,y\in \R^{n}: x^\top(A-\lambda UV^\top)\geqq 0$$.
                             Define $$\tilde{X} := \lambda^{-1} {(X^\top U)}^{-1}X^\top$$.
                             Then $$\tilde{X}u=\frac{X^\top U}{\lambda X^\top U}=\lambda^{-1}$$ is minimal, such that $$\tilde{X}^\top(A-\lambda UV^\top)=\tilde{X}^\top A-V^\top \geqq 0$$.
                             This means that the multi-linear multi-criteria program MLC($$U, A, V^\top$$) is solved by $$\tilde{X}^\top$$ with value $$\lambda^{-1}$$.
                         "$$\Longleftarrow$$" 
                             Assume $${X}^\top$$ is a solution of the multi-linear multi-criteria program MLC($$U, A, V^\top$$) with value $$\mu^{}$$.
                             This means $$\mu := X^\top u$$ is minimal such that $$X^\top A-V^\top\geqq 0$$.
                             One has $$V^\top=(X^\top U)^{-1}X^\top UV^\top = \mu^{-1}X^\top UV^\top \geqq 0$$. 
                             Hence $$X^\top(A-\mu^{-1} UV^\top)\geqq 0$$ and $$\lambda:=\mu^{-1}$$ is a maximal growth factor for VNM($$UV^\top,A$$).
             SIMPLEX
         Novel Equilibrium Level Estimates for an Extended Von Neumann Growth Model #h #VNM 
             ESTIMATES FOR $$\rho$$
                 Known Estimates:
     BY TOPIC (SLOW RESEARCH)
         BC 
             Description of Research Strand #h 
                 Introduction #slide
                     Background:
                         The concept of a Blockchain has experienced a tremendous interest, ever since the inception of Bitcoin as a pioneering Blockchain application
                     Context:
                         Kindly, there is a huge debate whether Blockchains will eventually become mainstream applications
                     Motivation:
                         There are some crucial aspects of mainstream Blockchain systems, that require addressing
                     Summary:
                         use of innovative cryptographic techniques with a focus on secret sharing and steganography
                 Aims and Research Questions #slide 
                     This line of research aims to improve the security and dependability of blockchain architectures by addressing scalability, storage requirements, performance and refinements of the mainstream security goals of confidentiality, integrity and availability. 
                     A central research question is how to use cryptographic techniques other than encryption, to add features and improve the above-mentioned aspects for blockchain architectures that are not met by mainstream implementations. 
                 Challenges #slide 
                     The main challenge in this research domain is creating practical impact based on implementations suitable for real-world deployment. 
                     Another challenge is to find poignant blockchain applications compatible with proposed prototype security architectures, offering functionality for novel use cases. 
                 Outlook #slide 
                     At this point, further diversification of additional cryptographic schemes proposed for the use for the blockchain is expected. 
                     However, it is unclear when these initiatives will substantially and positively impact current mainstream systems. 
                     Still, a clear potential exists, which will continue to motivate researchers in this area to put their efforts into ongoing projects.
                 Notations #slide 
                 Contributions/Novelty #slide 
             Introduction #slide
                 Background:
                 Context:
                 Motivation:
             Contributions/Novelty #slide 
             Notations #slide 
             Bibtex
                 All [22]
                     \cite{noauthor_undated-tq}
                     \cite{Ra2020-gl}
                     \cite{Rajput2021-co}
                     \cite{Cha2021-ya}
                     \cite{Raman2018-dk}
                     \cite{Zheng2021-zi}
                     \cite{Han2021-gj}
                     \cite{Popovska-Mitrovikj2020-yn}
                     \cite{Latha2021-yp}
                     \cite{Chen2022-pn}
                     \cite{Mao2020-gp}
                     \cite{Fan2022-ru}
                     \cite{Guojia2021-nm}
                     \cite{Harris2019-ft}
                     \cite{Kripa2021-xx}
                     \cite{Chen2021-aq}
                     \cite{Kim2019-qc}
                     \cite{Fukumitsu2017-bc}
                     \cite{Lopp2019-fj}
                     \cite{Maram2019-jt}
                     \cite{Chen2019-hd}
                     \cite{Raman2018-nv}
                 By Cluster
                     \cite{noauthor_undated-tq}
                     \cite{Ra2020-gl}
                     \cite{Rajput2021-co}
                     \cite{Cha2021-ya}
                     \cite{Latha2021-yp}
                     \cite{Chen2022-pn}
                     \cite{Mao2020-gp}
                     \cite{Fan2022-ru}
                     \cite{Guojia2021-nm}
                     \cite{Harris2019-ft}
                     \cite{Lopp2019-fj}
                     EARLY & INDEPENDENT WORKS
                         \cite{Maram2019-jt}
                         \cite{Fukumitsu2017-bc}
                     SOLID
                         \cite{Popovska-Mitrovikj2020-yn}
                         \cite{Chen2019-hd}
                         \cite{Kim2019-qc}
                         \cite{Raman2018-dk}
                         \cite{Raman2018-nv}
                     RECENT
                         \cite{Kripa2021-xx}
                         \cite{Zheng2021-zi}
                         \cite{Han2021-gj}
                         \cite{Chen2021-aq}
                     WWW
                     Fan2022-ru
             Introduction #slide
                 Background:
                 Context:
                 Motivation:
             Contributions/Novelty #slide 
             Notations #slide 
             Overlay+BCSecurity
                 Virtual Private Network Overlay Architectures and their Design \& Implementation #strand 
         CA
             CA+FR+Pseudo
                 Formal reduction of systems of linear functional equations #h 
                     Motivation #slide
                         Motivation: Similarities between linear differential, difference and $q$-difference equations and systems, e.g. Bronstein \& Petkovsek (1996)
                         Want to extend progress made in differential case (Barkatou 1997, Pfluegel 1998, 2000)
                         This talk: extend local analysis from regular (Barkatou \& Broughton \& Pfluegel 2010) to irregular singular case
                     Notations #slide 
                         $$\delta$$
                         $$\phi$$
                         $$\text{val}$$
                         $$\text{lc}$$
                         $$c$$
                         $$q$$
                     Pseudo-Linear Algebra #h
                         Introduction #slide 
                             Introduced by Jacobson (1937) as a unifying framework for linear differential and difference equations/systems 
                             Computer Algebra use by e.g. Bronstein \& Petkovsek (1996), Bronstein (2000), Barkatou (2006) and Barkatou, Broughton \& Pfluegel (2008, 2010)
                         Concepts #slide 
                             We need some notations:
                                 $$F$$ a field
                                 $$\phi$$ a $$K$$-automorphism of $$F$$
                                 $$\delta$$ a pseudo-derivation w.r.t. $$\phi$$, i.e.
                                     $$\delta(fg) = \delta f \phi g + f\delta g$$
                             One can show: if $$\phi \neq \text{id}$$, then $$\exists \gamma \in F: \delta = \gamma(\phi - \text{id})$$.
                                 
                     Systems of Pseudo-Linear Equations #h 
                         Introduction #slide 
                             System of Pseudo-Linear Equations:
                                 $$\delta Y(\tau) = A(\tau) \phi Y(\tau)$$
                             with $$A \in F^{n \times n}$$. This unifies common types of linear functional equations.
                             If $$\phi \neq \text{id}$$, the system can be represented in different formats:
                                 $$\phi Y(\tau) = A(\tau) Y(\tau)$$
                             or
                                 $$\delta Y(\tau) = A(\tau) Y(\tau)$$.
                             Conversions between formats can be done efficiently.
                         Local Solutions #h 
                             Aims and Objectives #slide 
                                 Ultimate aim: efficiently compute symbolic solutions of systems of linear functional equations.
                                 Objectives:
                                     To give a unifying theoretical framework for defining irregular parts of formal solutions.
                                     To provide a generic algorithm that can compute irregular parts efficiently.
                                 This is joint work with M. Barkatou and G. Broughton.
                             Formal Solutions of Pseudo-Linear Equations #h 
                                 Irregular Parts #h 
                                     Singular Systems of Pseudo-Linear Equations #slide 
                                         Additional notations:
                                             $$F = K((\tau))$$
                                             $$v: F\longrightarrow \Z\cup\{\infty\}$$ a valuation defined by
                                                 $$v(f) = \left \{\begin{array}{lcl} m & \mbox{if }& f=\tau^{m}(f_{0}+f_{1}\tau + \ldots), f_{0} \neq 0, \\ \infty & \mbox{if }& f = 0. \end{array}\right.$$
                                             $$\omega \in \Z$$ defined by $$\omega(\D) =v(\delta(\tau)) - v(\tau)$$.
                                         Also assume $$v(\phi(f)) = v(f) \;\;\;\forall f \in F$$. 
                                         A singular system of pseudo-linear equations is:
                                             $$\tau^{r-\omega}\delta Y(\tau) = A(\tau) \phi Y(\tau)$$
                                         with $$r \in \N$$ (the \emph{Poincar\'{e}-rank}) and $$A \in K[[\tau]]^{n \times n}$$.
                                     Local Characteristics #slide 
                                         We define the quantities $$c, q \in K^{\ast}$$ from the definition of $$\phi$$ and $$\delta$$:
                                             $$\phi(\tau) = q\tau + O(\tau^{2})$$
                                             $$\tau^{-\omega}\delta(\tau) = c\tau + O(\tau^{2})$$
                                         We then have inductively for $$h \in \N^{+}$$
                                             $$\phi(\tau^{h})  =  q^{h}\tau^{h} + O(\tau^{h+1})$$,
                                             $$\tau^{-\omega}\delta(\tau^{h}) = c [h]_{q}\tau^{h} + O(\tau^{h+1})$$
                                         where
                                             $$[\lambda]_q = \left \{\begin{array}{lcr} \frac{1-q^{\lambda}}{1-q} & \text{if}& q \neq 1, \\ \lambda & \text{if}& q = 1. \end{array}\right.$$
                                     Examples #slide 
                                         Linear Differential Systems:
                                             $$\phi = \text{id}, \; \delta = \frac{d}{d\tau}, \; \omega = -1, \; q=1, \; c=1$$
                                         Linear Difference Systems:
                                             $$\phi(\tau) = \frac{\tau}{\tau+1}, \; \delta = \phi - \text{id}, \; \omega = 1, \; q=1, \; c=-1$$
                                         Linear $$q$$-Difference Systems:
                                             $$\phi(\tau) = q\tau, \; \delta = \phi - \text{id}, \; \omega = 0, \; q \neq 1, \; c=q-1$$
                                     Classification of Singularities #slide
                                         %\begin{definition}
                                         %\label{first_kind} A local system of the form
                                         %(\ref{pseudo_lin_sys}) is said to be of the \emph{first kind}
                                         %if for its Poincar\'{e}-rank $$r$$, we have $$r=0$$.
                                         %\end{definition}
                                         Let $$ T \in \GLn{\F}$$. Change of variable
                                             $$Y=TZ$$
                                         leads to
                                         \emph{equivalent} system $$\tau^{-\omega} \D Z = B \Aut Z$$
                                         where
                                         $$B = T^{-1} (A \Aut T -\tau^{-\omega} \D T) =:T_{\delta,\phi}[A]$$
                                         #definition
                                             System (\ref{pseudo_lin_sys}) is called \emph{regular singular} if $$\exists$$ $$T_{\delta, \phi} $$ such that  $$T_{\delta , \phi}[A]$$ is of \emph{first kind}, i.e. $$r=0$$. Otherwise, it is called \emph{irregular singular}.
                                         Barkatou \& Broughton \& Pfluegel (2010): Regular Singular Case \& Incomplete FMS in Irregular Singular Case\    
                                         New Goal: find complete FMS of irregular system.
                                 Regular Solutions #h 
                             Formal Reduction #h 
                                 Formal Reduction #slide 
                                     Idea: transform into simpler system -- lower $$r$$, decrease $$n$$
                                     Originally established for differential systems
                                     Transformations:
                                         Changes of variable $$Y=TZ$$,
                                         Changes of variable $$Y = e_{r,\mu}Z$$ where $$e_{r,\mu}$$ is a suitable scalar function,
                                         Substituting $$\tau = \tilde{\tau}^{s}$$ with $$s\in \N$$, $$s>1$$.
                                     Problems:
                                         How to compute $$T$$?
                                         How to define $$e_{r,\mu}$$?
                                         How to find ramifications?
                                 Approaches -- Overview #slide 
                                     Approaches in the literature: 2 schools
                                          Traditional
                                             Use of Shearing transformations
                                         Algorithmic
                                             Use of Moser and/or super reduction
                                             Care about introducing algebraic extensions of ground field 
                                     Main differences:
                                 Basic Operations #h 
                                     Gauge-Transformation #slide
                                         Let $$T(x)$$ be invertible square matrix function. The change of variable
                                             $$y = Tz$$
                                         transforms system (\ref{system}) into
                                             $$x^{r+1}\frac{dz}{dx} = \tilde{A}z $$
                                         where
                                             $$ \tilde{A} = T[A] :=  T^{-1}AT - x^{r+1}T^{-1}\frac{dT}{dx}$$.
                                         We call (\ref{system}) and (\ref{tildesystem}) ($$A$$ and $$\tilde{A}$$ respectively) {\em equivalent}. 
                                     Exponential Shift #slide 
                                     Splitting Lemma #slide 
                                         Consider (\ref{system}) and assume that $$A_0$$ is block-diagonal 
                                             $$ A_0 = \left(\begin{array}{cc}  A_0^{11} & 0 \\  0 & A_0^{22} \\\end{array}\right)$$
                                         such that $$\rho(A_0^{11})\cap\rho(A_0^{22})=\emptyset.$$
                                         Then there exists a formal analytical transformation of the form
                                             $$T(x) = \sum_{j = 0}^{\infty}T_j x^{j}\quad (T_0 = I)$$
                                         such that the transformed system is block-diagonal with the same block partition as in $$A_0$$.
                                     Shearing Transformation #slide 
                                         Gauge-Transformation using diagonal matrix 
                                             $$S=\text{diag}(x^{s_1},\ldots,x^{s_n})$$ 
                                         where $$s_i\in\mathbb{Q}$$. The transformed system is 
                                             $$\delta(Y)=B\phi(Y)$$ 
                                         where
                                             $$B=S[A]=S^{-1}A\phi(S)-\delta(S)$$.
                                         This means $$b_{ij}=a_{ij}x^{s_i-s_j}-\text{diag}(\delta(x^{s_i})/\theta(x^{s_i})$$ and
                                             $$\text{val}(b_{ij})=$$
                                             $$\text{lc}(b_{ij})=$$
                                         In order to be useful for formal reduction, the new matrix needs to satisfy
                                             $$\text{val}(B)>\text{val}(A)$$. 
                                     Ramification #slide 
                                         This could introduce __ramifications__. 
                                 Advanced Operations #h 
                                     Moser-Reduction #h 
                                     Super-Reduction #h 
                                     Katz-Invariant #h
                                     Generalised Splitting Lemma #slide 
                                     Rational (Root-free) Splitting Lemma #h 
                                         Splitting Lemma for $$ (\omega, P)$$-Commutative  Systems #slide 
                                             #lemma:commutative_splitting 
                                                 Consider the system (\ref{qsystem}) and assume that $$\hat{A}$$ is $$(\omega, P)$$-commutative with $$\hat{A}_p$$ and $$P$$ block-diagonal with blocks of same dimension
                                                     $$\hat{A}_p = \left(\begin{array}{cc}\hat{A}_p^{11} & 0 \\0 & \hat{A}_p^{22} \\ \end{array}\right),\quad P =\left(\begin{array}{cc}P^{11} & 0 \\0 & P^{22}\\ \end{array}\right)$$
                                                 such that
                                                     $$\wpspec(\hat{A}_p^{11})\cap\wpspec(\hat{A}_p^{22})=\emptyset.$$
                                                 Then there exists a $$(\omega, P)$$-commutative $$q $$-meromorphic transformation of the form
                                                     $$\hat{T}(x) =\sum_{j=0}^{\infty}T_jx^{j/q}\quad (T_0 = I)$$ #equation 
                                                 such that the transformed system is $$(\omega, P)$$-commutative and block-diagonal with the same block partition as in $$\hat{A}_p $$ and $$P $$.
                                         Rational Splitting Lemma #slide 
                                             #proposition
                                                 Consider a system as in ( #qsystem) with leading matrix $$\hat{A}_p$$ and let $$q\geq 2$$. The following statements are equivalent:
                                                     There exists a system as in ( #qsystem) and a generalised Shearing-transformation $$\tilde{S}$$ of ramifications index $$q$$ such that $$\tilde{S}[A]=\hat{A}$$.
                                                     The system ( #qsystem) is $$(\omega, \tilde{P})$$-commutative, the matrix $$\tilde{P}$$ is similar to a diagonal matrix and $$\text{spec}(\tilde{P})\subseteq\{1,\omega,\omega^2,\ldots,\omega^{q-1}\} $$.
                                                 Furthermore, if $$\lambda$$ is an eigenvalue of $$\hat{A}_{p}$$ with multiplicity $$s$$, the numbers $$\omega\lambda,\ldots,\omega^{(q-1)}\lambda$$ are all eigenvalues of the same multiplicity $$s$$.
                             APPLICATIONS 
                                 Differential Case #h 
                                     Linear Differential Systems #slide 
                                         We consider
                                             $$x^{r+1}\frac{dy}{dx} = A(x)y$$
                                         with $$r\in\N$$ called the {\em Poincar\'{e}-rank} of the system, and
                                             $$A = \sum_{j=0}^\infty A_{j} x^j\quad(A_0 \neq 0)$$
                                         where $$A_\nu\in\mathbb{C}^{n\times n}$$. Distinguish between
                                             $$r=0$$: regular singular case
                                             $$r>0$$: irregular or regular singular case
                                 Difference Case #h 
                                 $$q$$-Difference Case #h 
                                 Difference Case #h
                                 $$q$$-Difference Case #h 
                         Global Solutions #h 
             CA+FR+Pseudo+DAE+VNM
                 Previous Work #slide 
                     Little is known
                     Analogy of generalised splitting was given by Pfluegel
                     Out of any algorithmic context
                     Poof of concept
                 Equilibrium Pole Order #slide 
                     We can reduce both either from the left (altering row valuations) or the right (changing valuations of the columns)
                     Idea: find a competing balance (equlibrium)
                     Definition.
                     We say that a generalised Shearing transformation $$(S^*,T^*)$$ is an __equilibrium Shearing transformation__ for the system $$\mathcal{D}= A\theta- B\delta$$ if it holds
                         (i) $$\text{val}(S^*\mathcal{D}T^*)\le\text{val} ({S}\mathcal{D}T^*)$$ for all left-shearing matrices $$S$$, 
                         (ii) $$\text{val}(S^*\mathcal{D}T^*)\ge\text{val}(S^*\mathcal{D}{T})$$ for all right-shearing matrices $$T$$. 
                     Then the rational number $$\rho=\text{val}(S^*\mathcal{D}T^*)$$ is called an __equilibrium pole order__ of the system.
                 Main Theorem #slide 
                 Connection to Game Theory #slide 
                 Connection to Volecic-Weight #slide 
         Edu
             Edu+Cyber+AI
             Edu+CyBOK
                 CyBOK+Map
                 CyBOK+ZOO
             Edu+ZOO
         GT
             DECONSTRUCTING
                 Equilibrium Concepts
                     ![Equilibria.png](https://dynalist.io/u/gqSUuOGOBYjmj1njYbjHUf-R)
                         
                 Block Pivot Steps
             GT Background #slide 
                 Linear Algebra
                 Security Games (Complete Information)
                 Stochastic Games
             GT+Bimatrix
                 Bimatrix Games and Generalised Eigensystems
                     #h #slide 
                     Relationship between Equilibrium Solutions and Eigensystems #h 
                         Sufficient Conditions for Equilibrium Solutions #slide #novel 
                             #theorem:bimatrix-regular-theorem 
                                 Given a square bimatrix game $$G(A,B)$$, assume the matrix pencils $$A-\lambda E$$  and $$B-\lambda E$$ are both regular, each with a real eigenvalue $$\mu_A$$ and $$\mu_B$$ respectively. Let $$x_{\mu_B}$$ be a nonnegative left eigenvector of $$B-\lambda E$$ with respect to $$\mu_B$$ and denote $$y_{\mu_A}$$ a nonnegative right eigenvector of $$A-\lambda E$$ with respect to $$\mu_A$$. Then $$(x^*,y^*) = (x_{\mu_B}$$, $$y_{\mu_A}$$) is a Nash Equilibrium strategy profile of the game $${G}$$ and $$(\mu_A, \mu_B)$$ is the corresponding game value pair. 
                         A Best Response Lemma #slide 
                             The proof of the theorem will be aided by the following lemma. 
                             It exhibits a special case arising where there exists a strategy of one player to which any strategy of the other player is a best response.
                             #lemma:best-response-eigen
                                 Following the notations as in the theorem, we have for a nonnegative left eigenvector $$x_{\mu_B}$$ that for all Player 2 strategies $$y$$ it holds $$x^\top_{\mu_B} B y = \mu_B $$. Similarly, a nonnegative right eigenvector $$y_{\mu_A}$$ satisfies $$x^\top A y_{\mu_A} = \mu_A$$ for all Player 1 strategies $$x$$.
                                 Using set notation, $$ \mathcal{BR}(y_{\mu_A})=X$$ and $$ \mathcal{BR}(x_{\mu_B})=Y$$.
                         Proof [of lemma] #slide 
                             #proof 
                                 Assume that $$x^{\top}_{\mu_A}\ge 0$$ is a left eigenvector, associated with the eigenvalue $${\mu_A}$$ of the regular matrix pencil $$A-\lambda E$$. This implies
                                 #equation:left-nullspace-eq
                                      $$ x^{\top}_{\mu_A}(A-{\mu_A} E)=0. $$
                                 Due to the normalisation property $$\sum x_{{\mu_A},i}=1$$ we have $$ x^{\top}_{\mu_A} E = x^{\top}_{\mu_A} ee^{\top}=e^{\top}$$ so that equation #ref:left-nullspace-eq implies 
                                     $$ x^{\top}_{\mu_A} A = {\mu_A} e^{\top}$$.  #displaymaths 
                                 The second property for a right eigenvector $$y_{\mu_B}$$ can be shown similarly. From this, the lemma follows. 
                         Proof [of Theorem #ref:bimatrix-regular-theorem ] #slide 
                             Let $$y_{\mu_A}$$ be nonnegative right eigenvector of $$A-\lambda E$$ with respect to the eigenvalue $$\mu_A$$. From Lemma #ref:best-response-lemma we deduce that $$y_{\mu_A}$$ is a best response to any Player 1 strategy $$x$$, in particular to  $$x=x_{\mu_B}$$. Likewise,  denote $$x_{\mu_B}$$ a nonnegative left eigenvector of $$B-\lambda E$$. We obtain that  $$x_{\mu_B}$$ is a best response to Player 2 strategy $$y=y_{\mu_A}$$. Hence these strategies are mutual best responses and by definition mixed Nash Equilibrium strategies with payoffs $$\mu_A$$ and $$\mu_B$$ as required. #proof 
                         Explicit Solution Formula #slide 
                             #proposition
                                 If the conditions of Theorem #ref:bimatrix-regular-theorem hold, we can compute the equilibrium solution $$(x^*, y^*)$$ as
                                     $$x^*=\frac{e^T{\rm adj}(B)} {e^T{\rm adj}( B)e}$$, $$y^*=\frac{{\rm adj}(A)e} {e^T{\rm adj}( A)e}$$ #displaymaths 
                                 generalising the result of Thompson et al in the matrix game case.
                     Completely Mixed Solutions #h 
                         Necessary and Sufficient Conditions for Weakly Completely Mixed Solutions #slide #novel
                             In the weakly completely mixed case, the use of eigensystems to characterise solutions turns out to be a natural approach. 
                             #theorem:bimatrix-weakly-mixed 
                                 A bimatrix game is weakly completely mixed if and only if both its associated generalised eigensystems are regular, with real eigenvalues and strictly positive left and right eigenvectors. 
                         Proof (Necessary Condition) #slide
                             #proof Follows from main theorem.  
                         Proof (Sufficient Condition) #h 
                             Step 1: Refinement of Raghavan's results #slide
                                 #lemma:cofactors 
                                     If a bimatrix game is completely mixed and $$v_A=0$$, the cofactors $$A_{i1},\ldots,A_{in}$$ of the matrix $$A$$ are either all zero or have the same sign, for all $$1\le i\le n$$. If $$v_B=0$$, the same property holds for the cofactors $$B_{1j},\ldots,B_{nj}$$ of the matrix $$B$$, for all $$1\le j\le n$$. 
                                 #proof 
                                     Based on [Raghavan, Theorem 1], using a technique similar to that in the proof for [Kaplanski, Theorem 4]
                                     Will prove for $$A$$ and $$v_A$$, statements for $$B$$ and $$v_B$$ can be done in analog fashion.. 
                                         Show that if value is zero, rank is $$n-1$$
                                         Use then adjoint formula
                                 Then show that for arbitrary value, sum of adjoins is not zero. 
                             Step 2: Structure of Characteristic Polynomial #slide 
                                 The characteristic polynomial is $$c_A(\lambda)=\det(A-\lambda E)$$. 
                                 #lemma:charpoly 
                                     We have $$c_A(\lambda)=c_1\lambda -c_0$$ where $$c_0=\det A$$ and $$c_1=\sum_{ij}A_{ij}$$ with $$A_{ij}$$ the cofactor of $$a_{ij}$$.  
                                 #proof 
                                     The degree of $$c_A$$ is bound by rank($$E)=1$$
                                     Formula for $$c_0$$ is clear (put $$\lambda=0$$)
                                     The remaining fact follows by considering the expansion of the determinant $$\det A'=\sum_{ij}a_{ij}A'_{ij}$$ in a sum of terms
                                     For each $$i,j$$, there is a $$\lambda$$ exactly once per term 
                             Step 3: Proof #slide 
                                 Follows directly from Lemma #lemma:cofactors:ref and #lemma:charpoly:ref .
                         Strictly Completely Mixed Case #slide 
                             #theorem:bimatrix-mixed
                                 A bimatrix game is completely mixed if and only if it is weakly completely mixed and the matrix pencils $$A-\lambda E$$ and $$B-\lambda E$$ are simultaneously equivalent to 
                     NON-SQUARE CASE
                     Limitations #slide 
                         Only sufficient algebraic conditions 
                         Difficult to exploit algorithmically
                     INBOX
                         Additional Uniqueness Result #slide 
                             Assume the bimatrix game $$\mathcal{G}(A,B)$$ is regular, with a value $$(v_A, v_B)$$ corresponding to real eigenvalues and nonnegative left and right eigenvectors $$x_\mu$$ and $$y_\mu$$, equilibrium solutions of the game. 
                             Then $$x_\mu$$ and $$y_\mu$$ are unique solutions if and only if $$\det(A'-\lambda E')= {c\neq 0}$$ where $$A'$$ and $$E'$$ are derived from $$A$$ and $$E$$ by replacing rows and columns with zeros at all inactive strategies $$i$$ of $$x$$ and $$j$$ of $$y$$.
                 Necessary and Sufficient Algebraic Conditions #h
                     In this section, it is shown how to extend work of @THOMPSON to a bimatrix game setting, refining results given by . Sufficient algebraic conditions for the existence of an equilibrium strategy of a bimatrix game are derived. It is then established that for games with completely mixed solutions, the sufficient conditions can be strengthened to also become necessary. Finally, #signpost
                     Notations and Terminology #h 
                     Generalised Eigensystems and Equilibrium Strategies #h 
                         The fundamental relationship between generalised eigensystems associated with a bimatrix game --- under the assumption of certain sufficient conditions --- and an equilibrium strategy of the game is established in this section. 
                         This extends results by @THOMPSON to bimatrix games. 
                         #theorem:bimatrix-regular-theorem
                             Given a square bimatrix game $$G=(A,B)$$, assume the matrix pencils $$A-\lambda E$$  and $$B-\lambda E$$ are both regular, each with a real generalised eigenvalue $$\mu_A$$ and $$\mu_B$$ respectively. Let $$x_{\mu_B}$$ be a nonnegative left generalised eigenvector of $$B-\lambda E$$ with respect to $$\mu_B$$ and denote $$y_{\mu_A}$$ a nonnegative right generalised eigenvector of $$A-\lambda E$$ with respect to $$\mu_A$$. Then $$(x^*,y^*) = (x_{\mu_B}$$, $$y_{\mu_A}$$) is a Nash Equilibrium strategy profile of the game $$G$$ and $$(\mu_A, \mu_B)$$ is the corresponding game value pair.
                         The proof of the theorem will be aided by the following lemma. It exhibits a special case arising where there exists a strategy of one player to which any strategy of the other player is a best response.
                         #lemma:best-response
                             Following the notations as in the theorem, we have for a nonnegative left generalised eigenvector $$x_{\mu_B}$$ that for all Player 2 strategies $$y$$ it holds $$x^\top_{\mu_B} B y = \mu_B $$. Similarly, a nonnegative right generalised eigenvector $$y_{\mu_A}$$ satisfies $$x^\top A y_{\mu_A} = \mu_A$$ for all Player 1 strategies $$x$$.
                         #proof 
                             Assume that $$x^{\top}_{\mu_A}\ge 0$$ is a left generalised eigenvector, associated with the generalised eigenvalue $${\mu_A}$$ of the regular matrix pencil $$A-\lambda E$$. This implies
                             #equation:left-nullspace-eq
                                  $$ x^{\top}_{\mu_A}(A-{\mu_A} E)=0. $$
                             Due to the normalisation property $$\sum x_{{\mu_A},i}=1$$ we have $$ x^{\top}_{\mu_A} E = x^{\top}_{\mu_A} ee^{\top}=e^{\top}$$ so that equation #ref:left-nullspace-eq implies 
                                 $$ x^{\top}_{\mu_A} A = {\mu_A} e^{\top}$$.  #displaymaths 
                             The second property for a right generalised eigenvector $$y_{\mu_B}$$ can be shown similarly. From this, the lemma follows. 
                         The proof of Theorem #bimatrix-regular-theorem.ref can now be stated as follows. 
                         #proof
                             Let $$y_{\mu_A}$$ be nonnegative right generalised eigenvector of $$A-\lambda E$$ with respect to the generalised eigenvalue $$\mu_A$$. From Lemma #ref:best-response-lemma we deduce that $$y_{\mu_A}$$ is a best response to any Player 1 strategy $$x$$, in particular to  $$x=x_{\mu_B}$$. Likewise,  denote $$x_{\mu_B}$$ a nonnegative left generalised eigenvector of $$B-\lambda E$$. We obtain that  $$x_{\mu_B}$$ is a best response to Player 2 strategy $$y=y_{\mu_A}$$. Hence these strategies are mutual best responses and by definition mixed Nash Equilibrium strategies with payoffs $$\mu_A$$ and $$\mu_B$$ as required. #proof 
                         This result can also be used in order to construct an explicite solution formula, generalising a result of Thompson et al in the matrix game case. Karlin
                         #proposition
                             If the conditions of Theorem #bimatrix-regular-theorem.ref hold, an equilibrium strategy $$(x^*, y^*)$$ can be computed as $$x^*=\frac{e^T{\rm adj}(B)} {e^T{\rm adj}( B)e}$$, $$y^*=\frac{{\rm adj}(A)e} {e^T{\rm adj}( A)e}$$.  #displaymaths 
                         #proof
                             These equations follow from
                         Milchtaich 
                     The Completely Mixed Case #h 
                         The use of generalised eigensystems to characterise a completely mixed equilibrium strategy turns out to be a natural approach, as suggested by the following
                         #theorem:bimatrix-weakly-mixed
                             A bimatrix game is weakly completely mixed iff its associated generalised eigensystems $$\mathcal{E}_A$$ and $$\mathcal{E}_B$$ are both regular, with corresponding real generalised eigenvalues $$\mu_A$$ and $$\mu_B$$ respectively, and strictly positive right generalised eigenvector $$y_{\mu_A}$$ (left generalised eigenvector $$x_{\mu_B}$$ respectively). 
                         #proof
                             __The conditions are necessary.__  This shall be proven in a number of steps. 
                                 The following theorem is a refinement of Raghavan's results, establish additional properties of the adjoints of the game matrices. 
                                     #theorem:cofactors 
                                         If a bimatrix game is completely mixed and $$v_A=0$$, the cofactors $$A_{i1},\ldots,A_{in}$$ of the matrix $$A$$ are either all zero or all have the same sign, for any $$1\le i\le n$$. If $$v_B=0$$, the same property holds for the cofactors $$B_{1j},\ldots,B_{nj}$$ of the matrix $$B$$, for all $$1\le j\le n$$. 
                                     #proof 
                                         The proof is based on [Raghavan, Theorem 4], using a technique similar to that in the proof for [Kaplanski, Theorem 4].
                                         The result will be proven for $$B$$ and $$v_B$$, the statements for $$A$$ and $$v_A$$ can be done in an analog fashion.
                                             Let $$x$$ be an equilibrium strategy for the second player and assume $$v_{B} = 0$$. Then for $$j\in 1\ldots n$$ one has
                                                 $$\sum_{i=1}^n x_ia_{ij}=0$$.
                                             On the other hand, expanding the determinant using column $$j$$ it holds
                                                 $$0=\det A=\sum_{i=1}^n a_{ij}A_{ij}$$.
                                             Raghavan has shown that a completely mixed bimatrix game with both values zero, the rank of the game matrices is $$n-1$$ and the equilibrium strategy is unique.
                                             Since the equilibrium strategy is unique and $$rank A = n-1$$, these two linear combinations must be unique up to multiplication with a constant. This yields
                                                 $$\frac{x_1}{A_{1j}} = \frac{x_2}{A_{2j}} = \cdots = \frac{x_n}{A_{nj}}$$
                                             So these cofactors have same sign or are all zero.
                                             Then show that sum of adjoints is not zero:
                                                 if it was zero, then $$c_A(\lambda)\equiv 0$$ 
                                                 for a unique completely mixed equilibrium solution $$(x,y)$$ 
                                                 Since $$rk(A)=n-1$$ it follows $$A^*=
                                 For a regular matrix pencil $$A-\lambda E$$, define the __generalised characteristic polynomial__ $$c_A(\lambda):=\det(A-\lambda E)$$. It will be shown to be a polynomial of degree at the most one. 
                                     #lemma:charpoly 
                                         The generalised characteristic polynomial is a linear function $$c_A(\lambda)=c_0-c_1\lambda$$ where $$c_0=\det A$$ and $$c_1=e^t A^*e = \sum_{ij}A_{ij}$$ with $$A_{ij}$$ denoting the cofactor of $$a_{ij}$$.  
                                     This identity has already been used but not proven in @KAPLANSKI. 
                                     A full proof can be found in @KARLIN [A.9], however for convenience to the reader a different and short elementary proof is given here, based on a generalisation to regular matrix pencils of @MILCHTAICH .
                                     #proof 
                                         Consider the square matrix pencil of order $$n+1$$
                                             $$\hat{A}=\begin{pmatrix} A &\lambda e\\- e^t &0\end{pmatrix} $$. 
                                         The determinant of $$\hat{A}$$ can be computed in two different ways. First, use Laplace expansion by the last row to obtain 
                                             $$\det \hat{A} =\sum_{j=1}^n(-1)^{n+j}\det \left( [A]_{j}|\lambda e\right) $$. 
                                         Applying one more Laplace expansion along column $$n$$ in the augmented matrices yields
                                             $$\det \left( [A]_{j}|\lambda e\right)=\sum_{i=1}^n(-1)^{i+n}\det {}_i[A]_{j}\cdot \lambda $$. 
                                         Combining these steps, one has
                                             $$\det \hat{A}= \sum_{i,j=1}^n(-1)^{i+j}\det {}_i[A]_{j}\cdot \lambda =\sum_{i,j} A_{ij}\cdot \lambda      $$. 
                                         On the other hand, rewriting the initial matrix as
                                             $$\hat{A} = \begin{pmatrix} A &0+\lambda e\\-e^t &1-1\end{pmatrix} $$
                                         and applying the linearity of the determinant w.r.t. the last column, it follows
                                             $$\det \hat{A} =\det \begin{pmatrix} A &0\\-e^t &1\end{pmatrix} -\det \begin{pmatrix} A &-\lambda e\\-e^t &1\end{pmatrix} =\det A-\det \begin{pmatrix} A-\lambda E &-\lambda e\\ 0 &1\end{pmatrix} =\det A-\det (A-\lambda E) $$.
                                         The second equality 
                                         Finally combining these results finishes the proof:
                                             $$\det (A-\lambda E) = \det A-\sum_{i,j} A_{ij}\cdot \lambda$$.
                                 Finally, the proof follows directly from Lemma #lemma:cofactors:ref and #lemma:charpoly:ref as the regularity of the pencil and the properties of the generalised eigenvectors are established. 
                             __The conditions are sufficient.__ This follows directly from Theorem #theorem:bimatrix-regular-theorem:ref yielding a completely mixed equlibrium strategy pair from the strictly positive generalised eigenvectors.
                     Related Work #h 
                         In summary, the purely game-theoretical results of this paper show that the use of generalised eigensystems is a natural approach when focussing on completely mixed equilibrium solutions of bimatrix games. 
                         Adapting the work of @THOMPSON to bimatrix games, the line of research initiated by @RAMAGHAN is led to a satisfying next level. Furthermore, some closely related results of @MILCHTAICH can be stated more naturally. The results on the relationship between inactive strategies, generalised eigenvalues and strategic dominance, first given by @WEIL for matrix games, appear to be novel in the bimatrix game setting. 
                         LIMITATIONS
                             At first glance, a limitation of this work appears to be the restriction to square bimatrix games. On the other hand, as shown in [], any non-square bimatrix game has inactive strategies and hence does not have completely mixed equilibrium strategies. 
                             It would be interesting to combine existing methods for solving non-square bimatrix games with the approach of this section and to investigate resulting advantages.
                 Three-Action Attack-Defense Game (Completely Mixed Solutions)
                     Motivation #slide 
                         Context #h
                             Resouce Allocation Game #slide 
                                 Game $$\mathcal{G}(t_1, t_2)$$:
                                     $$\begin{array}{ c | c | c }  \mathcal{D} \downarrow \mathcal{A}\rightarrow & s^\mathcal{A}_{t_1} & s^\mathcal{A}_{t_2} \\ \hline s^\mathcal{D}_{t_1} &  - c^{\mathcal{D}}_{t_1}, - c^{\mathcal{A}}_{t_1}&  -c^{\mathcal{D}}_{t_1} -l^ \mathcal{D}_{t_2},  -c^{\mathcal{A}}_{t_2} +b^ \mathcal{A}_{t_2} \\   \hline s^\mathcal{D}_{t_2} &  -c^{\mathcal{D}}_{t_2} -l^ \mathcal{D}_{t_1},  - c^{\mathcal{A}}_{t_1} + b^{\mathcal{A}}_{t_1} &  -c^{\mathcal{D}}_{t_2},  -c^{\mathcal{A}}_{t_2} \end{array}$$
                                 Notations:
                                     $$c^\mathcal{D}_{t_1}, c^ \mathcal{D}_{t_2}$$ -- the defense cost
                                     $$c^\mathcal{A}_{t_1}, c^ \mathcal{A}_{t_2}$$ -- the attack cost
                                     $$l^\mathcal{D}_{t_1}, l^ \mathcal{D}_{t_2}$$  -- the defender's loss from an attack
                                     $$b^\mathcal{A}_{t_1}, b^ \mathcal{A}_{t_2}$$  -- the benefit of the attacker
                             Analysis #slide 
                                 Let $$0\leq {p}\leq{1}$$ and $$0\leq {q}\leq{1}$$ and
                                     $$p$$ and $$(1-p)$$ be the probability for the attack actions
                                     $$q$$ and $$ (1-q)$$ be those for the defense actions
                                 Each game possesses one unique mixed NE solution $$(p^{*},1-p^{*})$$ and $$(q^{*},1-q^{*})$$.
                                     IDS Game: 
                                         $${p}^{*}=\frac{\alpha_f}{\alpha_f+\alpha_c+\alpha_m}$$ 
                                         $${q}^{*}=\frac{\beta_s}{\beta_c+\beta_s}$$ 
                                     RA Game:
                                         $$p^{*} = \frac{l^\mathcal{D}_{t_1} + c^\mathcal{A}_{t_2} - c^\mathcal{A}_{t_1}}{l^\mathcal{D}_{t_1} + l^\mathcal{D}_{t_2}}$$
                                         $$q^{*} = \frac{l^\mathcal{D}_{t_2} + c^\mathcal{D}_{t_1} - c^\mathcal{D}_{t_2}}{l^\mathcal{D}_{t_1} + l^\mathcal{D}_{t_2}}$$
                                 Corresponding equilibrium values
                                     IDS Game: 
                                         $$\mathcal{p}^{*}\alpha_c +(1-\mathcal{p}^{*})(-\alpha_f) = - \mathcal{p}^{*}\alpha_m  =\frac{-\alpha_f\alpha_m}{\alpha_f+\alpha_c+\alpha_m}$$
                                         $$\mathcal{q}^{*}(-\beta_c) +(1-\mathcal{q}^{*})\beta_s =  \mathcal{q}^{*}(0) +(1-\mathcal{q}^{*})(0) = 0$$
                                     RA Game:
                                          $$s^{*}_d = \frac {l^\mathcal{D}_{t_1}   l^\mathcal{D}_{t_2} (c^\mathcal{D}_{t_1}+c^\mathcal{D}_{t_2} +l^\mathcal{D}_{t_1}+l^\mathcal{D}_{t_2}  ) + c^\mathcal{D}_{t_1}{l^\mathcal{D}_{t_1} }^2 +  c^\mathcal{D}_{t_2} {l^\mathcal{D}_{t_2} }^2}{-(l^\mathcal{D}_{t_1}+l^\mathcal{D}_{t_2})^2} $$
                                         $$s^{*}_a = \frac {l^\mathcal{D}_{t_1}  l^\mathcal{D}_{t_2} (c^\mathcal{A}_{t_1}+c^\mathcal{A}_{t_2} -l^\mathcal{D}_{t_1}-l^\mathcal{D}_{t_2}  ) + c^\mathcal{A}_{t_1}{l^\mathcal{D}_{t_2} }^2 +  c^\mathcal{A}_{t_2}{l^\mathcal{D}_{t_1} }^2}{-(l^\mathcal{D}_{t_1}+l^\mathcal{D}_{t_2})^2}  $$
                         Research Question
                             What are the relationships between the two attack/defence actions, so that the overall game has suitable properties?
                         Contributions
                             We define a security game with two actions for the attacker
                             When restricted to one attack, the resulting games are fulfilling the AD 
                         INBOX
                             RESOURCE ALLOCATION (SEARCH) GAME #h
                                 Motivation
                                     a game with a restricted budget
                                     the utility compagny want to decide where to spend it
                                     type of game that is more realistic nowadays
                                 Notations
                                     $$t_1, t_2$$ -- targets (asset $$a_1$$ and $$a_2$$)
                                     $$r$$ -- resource, covering either $$t_1$$ or $$t_2$$ 
                                     Strategies
                                         $$S_\mathcal{D} = \{{defend }\; t_1, {defend }\; t_2\} = \{s^\mathcal{D}_{t_1}, s^\mathcal{D}_{t_2}\}$$
                                          $$S_\mathcal{A} = \{{attack}\; t_1, {attack}\; t_2\} = \{s^\mathcal{A}_{t_1},s^\mathcal{A}_{t_2}\}$$
                                 References #slide 
                                     [1] - Gianini, G., Cremonini, M., Rainini, A., Cota, G. L., & Fossi, L. G. (2015). A game theoretic approach to vulnerability patching. In 2015 International Conference on Information and Communication Technology Research, ICTRC 2015 (pp. 8891). Institute of Electrical and Electronics Engineers Inc. https://doi.org/10.1109/ICTRC.2015.7156428
                     Refined AD Game
                         Game Notations 
                             With superscript: 
                                 $$\begin{array}{ c | c | c | c}  {\mathcal{D}} \downarrow {\mathcal{A}} \rightarrow & aa & a & -{a} \\ \hline dd &  - c_{dd}^{\mathcal{D}}, - c_{aa}^{\mathcal{A}} & -c_{dd}^{\mathcal{D}}, -\tilde{c}_a^{\mathcal{A}}&  -c_{dd}^{\mathcal{D}},  0 \\ \hline d & -\tilde{l}_{aa}^{\mathcal{D}} -c_d^{\mathcal{D}},\tilde{b}_{aa}^{\mathcal{A}}  - \tilde{c}_{aa}^{\mathcal{A}} & -c_d^{\mathcal{D}},  -c_a^{\mathcal{A}} &  -c_d^{\mathcal{D}},  0 \\ \hline -{d} & -l_{aa}^{\mathcal{D}}  , -b_{aa}^{\mathcal{A}}  - c_{aa}^{\mathcal{A}} & -l_a^{\mathcal{D}}, - b_a^{\mathcal{A}}- c_a^{\mathcal{A}} &  0,  0  \end{array}$$
                             Simplified (without):
                                 $$\begin{array}{ c | c | c | c}  {\mathcal{D}} \downarrow {\mathcal{A}} \rightarrow & aa & a & -{a} \\ \hline dd &  - c_{dd}, - c_{aa} & -c_{dd}, -\tilde{c}_a&  -c_{dd},  0 \\ \hline d & -\tilde{l}_{aa} -c_d,\tilde{b}_{aa}  - \tilde{c}_{aa} & -c_d,  -c_a &  -c_d,  0 \\ \hline -{d} & -l_{aa}  , b_{aa}  - c_{aa} & -l_a,  b_a- c_a &  0,  0  \end{array}$$
                             As Matrices:
                                 $$A=\begin{pmatrix}  - c_{dd} & -c_{dd}&  -c_{dd}\\ -\tilde{l}_{aa} -c_d & -c_d &  -c_d \\  -l_{aa}  & -l_a&  0 \end{pmatrix}$$
                                 $$B=\begin{pmatrix} - c_{aa} &-\tilde{c}_a& 0 \\\tilde{b}_{aa}  - \tilde{c}_{aa} &-c_a &   0 \\b_{aa}  - c_{aa} &  b_a- c_a & 0  \end{pmatrix}$$
                             Table
                                 $$\begin{array}{ c | cc | cc | cc }         \mathcal{U} \downarrow\  \mathcal{A}\rightarrow & {s^\mathcal{A}_{att\degree}} & {s^\mathcal{A}_{att}} & {s^{\mathcal{A}}_{- att}} \\\hline  s^{\mathcal{U}}_{mon} & -c^{\mathcal{U}}_{mon} - l^\mathcal{U}_{att\degree}, &l^\mathcal{U}_{att\degree} - c^\mathcal{A}_{att\degree} & -c^{\mathcal{U}}_{mon} -c^\mathcal{U}_{def}, &- c^{\mathcal{A}}_{att} & -c^\mathcal{U}_{mon}, &0\\\hline      s^{\mathcal{U}}_{-mon} & -l^\mathcal{U}_{att\degree}, &l^\mathcal{U}_{att\degree} - c^\mathcal{A}_{att\degree} & -l^{\mathcal{U}}_{att}, &l^{\mathcal{U}}_{att}- c^{\mathcal{A}}_{att} & 0, &0     \end{array}  $$
                             Simplified (loss = benefit):
                                 $$A=\begin{pmatrix}  - c_{dd} & -c_{dd}&  -c_{dd}\\ -\tilde{l}_{aa} -c_d & -c_d &  -c_d \\  -l_{aa}  & -l_a&  0 \end{pmatrix}$$
                                 $$B=\begin{pmatrix} - c_{aa} &-\tilde{c}_a& 0 \\\tilde{l}_{aa}  - \tilde{c}_{aa} &-c_a &   0 \\l_{aa}  - c_{aa} &  l_a- c_a & 0  \end{pmatrix}$$
                             Using scale-factors:
                         Assumptions 
                         Equilibrium Analysis 
                         Discussion
             GT+Cloud
             GT+CVSS
                 Vulnerability Patching Game and Application
                     Methodology #slide
                         1. Design suitable generic strategic complete-information game #h
                             Generic Patching Game #slide 
                                 Focusing on the single software asset that contains a vulnerability, we define a __single-target small security game__ in normal form through the following payoff matrix
                                 $$\begin{array}{ | c | c | c | }  \mathcal{D} \downarrow \mathcal{A}\rightarrow & s_a & s_{-{a}} \\ s_d &  - c^{\mathcal{D}}, - c^{\mathcal{A}}&  -c^{\mathcal{D}},  0 \\  s_{-{d}} &  -l^{\mathcal{D}},  l^{\mathcal{D}}- c^{\mathcal{A}} &  0,  0 \end{array}$$  #normal
                                 where the rows correspond to the pure strategies available to the defender $$\mathcal{D}$$ and the columns are the attacker's pure strategies. Here  we assume that the attacker's benefit equals the loss of the defender. 
                                 This game has been studied in the past (see e.g. \cite{@Samarji2015}) and is suitable for our scenario which is based on a single asset vulnerability assessment. It is not the specialisation of a big security game.
                                 The following assumption seem reasonable in a realistic setup: 
                             Small security games for application scenarios #h 
                                 CVSS GAMES
                                     Basic CVSS Game [Cyber Science 2017 Paper] #h
                                         ******Notations &amp; Definitions ****** 
                                             ******$$\kappa$$ -- defense cost (direct cost)****** 
                                             ******$$\bar{V} = \langle V_C, V_I, V_A \rangle$$ -- asset value vector****** 
                                             ******$$\alpha$$ -- relates to attacker's profile (strength)****** 
                                             ******$$\bar{\mu}_{Imp} = \langle \mu_{Imp, C}, \mu_{Imp, I}, \mu_{Imp, A}\rangle$$ -- CVSS Impact score in vector representation****** 
                                             ******$$\mu_{Exp}$$ -- CVSS Exploitability score****** 
                                         **Further Work**
                                             ******#todo Use more  sophisticated defender cost framework (consider indirect costs -- colateral damage?) ****** 
                                             ******#todo considerable novelty: expand to incomplete information game, using Bayesian framework, enabling the use of environmental CVSS scores****** 
                                             ******#todo include additional CVSS subscores (cf vulnerability factors in [Panaousus GameSec 14]****** 
                                             ******#todo Address issue with the ease of attacker acceptance****** 
                                         **Game Type**
                                             ******A 2-person static complete-information "security game"****** 
                                         ******Discussion****** 
                                             ******This is a very simple model, although similar to most of the other game models published in the  context of vulnerability patching  [#todo list other papers]. ****** 
                                             ******The idea of an attacker profile is a novelty, extending the idea of a organisational cyber security profile as presented in [Panaousis GameSec 14]. ****** 
                                             ******Attacker might not easily accept this model, as his expected utility is zero (note: not many papers talk about this!)****** 
                                         Utility Matrix $$\begin{array}{ | c | c | c | } \hline &amp; s^{a}_A &amp; s^{-a}_A \\ \hline s^{d}_D &amp;  - \kappa, - \alpha \cdot {\mu_{Exp}}^{-1} &amp;  -\kappa,  0 \\ \hline s^{-d}_D &amp;  -\bar{\mu}_{Imp} \cdot \bar{V},  \bar{\mu}_{Imp} \cdot \bar{V} - \alpha \cdot {\mu_{Exp}}^{-1}&amp;  0,  0 \\ \hline \end{array}$$  #normal
                                         ******Summary****** 
                                             ******Aim: improve vulnerability scoring through the use of game theory****** 
                                             **Main contributions:**
                                                 ******Design novel utility functions based on using CVSS metrics****** 
                                                 ******Report on application potential for a cyber tool (CAESAIR)****** 
                                         **Nash Equilibrium Analysis**
                                             ******There exists no pure NE (#todo add justification)****** 
                                             **Optimal Expected Utilities**
                                                 ******$$u_D|_{p=p^{*}}=-\kappa$$  ****** 
                                                 ******$$u_A|_{q=q^{*}} = 0$$****** 
                                             **Optimal Mixed NE Strategies**
                                                 ******$$p^{*} =  1 - \frac{\alpha \cdot {\mu_{Exp}}^{-1}}{\bar{\mu}_{Imp} \cdot \bar{V}}$$****** 
                                                 ******$$q^{*} = \frac{\kappa}{\bar{\mu}_{Imp} \cdot \bar{V}}$$****** 
                                     CVSS Game with Reward #h
                                         Utility Matrix
                                         $$\begin{array}{ | c | c | c | } \hline & s^{a}_A & s^{-a}_A \\ \hline s^{d}_D & - \kappa, - \alpha \cdot {\mu_{E}}^{-1}+r &  -\kappa,  r \\ \hline s^{-d}_D &  -\bar{\mu}_{Imp} \cdot \bar{V},  B - \alpha \cdot {\mu_{E}}^{-1}& 0,  0 \\ \hline \end{array}$$  #normal
                                             
                                         ******Optimal Mixed NE Strategies %****** 
                                         ******Optimal Expected Utilities %****** 
                                 CLOUD GAMES
                                     **Notations**
                                         **$$U$$ -- user (defender) #GT #security**
                                         **$$A$$ -- attacker #GT #security**
                                         **$$C$$ -- cloud provider #GT #security**
                                     IaaS -- CCRAM, Quanyan14 #small #cloud #GT #h
                                     StaaS -- Maghrabi et al, CyberSA 2015 #small #cloud #GT #h
                                         This is a small two-target resource allocation game #GT #security #small #two-target
                                         Utility Matrix
                                             **This gives us eight utility functions, arranged in a utility matrix as follows:** #AD****
                                                 **\begin{center}** #AD****
                                                     **\begin{tabular}{ |c|c|c| }**
                                                         **\caption{Generic One-Shot Single-Target Attacker-Defender Game}**
                                                         **\label{GenericMatrix}**
                                                         **\hline**
                                                         **&amp; $$s^{a}_A$$ &amp; $$s^{-a}_A$$ \\**
                                                         **\hline**
                                                         **$$s^{d}_U$$ &amp; $$u^{{11}}_U$$, $$u^{{11}}_A$$ &amp; $$u^{{12}}_U$$, $$u^{{12}}_A$$ \\**
                                                         **\hline**
                                                         **$$s^{-d}_U$$ &amp; $$u^{{21}}_U$$, $$u^{{21}}_A$$ &amp; $$u^{{22}}_U$$, $$u^{{22}}_A$$ \\**
                                                         **\hline**
                                                     **\end{tabular}**
                                                 **\end{center}**
                                         $$a$$ -- key critical asset
                                         $$a_1$$ -- container asset on user's system #GT #security #small #two-target
                                         Strategy spaces
                                             **$${\mathcal S}_U = \{ \mbox{put asset on cloud ($$t_2$$)}, \mbox{keep asset in-house ($$t_1$$)} \} = \{s^{c}_U, s^{h}_U\}$$**
                                             **$${\mathcal S}_A = \{ \mbox{attack asset on user system} , \mbox{attack asset on cloud} \} = \{s^{u}_A, s^{c}_A\}$$**
                                         $$a_2$$ -- container asset on cloud #GT #security #small #two-target
                                         $$t_2$$ -- target: the cloud #GT #security #small #two-target
                                         $$t_1$$ -- target: the user's host system #GT #security #small #two-target
                                     PaaS -- CCRAM #small #cloud #GT #h
                                     SaaS -- CCRAM, Quanyan15, Moving Target paper #small #cloud #GT #h
                                         **Can I trust the results that my SaaS cloud provider computes for me? #GT**
                                         **Research question: how can a cloud provider apply game theory to inform and enhance the use of software vulnerability metrics to better defend his system against external attacks? #security #scoring #GT**
                             Game Analysis #slide 
                                 The analysis of this presented security game is not difficult, it can be shown that there are no pure Nash equilibrium strategies as [..] and hence a closed-form expression exists \cite{} for determining the values $$p^{*} = \frac{c^{\mathcal{A}}}{l^{\mathcal{D}}} = 1 - \frac{c^{\mathcal{A}}}{l^{\mathcal{D}}}$$ and $$q^{*} = \frac{c^{\mathcal{D}}}{l^{\mathcal{D}}}$$ forming a mixed Nash equilibrium strategy $$(s_D^{*}, s_A^{*})$$ where $$p^*$$ and $$q^*$$ are the probability of defense and attack respectively. 
                                 This will be the underlying method to compute our attack likelihood in this scenario, based on $$q^*$$.
                                 One verifies that the expected utilities in this case are $$ u_D^{*} = -c^{\mathcal{D}} $$ and $$ u_A^{*} = 0 $$.
                                 [TODO: derive these results by applying the algebraic framework from the previous section]
                                 Issues: complete info problematic; attacker needs to know defense cost and loss; defender needs to know attack cost;
                         2. Add CVSS metrics to the utility functions #h
                             Move to CVSS #slide 
                                 We  now use CVSS to specify the payoff functions of the single-target security game of the previous section.  
                                 To achieve this aim, we will use the CVSS impact and exploitability sub-scores. 
                                 Our aim is only use this publicly available scoring data, as we are assuming a complete information game.
                             Approach #slide 
                                 The loss for the defender is due to the attack impact, which will be modelled as a function of the CVSS impact sub-score: $$l^{\mathcal{D}} =f({\mu}_{Imp})$$. 
                                 Furthermore we assume that the defender applies the principle of adequate protection [@pfleeger] by investing an amount for defence that is proportional to the loss: $$c^{\mathcal{D}} \sim f({\mu}_{Imp})$$ where $$f$$ is linear. 
                                 The attack cost depends on the CVSS exploitability subscore, taking into account that high score values indicate a vulnerability that is easy to exploit: $$c^{\mathcal{A}} = g({\mu_{Exp}})$$.
                             CVSS Game #slide 
                                 We start with the following game:
                                 $$\begin{array}{ | c | c | c | } \mathcal{D} \downarrow \mathcal{A}\rightarrow & a& \overline{a} \\ d &?,?& ?, 0 \\ \overline{d} &? ,?& 0, 0 \end{array}$$ #normal
                         3. Find normalised (strategically equivalent) game #h
                             Normalised CVSS Game #slide 
                                 We obtain the following game normal form:
                                 $$\begin{array}{ c | c | c } \mathcal{D} \downarrow \mathcal{A}\rightarrow & a& \overline{a} \\ \hline d & - \mu_{Imp},  {\mu}_{Exp}-10& -\mu_{Imp}, 0 \\ \hline\overline{d} & -{\mu}_{Imp}, {\mu}_{Imp}+10- {\mu}_{Exp} & 0, 0 \end{array}$$
                         4. Solve game and derive metrics #h
                         5. Analyse metrics, compare with existing ones #h
                     Notations and Terminology #slide 
                         Throughout this section we assume that there is a software asset $$s$$ with a vulnerability $$v$$. 
                         We denote by $$S_{\mathcal{D}}=\{d,\overline{d}\}$$ the strategy set of the Defender, where $$d$$ corresponds to the strategy that the Defender patches $$v$$ and $$\overline{d}$$ corresponds to the strategy that the Defender does not patch $$v$$. Likewise, the strategy set of the Attacker is given by $$S_{\mathcal{A}}=\{a,\overline{a}\}$$, where $$a$$ corresponds to the strategy of the Attacker to exploit $$v$$ and $$\overline{a}$$ that the Attacker does not attempt to exploit $$v$$) respectively, e.g. by running some malware. To patch the vulnerability, we assume that there is an associate cost, $$c^{\mathcal{D}}$$ for the Defender. To exploit vulnerability $$v$$, we assume that there is a cost $$c^{\mathcal{A}}$$ for the Attacker and a benefit $$b^{\mathcal{A}}$$. We assume that this benefit matches a loss $$l^{\mathcal{D}} = b^{\mathcal{A}}$$ for the Attacker. % #gamesec
                     CVSS Game
                         Example: Case Study 2 #slide 
                             The analysis of the previous game can be used for the vulnerability patching scenario.
                             The goal is to find realistic values for the game payoff parameters $$l^D$$ and $$c^A$$.
                             This could be done for example using the __Common Vulnerability Scoring System__ (CVSS).
                             Information about the severity of the vulnerability is publicly available online.
                         Case Study 2 (continued) #slide 
                             The attacker's cost $$c^A$$ is proportional to the inverse of the CVSS __exploitability subscore__:
                                 $$c^A = \alpha \cdot {\mu_{E}}^{-1} $$.
                                 Here, $$\alpha$$ is a constant that needs to be suitably defined.
                             The loss of the defender $$l^D$$ is due to a threat event impact, exploiting the vulnerability and affecting the asset's CIA security requirements.
                             Using the CVSS impact subscore, a vector $$V$$ with numerical components is defined, depending on the security criticality of the asset. 
                                 This yields $$l^D =   \mu_{Imp, C} \cdot V_C + \mu_{Imp, I} \cdot V_I + \mu_{Imp, A} \cdot V_A$$.
                             Finally, by plugging this into the game solutions, a recommendation can be made for the decision to patch the vulnerability.
             GT+Grey
                 Ethical Hacking Games
                     GT IS GOOD TO CAPTURE DILEMMAS
                         Ethical Hacking Games #slide 
                             Can we model the interactions between a defending organisation and a black, gray or white hat hacker?
                             Can we design a generic all-compassing game?
                         Issues #slide 
                             Difficulties:
                                 Nature of Game: proactive versus reactive
                                 Plausibility of model
                                 Existence of dilemmas - should reflect real world
                                     Dilemma: a potential deviation from NE equilibrium solutions by human players in real world
                                 Interpretation of mixed NE
                         Overview #slide 
                             Strategic goals:
                                 
                     GREY HAT HACKERS ARE PROBLEMATIC
                         Motivation #slide 
                             Slide Title: Black Hat Hackers
                                 Black hat hackers are criminals who act with malicious intent.
                                 Their motivation is often financial gain or revenge.
                                     They may also release malware that destroys files, holds computers hostage, or steals personal information.
                                     Black hats spread havoc wherever they go, often causing serious damage to individuals and organizations alike.
                                 Sometimes they target people they strongly disagree with for ideological reasons.
                             Slide Title: Gray Hat Hackers
                                 Gray hat hackers engage in a mix of both black and white hat activities.
                                 They may look for system vulnerabilities without permission or knowledge from the owner, and may report any issues found to the owner for a small fee.
                                 Gray hats may sometimes violate laws or ethical standards but usually lack the malicious intent of black hat hackers.
                                 They may believe they are doing good for companies by hacking into their systems, but owners rarely appreciate unauthorized access to their business information infrastructure.
                                 Often, the real intention of gray hats is to showcase their skills and gain publicity and recognition for contributing to cybersecurity.
                             Slide Title: Definition of a White Hat Hacker
                                 A white hat hacker is a computer security expert who specializes in finding vulnerabilities in systems and networks.
                                 Unlike black hat hackers, white hat hackers use their skills for ethical and lawful purposes, such as testing and improving the security of computer systems and networks.
                                 White hat hackers may be hired by organizations to conduct penetration testing or vulnerability assessments to identify potential weaknesses in their systems.
                                 They may also participate in bug bounty programs, where companies offer rewards to hackers who identify and report vulnerabilities in their systems.
                                 White hat hackers may also develop and promote security best practices, and may work with law enforcement or other organizations to help combat cybercrime.
                             __Black hat hacker definition__
                                 __Black hat hackers are criminals who break into computer networks with malicious intent. They may also release malware that destroys files, holds computers hostage, or steals passwords, credit card numbers, and other personal information.__
                                 __Black hats are motivated by self-serving reasons, such as financial gain, revenge, or simply to spread havoc. Sometimes their motivation might be ideological, by targeting people they strongly disagree with.__
                             __White hat hacker definition__
                                 __White hat hackers  sometimes also called ethical hackers or good hackers  are the antithesis of black hats. They exploit computer systems or networks to identify their security flaws so they can make recommendations for improvement__
                             __Gray hat hacker definition__
                                 __Somewhere between white and black are gray hat hackers. Gray hat hackers enact a blend of both black hat and white hat activities. Gray hat hackers often look for vulnerabilities in a system without the owner's permission or knowledge. If issues are found, they report them to the owner, sometimes requesting a small fee to fix the problem.__
                                 __A grey hat is a computer hacker or computer security expert who may sometimes violate laws or typical ethical standards, but usually does not have the malicious intent typical of a black hat hacker.__
                                 __Some gray hat hackers like to believe they are doing something good for companies by hacking their websites and invading their networks without permission. Still, company owners rarely appreciate unauthorized forays into their business information infrastructure.__
                                 __Often, a gray hat's real intention is to show off their skills and gain publicity  maybe even appreciation  for what they consider a contribution to cybersecurity.__
                             https://www.kaspersky.com/resource-center/definitions/hacker-hat-types
                     #RC1
                         LOOKING AT THE SHADES OF GREY: ONE-STAGE STRATEGIC GAMES
                             Motivation #slide 
                                 Previous work
                                 Why not inspection game?
                                 Presence of dilemmas
                             Strategic Characterisation #h 
                                 Game $$G_1$$: Black-Hat Hacker #slide 
                                     $$\begin{array}{ c | c | c }  \mathcal{D} \downarrow \mathcal{B}\rightarrow & \text{not cooperate (attack)} & \text{cooperate (not attack)}  \\\hline  \text{not trust (defend)} &  \;\cdot\;,\rightarrow  &  \downarrow\; ,\;\cdot\;\\\hline   \text{trust (not defend)}  &  \uparrow\; ,\;\cdot\;  &  \;\;\cdot\;,\leftarrow \end{array}$$ #eyo-style:Normal 
                                     There is no pure NE but one mixed NE.
                                     No dilemma is present.
                                     This is a standard security game.
                                 Game $$G_2$$: Grey-Hat Hacker #slide 
                                     $$\begin{array}{ c | c | c }  \mathcal{D} \downarrow \mathcal{G}\rightarrow & \text{not cooperate (betray)} & \text{cooperate (not betray)}  \\\hline  \text{not trust (not employ)} & { \;\cdot\;, \;\cdot\;\;}& \; \downarrow\; ,\;\leftarrow\;\\\hline   \text{trust (employ)}  &  \uparrow\; ,\;\rightarrow\;  &  \;\cdot\;, \; \cdot \;\end{array}$$ #eyo-style:Normal 
                                     There are two pure NEs: (not trust, betray) and (trust, not betray).
                                     There is also one mixed NE.
                                     There are several dilemmas present.
                                 Game $$G_3$$: White-Hat Hacker #slide 
                                     $$\begin{array}{ c | c | c }  \mathcal{D} \downarrow \mathcal{W}\rightarrow & \text{not cooperate (betray)} & \text{cooperate (not betray)} \\\hline  \text{not trust (not employ)} &  \;\cdot\;, \;\rightarrow\;\;& \; \downarrow\; ,\;\cdot\;\\\hline   \text{trust (employ)}  &  \uparrow\; ,\;\rightarrow \;  &  \;\cdot\;, \; \cdot\;\end{array}$$ #eyo-style:Normal 
                                     There is one pure NE (trust, high effort). 
                                     There is no dilemma present.
                                 Discussion #slide 
                                     GT seems very fitting
                                     Justification 
                                         Number of dilemmas fits well
                                         Literature: inspection game
                             Games Details #h 
                                 Game $$G_1$$: Black-Hat Hacker #slide 
                                     $$\begin{array}{ c | c | c }  \mathcal{D} \downarrow \mathcal{B}\rightarrow & \text{not cooperate (attack)} & \text{cooperate (not attack)}  \\\hline  \text{not trust (defend)} &  - c_d, - c_a&  -c_d,  0 \\\hline   \text{trust (not defend)}  &  -c_l,  r_a- c_a &  0,  0 \end{array}$$ #eyo-style:Normal 
                                     Utilities
                                         $$c_{d}$$ -- the defense cost
                                         $$c_{a}$$ -- the attacker's cost
                                         $$c_{l}$$ -- the defender's loss from an attack
                                         $$b_{r}$$ -- the reward (benefit) of the attacker from an attack.
                                     Assumptions (\cite{Pfleeger2007-qm})
                                         __Principle of Adequate Protection__: $$c_{d} <c_{l}$$
                                         __Principle of Easiest Attack__: $$c_{a} < c_{l}$$
                                 Game $$G_2$$: Grey-Hat Hacker #h 
                                     Strategic normal form #slide 
                                         $$\begin{array}{ c | c | c }  \mathcal{D} \downarrow \mathcal{G}\rightarrow & \text{not cooperate (betray)} & \text{cooperate (not betray)}  \\\hline  \text{not trust (not employ)} &  \;-c_l\;, \;b_a\;\;& \; 0\; ,\;0\;\\\hline   \text{trust (employ)}  &  -c_f-c_l\; ,\;b_f+b_a-c_r\;  &  \;b_p-c_f\; ,\;b_f \;\end{array}$$ #eyo-style:Normal 
                                         Roles
                                     Utilities #slide 
                                         $$c_l$$ -- organisation's loss cost due to exploited vulnerability
                                         $$b_a$$ -- black-hat hacker benefit arising from exploiting the vulnerability
                                         $$c_f$$ -- organisation's cost of paying a fee for white-hat hacking role
                                         $$b_f$$ -- grey-hat hacker's remuneration from obtaining fee from organisation
                                         $$c_r$$ -- remorse (psychological) cost to the grey-hat hacker
                                         $$b_p$$ -- benefit of increased security for the organisation, due to patched vulnerability
                                     Assumptions #slide 
                                         All parameters are nonnegative, $$b_a$$, $$b_p$$, $$c_r$$ and $$c_f$$ are positive
                                         $$b_p>c_f$$: white-hat hacker is trusted to achieve better security
                                         $$c_r>b_a$$: trusted grey-hat hacker strives to cooperate based on psychological motivation 
                                             rewards the trust in them: remorse cost is greater than betrayal benefit #wfe-ignore-item 
                                         NE Solutions #slide 
                                             The game has three NE strategies: the pure strategy profiles $$s_1^*=((1,0),\begin{pmatrix} 1 \\ 0\\ \end{pmatrix})$$ and $$s_2^*=((0,1),\begin{pmatrix} 0 \\ 1\\ \end{pmatrix})$$ and the mixed strategy profile $$s_3^*=(x^*,y^*)$$ where $$x^*=(1-b_a/c_r,b_a/c_r)$$ and $$y^*=\begin{pmatrix} 1-c_f/b_p \\ c_f/b_p\\ \end{pmatrix}$$.
                                             The corresponding game value pairs are $$v_{1}=(-c_l,b_a)$$, $$v_{2}=(b_p-c_f,b_f)$$ and $$v_{3}=(c_l(c_f-b_p)/b_p,b_ab_f/c_r)$$.
                                     Equilibrium Analysis (I) #slide 
                                         $$v_B \prec_{\mathcal{D}} v_G \prec_{\mathcal{D}} v_W$$
                                         if $$b_a \neq b_f$$:
                                             $$v_G \prec_{\mathcal{H}} v_W$$
                                             $$\Rightarrow v_G \prec v_W$$
                                             if $$b_a < b_f$$:
                                                 $$v_B \prec_{\mathcal{H}} v_W$$
                                                 $$\Rightarrow v_B \prec v_W$$
                                             if $$b_a > b_f$$:
                                                 $$v_W \prec_{\mathcal{H}} v_B$$
                                         if $$b_a=b_f$$:
                                             $$v_G \prec_{\mathcal{H}} v_W$$
                                             $$v_G \prec_{\mathcal{H}} v_B$$
                                             $$\Rightarrow v_G \prec v_W$$
                                     Equilibrium Analysis (II) #slide 
                                         Proposition
                                         Given the generic utility functions and their assumptions (A1)-(A3), the following statements hold:
                                             $$v_G \prec v_W$$, so $$v_W$$ is Pareto-optimal.
                                             If $$b_a < b_f$$ then $$v_B \prec v_W$$.
                                 Game $$G_3$$: White-Hat Hacker #slide 
                                     $$\begin{array}{ c | c | c }  \mathcal{D} \downarrow \mathcal{B}\rightarrow & \text{not cooperate (betray)} & \text{cooperate (not betray)} \\\hline  \text{not trust (not employ)} &  \;\cdot\;, \;\rightarrow\;\;& \; \downarrow\; ,\;\cdot\;\\\hline   \text{trust (employ)}  &  \uparrow\; ,\;\rightarrow \;  &  \;\cdot\;, \; \cdot\;\end{array}$$ #eyo-style:Normal 
                                     Utilities
                                          
                                          
                                          
                                         
                                     Assumptions 
                             Unifying Approach #h 
                                 Burden Game #h 
                                     Unconditionally un-cooperative case #h  
                                         Notations #slide
                                             $$B$$: Burden to carry (joint burden)
                                             $$p$$: reward (pride) for sole carrying of honorable duty
                                             $$d$$: Sole punishment from defecting (system damage due to neglecting honorable duty)
                                             $$r$$: relief from sole defecting of criminal duty
                                             $$g$$: reward (gain from attack) for sole carrying of criminal duty
                                         Game #slide
                                             $$\begin{array}{ c | c | c }  S \downarrow W\rightarrow & \text{carry (attack)} & \text{defect (not attack)}  \\\hline  \text{carry (defend)} &  -B\;,\;-B\rightarrow  &  \downarrow\;-B+p ,\;-B+r\;\\\hline   \text{defect(not defend)}  &  \uparrow\; -d,\;g\;  &  0\;,\;0\leftarrow \end{array}$$ #eyo-style:Normal 
                                         New Game #slide
                                             $$\begin{array}{ c | c | c }  S \downarrow W\rightarrow & \text{carry (attack)} & \text{defect (not attack)}  \\\hline  \text{carry (defend)} &  -B\;,\;-B\rightarrow  &  \downarrow\;-B+p ,\;-B+r\;\\\hline   \text{defect(not defend)}  &  \uparrow\; -d,\;g\;  &  0\;,\;0\leftarrow \end{array}$$ #eyo-style:Normal 
                             Payoff Design #slide 
                             INVESTIGATION
                                 D: matrix([-c[l],0],[-c[f]-c[l],b[p]-c[f]]);
                                 G: matrix([b[r],0],[b[r]+b[f]-c[r],b[f]]);
                     #RC2
                         Background #slide 
                             Bimatrix Games
                             Stochastic Games
                         Bimatrix Games with Rational Payoff Functions #h 
                             Game and NE Equilibrium Strategy Definitions #slide 
                                 Denote $${\mathcal{G}}(A,B,C)$$ bimatrix game with rational payoff functions
                                 The corresponding payoffs to Player 1 and Player 2 are $$\frac{^\top{\!}xAy}{^\mathsf{T}{\!}xCy}$$ and $$\frac{^\top{\!}xBy}{^\top{\!}xCy}$$ respectively. 
                                 An __equilibrium strategy__ $$(x^*,y^*)$$ satisfies $$x^*Cy^*\neq 0$$ and
                                     $$ \frac{x^*Ay^*}{x^*Cy^*} \ge  \frac{xAy^*}{xCy^*} \quad\forall x: xCy^*\neq 0$$
                                     $$ \frac{x^*By^*}{x^*Cy^*} \ge  \frac{x^*By}{x^*Cy} \quad\forall y: x^*Cy\neq 0$$
                                 We say that $$s^*=(x^*,y^*)$$ is an __NE strategy profile__ and that $$v=(v_A,v_B)$$ is the corresponding __NE equilibrium value pair__. 
                                 Need to assume $$C>0$$ #wfe-ignore-item 
                             Generalised Eigensystem Theorem #slide 
                                 The following theorem gives a sufficient condition for the existence of an NE of the form (\ref{eq:NE-bimatrix). 
                                 Given the game $$\mathcal{G}(A,B,C)$$, assume the matrix pencils $$A-\lambda C$$  and $$B-\lambda C$$ are both regular, each with a real eigenvalue $$\mu_A$$ and $$\mu_B$$ respectively. Let $$x_{\mu_B}$$ be a nonnegative left eigenvector of $$B-\lambda C$$ with respect to $$\mu_B$$ and denote $$y_{\mu_A}$$ a nonnegative right eigenvector of $$B-\lambda C$$ with respect to $$\mu_A$$. Then $$(x^*,y^*) = (x_{\mu_B}$$, $$y_{\mu_A}$$) is an NE strategy profile of the game $$\mathcal{G}$$ and $$(\mu_A, \mu_B)$$ is the corresponding game value pair.
                             Proof #slide 
                                 We have for a nonnegative left eigenvector $$x_{\mu_B}$$ satisfying $$x^\top_{\mu_B} B = \mu_B x^\top_{\mu_B} C$$ that for any Player 2 strategy $$y$$ it holds $$\frac{x^\top_{\mu_B} B y}{x^\top_{\mu_B} C y} = \mu_B $$. 
                                 This trivially implies $$\frac{x^\top_{\mu_B} B y_{\mu_A}}{x^\top_{\mu_B} C y_{\mu_A}} \ge \frac{x^\top_{\mu_B} B y}{x^\top_{\mu_B} C y} $$. 
                                 Similarly, we can show for a nonnegative right eigenvector $$y_{\mu_A}$$ that $$\frac{x^\top_{\mu_B} Ay_{\mu_A}}{x^\top_{\mu_B} C y_{\mu_A}} \ge \frac{x Ay_{\mu_A}}{x C y_{\mu_A}} $$ for any Player 1 strategy $$x$$.
                                 Hence these strategies are mutual best responses and by definition NE strategies with payoffs $$\mu_A$$ and $$\mu_B$$ as required.  
                                 From this, the theorem follows. 
                             Remarks #slide 
                                 If $$C=E$$, this yields a linear algebra characterisation for NE solutions for standard bimatrix games.
                                 If eigenvectors are positive, we obtain completely mixed solutions
                                 Compare with Milchtaich \cite{Milchtaich2006-ro,Milchtaich2008-ny}, w/o LA
                                 If $$C=E$$ and $$B=-A$$, c.f. Weil 
                                 If $$B=-A$$, one obtains the work by Thomson et al.~\cite{} on the von Neumann model for game theory.
                                 A mixed solution is a generalised eigensystem. 
                             Lag-free Equilibrium Solutions #slide 
                                 Define a particular type of NE solutions: lag-free solutions
                                 Definition: a NE solution satisfying
                                     $$\frac{x^\top_{\mu_B} B y_{\mu_A}}{x^\top_{\mu_B} C y_{\mu_A}} \ge \frac{x^\top_{\mu_B} B y}{x^\top_{\mu_B} C y} $$. 
                                     $$\frac{x^\top_{\mu_B} Ay_{\mu_A}}{x^\top_{\mu_B} C y_{\mu_A}} \ge \frac{x Ay_{\mu_A}}{x C y_{\mu_A}}$$
                                 is called a __lag-free__ solution.
                             Necessary and Sufficient Conditon #slide 
                             A Specific Pencil #slide 
                                 Consider a regular matrix pencil of the form $$A-\lambda B$$ where $$A$$ is invertible and $$\text{rank}(B)=1$$. 
                                 We call this a __rank-1 pencil__. 
                                 We can write $$B=uv^\top$$ where $$u,v\in {\R}^n$$ nonnegative. 
                                 We define normalised left and right eigenvectors w.r.t. the factorisation of $$B$$ as eigenvectors satisfying $$x^\top u = 1$$ and $$y v^\top = 1$$. 
                             Eigenspace Structure rank-1 regular pencil Result #slide 
                                 If $$v^\top \text{adj}(A) u=0$$, the pencil has no finite eigenvalues. 
                                 Otherwise, the pencil has a single finite eigenvalue $$c=\frac{\det(A)}{v^\top \text{adj}(A) u}$$.
                                 The associated left and right normalised eigenvectors $$x,y$$ can be determined as follows:
                                     $$x^\top=\frac{v^\top\text{adj}(A)}{v^\top \text{adj}(A) u}$$,
                                     $$y=\frac{\text{adj}(A)u}{v^\top \text{adj}(A) u}$$.
                             Proof #slide #proof
                                 It can directly be verified that, based on the definitions of $$c$$, $$x$$ and $$y$$ as in the theorem, that it holds $$Ay=cuv^\top y$$ and $$x^\top A=cx^\top uv^\top$$. 
                                 So $$c$$ is an eigenvalue, and this must be the only one as the degree of the characteristic polynomial $$\det(A-\lambda B)$$ is one. 
                                 Furthermore, it can be seen that $$x^\top$$ and $$y$$ are normalised eigenvectors.
                             Rank-1 Bimatrix Games #h 
                                 \subsection{Rank-1 Bimatrix Games}
                                 This section considers the case where $$C\ge 0$$, $${\rm rank}(C)=1$$, and the implications on the existence of NE solutions of the game $${\mathcal{G}}(A,B,C)$$.
                                 
                                 We refer to a matrix pencil of the form $$A-\lambda B$$ and $${\rm rank}(C)=1$$ as a rank-1 pencil. We can then use rank-factorisation to write $$C={p}{q}$$ where $${p},{q}\in \mathbb{R}^n$$ are nonnegative row and column vectors.
                                 We define normalised left and right eigenvectors w.r.t. the representation $$C=pq$$ as eigenvectors satisfying $$x {p} = 1$$ and $$y {q} = 1$$.
                                 
                                 The following proposition provides an eigenspace structure result for rank-1 regular matrix pencils, which will be required when analysing the Shades of Grey game in Section \ref{sec:shades-of-grey}.
                                 \begin{proposition}
                                     The rank-1 pencil $$A-\lambda pq$$ has no finite eigenvalues if $${q}\,{\rm adj}(A) {p}=0$$. Otherwise, the pencil has the single finite eigenvalue $$c=\frac{\det(A)}{{q} \,\,{\rm adj}(A) {p}}$$.
                                     The associated left and right normalised eigenvectors $$x,y$$ can be determined explicitly using the formulae $$x=\frac{{q}\,{\rm adj}(A)}{{q} \,{\rm adj}(A) {p}}$$ and $$y=\frac{\,{\rm adj}(A){p}}{{q} \,{\rm adj}(A) {p}}$$.
                                 \end{proposition}
                                 \begin{proof}
                                     Based on the definitions of $$c$$, $$x$$ and $$y$$ as in the proposition, it can be directly verified that $$Ay=c{p}{q} y$$ and $$x A=cx {p}{q}$$.
                                     So $$c$$ is a finite eigenvalue of $$A-\lambda pq$$ with left and right eigenvectors $$x$$ and $$y$$. This must be the only eigenvalue as the degree of the characteristic polynomial $$\det(A-\lambda pq)$$ is bound by $${\rm rank}(pq)$$, which is one. Furthermore, it is straightforward to see that $$x$$ and $$y$$ are normalised eigenvectors.
                                 \end{proof}
                         Bimatrix Stochastic Stopping Games #h 
                             Introduction #slide 
                                 In this game model, we have $$N=1$$ using the notations of \cite{Shapley1953-hi}. 
                                 Using modern terminology, we would say we have a 2-state Markov-game with a transient state $$s_0$$ ``play" and an absorbing state $$s_1$$ ``stop''. 
                                 State transition probabilities depend on the current state and chosen strategies. 
                             Research Questions #slide 
                                 Natural questions to ask are then:
                                     What is the expected number of steps for the game to finish?
                                     How can we define a value and optimal solutions to this repeated zero-sum game?
                                     How it might these relate to the value and optimal solutions of the stage game?
                                 Let us fix a strategy profile $$(x^\top,y)$$.
                             Value of Stochastic Matrix Game #slide 
                                 The following well-known lemma summarises answers:
                                 \begin{lemma}[\cite{Shapley1953-hi}]
                                     The expected number of steps required for the game $$\mathcal{G}(A,S)$$ to stop when using the stationary strategy $$(x^\top,y)$$ is $$1/x^\top Sy$$. The expected resulting payoff  is $$u=\frac{x^\top Ay}{x^\top Sy}.$$ The value $$v$$ of the game is well-defined by
                                     $$ v=\max_x\min_y \frac{x^\top Ay}{x^\top Sy} = \min_y\max_x \frac{x^\top Ay}{x^\top Sy}. $$
                                     In general, $$v$$ is hence different from the value of the stage game.
                                 \end{lemma}
                             Bimatrix Version #slide 
                                 A partial extension is:
                                 \begin{lemma}
                                     Assume the stationary strategy $$(x^\top,y)$$ satisfies $$x^\top Sy<1$$.
                                     Then the expected number of steps required for the game $$\mathcal{G}(A,B,S)$$ to stop when the players are using $$(x^\top,y)$$ is $$1/x^\top Sy$$. The expected resulting payoff is $$u=(\frac{x^\top Ay}{x^\top Sy},\frac{x^\top By}{x^\top Sy}).$$ 
                                 \end{lemma}
                             Proof #slide 
                                 After $$k$$ iterations the accumulated payoff of the game when playing the same strategy $$(x^\top,y)$$ in each round is $$u_{A,k}(x,y)=x^\top Ay\sum_{i=0}^{k-1}(1-x^\top Sy)^i$$ and $$u_{B,k}(x,y)=x^\top By\sum_{i=0}^{k-1}(1-x^\top Sy)^i$$. 
                                 Since $$s:=1-x^\top Sy<1$$, the game finishes with probability one and $$ \sum_{i=0}^\infty s^i = \frac{1}{1-s}$$.
                                 The expected game payoff pair is $$u = (u_{A},u_{B}) = \lim_{k\to \infty}(u_{A,k},u_{B,k})=(\frac{x^\top Ay}{x^\top Sy},\frac{x^\top By}{x^\top Sy})$$.
                             More #slide 
                                 We would like to maximise $$u$$
                                 This leads to $$ u=(\max_x\max_y \frac{x^\top Ay}{x^\top Sy},\max_y\max_x \frac{x^\top By}{x^\top Sy}).$$
                                 This value might not be specific to $$u$$, and not unique
                                 Further theoretical characterisations are not in the scope of this outline
                     #RC3
                         REPEATED GAMES ARE MORE REALISTIC
                             Grey-Hat Stochastic Stopping Game #h 
                                 Repeated Grey-Hat Game #h 
                                     Generic Game Design #slide 
                                         Game $$\mathcal{G}(D,G,S)$$:
                                             $$D=\begin{pmatrix}  -c_l&0 \\ -c_f-c_l & b_p-c_f \\  \end{pmatrix}$$
                                             $$G=\begin{pmatrix}  b_r&0 \\ b_f+b_r-c_r &b_f  \\  \end{pmatrix}$$
                                             $$S=\begin{pmatrix}  s_0&s_1\\ s_2 &s_3  \\  \end{pmatrix}$$ $$(0<s_i\le 1)$$
                                     Specific Game Instances #slide 
                                         Rank-1 Games:
                                             Tints of Black: a grey-hat hacker, determined to turn into black-hat hacker: $$S=\begin{pmatrix}  1&s_B\\ 1&s_B\\  \end{pmatrix}$$
                                             Tints of White: a grey-hat hacker, striving to become white-hat hacker: $$S=\begin{pmatrix}  s_W&1\\ s_W&1\\  \end{pmatrix}$$
                                             Self-Absorbed Syndicate: an egoistic organisation, on a mission to detect unethical hacking: $$S=\begin{pmatrix}  1&1\\ s_E&s_E \\  \end{pmatrix}$$
                                             Selfless Syndicate: an altruistic organisation, believing in ethical hacking: $$S=\begin{pmatrix}  s_A&s_A\\1&1 \\  \end{pmatrix}$$
                                         Rank-2 Game:
                                             Black or White Thinking: both $$S=\begin{pmatrix}  1&0\\ 0&1  \\  \end{pmatrix}$$
                                     Stationary Equilibrium Solutions #slide 
                                         Consider the stochastic non-zero sum game $$\mathcal{G}(D,G,S)$$. If $$\text{rank}(S)=1$$, the game has two pure and one mixed stationary NE.
                                 Discussion #slide 
                                     Rank-condition
                                 INBOX #later
                                     Otherwise, $$\text{rank}(S)=2$$, and:
                                         If $$-c_l/s_0>-(c_l+c_f)/s_2 \Longleftrightarrow s_0/c_l>s_2/(c_l+c_f)$$ then $$((1,0),\begin{pmatrix} 1 \\ 0 \\  \end{pmatrix})$$ is a pure NE with $$\lambda^*=-c_l/s_0$$.
                                         If $$b_p>c_f$$ then $$((0,1),\begin{pmatrix} 0\\ 1\\  \end{pmatrix})$$ is a pure NE with $$\lambda^*=0$$.
                                         GRANULARITY I
                                             RESULT
                                                 If $$D-\lambda S$$  and $$A-\lambda S$$ are both regular, each with a real eigenvalue $$\mu_D$$ and $$\mu_A$$ respectively. Let $$x_{\mu_A}$$ be a nonnegative left eigenvector of $$B-\lambda S$$ with respect to $$\mu_A$$ and denote $$y_{\mu_D}$$ a nonnegative right eigenvector of $$A-\lambda S$$ with respect to $$\mu_D$$. Then $$(x^*,y^*) = (x_{\mu_A}$$, $$y_{\mu_D}$$) is a stationary equilibrium strategy profile of the game $$\mathcal{G}$$ and $$(\mu_D, \mu_A)$$ is the corresponding game value pair.
                                             GRANULARITY II
                                     PROOFS
                                         Proof -- Case $$\text{rank}(S)=1$$ #slide 
                                             Let $$S=lr^\top$$ where $$l,r \in \R^n$$ are nonnegative vectors
                                             The stage game $$G_2$$ has two pure and one mixed stationary NE.
                                             Let $$(^\top x^\ast,y^\ast)$$ be such an NE solution.
                                             Then $$^\top x^\ast S y^\ast>0$$ and with $$\alpha=^\top x^\ast l$$, $$\beta=r^\top y^\ast$$
                                                 $$ \frac{x^*Dy^*}{x^*Sy^*} \ge  \frac{xDy^*}{xSy^*} \quad\forall x: xCy^*\neq 0$$
                                                 $$ \frac{x^*By^*}{x^*Cy^*} \ge  \frac{x^*By}{x^*Cy} \quad\forall y: x^*Cy\neq 0$$
                                                 $$ x^*Ay^* \ge  xAy^* \quad\forall x$$
                                                 $$ x^*By^*\ge x^*By \quad\forall y$$
                                         Proof -- Case $$\text{rank}(S)=2$$ #slide 
                                     Shades of Grey: $$S=\begin{pmatrix}  1&s_B\\ s_W&1  \\  \end{pmatrix}$$
                                     Best Response #slide 
                                         $$\mathcal{BR}(y)$$ -- the set of __best responses__ to a strategy $$y$$ (the set of all strategies $$x$$ of Player 1 maximizing his expected payoff $$x^\top Ay/x^\top Cy$$).
                                         Similarly a best response to $$x$$ is a strategy $$y\in \mathcal{BR}(x)$$ of Player 2 that maximizing her expected payoff $$x^\top By/x^\top Cy$$. 
                                         #definition
                                             A Player 2 strategy $$y^*$$ is a __Nash equilibrium best response__ to a Player 1 strategy $$x$$ (denoted $$y^* \in \mathcal{BR}(x)$$ in the sequel) is a strategy $$y^*$$ satisfying $$ xBy^* \ge    xBy$$ for all other Player 2 strategy $$y$$.
                                         An equilibrium strategy is hence a strategy pair $$(x^*,y^*)$$ of mutual best responses: $$ x^* \in \mathcal{BR}(y^*) $$ and $$ y^* \in \mathcal{BR}(x^*) $$.
                                     A Best Response Lemma #slide #CYENS 
                                         #lemma:best-response 
                                             If Player 1's mixed strategy $$x^*$$ is a best response to the (mixed) strategy $$y$$ of the other player, then, for each pure strategy $$e_i$$ such that $$x_i > 0$$, it must be the case that $$e_i$$ is itself a best response.  In particular, the payoff $$e_i Ay$$ must be the same for all such strategies.
                                         Note: an analogous lemma can be stated for Player 2, $$y^*$$ and $$x$$.
                                     Proof (I) #slide #CYENS 
                                         Recap: due to $$x^* \in \mathcal{BR}(y^*)$$ we have $${}^t \!x^*Ay^*=v_{A}$$ and $${}^t \!xAy^*\le v_{A}$$ for all $$x$$. 
                                         Let us write $${}^t \!x^*= (x^*_{1},\ldots ,x^*_{i},\ldots ,x^*_{n})$$ and assume $$x^*_{i}\neq 0$$.
                                         Furthermore, denote $${}^t \!e_{i}= (\underbrace{0,\ldots ,0}_{i-1}, 1, 0,\ldots , 0)$$.
                                         It is clear that $${}^t \!e_{i}Ay^*\le v_{A}$$ (why?).
                                     Proof (II) #slide #CYENS 
                                         Now assume $${}^t \!e_{i}Ay^*< v_{A}$$, minimal for all pure strategies. 
                                         Find $$j\neq i$$, $$x_{j}^*\neq 0$$ (such $$j$$ exists since $$x^*$$ is not pure) and define ("falling from the sky"):
                                             $${}^t \!\hat{x}={}^t \!x^*-x_i^* {\;}^t\! e_i+x_i^* {\;}^t\! e_j$$.
                                         It follows
                                             $$^t\!\hat{x}Ay^*={}^t\!x^*Ay^*+x_{i}^*\overbrace{(^t\!e_{j}Ay^*-{}^t\!e_{i}Ay^*)}^{>0}>\,{}^t\! x^*Ay^*$$
                                         which is a contradiction. Hence we must have $${}^t \!e_{i}Ay^*= v_{A}$$. 
                                         An additional consequence is $${}^t \!x^*Ay^*= v_{A}{}^t\!e$$. 
                                     The Rank-2 Case
                                         The generalised eigensystems are
                                             $$\mathcal{E}_D=\left\{\left[ -c_l, \left\{ \begin{pmatrix}  1&0  \\ \end{pmatrix},\begin{pmatrix}  c_l+b_p-c_f\\c_l+c_f  \\ \end{pmatrix}  \right\}\right],\left[b_p-c_f,\left\{ \begin{pmatrix}  c_l+c_f & c_f-c_l-b_p \\ \end{pmatrix} \begin{pmatrix}  0\\1  \\ \end{pmatrix}  \right\}\right]\right\}$$
                                         and
                                             $$\mathcal{E}_G=\left\{\left[b_a,\left\{ \begin{pmatrix}  b_a-b_f & b_a+b_f-c_r \\ \end{pmatrix}, \begin{pmatrix}  1\\0  \\ \end{pmatrix}  \right\}\right],\left[ b_f, \left\{ \begin{pmatrix}  0&1  \\ \end{pmatrix},\begin{pmatrix}  c_r-b_f-b_a\\b_a-b_f  \\ \end{pmatrix}  \right\}\right]\right\}$$.
                                         Potentially large number of combinations
                                         discuss cases
                                         positive eigenvectors
                                         $$\mathcal{E}_D$$: selecting $$y_D$$
                                             both eigenvectors of $$\mathcal{E}_D$$ are nonnegative
                                             Note however: interchangeable
                                             This means:
                                                 We only need to consider one element of the set $$\mathcal{E}_D$$: 
                                                 this will be preferred by the defending organisation.
                                                 this is $$y_D^{(2)}$$ since $$b_p-c_f>0>-c_l$$.
                                                 need to pair this up with either (or both) $$x_G^{(1)},x_G^{(2)}$$
                                                 equilibrium solutions are obtained after normalising
                                         Selecting $$x$$:
                                             Case $$b_a < b_f$$:
                                                 choose $$x_G^{(2)}$$ as better game value (and anyway since $$b_a-b_f<0$$ and $$b_a+b_f-c_r>0$$)
                                             Case $$b_a > b_f$$:
                                                 
                                             Case $$b_a = b_f$$:
                                                 both $$x$$ yield the same strategy $$(0,1)$$
                                                 there is no second EV? dimension is one as $$G$$ is not diagonalisable
                                         Theorem #slide 
                                             The rank-2 Black or White game has precisely one Pareto-optimal Nash equilibrium $$(x^*,y^*)$$ with associated game value profile $$(v^*_D,v^*_G)$$. Depending on the comparative relationship between $$b_a$$ and $$b_f$$, it holds:
                                                 If $$b_a \le b_f$$, then the equilibrium is pure with $${}^tx^*=(0,1),y^*=\begin{pmatrix}  0\\1  \\ \end{pmatrix}$$ and $$v^*_D=b_p-c_f,v^*_G=b_f$$.
                                                 If $$b_a > b_f$$, then there is an equilibrium with one mixed and one pure strategy: $${}^tx^*=\begin{pmatrix}  \frac{b_a-b_f}{2b_a-c_r},&\frac{b_a+b_f-c_r}{2b_a-c_r}  \\ \end{pmatrix},y^*=\begin{pmatrix}  0\\1  \\ \end{pmatrix}$$ and $$v^*_D=b_p-c_f,v^*_G=b_a$$.
                                         Proof #h 
                                             The pencils $$D-\lambda S=D-\lambda I$$ and $$G-\lambda S=G-\lambda I$$ are trivially regular. 
                                             One finds for $$G-\lambda I$$
                                             $$\mathcal{E}_G=\left\{\left[ \mu_G^{(1)}, x_G^{(1)}, y_G^{(1)}\right],\left[\mu_G^{(2)}, x_G^{(2)}, y_G^{(2)}\right]\right\}$$
                                             where
                                             $$\mu_G^{(1)}=b_a,\;x_G^{(1)}=\begin{pmatrix}  b_a-b_f, & b_a+b_f-c_r \\ \end{pmatrix},\;y_G^{(1)}=\begin{pmatrix}  1 \\ 0  \\ \end{pmatrix}$$
                                             and
                                             $$\mu_G^{(2)}=b_f,\;x_G^{(2)}=\begin{pmatrix}  0,&1  \\ \end{pmatrix},\;x_D^{(2)}= \begin{pmatrix}  c_r-b_f-b_a\\b_a-b_f  \\ \end{pmatrix}.$$
                                             We now distinguish three cases:
                                                 Based on assumptions (A1)-(A3), both eigenvectors can be normalised to be nonnegative, and we can again use the interchangeable property to choose a suitable one 
                                                 If $$b_a<b_f$$, then 
                                         INBOX
                                             The pencils $$D-\lambda S=D-\lambda I$$ and $$G-\lambda S=G-\lambda I$$ are trivially regular. 
                                             In fact, the generalised eigensystems of the pencil in question coincide with ordinary eigensystems.
                                             $$\mathcal{E}_D=\left\{\left[ \mu_D^{(1)}, x_D^{(1)}, y_D^{(1)}\right],\left[\mu_D^{(2)}, x_D^{(2)}, y_D^{(2)}\right]\right\}$$
                                             where
                                             $$\mu_D^{(1)}=-c_l,\;x_D^{(1)}=\begin{pmatrix}  1,&0  \\ \end{pmatrix},\;y_D^{(1)}=\begin{pmatrix}  c_l+b_p-c_f\\c_l+c_f  \\ \end{pmatrix}$$
                                             and
                                             $$\mu_D^{(2)}=b_p-c_f,\;x_D^{(2)}=\begin{pmatrix}  c_l+c_f, & c_f-c_l-b_p \\ \end{pmatrix},\;x_D^{(2)}= \begin{pmatrix}  0\\1  \\ \end{pmatrix} .$$
                                             One finds for $$G-\lambda I$$
                                             $$\mathcal{E}_G=\left\{\left[ \mu_G^{(1)}, x_G^{(1)}, y_G^{(1)}\right],\left[\mu_G^{(2)}, x_G^{(2)}, y_G^{(2)}\right]\right\}$$
                                             where
                                             $$\mu_G^{(1)}=b_a,\;x_G^{(1)}=\begin{pmatrix}  b_a-b_f, & b_a+b_f-c_r \\ \end{pmatrix},\;y_G^{(1)}=\begin{pmatrix}  1 \\ 0  \\ \end{pmatrix}$$
                                             and
                                             $$\mu_G^{(2)}=b_f,\;x_G^{(2)}=\begin{pmatrix}  0,&1  \\ \end{pmatrix},\;x_D^{(2)}= \begin{pmatrix}  c_r-b_f-b_a\\b_a-b_f  \\ \end{pmatrix}.$$
                 INBOX
                     Game $$G_3$$: Untrusted White-Hat Hacker #slide 
                         $$\begin{array}{ c | c | c }  S \downarrow W\rightarrow & \text{not cooperate (low effort)} & \text{cooperate (high effort)}  \\\hline  \text{not trust} &  \;\cdot\;, \;\cdot\;\;& \; \downarrow\; ,\;\leftarrow\;\\\hline   \text{trust}  &  \uparrow\; ,\;\cdot \;  &  \;\cdot\;, \; \leftarrow\;\end{array}$$ #eyo-style:Normal 
                         There is one pure NE (not trust, low effort). 
                         One dilemma is present.
             GT+Matrix
                 One of the early works which was a source of inspiration for this present paper is @KAPLANSKI. In his article, the value $$v$$ of a zero-sum game is determined from its coefficient matrix, although the algorithm is not efficient. The uniqueness property of completely mixed solutions is established and their presence detected based on necessary and sufficient conditions involving order, rank and adjoint properties of the game matrix $$A$$, after reducing $$v$$ to zero using a substitution.
                 Theorem #theorem:bimatrix-mixed:ref of this paper, when specialised to matrix games, generalises Kaplanski's result as the  necessary and sufficient conditions stated in the theorem are valid for any value $$v$$. 
                 @WEIL #wfe-ignore-item 
                 In a series of papers ( @THOMPSON-a, @THOMPSON-b) work on the relationship between matrix games and generalised eigensystems, later extended to a more general problem (the Von Neumann economic model) in @THOMPSON-c, was undertaken. 
                 These results failed to achieve great  attention in the wider game theory research community apart from the niche specialist area due to their "lack of parsimony" (as quoted from @THOMPSON-a) and inability of leading to significant algorithmic improvements. 
                 One of the game theoretical insights gained in this paper is the fact that for restricted types of equilibrium solutions --- that of completely mixed ones --- the view of equilibrium solutions as solutions of associated generalised eigensystems is in fact very natural and useful, as will be demonstrated in the application section of this paper.
                 More recently, @RAGHAVAN revisits @KAPLANSKI and initiates an extension to bimatrix games. 
                 In his work, Raghavan shows that important properties of completely mixed solutions known for matrix games also are valid for bimatrix games. His main result is that completely mixed equilibrium strategies are unique and require the game matrices to be square. 
                 However Theorem xxx is not stated for bimatrix games. A necessary condition is given, on the other hand, the result is not constructive, as supportive of Theorem 4 in \cite{} requires the knowledge of the game's value pair.
                 His work does not use the notion of generalised eigensystems. 
                 In two consecutive papers ( @MILCHTAICH2006, @MILCHTAICH200x ), the authors present work which is closely related to the results of this section, although they do not use the language of generalised eigensystems. In the first paper, a formula is developed for determining an equilibrium value of a bimatrix game if the support of the corresponding solution is known in advance. This is extended in the second paper where necessary and sufficient conditions for the existence of completely mixed solutions are given, and an explicit solution formula is constructed for this case. 
                 Using the linear algebra concepts of this paper, their results can be viewed as stating necessary and sufficient conditions for the existence of non-negative (strictly positive in the completely mixed case) left and right generalised eigenvectors of the game matrices, with respect to real generalised eigenvalues, as well as the explicit construction of these. Their solution formula, necessary and sufficient conditions for completely mixed solutions are algebraically equivalent to the ones developed in this paper. 
                 @HEUER
             GT+HiTL
                 HaaS Game
                     Background  #slide 
                         Recent technological advances have made communication more affordable and computation faster.
                         The change in norms regarding the use of technology have enabled a range of new applications and systems that collect data from humans.
                         The concept of Human-as-a-Sensor (HaaS) formalises a methodology where instead of automated sensors, humans are the primary source of information. 
                     HaaS Examples #slide 
                         Non-cyber applications
                             commuters to report suspicious luggage 
                             residents participating in neighbourhood watch schemes
                             emergency response (report quakes, search and rescue)
                             participants on the road reporting traffic congestion
                             proposals for teachers to spot tendency to criminal behaviour of pupils 
                         Cyber applications
                             social media users reporting security threats
                             employees to report spam or phishing emails
                             more??
                     Relevant Research #slide 
                         Research Strand: Incomplete information game theoretic approaches for modelling wireless sensor network and client-server architecture scenarios. 
                         Research Question: How can we model a human sensor using non-cooperative game theory, and what are pertinent insights can one gain when analysing the game?
                     Research Contributions #slide
                         The formulation of a generic Sensor Reference Game, of which all previously published Sensor games are special cases.  
                             using the language of security and dependability. #wfe-ignore-item 
                             Helps other researchers with defining games for new application areas
                             It also aids in understanding the additional features required to model human sensors, and the novelty of our game 
                             Furthermore it promotes the acceptance of game theory as a tool for analysing security Scenario is. 
                         The first GT model of HaaS, taking into account a rich type profile of typical human sensor nodes
                             Based on expanding previous work on Sensor Games
                             Solving the game 
                             Devise repeated game
                     === #wfe-ignore-item 
                     Secure and Dependable Systems #slide 
                         Idea of system analysis: use security and dependability framework (A. Avizienis et al, Basic concepts and taxonomy of dependable and secure computing, IEEE Transactions on Dependable and Secure Computing, vol. 1, no. 1, pp. 1133, Jan. 2004).
                         Security = CIA
                             (Confidentiality)
                             Integrity 
                             Availability
                         Dependability = AMRIS
                             Availability
                             (Maintainability)
                             Reliability
                             Integrity
                             (Safety)
                     System Model #slide 
                         Sensor System
                             Sensor $$S$$: collects data and sends to receiver $$R$$, via a Communication Channel $$C$$
                         A sensor system can have faults and security vulnerabilities
                             $$f$$ -- fault (deviation of system from correct state)
                             $$v$$ -- vulnerability = internal fault that enables an external fault to harm the system (exploitable by an attacker)
                         Another issue is that the entire system could be compromised and turned into a hostile system/threat.
                         We require $$S$$ to be free of faults, of system alterations or interruption by an attacker, and $$C$$ to be secure 
                     System Model -- Illustration #slide 
                         ![](https://dynalist.io/u/RLJxRXEazablAgnCy5ttM5Ci)( sensor_1.png) #eyo-style:Normal
                     === #wfe-ignore-item 
                     HaaS Scenario #slide 
                         Employees in an organisation are used as human sensors 
                         They report on cyber security incidents they encounter 
                         Organisation needs to decide whether they can trust an incoming report $$r$$ (or its absence)
                         Reports have the following properties:
                             Could report incidents only, or also their absence
                             For the most general scenario: they could be externally attacked (modified, delayed or fabricated)
                             Could be synchronous or asynchronous
                     Reports -- Examples #slide
                         Alice reports:
                             "I have received a spam email at 8:10h, which was not detected by the spam filter"
                             "While browsing the web for free tools that could be used for our project, I have discovered a freeware website that contains links to some malware"
                             "Within the last seven days of the reporting period, there were three replies to the company's Twitter feed that appear to mislead potential customers"
                     Human Sensor System #slide 
                         Human sensor has internal fault $$f$$ and/or external fault (vulnerability) $$v$$
                             Faults = human lack of willingness to contribute to the security of the organisation 
                             Vulnerabilities = Weaknesses in personality traits leading to exploitation by social engineering attacks
                         Here $$f$$ has fault mode: Byzantine rather than fault-stop #wfe-ignore-item 
                         Blurring traditional boundaries: fault can be deliberate
                     Human-made Faults #slide 
                         ![](https://dynalist.io/u/YvZWuj6z_yyqithSACMX1tw_)( human-made-faults.png) #eyo-style:Normal 
                     Assumptions #slide 
                         Public information, known to all players:
                             Specific game theoretic model, comprising of game type and payoff  functions, including solution algorithm 
                         Private information:
                             The human sensor knows his own type (based on previous experience, appraisal or self observation/reflection).
                             The report receiver does not know the human sensor's type.
                         The reports are sent through a secure channel.
                         The users are competent in their non-security related job tasks
                     HaaS Sensor Types #slide 
                         Human sensor is not necessarily competent in security. 
                         The human sensor could be cooperative or uncooperative.
                         Using formal terminology: human sensor might have faults and/or vulnerabilities
                             have a vulnerability (unknowingly -- socially engineered)
                             a fault (deliberately)
                         Human sensor could also turn malicious. 
                         We obtain 3 different types. 
                     Type 1: Cooperative Human Sensor #slide
                          Is willing to help with security but potentially lacking in precision/reliability 
                             Could be socially engineered (externally attacked)
                             Could have insufficient cyber skills to recognise security anomalies
                     Type 2 and 3: Uncooperative Human Sensor #slide 
                         Type 2: Could be deliberately unreliable and apply minimal effort in contribution to overall security 
                             lazy -- give it low priority
                             distracted -- too focused on non-security job aspects
                         Type 3: Could be malicious  (internal threat/attacker), wanting to create harm.
                             disgruntled (seeking emotional reward), 
                             greedy (seeking financial reward)
                     Scenario -- Sensor #slide 
                         Player: Human Sensor $$H$$ ($$S$$ in reference game)
                         Strategies: Human sensor $$\mathcal{H}$$ has three pure strategies $$s^\mathcal{H}\in \{c, a, n\}$$:
                             $$c$$ -- cooperate and to send the perceived correct report (and to benefit from increased esteem, or being paid a bounty)
                             $$a$$ -- perform an attack by giving misleading reports(in order to get a psychological "kick" or some other financial reward from a cyber criminal)
                             $$n$$ -- not sending a report at all (as too lazy and preferring to "get on with the job")
                     Scenario -- Report Receiver #slide 
                         Player: Report Receiving Organisation $$R$$ ($$R$$ in reference game)
                         Strategies: Report receiver $$\mathcal{R}$$ has two pure strategies $$s^\mathcal{R}\in \{t_r,\overline{t}_r\}$$ : 
                             $$t_r$$ -- to trust the received report (and to benefit from its content to improve national security)
                             $$\overline{t}_r$$ -- to not trust (to prevent damage, either by recognising the reporting node as malicious or as unreliable)
                     Cost Benefit Model -- Human Sensor #slide 
                         Benefit
                             $$b_{rew}$$ -- reward (operational gain), threatened by operational punishment
                             $$b_{est}$$ -- esteem (reputation), threatened by reputational punishment
                         Cost
                             $$c_{op}$$ -- operational (data collection, message creation)
                             $$c_{att}$$ -- Message attack (data modification, deletion or fabrication)
                             $$c_{comm}$$ -- Message sending (communication cost)
                             $$c_{pun}$$ -- Punishment: operational and reputational
                     Cost Benefit Model -- Receiving Organisation #slide 
                         Benefit
                             $$b_{sec}$$ -- System security, threatened by direct costs
                             $$b_{rep}$$ -- Good reputation, threatened by indirect costs
                         Cost
                             $$c_{def}$$ -- Defence costs: verifying correctness of data
                             $$c_{dir}$$ -- Direct costs: operational losses due to 
                                 false positives/alarm (wrongly mistrust)
                                 false negatives (missed alarm -- wrongly trust)
                             $$c_{ind}$$ -- Indirect costs: loss of reputation
                     Next Steps #slide 
                         Continue Literature Review 
                         Review threat taxonomy and adapt our terminology if appropriate 
                         Design game payoff  functions and game
                         Solve it!
                         Design and solve repeated game
                     === #wfe-ignore-item 
                     REFERENCES #slide 
                         Paper 0: Maryam Mohi, Ali Movaghar, and Pooya Moradian Zadeh. 2009. __A Bayesian Game Approach for Preventing DoS Attacks in Wireless Sensor Networks__. In Proceedings of the 2009 WRI International Conference on Communications and Mobile Computing - Volume 03 (CMC '09), Vol. 3. IEEE Computer Society, Washington, DC, USA, 507-511. DOI: https://doi.org/10.1109/CMC.2009.325 (http://www.sciencedirect.com/science/article/pii/S0898122111005815)]
                         Paper 1: Shigen Shen et al, Signaling game based strategy of intrusion detection in wireless sensor networks, __Computers & Mathematics with Applications__, Volume 62, Issue 6, 2011, Pages 2404-2416, [cited: 53]
                         Paper 2: M. Estiri and A. Khademzadeh, "A theoretical signaling game model for intrusion detection in wireless sensor networks," 2010 14th International Telecommunications Network Strategy and Planning Symposium [cited: 15]
                         Paper 3: Mohebbi Moghaddam M., Manshaei M.H., Zhu Q. (2015) To Trust or Not: A Security Signaling Game Between Service Provider and Client. In: Panaousis E. et al ed., Decision and Game Theory for Security. GameSec 2015. [cited: 6]
                 Human-in-the-Loop Games #h 
                 Complete Information Human-in-the-Loop Games #h
                     Motivation #slide 
                         Classification of 2x2 bimatrix games due to (Moulin, )
                             based on concept of strategic equivalence
                             there are three categories of games
                         In order to demonstrate the use of the generalised eigensystem approach, we exemplify an analysis of the classification of 2x2 non-zero-sum security games.
                         Give unifying framework how to express solutions algebraically from the game matrices 
                         We exclude Type 0 (cooperative, reliable)
                     The Human-in-the-Loop Principle #slide 
                         Definition: Human-in-the-Loop (HITL) is a design pattern that integrates human expertise into the automated process of a system.
                         Explanation: This means that humans are involved in the loop of a system to make critical decisions, improve the system's performance, and ensure accountability.
                         Benefits: HITL systems are more flexible, adaptable, and can handle edge cases better than purely automated systems. They can improve the accuracy and efficiency of the system, while also providing a means of accountability for actions taken.
                         Example: HITL is often used in cybersecurity, where automated systems are combined with human expertise to detect and respond to security threats. For example, security analysts can be alerted to potential attacks and then investigate to determine the validity of the threat and decide on the appropriate response.
                         Challenges: Implementing HITL systems can be challenging because it requires the integration of human expertise with automated processes. It also requires proper training, clear communication, and well-defined roles and responsibilities to ensure that the human-in-the-loop system functions effectively.
                     Moulin #slide 
                          ![Pasted image](https://dynalist.io/u/Ep39jjvZnnZiG0sSoAwSJjm4) 
                     Game $$G_1$$: Malicious Wizard #slide 
                         $$\begin{array}{ c | c | c }  S \downarrow W\rightarrow & \text{not cooperate} & \text{cooperate}  \\\hline  \text{not trust} &  \;\cdot\;,\rightarrow  &  \downarrow\; ,\;\cdot\;\\\hline   \text{trust}  &  \uparrow\; ,\;\cdot\;  &  \;\;\cdot\;,\leftarrow \end{array}$$ #eyo-style:Normal 
                         There is no pure NE but one mixed NE.
                     Game $$G_2$$: Impulsive Wizard #slide 
                         $$\begin{array}{ c | c | c }  S \downarrow W\rightarrow & \text{quick} & \text{slow}  \\\hline  \text{not trust} &  \;\cdot\;, \;\cdot\;\;& \; \downarrow\; ,\;\leftarrow\;\\\hline   \text{trust}  &  \uparrow\; ,\;\cdot \;  &  \;\cdot\;, \; \leftarrow\;\end{array}$$ #eyo-style:Normal 
                         There is one pure NE (not trust, quick). 
                     Game $$G_3$$: Selfish Wizard #slide 
                         $$\begin{array}{ c | c | c }  S \downarrow W\rightarrow & \text{low effort} & \text{high effort}  \\\hline  \text{not trust} &  \;\cdot\;, \;\cdot\;\;& \; \downarrow\; ,\;\leftarrow\;\\\hline   \text{trust}  &  \uparrow\; ,\;\rightarrow\;  &  \;\cdot\;, \; \cdot \;\end{array}$$ #eyo-style:Normal 
                         There are two pure NEs: (not trust, low effort) and (trust, high effort).
                         There is also one mixed NE.
                     Discussion #h 
                         Additional Assumptions #slide 
                              Selfish Wizard:
                         Classification of 2x2 Security Games #slide 
                             Game $$G_1$$:
                                 Typical example of a __security game__ (more generally: __search game__). Classical game: __Chicken__.
                                 Hawk-Dove Game
                                 Literature: IDS Game (Alpcan & Bazar, 2011).
                                 Game is strategically zero-sum.
                             Game $$G_2$$:
                                 Strategically equivalent to:
                                     The famous __Prisoner Dilemma__. 
                                     
                                 Has strong dilemma.
                                 Two-player version of Public Goods Game.
                                 Game is strategically zero-sum.
                             Game $$G_3$$:
                                 Strategically equivalent to:
                                      __The Battle of the Sexes__. 
                                     Stag-Hunt
                                 Game is not strategically zero-sum.
                                 Can we use mechanism design to achieve a preferred NE in this case?
                     Conclusion #slide 
                     
             GT+OaG
                 Chen2021-td
                 Cui2020-vg
                     Cui, Y., Quddus, N. and Mashuga, C.V. (2020) Bayesian network and game theory risk assessment model for third-party damage to oil and gas pipelines, __Process Safety and Environmental Protection__, 134, pp. 178188.
                         Tremendous amounts of oil and gas products are transported in pipelines worldwide resulting in increasing interest to identify the hazards and evaluate the associated risks associated with this critical infrastructure. Third-party intrusion is one of the least quantifiable factors being considered during the pipeline hazard assessment stage despite the substantial contributing to the total number of oil and gas pipeline incidents. This is because a probabilistic risk assessment cannot reliably model human actions and be applied to intentional acts. Due to the distinctive motivations of third-party damage, an unintentional third-party damage Bayesian Network model and a game-theoretic model on malicious intrusion will therefore be built, to examine the mechanism of pipeline failure caused by this mode. This study is conducted aiming at investigating pipeline risk resulting from third-party damage, and will formulate risk assessment models to identify threats, prioritize risks and determine which integrity plan should apply to different pipeline segments given the condition of third-party interference (both the accidental damage and malicious acts).
                 Hawash2020-yt
                 Rezazadeh2019-sz
                 Araujo2018-ng
                 Wadhawan2016-sf
                 Bucelli2018-vd
                 noauthor_undated-ow
                 Vieira2014-rr
                 Peskir2008-rz
             GT+RA
                 Game theory applications to security Risk Assessment #GTSec #h 
                     Complete Information Security Assessment Game #h #single-target 
                         Introduction #slide 
                             SA game is a __proactive__ security game (actions are non-observable, this is a static game)
                             Single-target game: we only consider one target. The focus is on the single asset that has a vulnerability.
                             Most simple attacker defender scenario.
                                 Rows corresponds to the strategies available to the defender.
                                 Columns are the attacker's strategies.
                             Strategies:
                                 $$S_\mathcal{D} = \{$$defend, not defend$$\} = \{s_d, s_{-d}\}$$ 
                                 $$S_\mathcal{A} = \{$$ attack, not attack $$\} = \{s_a, s_{-a}\}$$ 
                         Payoff Notations #slide 
                             $$c_{\mathcal{D}}$$ -- the defense cost
                             $$I$$ -- the defender's cost due to the impact of an attack
                             $$c_{\mathcal{A}}$$ -- the attacker's cost
                             $$G$$ -- the gain (benefit) of the attacker from an attack.
                             Assumptions:
                                 __Principle of Adequate Protection__: $$c_{\mathcal{D}} <I$$
                                 __Principle of Easiest Attack__: $$c_{\mathcal{A}} < G$$
                         Game Description  #slide 
                             $$\mathcal{G}(\mathcal{D},\mathcal{A})$$  Payoff Matrix:
                                 $$\begin{array}{  c | c | c }  \mathcal{D} \downarrow \mathcal{A}\rightarrow & s_a & s_{-{a}} \\ \hline s_d &  - c_{\mathcal{D}}, - c_{\mathcal{A}}&  -c_{\mathcal{D}},  0 \\ \hline s_{-{d}} &  -I,  G- c_{\mathcal{A}} &  0,  0 \\ \end{array}$$ #eyo-style:Normal 
                             We will also use bimatrix notation $$\mathcal{G}(A,B)$$.
                         Game Equilibrium Analysis #slide 
                             There is a unique mixed NE solution pair with
                                 $$x^{*} = \frac{G-c_{\mathcal{A}}}{G} = 1 - \frac{c_{\mathcal{A}}}{G}$$
                                 $$y^{*} = \frac{c_{\mathcal{D}}}{I}$$
                             The corresponding optimal expected payoffs are:
                                  $$s^{*}_d = -c_{\mathcal{D}} $$
                                 $$s^{*}_a =  0 $$ 
                             The game is strategically zero-sum. 
                         Game Analysis Summary #slide
                             In order to slightly simplify the game, we assume "the winner gets it all": $$G = I$$
                             **Theorem 1**. The security game $$\mathcal{G}(\mathcal{D},\mathcal{A})$$ has no pure Nash Equilibrium. A mixed Nash Equilibrium strategy pair $$(x_\mathcal{D}^,y_\mathcal{A}^)$$ is obtained, where $$x_\mathcal{D}^=1-c_\mathcal{A}/G$$ and $$y_\mathcal{A}^=c_\mathcal{D}/I$$ are the probability of defense and attack respectively. The resulting expected payoffs, in this case, are $$u_\mathcal{D}^=c_\mathcal{D}$$ and $$u_\mathcal{A}^=0$$.
                             **Proof**: The proof of this theorem will be obtained as a special case for that of Theorem 2.
                         Discussion #slide 
                             Main problem: $$u_\mathcal{A}^=0$$.
                                 Would this be desirable for attacker?
                                 GT needs to be accepted by all real-world players.
                             Solution: reward scheme.
                                 If outcomes of security assessment match observed reality, there will be a reward $$r_{\mathcal{D}}$$ for the defender
                                 Otherwise, the attacker will benefit from a reward $$r_{\mathcal{A}}$$.
                         Extended Game  #slide 
                             $$\mathcal{G}_r(\mathcal{D},\mathcal{A})$$  Payoff Matrix:
                                 $$\begin{array}{  c | c | c }  \mathcal{D} \downarrow \mathcal{A}\rightarrow & s_a & s_{-{a}} \\ \hline s_d &  - c_{\mathcal{D}}+r_{\mathcal{D}}, - c_{\mathcal{A}}&  -c_{\mathcal{D}},  r_{\mathcal{A}} \\ \hline s_{-{d}} &  -I,  G- c_{\mathcal{A}}+r_{\mathcal{A}} &  r_{\mathcal{D}},  0 \\ \end{array}$$ #eyo-style:Normal 
                         Extended Game Equilibrium Analysis #slide 
                             **Theorem 2**. The security game $$\mathcal{G}_r(A, B, \mathcal{D},\mathcal{A})$$ has no pure Nash Equilibrium. A mixed Nash Equilibrium strategy pair $$(x_\mathcal{D}^,y_\mathcal{A}^)$$ is obtained, where $$x_\mathcal{D}^=1 - \frac{r_{\mathcal{A}}+c_{\mathcal{A}}}{G+2r_{\mathcal{A}}}$$ and $$y_\mathcal{A}^=\frac{c_{\mathcal{D}}+r_{\mathcal{D}}}{2r_{\mathcal{D}}+I}$$ are the probability of defense and attack respectively. The resulting expected payoffs, in this case, are $$u_\mathcal{D}^=\frac{r_{\mathcal{D}}^2c_\mathcal{D}(I+r_{\mathcal{D}})}{I+2r_{\mathcal{D}}}$$ and $$u_\mathcal{A}^=\frac{r_{\mathcal{A}}^2+r_\mathcal{A}(G-c_{\mathcal{A}})}{G+2r_{\mathcal{A}}}$$. Furthermore, if $$r_{\mathcal{A}}>0$$ then it holds $$u_\mathcal{A}^>0$$.
                             INBOX
                                 $$r_{\mathcal{D}}>0$$ then $$u_\mathcal{D}^>0$$ and if 
                                 RESULTS
                                     There is a unique mixed NE solution pair with
                                         $$x^{*} =  1 - \frac{r_{\mathcal{A}}+c_{\mathcal{A}}}{I+2r_{\mathcal{A}}}$$
                                         $$y^{*} = \frac{c_{\mathcal{D}}+r_{\mathcal{D}}}{2r_{\mathcal{D}}+I}$$
                                     The corresponding optimal expected payoffs are:
                                          $$s^{*}_d  \neq 0  $$ if $$ r_\mathcal{D}\neq 0$$
                                         $$s^{*}_a \neq 0  $$ if $$ r_\mathcal{A}\neq 0$$
                     TEMP
                         Introduction #slide 
                             Motivation 
                                 The budget source for rewards
                                 We are interested in capturing realistic assumptions 
                             Contributions  
                                 A systematic, complete analysis of 2x2 bimatrix games capturing  
                                 A formulation and analysis of a Bayesian non-zero sum 2-player game, informed by this analysis.
                         Motivation #slide 
                         Assumptions #slide 
                             Defender does not know about attacker reward and assumes 
                             
                         Moulin #slide 
                              ![Pasted image](https://dynalist.io/u/Ep39jjvZnnZiG0sSoAwSJjm4) 
                         Budget Game $$G_B(\mathcal{D},\mathcal{A})$$: #slide   
                             Payoff Matrix:
                                 $$\begin{array}{  c | c | c }  \mathcal{D} \downarrow \mathcal{A}\rightarrow & s_a & s_{-{a}} \\ \hline s_d &  - c_{\mathcal{D}}-r_{\mathcal{D}}, - c_{\mathcal{A}}&  -c_{\mathcal{D}},  0 \\ \hline s_{-{d}} &  -I,  g- c_{\mathcal{A}} &  -r_{\mathcal{D}},  0 \\ \end{array}$$ #eyo-style:Normal 
                             Classification of 2x2 bimatrix games due to (Moulin, )
                                 based on concept of strategic equivalence
                                 there are three categories of games
                             Depending on the value of $$r_{\mathcal{D}}$$, there could be no, one or two pure NEs.
                             In the latter case, there will also be one mixed NE equilibrium. 
                         Budget Game $$G_2$$: Selfless RA Team #slide 
                             $$ $$ 
                             
                             
                             There is one pure NE (not trust, quick). 
                         External Budget Game $$G_1$$: Selfish RA Team #slide 
                             There is no pure NE but one mixed NE.
                         Internal Budget Game $$G_2$$: Selfless RA Team #slide 
                             There are two pure NEs: (not trust, low effort) and (trust, high effort).
                             There is also one mixed NE.
                         Discussion #h 
                             Additional Assumptions #slide 
                                  Selfish Wizard:
                             Classification of 2x2 Security Games #slide 
                                 Game $$G_1$$:
                                     Typical example of a __security game__ (more generally: __search game__). Classical game: __Chicken__.
                                     Hawk-Dove Game
                                     Literature: IDS Game (Alpcan & Bazar, 2011).
                                     Game is strategically zero-sum.
                                 Game $$G_2$$:
                                     Strategically equivalent to:
                                         The famous __Prisoner Dilemma__. 
                                         
                                     Has strong dilemma.
                                     Two-player version of Public Goods Game.
                                     Game is strategically zero-sum.
                                 Game $$G_3$$:
                                     Strategically equivalent to:
                                          __The Battle of the Sexes__. 
                                         Stag-Hunt
                                     Game is not strategically zero-sum.
                                     Can we use mechanism design to achieve a preferred NE in this case?
                     Game Analysis #h 
                         Motivation #slide 
                             Main interest: compute closed form solutions for mixed equilibrium. 
                         Analysis Approach  #slide 
                             Degeneracy conditions ( @Moulin): $$a_1\neq a_3$$, $$a_2\neq a_4$$ and $$b_1\neq b_2$$, $$b_3\neq b_4$$.
                             Consequence: together with additional assumptions, might be shown either $$\mu$$ is well-defined, or does not exist.
                             Does it imply $$\det(A-\lambda E)= c_0-c_1\lambda$$ with $$c_0, c_1 \neq 0$$?
                             Are EVs non-negative?
                             This will be used in the different cases, to detail the solutions in closed-form expression. 
                         Equations for Generic Generalised Eigensystem #slide 
                             For a generic matrix $$A$$, the components of a generalised eigensystem $$\mathcal{E}_A=\left(\mu, x^t, y\right)$$ are determined as follows:
                                 The eigenvalue is the real number $$\mu = {{a_{1}\,a_{4}-a_{2}\,a_{3}}\over{a_{1}+a_{4}-a_{2}-a_{3}}}$$, assuming that the denominator in this expression does not vanish. 
                                 The corresponding left eigenvector  is $$x^t=\left(a_{3}-a_{1}\right)\,\begin{pmatrix}a_{4}-a_{3}&a_{1}-a_{2}\end{pmatrix}$$ and $$y=\left(a_{1}-a_{2}\right)\begin{pmatrix}a_{2}-a_{4}\cr a_{3}-a_{1}\end{pmatrix}$$ is the right eigenvector. 
                         Aggregated Generalised Eigensystem for Bimatrix Games #slide 
                             For a bimatrix game $$G(A,B)$$, the following aggregated generalised eigensystem is of interest: $$\mathcal{E}_{A,B} = \left(\mu_A, y_A,\mu_B, x_B^t\right)$$
                             We have
                                 $$\mu_A = {{a_{1}\,a_{4}-a_{2}\,a_{3}}\over{a_{1}+a_{4}-a_{2}-a_{3}}}$$
                                 $$y_A=\left(a_{1}-a_{2}\right)\begin{pmatrix}a_{2}-a_{4}\cr a_{3}-a_{1}\end{pmatrix}$$
                                 $$\mu_B = {{b_{1}\,b_{4}-b_{2}\,b_{3}}\over{b_{1}+b_{4}-b_{2}-b_{3}}}$$
                                 $$x_B^t=\left(b_{1}-b_{3}\right)\,\begin{pmatrix}b_{3}-b_{4}&b_{2}-b_{1}\end{pmatrix}$$
                         Fundamental Theorem #slide 
                             Specialising the work of (Thompson et al) to matrix games, we extend their main fundamental theorem to bimatrix games as follows: 
                             Given a square bimatrix game $$G(A,B)$$, assume the matrix pencils $$A-\lambda E$$  and $$B-\lambda E$$ are both regular, each with a real eigenvalue $$\mu_A$$ and $$\mu_B$$ respectively. Let $$x_{\mu_B}$$ be a nonnegative left eigenvector of $$B-\lambda E$$ with respect to $$\mu_B$$ and denote $$y_{\mu_A}$$ a nonnegative right eigenvector of $$A-\lambda E$$ with respect to $$\mu_A$$. Then $$(x^*,y^*) = (x_{\mu_B}$$, $$y_{\mu_A}$$) is a Nash Equilibrium strategy profile of the game $$G$$ and $$(\mu_A, \mu_B)$$ is the corresponding game value pair. #eyo-style:Theorem  #theorem:bimatrix-regular-theorem 
                         A Best Response Lemma #slide 
                             The proof of the theorem will be aided by the following lemma. 
                             It exhibits a special case arising where there exists a strategy of one player to which any strategy of the other player is a best response.
                             Following the notations as in the theorem, we have for a nonnegative left generalised eigenvector $$x_{\mu_B}$$ that for all Player 2 strategies $$y$$ it holds $$x^\top_{\mu_B} B y = \mu_B $$. Similarly, a nonnegative right eigenvector $$y_{\mu_A}$$ satisfies $$x^\top A y_{\mu_A} = \mu_A$$ for all Player 1 strategies $$x$$. #eyo-style:Lemma  #lemma:best-response-eigen
                         Case 1 #slide 
                             The non-existence of a pure NE leads to the following conditions, up to permution: $$a_1>a_3$$, $$a_4>a_2$$, $$b_2>b_1$$ and $$b_3>b_4$$.
                             We deduce that both eigenvalues $$\mu_A$$ and $$\mu_B$$ are well defined. 
                             The vectors $$x_B^t$$ and $$y_A$$ are non-zero. 
                             Furthermore each vector has entries having the same sign. 
                                 Define $$\text{sign}(v)$$ as the sign of #wfe-ignore-item 
                             Apply Theorem #theorem:bimatrix-regular-theorem to obtain the unique mixed NE solution pair. 
                         Case 2 #slide 
                             With two pure NEs one obtains $$a_1>a_3$$, $$a_4>a_2$$, $$b_1>b_2$$ and $$b_4>b_3$$.
                             As in Case 1, both vectors are non-zero and all entries have the same sign. 
                             Same approach to obtain the unique mixed NE solution pair by applying Theorem #theorem:bimatrix-regular-theorem . 
                         Case 3 #slide 
                             In this case, a single pure NE implies either 
                             Case (i): $$a_1>a_3$$, $$a_4>a_2$$, $$b_1>b_2$$ and $$b_3>b_4$$; or
                             Case (ii): $$a_1>a_3$$, $$a_2>a_4$$, $$b_1>b_2$$ and $$b_3>b_4$$.
                             There is dominance
                                 In both case (i) and (ii): column 2 of $$B$$ is dominated by column 1
                                 In the case of (ii): row 2 of $$A$$ is also dominated by row 1
                             The game is trivial for at least one of the players.
                             Algebraic property: empty generalised eigensystem.
                             This implies $$\det(A-\lambda E)\equiv c\neq 0$$ or the existence of not nonnegative eigenvectors. 
                             Proof:
                         Conclusion #slide 
                             Summarising theorem:
                             This is exhaustive result, completely covering all security game types. 
                             Preparation for Bayesian game analysis. 
                     Bayesian Game #h 
                         Motivation #slide 
                             Focus on first and second game
                             This avoids third, which is less interesting from GT point of view and also could be avoided through proper vetting 
                             Strategies are effectively: cooperate, not cooperate and trust, not trust
                             Denoted as $$\{C, \bar{C}\}$$ and  $$\{T, \bar{T}\}$$. 
                         Wizard Types #slide 
                             Type 1: Malicious
                                 deliberately wanting to reduce accuracy of system
                                  seeking emotional or financial reward
                             Type 2: Selfish
                                 knowingly/deliberately unreliable -- apply minimal effort in contribution to overall system accuracy, if possible 
                                 lazy (give it low priority, too focused on other job aspects)
                             Type 3: Incompetent
                                 unknowingly unreliable
                                 Impulsive 
                         A Bayesian Game #slide
                             This will lead to a Bayesian game $$G_B$$ with three Wizard types $$\Theta=\{m, s, i\}$$
                             Formally, game is a tuple $$(N, A,\Theta, p, u)$$ where:
                                 $$N$$ is a set of agents
                                 $$A = A_1 \times A_2 $$ where $$A_i$$ is the set of actions available to player $$i$$
                                 $$\Theta$$ is the type space of player $$W$$
                                 $$p : \Theta \rightarrow [0, 1]$$ is a common prior over types
                                 $$u = (u_1 , u_2)$$, where $$u_i : A \times \Theta \rightarrow R$$ is the utility function for player $$i$$
                             Static vs dynamic game
                         Game $$G_1(A,B)$$: 
                             $$ A=\begin{pmatrix} a_{1} &a_{2}\\a_{3} &a_{4}\end{pmatrix} $$, $$ B=\begin{pmatrix} b_{1} &b_{2}\\b_{3} &b_{4}\end{pmatrix} $$ and $$a_{1}>a_{3};a_{4}>a_{2};$$ $$b_{2}>b_{1 };b_{3}>b_{4};$$
                         Game $$G_2(\hat{A},\hat{B})$$: 
                             $$ \hat{A}=\begin{pmatrix} \hat{a}_{1} &\hat{a}_{2}\\\hat{a}_{3} &\hat{a}_{4}\end{pmatrix} $$, $$ \hat{B}=\begin{pmatrix} \hat{b}_{1} &\hat{b}_{2}\\\hat{b}_{3} &\hat{b}_{4}\end{pmatrix} $$ and $$\hat{a}_{1}>\hat{a}_{3};\hat{a}_{4}>\hat{a}_{2};$$ $$\hat{b}_{1}>\hat{b}_{2};\hat{b}_{4}>\hat{b}_{3};$$
                     Game Analysis #h 
                         Overview #slide 
                             Non-Bayesian game: strategy profile is a NE iff every strategy in that profile is a best response to every other strategy
                             Our game: find Bayesian Nash Equilibria (BNE) 
                             Bayesian Games: Players maximise their expected payoffs
                         BNE Types #slide 
                             __Pooling Equilibrium__: if the first player's best response remains the same, regardless of his belief in the type of Player 2.
                             __Separating Equilibrium__: if best response is different, depending on the type.
                         Harsani-Transformation #slide 
                             Idea: convert game with uncertainty over strategies (types) into game with payoff uncertainty. 
                             Assume knowledge of probability distribution for types. 
                             Consider 2 types.
                         The Imperfect Information Game #slide 
                             Denote
                             We have $$\tilde{A}=P_1A+P_2\hat{A}$$ and  $$\tilde{B}=P_1B+P_2\hat{B}$$ where 
                                 $$P_1 = \begin{pmatrix}  p&0 \\ p &0 \\ 0 &p  \\ 0 &p \\  \end{pmatrix}$$.
                                 $$P_2 = \begin{pmatrix}  1-p&0 \\ 0 &1-p  \\ 1-p &0  \\ 0 &1 -p \\  \end{pmatrix}$$.
                         The Imperfect Information Game (cont.) #slide 
                         Pure NE Analysis #h 
                             Pure NE Result #slide 
                                 Let $$\epsilon_1=\frac{b_{1}-\hat{b}_{2}}{b_{2}-\hat{b}_{2}}$$ and $${\epsilon_2}=\frac{b_{4}-\hat{b}_{3}}{b_{3}-\hat{b}_{3}}$$. Then it holds $$0<\epsilon_1<1$$ and $$0<{\epsilon_2}<1$$. Then if $$p<\epsilon_1$$, the game admits a Pooling BNE $$(\bar{T}\bar{T},\bar{C})$$. Furthermore, if $$p<\epsilon_2$$, there is a Pooling BNE $$(TT,C)$$. #eyo-style:Proposition
                             Proof #h 
                                 Step 1 #slide 
                                     First we show that Player 1's best responses to pure strategies of Player 2 are independent of the value of $$p$$. 
                                     For this, we establish $$\alpha_1>\alpha_5$$ and the chain of unequalities $$\alpha_1>\alpha_3>\alpha_7$$.
                                     Proving $$\alpha_1>\alpha_5$$:
                                     Proving $$\alpha_1>\alpha_3>\alpha_7$$:
                                 Step 2 #slide 
                                     If $$\beta_1>\beta_2$$, the game admits a Pooling BNE $$(\bar{T}\bar{T},\bar{C})$$. 
                                     If $$\beta_4>\beta_3$$, there is a Pooling BNE $$(TT,C)$$.
                                 Step 3 #slide 
                         Mixed NE Analysis #h 
                             Analysing Rectangular Games #slide 
                                 We need an extension of theorem #theorem:bimatrix-regular-theorem 
                         Discussion #slide 
                     Conclusion #slide 
             GT+SA
                 Louis_Anthony_Tony_Cox2009-fo
             GT+Stego
                 Game-Theoretic Adaptive Hybrid Steganography #h 
                     Stego Games
                         Introduction #slide
                             Background:
                             Context:
                             Motivation:
                         Contributions/Novelty #slide 
                         Notations #slide 
                         Terminology for Steganography #slide 
                             Cover-medium + payload = carrier-medium
                                 Cover-medium (cover object, cover) -- e.g. text, image, audio or video file
                                 Secret payload -- e.g. image, document, audio, video file
                                 Carrier-medium (stego-object) -- usually same as cover-object 
                             Stego-key: method or key required to access the payload from the carrier-medium 
                                 E.g. instructions, algorithm, tool with key or password
                         Simple Stego-Game #h 
                             Scenario #slide 
                                 An entity $$\mathcal U$$ wants to transmit a secret message to a friend. 
                                 The entity $$\mathcal U$$ decides to transmit the secret message $$m$$ as an email through a home internet connection
                                 However, $$\mathcal U$$ is in an environment where all email and internet communications are monitored by the intelligence agencies and the government, they are not to be trusted
                                 The current security techniques used for e-mail security are complicated
                                 PGP (Pretty Good Privacy) and GPG (GNU Privacy Guard) can used but in practice, the setup can be complicated and confusing.
                             Motivation for Security Game Model #slide 
                                 Furthermore, $$\mathcal U$$ decides to apply a game theoritcal approach to formalize decision making processess and predict the adversary behaviour
                                 $$\mathcal U$$ aims to implement an afforable and simple steganographic technique with hope that the secret message will be transmitted securly
                                 The simple stego game presented in this section adopts formost a more defense oriented perspective and focus more on defense rather than the adversary strategies.
                             Simple Stego-Game #slide 
                                 Aim: to decide when we should use expensive steganography, rather than cheap plaintext message sending.
                                 Players:
                                     $$\mathcal U$$ -- User
                                     $$\mathcal S$$ -- Steganalyst
                                 They can choose strategies:
                                     $$\mathcal U$$:
                                         $$hide, \lnot hide$$
                                     $$\mathcal S$$:
                                         $$look, \lnot look$$
                             Payoffs #slide 
                                 $$\mathcal U$$:
                                     $$b_{hide}$$ -- benefit of hiding (secrecy): assume = 0
                                     $$c_{hide}$$ -- cost of hiding 
                                     $$c_{leak}$$ -- cost arising from payload leaking
                                 $$\mathcal S$$:
                                     $$b_{leak}$$ -- reward of accessing leaked payload 
                                     $$c_{look}$$ -- cost of looking at carrier-object 
                             Game Strategic Normal Form #slide
                                 $$\begin{array}{c|c|c} \mathcal{U} \downarrow \mathcal{S} \rightarrow & look &\lnot look \\ \hline  hide & -c_{hide}, -c_{look}& -c_{hide}, 0\\ \hline  \lnot{hide}  &-c_{leak},b_{leak}-c_{look}&0, 0\end{array}$$ #eyo-style:Normal 
                                 Assumptions
                                     Principle of Adequate Protection : $$c_{leak} > c_{hide}$$
                                     Principle of Easiest Attack : $$b_{leak} >c_{look}$$
                             Game Analysis #slide
                                 Relationship with AD-Game
                                     $$\mathcal{U} \hat{=} \mathcal{D} $$
                                     $$\mathcal{S} \hat{=} \mathcal{A} $$
                                     Direct mapping between payoffs
                                 NE Solutions:
                                     Theorem 1. The security game has no pure Nash Equilibrium strategy.
                                     Proof: By inspecting the game.
                                     Theorem 2. A mixed Nash Equilibrium strategy $$(s_{\mathcal U}^*,s^*_{\mathcal S})$$ is obtained, where $$p^*=\dfrac{b_{leak}-c_{look}}{b_{leak}}$$ and $$q^*=\dfrac{c_{hide}}{c_{leak}}$$ are the probability of hiding and looking respectively. The resulting expected utilities in this case are $$u_{\mathcal U}^*=-c_{hide}$$ and $$u_{\mathcal S}^*=0$$.
                                     Proof: Following Nash.
                                         [https://dynalist.io/d/LEdIn-fQiooRnQn8D-7fFHVC#z=MtWHZzltzod30Ojb2lEysQxX](https://dynalist.io/d/LEdIn-fQiooRnQn8D-7fFHVC#z=MtWHZzltzod30Ojb2lEysQxX)
                                     $$\Longrightarrow p^*=\dfrac{b_{leak}-c_{look}}{b_{leak}-c_{look}+c_{look}}=\dfrac{b_{leak}-c_{look}}{b_{leak}}$$
                                     $$\Longrightarrow q^*=\dfrac{c_{hide}}{c_{leak}}$$
                             Discussion #slide 
                                 Find good example illustrating solution properties (low attack cost and high reward)
                                 Extend game for low- and high entropy steganography
                         Entropy-Game #h 
                             Entropy-Game #slide 
                             Payoffs #slide 
                                 $$\mathcal U$$:
                                     [$$b_{hide}$$ -- benefit of hiding (secrecy): assume = 0]
                                     $$c_{hide}$$ -- cost of hiding 
                                     $$c_{leak}$$ -- cost arising from payload leaking
                                 $$\mathcal S$$:
                                     $$b_{leak}$$ -- reward of accessing leaked payload 
                                     $$c_{look}$$ -- cost of looking at carrier-object 
                             Game Strategic Normal Form #slide 
                                 $$\begin{array}{c|c|c|c} \mathcal{U} \downarrow \mathcal{S} \rightarrow & scan^+ & scan & look\\ \hline  low & -c_{low}, -c_{scan^+}& -c_{low}, -c_{scan}& -c_{low}, -c_{look}\\ \hline  high  &-c_{leak},-c_{scan^+}&-c_{leak},-c_{scan}&-c_{leak}, -c_{look}\end{array}$$ #eyo-style:Normal 
                             Game Analysis #slide
                             Discussion #slide 
             GT+Stochastic+Stopping
                 MATRIX GAMES & GENERALISED EIGENSYSTEMS
                     CONCEPTS
                         SUPPORT, DEFECT, SLACK, LABELS
                     SUFFICIENCY FOR VALUE AND OPTIMAL SOLUTIONS
                         Fundamental Theorem (Linking Generalised Eigensystem and Value and Optimal Solutions of Game) #slide
                         #theorem:zero-sum-regular-pencil 
                             Assume the matrix game $$G(A)$$ is regular, with a real generalised eigenvalue $$\mu$$ corresponding to nonnegative left and right generalised (normalised) eigenvectors $$x_\mu$$ and $$y_\mu$$. Then the generalised eigenvalue and the value of the game coincide: $$v(A)=\mu$$. Furthermore, $$x_\mu$$ and $$y_\mu$$ are optimal solutions of the game with maximal support. #novel 
                                 Assume the matrix pencil $$A-\lambda E$$ is regular, with a real eigenvalue $$\mu$$ corresponding to nonnegative left and right normalised eigenvectors $$x_\mu$$ and $$y_\mu$$. Then the value of the game $$G(A)$$ is $$v(A)=\mu$$ and $$(x_\mu$$, $$y_\mu$$) is an optimal strategy profile.  #novel 
                         #proof:zero-sum-regular-pencil
                             We have $$v\le x^* Ay_\mu=\mu ex^*=\mu$$ for any optimal solution $$x^*$$. Furthermore it also holds $$v\ge x_\mu Ay^*=\mu ^\top\! ey^*=\mu$$ for any optimal solution $$y^*$$.
                             From this we obtain $$v=\mu$$ and $$x_\mu Ay_\mu=\mu$$ from which the theorem follows.
                         Proof (Alternatives) #slide
                             Alternative proof: use strategy transformation
                             $$^\top\! e$$
                             The proof of this theorem can also be obtained as a special case of our proof for Theorem #ref:non-zero-sum-regular-theorem. 
                         Lower and Upper Value Lemma #slide 
                             #lemma
                                 Assume the matrix pencil $$A-\lambda E$$ is regular, with a real eigenvalue $$\mu$$. Then the following holds:
                                     There is an associated generalised nonnegative left eigenvector $$x_\mu ^t\Longrightarrow \underline{v} \ge \mu$$. 
                                     There is an associated generalised nonnegative right eigenvector $$y_\mu \Longrightarrow  \overline{v} \le \mu$$.
                                 In particular, if both generalised eigenvectors are nonnegative, $$v=\mu$$.
                         Proof #slide 
                             #proof
                                 We have $$\underline{v} = \min_y \max_x xAy \ge \min_y \mu e^\top y = \mu$$ by choosing $$x=x_\mu$$ to derive the lower estimate of the maximum. 
                                 On the other hand, $$\overline{v}=\max_x \min_y xAy \le \max_x \mu xe = \mu$$. 
                     INACTIVE STRATEGIES
                         SUFFICIENT CONDITIONS
                             #lemma 
                                 If the game has an associated matrix pencil that is singular, there exist inactive strategies. #novel 
                             #lemma 
                                 If the game has an associated regular matrix pencil without positive eigenvectors, there exist inactive strategies. #novel 
                             #lemma 
                                 If the game has an associated regular matrix pencil with non-negative eigenvectors, there exists at the most one inactive strategy. #novel 
                     DOMINANCE
                     COMPLETELY MIXED CASE
                         #theorem:zero-sum-mixed-result
                             A matrix game is completely mixed if and only if its associated generalised eigensystem is regular, with a real eigenvalue and strictly positive left and right eigenvectors. #novel 
                     UNIQUENESS OF SOLUTIONS
                         Canonical Case: Unique Solutions #h 
                             Uniqueness Result #slide 
                             Necessary Conditions for Inactive Strategies #slide 
                             Solutions with Maximal Support #slide
                                 #lemma 
                                     A solution with maximal support has the same number of active strategies for each player. #novel 
                                      and is unique solution with that support. #novel 
                     PERTURBATIONS
                         REDUCTION
                     ARCHIVE
                         #theorem @zero-sum-regular-theorem-old
         LA #LA 
             Background #slide 
                 Matrix pencils
                 Matrix rank factorisations
             LA+Pencil+RFactor
                 Eigenspace characterisations of regular matrix pencils through rank factorisations. #EigenRankFactor
                     Introduction #slide
                         Background:
                             Matrix pencils
                             Matrix factorisations
                         Context:
                             To determine the structure of eigenspace of a regular matrix pencil 
                             To achieve this through matrix (full-) rank factorisation. 
                         Motivation:
                             To benefit from low-rank situations of the matrix $$B$$. 
                     Contributions/Novelty #slide 
                         Reduction of the pencil eigenspace problem to a matrix eigenspace problem, based on rank-factorisation of the matrix $$B$$. #novel:contribution
                         Novelty relation to previous work:
                             relation pencil to matrix: numerical maths
                             matrix determinant lemma
                             Italian guy 
                     Notations #slide 
                         Regular Matrix Pencils
                         Matrix Rank Factorisation
                         Normalised eigenvectors 
                     Characteristic Polynomial Lemma #slide #novel:lemma
                         The following lemma relates the characteristic polynomial of the matrix pencil $$P(\lambda)$$ to that of a pencil of smaller size, if $$r<n$$. 
                         #lemma Assume that $$A$$ is invertible. Then $$\det(\beta A-\alpha LR^\top)=\beta^{n-r}\det(A)\det(\beta I_r-\alpha R^\top A^{-1}L)$$. 
                             Proof: based on block-determinant identity (see e.g.~ \cite{Bernstein2018-bj}).
                                 Proof of Lemma #slide #proof
                                     Define the matrix
                                         $$M=\begin{pmatrix}  I_r&R^\top \\ \alpha L & \beta A  \\  \end{pmatrix}$$.
                                     Applying the block-determinant identity to the submatrix $$I_r$$, we obtain
                                         $$\det(M)=\det(\beta A- \alpha B)$$.
                                     On the other hand, we can swap rows and columns block-wise while preserving the determinant of the block-matrix, and apply the same identity to the top left block of
                                         $$\tilde{M}=\begin{pmatrix}  \beta A & \alpha L  \\ R^\top & I_r\\   \end{pmatrix}$$.
                                     Collecting powers of $$\beta$$, this yields
                                         $$\det(\tilde{M})=\beta^{n-r}\det(A)\det(\beta I_r-\alpha R^\top A^{-1}L)$$.
                                     This proves the lemma.
                     Reduction of Matrix Pencil Eigenspace to Matrix Eigenspace #slide #novel:proposition 
                         #proposition Given the regular matrix pencil $$A-\lambda LR^\top$$ and $$\det(A)\neq 0$$, define the matrix $$C=R^\top A^{-1}L$$. Then the following statements hold: 
                             If $$y\not\in \text{ker}\; L$$ is a right eigenvector of $$C$$ with eigenvalue $$\mu$$, $$A^{-1}Ly$$ is a right eigenvector of $$A-\lambda LR^\top$$ with eigenvalue $$[ \mu,1]_{\sim}$$.
                             If $$y$$ is a right eigenvector of $$A-\lambda LR^\top$$ with eigenvalue $$[\mu_2, \mu_1]_{\sim}$$ ($$\mu_1\neq 0$$), $$L^{-1}_RAy$$ is a right eigenvector of $$C$$ with eigenvalue $${\mu}_2/{\mu}_1$$. 
                     Proof of Proposition #slide 
                         The assertions can be verified by direct calculations. 
                     Results for Left Eigenvectors #slide #novel:proof 
                         Similarly, for left eigenvectors it holds:
                             If $$x_\mu^\top \not\in \text{ker}\; R^\top$$ is a left eigenvector of $$C$$ with eigenvalue $$\mu$$, $$x^\top R^\top A^{-1}$$ is a left eigenvector of $$A-\lambda LR^\top$$ with eigenvalue $$[1, \mu]_{\sim}$$. 
                             If $$y_\mu\not\in \text{ker}\; L$$ is a right eigenvector of $$A-\lambda LR^\top$$ with eigenvalue $$[\mu_2, \mu_1]_{\sim}$$ ($$\mu_2\neq 0$$), $$L^{-1}_RAy_\mu$$ is a right eigenvector of $$C$$ with eigenvalue $$\mu_1/\mu_2$$.  
                     On the Infinite Eigenvalue #slide #novel 
                         The algebraic multiplicity of the infinite eigenvalue of $$P(\lambda)$$ is $$m_\infty=r-\text{rank}(B)+m_0$$ where $$m_0$$ is the algebraic multiplicity of the eigenvalue $$\mu=0$$ of $$C$$. #lemma 
                         Proof:
                     Summary #slide 
                         The complete set of eigenvalues and corresponding eigenvectors of a regular matrix pencil $$A-\lambda B$$ can be determined as follows:
                             Assume $$B=LR^\top$$ is a full rank factorisation. 
                             Let $$k\in\R$$ such that $$A+kB$$ is invertible. 
                             Define the matrix $$C=R^\top (A+kB)^{-1}L$$. 
                         The eigensystem can then be derived from that of $$C$$:
                             The finite, nonzero eigenvalues of $$C$$ can be mapped into the finite eigenvalues of $$A-\lambda B$$,
                             The matrix eigenvalue zero corresponds to the infinite eigenvalue of the pencil.
                     Summarising Theorem #slide  #novel 
                         If $$B=LR^\top$$ is a full-rank factorisation and $$k\in \R$$ such that $$A+kB$$ is nonsingular, there is a one-to-one correspondence between eigenvalues and eigenvectors of $$A-\lambda B$$ and those of $$C=R^\top (A+kB)^{-1}L$$. For each right eigenvector $$y_\mu$$ of $$C$$ associated with an eigenvalue $$\mu$$ (left eigenvector $$x^\top_\mu$$ respectively), if $$A^{-1}Ly_\mu\neq 0$$, this vector is a right eigenvector (the vector $$x^\top_\mu R^\top A^{-1}\neq 0$$ is a left eigenvector respectively) of $$P(\lambda)$$ with finite eigenvalue $$\lambda=\mu^{-1}-k$$ if $$\mu\neq 0$$, and the infinite eigenvalue otherwise. #theorem
                     On Rank-1 Regular Matrix Pencils #h
                         Introduction #slide 
                             Consider a regular matrix pencil of the form $$A-\lambda B$$ where $$\text{rank}(B)=1$$. 
                             We call this a __rank-1 pencil__. 
                             We can write $$B=uv^\top$$ where $$u,v\in {\R_{\neq 0}}^n$$. 
                             Note that then $$\text{rank}(A) \ge n-1$$ (as otherwise $$\text{rank}(A-\mu B) < n-1+1 =n$$ for all $$\mu \in \R$$ and the pencil would not be regular).
                         Remarks #slide 
                             It is clear that the pencil has an eigenvalue at infinity with algebraic multiplicity $$m_\infty=n-1$$. 
                             The corresponding left and right eigenvectors are the elements of $$\text{ker}(B^\top)$$ and $$\text{ker}(B)$$.
                             Now the goal is to find the structure of the finite eigenspaces.
                         Eigenspace Structure Result #slide 
                             We define normalised left and right eigenvectors w.r.t. the factorisation of $$B$$ as eigenvectors satisfying $$x^\top u = 1$$ and $$y v^\top = 1$$. 
                             Structure theorem for finite eigenspace of rank-1 regular pencil:  #novel:theorem
                                 If $$v^\top \text{adj}(A) u=0$$, the pencil has no finite eigenvalues. 
                                 Otherwise, the pencil has a single finite eigenvalue $$c=\frac{\det(A)}{v^\top \text{adj}(A) u}$$.
                                 The associated left and right normalised eigenvectors $$x,y$$ can be determined as follows:
                                     $$x^\top=\frac{v^\top\text{adj}(A)}{v^\top \text{adj}(A) u}$$,
                                     $$y=\frac{\text{adj}(A)u}{v^\top \text{adj}(A) u}$$.
                         Proof of Theorem #slide #proof
                             It can directly be verified that, based on the definitions of $$c$$, $$x$$ and $$y$$ as in the theorem, that it holds $$Ay=cuv^\top y$$ and $$x^\top A=cx^\top uv^\top$$. 
                             So $$c$$ is an eigenvalue, and this must be the only one as the degree of the characteristic polynomial is one. 
                             Furthermore, it can be seen that $$x^\top$$ and $$y$$ are normalised eigenvectors.
                         Some Matrix-Adjoint Identities #slide #novel:proposition 
                             The previous results allow proving the following identities:
                             #proposition For $$a\in \R$$, the following holds:
                                 $$\det(A+a uv^\top)=\det(A)+ av^\top\text{adj}(A)u$$
                                 $$v^\top \;\text{adj}(A+a uv^\top)=v^\top\;\text{adj}(A)$$
                                 $$\text{adj}(A+a uv^\top)u=\text{adj}(A)u$$
                         Proof of Identities #slide 
                             Note that if $$v^\top\;\text{adj}(A)u= 0$$, it follows $$\det(A+a uv^\top)=\det(A)$$ and hence the identities are trivially fulfilled in this case.
                             Otherwise:
                                 It must hold $$\det(A+\lambda uv^\top)=b\lambda +\det(A)$$. 
                                 This is the characteristic polynomial. 
                                 Then we can solve for $$\lambda = -\frac{\det(A)}{b}$$. 
                                 Since $$-\lambda$$ is an eigenvalue, the previous theorem yields $$b=v^\top \text{adj}(A) u$$.
                             The other identities are immediate consequences of the fact that $$A-\lambda uv^\top$$ and $$(A+a uv^\top)-\lambda uv^\top$$ have the same eigenvectors for all real numbers $$a$$.
                         Remarks #slide 
                             The first identity is also known as __matrix determinant lemma__ in the literature \cite{}. 
                             The three identities generalise Karlin's well-known identities for computing optimal solutions of matrix games.
                             This is a pencil with $$B=E$$.
                     Irreducible Pencil #slide 
                         #proposition If the pencil is irreducible, the formulae as in Proposition \ref{} still apply.  
                         Proof
                             Being irreducible, the pencil is similar to either $$I-\lambda N$$ or $$J-\lambda I$$ where $$N$$ is a single nilpotent Jordan block and $$J$$ a single Jordan block with eigenvalue $$\mu\in\R$$. 
                             The case that needs examining is if $$A$$ singular, which corresponds to the latter with $$\mu=0$$. 
                             But then $$\text{rank}(A)=n-1$$, and there exist $$\tilde{u},\tilde{v}\in\R^n$$ such that $$\text{adj}(A)=\tilde{u}\tilde{v}^\top$$. 
                             Then $$x^\top=\tilde{v}^\top L$$, $$y=R\tilde{u}$$.
                         INBOX #h
                             The substitution $$\lambda \leftarrow \lambda+a$$ where $$a\in \R$$ adds $$a$$ to all finite eigenvalues and leaves their eigenvectors invariant. Without loss of generality, it can thus be assumed that $$\det(A)=f(0)=a\neq 0$$ and that $$A$$ be invertible. 
                             If the matrix $$A$$ is singular the previous results still hold subject to a rank condition. 
                             #lemma The following identity holds for a square $$n \times n$$ matrix $$A$$ and $$n \times r$$ $$(r\le n)$$ matrices $$L$$, $$R$$: 
                                 $$(\det(A))^{r-1}\det(A+a LR^\top)=\det( \det(A)I_r+ aR^\top\text{adj}(A)L)$$ #novel 
                                 $$R^\top \;\text{adj}(A+a LR^\top)=R^\top\;\text{adj}(A)$$ #novel 
                                 $$\text{adj}(A+a LR^\top)L=\text{adj}(A)L$$ #novel 
                                     #proof 
                                 (ii) 
                                 #proof 
                             #remark 
                                 Can be seen as a generalisation of the matrix determinant lemma in [,] to a singular matrix $$A$$.
                                 This is more compact than the result in [].
                                 In a simple form, it has already been stated in [] in the context of game theory.
                             #novel 
                             define the matrix $$C$$ as $$C=R^\top \text{adj}(A)L$$.
                             $$\text{rank}(A)=n$$ and $$x^\top=v^\top A^{-1}$$, $$y=A^{-1}u$$.
                     Conclusion #slide 
                     INBOX
                         #lemma The matrix $$uv^\top$$ has $$v^\top u$$ as an eigenvalue, with corresponding left and right eigenvectors $$v^\top$$ and $$u$$. If $$v^\top u=0$$, then $$uv^\top$$ is nilpotent. #novel 
                             #proof 
                         #theorem #novel Given the regular matrix pencil $$P(\lambda)= A-\lambda B$$ where $$B=LR^\top$$ and $$\det(A)\neq 0$$, define the matrix $$C=R^\top A^{-1}L$$. Then the following statements hold:
                             FINITE
                                 For each right eigenvector $$y_\mu$$ of $$C$$ associated with an eigenvalue $$\mu\neq 0$$ (left eigenvector $$x^\top_\mu$$ respectively), the vector $$A^{-1}Ly_\mu\neq 0$$ is a right eigenvector (the vector $$x^\top_\mu R^\top A^{-1}\neq 0$$ is a left eigenvector respectively) of $$P(\lambda)$$ with eigenvalue $$\lambda=\mu^{-1}$$.
                             INFINITE
                                 If the factorisation of $$B$$ is full-rank, the geometric multiplicity of the infinite eigenvalue of $$P(\lambda)$$ and that of $$\mu=0$$ as an eigenvalue of $$C$$ coincide. 
                         CASE A INVERTIBLE #hh 
                         #theorem 
                             The matrix pencil $$P(\lambda)$$ is irreducible iff the matrix $$C$$ is irreducible. 
                                 infty
                                     For corresponding unique eigenvectors y,z it holds #novel 
                     ARCHIVE
                         $$\deg(\det(I-\lambda LR^\top))\le \text{rank}(LR^\top)\le r$$
                         In this case there is a one-to-one correspondence between finite eigenvalues and eigenvectors of the pencil, and that of a matrix of size $$r$$.
                         #proposition The finite eigenvalues of the regular matrix pencil $$P(\lambda)= A-\lambda B$$ where $$B=LR^\top$$ and $$\det(A)\neq 0$$ are the reciprocals of the non-zero eigenvalues of the matrix $$C=R^\top A^{-1}L$$. For each right eigenvector $$y_\mu$$ of $$C$$ associated with an eigenvalue $$\mu\neq 0$$ (left eigenvector $$x^\top_\mu$$ respectively), the vector $$A^{-1}Ly_\mu\neq 0$$ is a right eigenvector (the vector $$x^\top_\mu R^\top A^{-1}\neq 0$$ is a left eigenvector respectively) of $$P(\lambda)$$. #novel 
                             #proof 
                                 The proof is constructive.
                                 Note that vectors $$A^{-1}Ly_\mu\neq 0$$ and $$x^\top_\mu R^\top A^{-1}\neq 0$$ as otherwise we would have $$\mu=0$$. 
                                 The set of finite eigenvalues can be seen to coincide with the reciprocals of the non-zero eigenvalues of $$C$$ using Lemma #ref:lemma:C-matrix
                         Note that if $$\deg(f)=0$$, since $$P(\lambda)$$ is a regular matrix pencil, we can see from its Weierstrass normal form that $$\det(A)\neq 0$$.
                         #proposition #label:infty If the regular matrix pencil $$P(\lambda)$$ as in the previous proposition has an infinite eigenvalue of multiplicity $$k$$, then zero is an eigenvalue of $$C$$ of multiplicity at least $$k$$. Corresponding eigenvectors can be computed from a suitable subset of $$k$$ eigenvectors of $$C$$, in a similar manner as in Proposition #ref:infty. #novel 
                             #proof 
                         #proposition  If the factorisation of $$B$$ is full-rank, the multiplicity of the infinite eigenvalue of $$P(\lambda)$$ and that of 0 as an eigenvalue of $$C$$ coincide. #novel
                             #proof 
                         #example Not full rank factorisation...
                 RFactor
                     (Franchi & Paruolo, 2011)
                         Achieves calculation of matrix invariants such as Jordan and Smith normal forms
                         Done through the computation of sequences of local rank factorisations 
                         Does apply to linear matrix pencils, where the Kronecker normal form is determined, and the Weierstra{\ss} normal form in the case of regular pencils.  
                         Local analysis requires the prior knowledge of eigenvalues 
             LA+EPF
                 Extended Perron-Frobenius Theory #EPF
                     Introduction #slide 
                         Background 
                         Context
                         Extended Perron-Frobenius Theory #slide #EPF 
                             Extended Perron-Frobenius Theory:
                                 Defining pertinent classes of matrices with spectral positivity and nonnegativity properties
                                 Find [necessary and] sufficient conditions for these properties to hold, based on inspecting matrix coefficients and performing elementary matrix operations
                             Recently:
                                 Generalising the theory to linear matrix pencils
                     TAXONOMY: EPF [NECESSARY & SUFFICIENT] CONDITIONS FOR SPECTRAL POSITIVITY PROPERTIES
                         Studied Matrix Pencils #slide 
                             $$A-\lambda I$$ #EPF:FMat #EPF:P #EPF:M #EPF:PF 
                             $$A-\lambda B$$ #EPF:FTrans #EPF:Mehr
                             $$A-\lambda E$$ #EPF:M 
                         Considered Properties of Interest #h 
                             General Matrix Properties #slide 
                                 Multiplicity of eigenvalue
                                     Simple eigenvalue #EPF:P #EPF:FTrans #Irr 
                                     Unique eigenvalue #EPF:FTrans #EPF:FMat
                                 Irreducibility #EPF:F #Irr 
                                 Nilpotency 
                             Spectral Positivity Properties #slide 
                                 Eigenvalues
                                     Positive eigenvalue #EPF:P #EPF:FTrans #EPF:FMat 
                                     Nonnegative eigenvalue #EPF:F 
                                     Dominant eigenvalue #EPF:P #EPF:F #EPF:PF 
                                         Strictly dominant eigenvalue #EPF:S 
                                     Eigenvalue(s) with positive real part #EPF 
                                     Eigenvalue(s) with dominant real part #EPF 
                                 Eigenvectors 
                                     Positive (right) eigenvector #EPF:P #EPF:F #EPF:FTrans #EPF:S #EPF:FMat #Irr 
                                         Unique
                                     Positive left eigenvector #EPF:FTrans #EPF:S #EPF:FMat 
                                         Unique
                                     Nonnegative (right) eigenvector #EPF:F #EPF:PF 
                                     Nonnegative left eigenvector
                             Published Named Properties
                                 Perron #EPF:P
                                 Frobenius #EPF:F
                                 PerronFrobenius Property #EPF:PF
                                 Weak Frobenius #EPF:W
                                 Strong Frobenius #EPF:S
                                 Left/Right PF #EPF
                                 Eventually PF #EPF
                                 PFn #EPF:PFn
                                     Following [16], we let PFn denote the collection ofnnreal matrices whose spectral radius is a simple positive and strictly dominant eigenvalue having positive left and right eigenvectors. 
                                     $$A$$ and $$A^\top$$ are Strong PF. #EPF:S  
                                     Equivalently, we can say that PFn is the collection of matrices such that bothAandATpossess the strong Perron-Frobenius property.
                                 WPFn #EPF:WPFn
                                     $$A$$ and $$A^\top$$ are PF. #EPF:WPFn 
                                     Following [16], Similarly, WPFn denotes the collection ofnnreal matrices whose spectral ra-dius is an eigenvalue having nonnegative left and right eigenvectors. 
                                     Equivalently,WPFn is the collection of matricesAsuch that bothAandATpossess the Perron-Frobenius property.
                         Published Sufficient Conditions #h 
                             Concepts #slide 
                                 Positive matrix #EPF:P 
                                 Nonnegative matrix #EPF:F 
                                 Eventually positive matrix
                                 Eventually nonnegative matrix
                                 Nilpotent matrix
                                 Irreducible matrix
                             Results in the Literature #h
                                 PERRON
                                     #theorem (Perrons Theorem). Let $$A$$ be a real positive square matrix. Then its spectral radius $$r=\rho(A)$$ is a simple, positive eigenvalue of $$A$$, and there is no other eigenvalue of the same modulus. Furthermore, there exists a corresponding positive right eigenvector $$y_r$$. #EPF:P
                                 FROBENIUS
                                     #theorem (Frobenius' Theorem). Let $$A$$ be a real nonnegative square matrix. Then $$r=\rho(A)\ge 0$$ is an eigenvalue of $$A$$, with a corresponding nonnegative right eigenvector $$y_r$$. If $$A$$ is an irreducible matrix, then $$y_r$$ is positive. #EPF:F #EPF:PF SIMPLE?? #todo 
                                 MINKOWSKI & RAGHAVAN
                                     M-MATRIX
                                         #theorem Let $$A$$ be an invertible $$M$$-Matrix. Then it holds #EPF:M 
                                             The matrix $$A^{-1}$$ has the Frobenius property. 
                                             Assume the pencil $$A-\lambda E$$ is regular. Then it has the Frobenius property. 
                                             The matrix game $$G(A)$$ is completely mixed. 
                                 UZAWA
                                     F-MATRIX 
                                         #EPF:FMat
                                 ELHASHASH & SZYLD
                                     #theorem Eventually nonnegative matrix #EPF:EV
                                 DRANDAKIS 
                                     F-TRANSFORMATIONS #EPF:FTrans
                                 MEHRMANN
                                     #EPF:Mehr
                     AUTHORS/REFERENCES
                         GENERAL PROPERTIES OF EVENTUALLY NONNEGATIVE MATRICES
                             Zaslavsky, McDonald, and Tam [31], [32] studied the Jordan form of eventuallynonnegative matrices. 
                             Carnochan Naqvi and McDonald [5] studied combinatorialproperties of eventually nonnegative matrices whose index is 0 or 1 by consideringtheir Frobenius normal forms. 
                         DOMINANT EV
                             Friedland [8] showed that for eventually nonnegative matrices the spectral radius is an eigenvalue. 
                                 Such an eigenvalue and any other eigenvalue whose modulus is equalto the spectral radius is called adominanteigenvalue. Furthermore, if a matrix hasonly one dominant eigenvalue (regardless of its multiplicity), then we call such aneigenvaluestrictly dominant.
                                 Eschenbach and Johnson [7] studied sign patterns of a matrix requiring the spectral radius to be an eigenvalue. They called such a propertythePerron property. 
                             We mention in passing the work of Rump [23], [24], who generalized the conceptof a positive dominant eigenvalue, but this is not related to the questions addressedin this paper.
                         EARLIER
                             Other earlier papers looking at issues relating to the spectralradius being an eigenvalue, at positive or nonnegative corresponding eigenvector, orat matrices with these properties,
                                  include [11], [12], [13], [16], [17], [19], [26], [27], [29].
                         EXTENDED PERRON PROPERTIES 
                             Different nomenclature for different Perron properties appear in the literature.In [7], as we already mentioned, thePerron propertystands for having the spectralradius as an eigenvalue, whereas, in [11] theweak Perron propertystands for havingthe spectral radius as a simple positive and strictly dominant eigenvalue. 
                             In [19],thePerron-Frobenius  propertystands for having the spectral radius as a positiveeigenvalue with a nonnegative eigenvector; this is also the definition used in [6].
                              Onthe other hand, in this paper we say that a real matrixApossesses thePerron-Frobenius propertyif(A) (whether it is zero or positive) is an eigenvalue ofAhavinga nonnegative eigenvector (which is the same as the definition introduced in [29]).
                                 Moreover, we say thatApossesses thestrong Perron-Frobenius propertyifAhas asimple, positive, and strictly dominant eigenvalue with a positive eigenvector (whichis the same as the definition introduced in [19]).
                 Extensions of the Perron-Frobenius theory to regular matrix pencils. #strand #EPF #novel:slow 
                     Introduction #slide
                         Background:
                         Context:
                         Motivation:
                     Contributions/Novelty #slide 
                     Notations #slide 
                     Perron-Frobenius Properties #slide 
                         Definition
                         Definition
                     Definition of Lambda-Matrix #slide #novel:definition 
                         For a regular matrix pencil $$A-\lambda B$$ with a rank-factorisation $$B=LR^\top$$ we define the $$r\times r$$ matrix $$\Lambda:=R^\top \text{adj}(A)L$$. #definition 
                     Well-Defined Lemma #novel:lemma 
                         Lemma.
                         The $$\Lambda$$-matrices obtained from different rank-factorisations of the same matrix $$B$$ are related to each other through application of suitable similarity transformations. 
                         Proof.
                         If $$B=L_1 R_1^\top =L_2 R_2^\top$$, then $$\Lambda_1\sim \Lambda_2$$.
                             \cite{Piziak1999-iu}
                         Lemma.
                         Two equivalent regular matrix pencils have all their associated $$\Lambda$$-matrices being similar.  
                         Proof.
                             If $$A-\lambda B \sim \tilde{A}-\lambda \tilde{B} $$, then $$\Lambda=\tilde{\Lambda}$$.
                                 $$\tilde{A}=SAT$$
                                 $$\tilde{B}=SBT=SLR^\top T=\tilde{L}\tilde{R}^\top$$
                                 $$\tilde{\Lambda}:=R^\top T \text{adj}(SAT)SL = R^\top T T^{-1}\text{adj}(A)S^{-1}SL=R^\top \text{adj}(A)L=\Lambda$$
                         SCREENSHOT
                             ![Lambda-Mat.png](https://dynalist.io/u/8KZtLlw6t7Ml6N_uyxIQTMvE)
                     Strong EPF Theorem #slide #novel:theorem 
                         If $$[A^{-1}?],L, R > 0$$ and $$\Lambda$$ has the strong PF property, then the regular matrix pencil $$A-\lambda LR^\top$$ has the strong PF property. 
                         If $$A,L_R^{-1}, R_R^{-1} > 0$$ and the regular matrix pencil $$A-\lambda LR^\top$$ has the strong PF property, then $$\Lambda$$ has the strong PF property.
                         If $$A,L,R>0$$ are inverse positive, then: the pencil has the strong PF property iff $$\Lambda$$ has the strong PF property. 
                             #theorem 
                     Proof of Theorem #slide 
                         Due to the definition of the $$\Lambda$$-matrix, we have
                             $$R^\top \text{adj}(A)L\cdot\Lambda=\det(R\top \text{adj}(A)L)\cdot I_r$$ #label:Lambda
                         We will denote $$\mu := \det(R^\top \text{adj}(A)L)$$ for ease of notation.
                         Let $$y>0$$ such that $$\Lambda y=\lambda y$$. We will assert that from this, we can derive a positive eigenvector for the pencil #label:the-pencil, for a suitable eigenvalue.
                          Define $$\tilde{y}= \text{adj}(A)Ly$$. Then we obtain
                             $$A \tilde{y}=A\; \text{adj}(A)Ly=\det(A)Ly$$. 
                         Furthermore, using #label:Lambda 
                             $$\mu y=R^\top \text{adj}(A)L\cdot \Lambda y=R^\top \text{adj}(A)L\cdot \lambda y$$.
                         Hence, putting this together, 
                             $$\mu A \tilde{y}=\det(A)LR^\top \text{adj}(A)L\cdot \lambda y=\det(A)\lambda B\tilde{y}\Longleftrightarrow (\mu A-\det(A)\lambda B)\tilde{y}=0$$.
                         We now distinguish three cases:
                             (i) Case $$\mu\neq 0, \det(A) \neq 0$$:
                                 We can see that $$\frac{\det(A)\lambda}{\mu}$$ is a finite nonzero eigenvalue, with positive eigenvector $$\tilde{y}$$.
                             (ii) Case $$\mu = 0, \det(A) \neq 0$$:
                                 In this case, we can see that $$\tilde{y}$$ is a positive eigenvector for an infinite eigenvalue. 
                             (iii) Case $$\mu \neq 0, \det(A) = 0$$:
                                 Consider $$a \neq 0$$ chosen so that $$\det(A + aLR^\top) \neq 0$$. 
                                 [..]
                                 This can be treated by Case (i) for the pencil $$A+ aLR^\top-\lambda LR^\top$$.
                                 Finally, we obtain that $$\tilde{y}$$ is a positive eigenvector for the eigenvalue $$0$$.
                             (iv) Case $$\mu = 0, \det(A) = 0$$:
                     Weak EPF Theorem #slide #novel:theorem 
                         [If $$A, L, R \ge 0$$, $$A$$ is irreducible and $$\Lambda$$ has the weak PF property, then the regular matrix pencil $$A-\lambda LR^\top$$ has the weak PF property.]
                     Proof of Theorem #slide 
                     Application: Game Theory #slide #novel:application 
                         The pencil is $$A-\lambda E$$.
                         Strong EPF => cm
                         Weak EPF => lag-free sols
                         Raghavaran
                     Application: Optimisation #slide #novel:application 
                         MC2 
                     Application: Economics #slide #novel:application 
                         Von Neumann Economical Growth Model
                             The pencil is $$A-\lambda E$$.
                             Strong EPF => cm
                             Weak EPF => lag-free sols
                             Giorgi
                     INBOX
                         The pencil is PF in the sense of Mehrmann et al if and only  it is..
                         Totally Positive Theorem #slide 
                             Let $$A-\lambda B$$ be totally positive. The it has the PF-property. #theorem 
             LA+M-Mat #m-mat 
                 Background
                     M-Matrices and other special nonnegative matrices
                 Generalisations of the notion of M- [Minkowski-Leontief-] matrices, based on matrix pencils #GMP #novel:slow 
                     Introduction #slide
                         Context:
                         Motivation:
                             Has not been done for pencils yet
                     Contributions/Novelty #slide 
                     Notations #slide 
                     Motivation
                     MP-Matrix Definition #slide #novel:definition add infinite EV
                         A square matrix $$A$$ admitting a splitting of the form $$A=sC-tB$$ where $$B,C>0$$ is called an $$MP$$-Matrix, if it is an $$MP$$-Matrix of the finite type, or an $$MP$$-Matrix of the infinite type.
                         $$A$$ is called an $$MP$$-Matrix of the finite type, if $$s\ge 0$$, $$t>0$$ such that 
                             $$B-\lambda C$$ is a regular matrix pencil which has the finite PF property,
                             $$\frac{s}{t}\ge \rho_0(B-\lambda C)$$.
                         If $$\frac{s}{t}> \rho(B-\lambda C)$$, then $$A$$ is called a non-singular $$MP$$-Matrix. Otherwise, it is referred to as a singular $$MP$$-Matrix.
                     Interpretation as Pencils #slide 
                         Interpret as matrix pencil
                             $$(B-sI)-\lambda I=:P(\lambda)$$
                         This can be defined for a general regular matrix pencil $$P(\lambda)=B-\lambda C$$ 
                             Non-singular $$M$$-Pencil: $$(sC-tB)-\lambda C$$ where $${s}/{t}>\rho(B-\lambda C)$$ 
                                 and $$B-\lambda C$$ has the strong Perron-Frobenius property.
                     MP-Matrix Properties #slide #novel 
                         totally positive
                         positive principal minors
                         all eigenvalues have positive real part
                     MP-Matrix and M-Matrix Relationship #slide #novel 
                         The matrix $$sA-tLR^\top$$ where $$A$$ is non-singular and $$L,R>0$$ are full rank matrices is an ML-matrix iff the matrix $$st^{-1} I-R^\top A^{-1}L$$ is an M-Matrix. 
                     Assume $$A$$ is an $$M$$-Matrix. Then $$A-\lambda B$$ has the XYZ-property for all $$B$$. 
                     Assume $$L,R>0$$. Then the pencil $$A-\lambda LR^\top$$ is an $$F$$-pencil iff the matrix $$R^\top A^{-1}L$$ is an $$F$$-matrix. 
                     GM-Matrix
                 Estimate for eigenvalues of $M$-Matrices #m-mat 
                 Further characterisations of F-Transformations based on M-Matrices
                     The Easy Result #slide #m-mat #VNM #eigen
                         Suppose the matrix $$A/B$$ ($$A \ge 0, B>0$$) is an $$M$$-Matrix. Then the pencil $$A-\lambda B$$ is an $$F$$-pencil and its nonnegative left (right resp.) generalised eigenvector is positive. #proposition 
                     Proof #slide 
                     Example #slide 
                     The Hard Result #slide #m-mat #VNM #eigen
                         Suppose the matrix $$A/B$$ ($$A \ge 0, B \ge 0$$, we define $$\infty:=a/0$$, 0/0 not allowed) is an $$M$$-Matrix. Then the pencil $$A-\lambda B$$ is an $$F$$-pencil and its nonnegative left- and right generalised eigenvectors are positive. #proposition 
                             0/0?
                             
         Prob
             Background
             Markov+Bilinear
         Risk
             Notations -- Linear #slide 
                 DEFENDED ASSET
                     $$a$$: asset
                     $$v$$: vulnerability
                     $$e$$: exploitability of vulnerability [MAEVA]
                 RISK
                     $$R=p\cdot I$$
                         $$R$$: risk
                         $$p$$: attack likelihood
                         $$I$$: impact
                 ATTACKER
                     $$S$$: Risk source
                     $$\theta$$: threat 
                     $$E$$: event 
                 ATTACK INCENTIVE
                     $$A=\nu\cdot V$$
                         $$A$$: attack incentive
                         $$\nu$$: visibility of asset [MAEVA]
                         $$V$$: value of asset
             Notations - Hierarchical #slide 
                 DEFENDER
                     HAS
                         $$a$$: asset
                             $$v$$: vulnerability
                                 [$$e$$: exploitability of vulnerability [MAEVA]]
                     RISK
                         $$R=p\cdot I$$
                             $$R$$: risk
                             $$p$$: attack likelihood
                             $$I$$: impact
                 ATTACKER
                     IS
                         $$\theta$$: threat 
                         $$S$$: Risk source
                             $$E$$: event 
                     ATTACK INCENTIVE
                         $$A=\nu\cdot V$$
                             $$A$$: attack incentive
                             $$\nu$$: visibility of asset [MAEVA]
                             $$V$$: value of asset
             VA
                 CVSS+DREAD #slide 
                     BASE
                         $$\mu_{Base} = M_{Base}(\mu_{Imp},\mu_{Exp},\mu_{Dis})$$
                             IMPACT
                                 $$\mu_{Imp} = M_{Imp}(\mu_{CIA},\mu_{\overline{CIA}})$$
                             EXPLOITABILITY
                                 $$\mu_{Exp}(v_i) = M_{Exp}(\mu_{Exp}(v_i),\mu_{Exp}(v_{i+1}))$$
                             DISCOVERY
                                 $$\mu_{Dis}(v_i) = M_{Dis}(\mu_{Dis}(v_i),\mu_{Dis}(v_{i+1}))$$
                         ASSET PAIR $$a=(a_i,a_{i+1})$$
                             INDEPENDENT
                             DEPENDENT (CHAIN) , v=(v_i,v_{i+1})$$
                                 DEPENDEND/DIRECT/INTERNAL/SERIES
                                     IMPACT
                                         $$\mu_{Imp}(v) = \mu_{Imp}(v_i)$$
                                         $$\mu_{\overline{CIA}}(v_i)=\mu_{Imp}(v_{i+1})$$
                                         $$\mu_{Imp}(v_i) = M_{Imp}(\mu_{CIA}(v_i),\mu_{Imp}(v_{i+1}))$$
                                     EXPLOITABILITY
                                     DISCOVERY
                                 INDEPENDENT/INDIRECT/EXTERNAL/PARALLELL
                                     IMPACT
                                         [$$\mu_{\overline{CIA}}(v_i)=0$$]
                                         $$\mu_{Imp}(v) = \mu_{Imp}(v_i)+\mu_{Imp}(v_{i+1})$$
                                     EXPLOITABILITY
                                         $$\mu_{Exp}(v) < \mu_{Exp}(v_i)+\mu_{Exp}(v_{i+1})$$
                                     DISCOVERY
                 Open Data Framework
                     Risk -- Equations #slide 
                         $$R=p\cdot I$$
                         $$p=p(e,\nu,V)$$
                         $$I = I(v,V)$$
                         Open Data 
                             $$o$$: Open Data (primary) asset
                         IMAGE
                              ![Pasted image](https://dynalist.io/u/5F6uC_TtvqWeCZsljZYnPvzx) 
             RA
         SS
             SS+Matrix
                 Matrix-based Space-Efficient Online Secret Sharing: A Contribution
                     Introduction #slide
                         Background:
                         Context:
                         Motivation:
                     Contributions/Novelty #slide 
                     Notations #slide 
                     Background #slide 
                         The probabilistic algorithm for secret matrix share size reduction by \cite{Pfluegel2013-as}:
                             Inspired by previous matrix-based work, but avoid Jordan normal form
                             Propose a probabilistic algorithm, based on using companion form
                             We achieve similarly short shares as Yang and Zhao, but are more efficient
                             This yields a probabilistic online secret sharing scheme with small expected share size
                     Linear Algebra Concepts #slide 
                         Let us review some linear algebra concepts that will be used in the sequel.
                         Let $$A \in \mathbbm{F}_p^{t \times t}$$. The matrix $$A$$ is \emph{cyclic} iff it is similar to matrix in {\em companion form}
                             $$C =\left(\begin{array}{ccccc}0 & 1 & 0 & \ldots & 0 \\0 & 0 & 1 & \ddots & \vdots \\\vdots & \vdots & \ddots & \ddots & 0 \\0 & 0 & \ldots & 0 & 1 \\c_{0} & c_{1} & \ldots & c_{t-2} & c_{t-1} \\\end{array}\right)$$.
                         Here, we have that
                             $$f (\lambda) = \lambda^{t} - c_{t-1} \lambda^{t-1} - \cdots- c_{1} \lambda - c_{0}$$
                         is the characteristic polynomial of $$C$$. 
                         For a cyclic matrix, we have that 
                             $$f(\lambda) = \det(C- \lambda I) = \det(A- \lambda I) = m(\lambda)$$ 
                         where $$m(\lambda)$$ is the minimal polynomial of $$A$$.
                     Cyclic Vectors and a Probability Result #slide 
                         If $$A$$ is cyclic, we can use standard linear algebra techniques  to compute $$C$$
                         Algorithm Cyclic\_Vector($$A$$)
                             [(1)] $$v_0:=$$ random vector
                             [(2)] {\bf for} $$i=1$$ {\bf to} $$t-1$$: compute $$v_i:=v_{i-1}A$$
                             [(3)] {\bf if} $$v_0, \ldots, v_{t-1}$$ are linearly independent {\bf then return} \emph{$$v_0$$} {\bf else return} {\em FAIL}
                     Research Question #slide 
                         Question: given a secret $$s$$, and a randomly chosen prime number $$p$$, we can convert $$s$$ to a matrix. How likely is this to induce a random cyclic matrix?
                         \begin{proposition}[Neumann et al., 1994]
                         If a matrix $$A$$ and a vector $$v$$ are chosen at random, then the probability that $$A$$ is cyclic and $$v$$ is a cyclic vector for $$A$$ is $$(1-p^{-1})(1-p^{-2})\cdots(1-p^{-t}) $$ .
                         \end{proposition}
                     Matrix Share Size Reduction Algorithm #slide 
                         This probabilistic algorithm splits secret $$s$$ into public part $$P$$ and (short) secret part $$Q$$
                         We use repeated matrix conversion, with increasing prime numbers
                         Algorithm MSSR($$s$$)
                             [(1)] $$p:=2$$
                             [(2)] /* Conversion of secret */
                                 [(a)] $$p:=$$ next\_prime$$(p)$$
                                 [(b)] Compute the base-$$p$$ digits of $$s$$
                                 [(c)] Convert secret $$s$$ into a $$t \times t$$ matrix $$S$$ by using these digits (padding with 0 if necessary)
                             [(3)] /* Size reduction step */
                                 [(a)] Attempt to compute cyclic vector $$v$$
                                 [(b)] If not successful, go to Step (2)
                                 [(c)] Construct similarity transformation $$T$$ such that $$C := T^{-1}S T$$ is a companion matrix
                             [(4)] Put $$P := T$$ and $$Q := [c_0, c_1, \ldots, c_{t-1}, p]$$
                     An Online Secret Sharing Scheme #slide 
                         We use the MSSR algorithm for an online secret sharing scheme with public and secret data
                         {Share creation}:
                             Compute $$P$$ and $$Q$$ using MSSR algorithm
                             Publish $$P$$
                             Share $$Q$$, using any space efficient secret sharing scheme
                         {Reconstruction of secret}:
                             Reconstruct the characteristic polynomial $$f$$ and the value of $$p$$ by acquiring at least $$k$$ shares
                             Build $$C$$ from the $$t$$ coefficients of $$f$$
                             Compute $$S$$ from $$C$$, by using the public transformation $$T$$ as $$S = T C T ^{-1}$$
                             Reconstruct $$s$$ from $$S$$ and $$p$$
             SS+Pre
             SS+Space
                 Space-efficient Secret Sharing for Constrained Channels #h 
                     Introduction #slide
                         Background:
                         Context:
                         Motivation:
                     Contributions/Novelty #slide 
                     Notations #slide 
                     Basic Idea #slide 
                     Simplified Version of \cite{CMI} #slide 
                     Closer to \cite{CMI} #slide 
                     Pertinent Points of \cite{CMI} #slide 
             SS+Stego
         Stego
             Background 
             Stego+Security
                 Litmap
                      ![Pasted image](https://dynalist.io/u/EXmYFHEDRMLNe7QoVtiO1z6K) 
                      ![Pasted image](https://dynalist.io/u/3Wv-ZAM5q7AKaArI314FVZFq) 
                     
             Stego+GT
             Stego+Adaptive
         Tropical Reduction
         Von Neumann Model Theory (VNM)
     BY DOMAIN
         Strand 0
             LA
             Simplex
             Nonnegative Matrices
             Formal Reduction
         Strand 1
             VNM
             GT
             CA
             Risk
             OaG
         Strand 2
             BC
             SS
             Stego
         Strand 3
             Edu
                 NCSC
                 ACE
                 NIS
                 CyBOK
                     Mapping
                 ZOOs
     By Other Authors
     TAXONOMIES
         Crowdsourcing #h 
             CROWDSOURCING
                 GENERAL
                     @kazai2011worker,
                         The paper by Kazai & al introduces a typology of workers, taking into account speed and accuracy.
                         It also addresses aspects of trust, but this could be developed further.
                             $$\begin{array}{|c| | c|c|c|c|} \hline Worker Type & \text{accurate} & fast  & honest & trustworthy  \\ \hline  \hline competent  & \checkmark & \checkmark  & \checkmark  & -  \\ diligent &\checkmark & - & \checkmark  & \checkmark   \\ sloppy & - & \checkmark &\checkmark  & -  \\ incompetent & - & - & \checkmark   & -   \\ spammer & ? & ? & - & -  \\ \hline \end{array}$$
                     @choi2016detecting,
                         title={Detecting malicious campaigns in crowdsourcing platforms},
                         author={Choi, Hongkyu and Lee, Kyumin and Webb, Steve},
                         booktitle={2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)},
                         pages={197--202},
                         year={2016},
                         organization={IEEE}
                         }
                     @gadiraju2015human,
                         title={Human beyond the machine: Challenges and opportunities of microtask crowdsourcing},
                         author={Gadiraju, Ujwal and Demartini, Gianluca and Kawase, Ricardo and Dietze, Stefan},
                         journal={IEEE Intelligent Systems},
                         volume={30},
                         number={4},
                         pages={81--85},
                         year={2015},
                         publisher={IEEE}
                         }
                 GAMIFICATION
                     @morschheuser2016gamification,
                         title={Gamification in crowdsourcing: a review},
                         author={Morschheuser, Benedikt and Hamari, Juho and Koivisto, Jonna},
                         booktitle={2016 49th Hawaii International Conference on System Sciences (HICSS)},
                         pages={4375--4384},
                         year={2016},
                         organization={IEEE}
                         }
                     @feng2018gamification,
                         title={Gamification artifacts and crowdsourcing participation: Examining the mediating role of intrinsic motivations},
                         author={Feng, Yuanyue and Ye, Hua Jonathan and Yu, Ying and Yang, Congcong and Cui, Tingru},
                         journal={Computers in Human Behavior},
                         volume={81},
                         pages={124--136},
                         year={2018},
                         publisher={Elsevier}
                         }
                     @yang2018fair,
                         title={Fair or not: Effects of gamification elements on crowdsourcing participation},
                         author={Yang, Congcong and Feng, Yuanyue and Zheng, Xizhi and Feng, Ye and Yu, Ying and Niu, Ben and Yang, Pianpian},
                         booktitle={Proceeedings of 18th International Conference on Electronic Business},
                         pages={325--335},
                         year={2018}
                         }
                     @eickhoff2012quality,
                         title={Quality through flow and immersion: gamifying crowdsourced relevance assessments},
                         author={Eickhoff, Carsten and Harris, Christopher G and de Vries, Arjen P and Srinivasan, Padmini},
                         booktitle={Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval},
                         pages={871--880},
                         year={2012}
                         }
                 GAME THEORY
                     @moshfeghi2016identifying,
                         title={Identifying careless workers in crowdsourcing platforms: a game theory approach},
                         author={Moshfeghi, Yashar and Huertas-Rosero, Alvaro F and Jose, Joemon M},
                         booktitle={Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval},
                         pages={857--860},
                         year={2016}
                         }
                         Overview
                             This paper studies the Type 2 worker, referred to as "careless"
                             Circulating Idea: game-theoretic betting based on various incentives
                     @hu2019enhancing,
                         title={Enhancing Crowdsourcing With the Zero-Determinant Game Theory},
                         author={Hu, Qin},
                         year={2019},
                         school={The George Washington University}
                         }
                     @tang2019incentive,
                         title={Incentive mechanism for macrotasking crowdsourcing: A zero-determinant strategy approach},
                         author={Tang, Changbing and Li, Xiang and Cao, Mengwen and Zhang, Zhao and Yu, Xinghuo},
                         journal={IEEE Internet of Things Journal},
                         volume={6},
                         number={5},
                         pages={8589--8601},
                         year={2019},
                         publisher={IEEE}
                         }
                     @liu2017mechanism,
                         title={Mechanism design games for thwarting malicious behavior in crowdsourcing applications},
                         author={Liu, Chunchi and Wang, Shengling and Ma, Liran and Cheng, Xiuzhen and Bie, Rongfang and Yu, Jiguo},
                         booktitle={IEEE INFOCOM 2017-IEEE Conference on Computer Communications},
                         pages={1--9},
                         year={2017},
                         organization={IEEE}
                         }
                     @qiu2019incentivizing,
                         title={Incentivizing distributive fairness for crowdsourcing workers},
                         author={Qiu, Chenxi and Squicciarini, Anna and Hanrahan, Benjamin},
                         booktitle={Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems},
                         pages={404--412},
                         year={2019}
                         }
                 INBOX
                     @dipalantino2011individual,
                         title={Individual and collective user behavior in crowdsourcing services},
                         author={DiPalantino, Dominic and Karagiannis, Thomas and Vojnovic, Milan},
                         booktitle={Technical report MSR-TR-2010-59, microsoft research},
                         year={2011}
                         }
                     @gadiraju2015understanding,
                         title={Understanding malicious behavior in crowdsourcing platforms: The case of online surveys},
                         author={Gadiraju, Ujwal and Kawase, Ricardo and Dietze, Stefan and Demartini, Gianluca},
                         booktitle={Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
                         pages={1631--1640},
                         year={2015}
                         }
                     @dwarakanath2016trustworthiness,
                         title={Trustworthiness in enterprise crowdsourcing: a taxonomy \& evidence from data},
                         author={Dwarakanath, Anurag and Shrikanth, NC and Abhinav, Kumar and Kass, Alex},
                         booktitle={Proceedings of the 38th International Conference on Software Engineering Companion},
                         pages={41--50},
                         year={2016}
                         }
                     @eickhoff2011crowdsourcable,
                         title={How crowdsourcable is your task},
                         author={Eickhoff, Carsten and de Vries, Arjen},
                         booktitle={Proceedings of the workshop on crowdsourcing for search and data mining (CSDM) at the fourth ACM international conference on web search and data mining (WSDM)},
                         pages={11--14},
                         year={2011}
                         }
                     @liao2019data,
                         title={A data-driven game theoretic strategy for developers in software crowdsourcing: a case study},
                         author={Liao, Zhifang and Zeng, Zhi and Zhang, Yan and Fan, Xiaoping},
                         journal={Applied Sciences},
                         volume={9},
                         number={4},
                         pages={721},
                         year={2019},
                         publisher={Multidisciplinary Digital Publishing Institute}
                         }
                     @hu2017anti,
                         title={Anti-malicious crowdsourcing using the zero-determinant strategy},
                         author={Hu, Qin and Wang, Shengling and Ma, Liran and Bie, Rongfang and Cheng, Xiuzhen},
                         booktitle={2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS)},
                         pages={1137--1146},
                         year={2017},
                         organization={IEEE}
                         }
                     @lopez2019effects,
                         title={The effects of player type on performance: A gamification case study},
                         author={Lopez, Christian E and Tucker, Conrad S},
                         journal={Computers in Human Behavior},
                         volume={91},
                         pages={333--345},
                         year={2019},
                         publisher={Elsevier}
                         }
                     @ye2015crowd,
                         title={Crowd trust: A context-aware trust model for worker selection in crowdsourcing environments},
                         author={Ye, Bin and Wang, Yan and Liu, Ling},
                         booktitle={2015 IEEE international conference on web services},
                         pages={121--128},
                         year={2015},
                         organization={IEEE}
                         }
                     @Kazai2011,
                         abstract = {Crowdsourcing platforms offer unprecedented opportunities for creating evaluation benchmarks, but suffer from varied output quality from crowd workers who possess different levels of competence and aspiration. This raises new challenges for quality control and requires an in-depth understanding of how workers' characteristics relate to the quality of their work. In this paper, we use behavioral observations (HIT completion time, fraction of useful labels, label accuracy) to define five worker types: Spammer, Sloppy, Incompetent, Competent, Diligent. Using data collected from workers engaged in the crowdsourced evaluation of the INEX 2010 Book Track Prove It task, we relate the worker types to label accuracy and personality trait information along the 'Big Five' personality dimensions. We expect that these new insights about the types of crowd workers and the quality of their work will inform how to design HITs to attract the best workers to a task and explain why certain HIT designs are more effective than others. {\textcopyright} 2011 ACM.},
                         author = {Kazai, Gabriella and Kamps, Jaap and Milic-Frayling, Natasa},
                         booktitle = {International Conference on Information and Knowledge Management, Proceedings},
                         doi = {10.1145/2063576.2063860},
                         isbn = {9781450307178},
                         keywords = {bfi test,crowdsourcing relevance labels,worker typology},
                         title = {{Worker types and personality traits in crowdsourcing relevance labels}},
                         year = {2011}
                         }
         Eigensystems of Linear Matrix Pencils and Rank-Factorisations #rank-factor+pencil+eigen 
         Specific Games #h 
             Sensor Signalling Games #h 
                 Description of Research Theme #slide 
                     A number of papers have been published in the area of incomplete information game theoretic approaches for modelling wireless sensor network and client-server architecture scenarios.
                     Types of games considered: mostly dynamic Bayesian (Signalling)
                     Main idea: model different "types" of sensors and their interaction with the receiver $$R$$
                     Precise nature of the types varies, but typically there tend to be 2 types considered in the literature  
                 System Model -- Examples #slide 
                     Cloud service provider, WSN node
                         Faults = attempts to save resources (selfish provider)
                         Vulnerabilities = system breaches by external or internal attackers
                     IDS Node 
                         Faults = deviation from true system state due to miscategorisation of patterns (false positives, true negatives)
                         Vulnerabilities = deliberate deception by attacker who has taken over the node
                 Informal Sensor Types #slide 
                     Cooperative honest sensor
                         Sends accurate results
                         Will also fulfil security requirements
                         less interesting in non-cooperative game theory context
                     Selfish sensor
                         this sensor is non-cooperative
                         tries to save resources, leading to lower quality results/service degradation
                         could be interpreted as (malicious) Byzantine fault
                     Malicious sensor
                         Non-cooperative sensor, interested in personal reward
                         will launch typical attacks (modification, interruption)
                         the entire sensor could be taken over by attacker, or the communication channel could be attacked
                 Reference Sensor Signalling Game #slide 
                     **Game** $$\mathcal{G}_{Ref}(S,R,\theta,s,u)$$
                     **Players**: 
                         $$S$$: Sender (Sensor)
                         $$A$$: Attacker
                         $$R$$: Receiver (Monitor, IDS) 
                     **Types**:
                         $$\theta=0$$: cooperative: honest and reliable (secure and dependable system)
                         $$\theta=1$$: unreliable/faulty ("lazy") sender (presence of internal Byzantine fault)
                         $$\theta=2$$: Malicious/uncooperative/not secure/vulnerable (compromised/externally attacked or internal attacker)
                     **Strategy Space**:
                         First Move: $$S(\theta)$$ sends signal
                             $$S|_{\theta=0}$$: $$c$$ -- cooperate and send correct data on secure channel. 
                             $$S|_{\theta=1}$$: with probability $$\alpha$$, experience a fault and send false data. With probability $$1-\alpha$$, send correct data. 
                             $$S|_{\theta=2}$$: with probability $$\beta$$, send correct data on secure channel. With probability $$1-\beta$$, send wrong data, or correct data on insecure, externally attacked channel. 
                         Second Move: $$R$$ takes action
                             $$s_{T}$$: trust data, $$s_{-T}$$: do not trust data
                     **Payoffs**:
                         Sender: Benefit - Cost
                         Receiver: Benefit - Cost
                 Reference Cost Benefit Model #slide 
                     Based on []
                 Reference Cost Benefit Model -- Sender #slide 
                     Benefit
                         $$b_{rew}$$ -- reward (operational gain), threatened by operational punishment
                         $$b_{est}$$ -- esteem (reputation), threatened by reputational punishment
                     Cost
                         $$c_{op}$$ -- operational (data collection, message creation)
                         $$c_{att}$$ -- Message attack (data modification, deletion or fabrication)
                         $$c_{comm}$$ -- Message sending (communication cost)
                         $$c_{pun}$$ -- Punishment: operational and reputational
                 Reference Cost Benefit Model -- Receiver #slide 
                     Benefit
                         $$b_{sec}$$ -- System security, threatened by direct costs
                         $$b_{rep}$$ -- Good reputation, threatened by indirect costs
                     Cost
                         $$c_{def}$$ -- Defence costs: verifying correctness of data
                         $$c_{dir}$$ -- Direct costs: operational losses due to 
                             false positives/alarm (wrongly mistrust)
                             false negatives (missed alarm -- wrongly trust)
                         $$c_{ind}$$ -- Indirect costs: loss of reputation
                 Critical Analysis #slide 
                     What are common elements in these papers and games?
                         Game
                         Scenario/Players
                         Types
                             $$\theta\in \{0,1,2\}$$
                         Strategies 
                     Not the solving aspect -- this is deferred for later. 
                     $$\begin{array}{|l||l|l|l|} \hline \text{Reference} & \text{Scenario} & \text{Types} & \text{Stochastic}  \\ \hline\hline \text{(Shen et al, 2011)}&  \text{WSN} & \{0,2\} &   \\ \hline \text{(M. Estiri et al, 2014)}&  \text{IDS} & \{1,2\} &   \\ \hline \text{(Moghaddam et al, 2015)}& \text{Cloud} & \{1,2\}  &   \\\hline\end{array}$$
                 References #h 
                     Paper 1 -- Game Overview #slide 
                         ![IDS-GAME.png](https://dynalist.io/u/HgjPz1It3c6p1_pkSBUga95r)
                     Paper 2 -- Game Overview #slide 
                         ![ids-signalling-game.jpg](https://dynalist.io/u/wL7rdyiTUdi0-cFY6SFkAzSo)
                     Paper 3 -- Aim of the Game #slide 
                         A dynamic, incomplete information game for helping a Client (C) to decide whether to trust a Service Provider (SP) or not
                         Nested 3-player game between
                             Attacker of SP
                             SP
                             Client
                         Contains Signalling/Bayesian incomplete information game:
                             Client uncertain about the type of SP (safe or compromised)
                             Decides after receiving signal from SP
                     Illustration -- Overview #slide 
                         ![Signalling Game - Moghaddam2015.png](https://dynalist.io/u/ocyDAQboIpYg_6iR6wIhGPnO)
                     Illustration -- Safe SP #slide 
                         ![safe-cloud.png](https://dynalist.io/u/lxWG1VftZwHuqdcWZmojJcK6)
                     Illustration -- Compromised SP #slide 
                         ![compromised-cloud.png](https://dynalist.io/u/N55buJbom68VlznmzVayIz00)
                     Nested Game Overview #slide 
                         The overarching nested game is of imperfect (?) and incomplete information
                         Move 1:
                             Run Game 1: Attacker-Defender (AD) Static Complete Information Game
                             An attack probability value of $$\theta$$ is obtained from the (unique) mixed NE solution of this Game 1
                         Move 2:
                             Nature chooses randomly one of the two SP types in Game 2:
                                 With probability $$\theta$$: SP is under attack (compromised)
                                 With probability $$1-\theta$$: SP is safe (but selfish)
                             Run Game 2: Cloud Service Provider - Client (SPC) Signalling Game
                     Game 1: Attacker-Defender (AD) Avoiding Game #slide 
                         Players
                             Cloud Service Provider (SP)
                             External attacker (A)
                         Scenario
                             A cloud service provider is using resources in order to fulfil the client's request
                             An attacker attacks resources that are in use.
                             Cost/benefit functions are not explicitly given
                             Has typical properties of non-zero sum 2-action security game (no pure NE)
                             Initially there are only two resources in the cloud, but then later there are $$N$$ (Extended AD-Game).
                     Game 2 (Type 1: Safe but Selfish SP, Move 1 and 2) #slide 
                         First move $$SP_1(h, l)$$: cloud Provider can perform required computations on data using
                             h: enough precise computational resources 
                             l: low precise computational resources
                         Second, chance move: returned result can be
                             C: correct result
                             I: incorrect result
                     Game 2 (Type 2: Compromised Cloud,  Move 1 and 2) #slide 
                         First move $$SP_2(C, I)$$: return correct or incorrect results
                             m: alter results
                             nm: no manipulation
                         Attacker eavesdrops and decides whether to alter or ignore the result 
                         Attacker knows possibility for generating false result by the service provider
                         Second, chance move: returned result can be
                             C: correct result
                             I: incorrect result
                     Game 2  (Both Types, Move 3 and 4) #slide 
                         Game 2 (dynamic (sequential) Bayesian game (Signalling Game))
                             Third move -- SP($$X$$, $$Y$$)
                                 The SP sends either signal $$X$$ or $$Y$$
                             Fourth move -- C($$T$$, $$N$$)
                                 The Client decides: $$T$$ -- trust the signal, $$N$$ -- do not trust 
             @Moghaddam2015 #review #GT #cloud #signal
                 This signalling game is nested and can be decomposed into two games: #slide 
                     Attacker-Defender (AD) game "Avoiding Game"
                     Service Provider-Client Signalling Game
                 Discussion #slide 
                     Similarity to our work
                         Client-based perspective
                     Differences to our work
                         Service-oriented (SaaS): This might be more complex than our game as we are only interested in protecting an asset (Cloud storage).
                         They obtain some information on $$T$$ as an outcome of the signalling game analysis
                         We assume we know the trust level $$T$$.
                     Possible Extensions
                         Use a Repeated game for the AD-game
                         We could use our scenario with selfish (internal attacker) or trusted cloud (without external attacker) for a simple signalling game (Demonstration for Monday)
                         Replace AD-game with other static games for different types of cloud deployment models
     HIERARCHICAL REVIEWS
     GTD
     REFERENCES
         @ARTICLE{Franchi2011-qc,
             title    = "Inversion of regular analytic matrix functions: Local Smith form
                 and subspace duality",
             author   = "Franchi, Massimo and Paruolo, Paolo",
             abstract = "This paper analyzes the relation between the local rank-structure
                 of a regular analytic matrix function and the one of its inverse
                 function. The local rank factorization (lrf) of a matrix function
                 is introduced, which characterizes extended canonical systems of
                 root functions and the local Smith form. An interpretation of the
                 local rank factorization in terms of Jordan chains and Jordan
                 pairs is provided. Duality results are shown to hold between the
                 subspaces associated with the lrf of the matrix function and the
                 one of its reduced adjoint.",
             journal  = "Linear Algebra Appl.",
             volume   =  435,
             number   =  11,
             pages    = "2896--2912",
             month    =  dec,
             year     =  2011,
             keywords = "Matrix valued function; Jordan chains; Matrix inversion;
                 Canonical forms; Smith form"
             }
         
     By Scientific Fields
     Computer Science #h 
         Computer Algebra #h 
         Computer Security #h 
             CVSS #h 
                 ARCHIVE
                     Introduction #slide #CI6280 
                         The Common Vulnerability Scoring System (CVSS) is a specific vulnerability scoring technique.
                         Developed by the Forum of Incident Response and Security Teams ([FIRST](https://www.first.org/)).
                         Current version: v4.0, published in 2023. Still under active development!
                         CVSS provides an open framework for assessing the severity of software vulnerabilities, which is an industry-recognised standard
                     CVSS Version History #slide 
                         v1.0 (2005): The initial version focused on exploitability and impact, but lacked peer review and had limitations.
                         v2.0 (2007): Introduced environmental and temporal metrics, along with a refined scoring system for better accuracy.
                         v3.0 (2015): Major overhaul that incorporated exploitability, impact, and scope sub-scores, enabling more granular assessments.
                         v3.1 (2019): Minor updates clarified scoring and addressed edge cases to enhance consistency and usability.
                         v4.0 (2023): Significant changes include dynamic scoring based on attack patterns, improved environmental metrics, and a focus on attack surface reduction.
                     CVSS Scores #slide #CI6280 
                         A CVSS score is a quantity (numerical value), ranging from 0 to 10.
                         One use $$\mu:v \rightarrow [0, \ldots, 10]$$, the vulnerability score/metric function. 
                         An alternative qualitative representation consists of a vector, providing a compressed textual representation reflecting the values used to derive the score.
                         A CVSS Score consists of a base score, which can be refined by additional scores/metrics (temporal, environmental).
                         Generally, the organisation specifies the Base and Temporal metrics, while the environmental metric depends on the end-users.
                     CVSS Example: Heartbleed Bug #slide #CI6280 
                         ![Heartbleed-cvss.png](https://www.dropbox.com/s/o1o5ovl2zkk78te/Heartbleed-cvss.png?dl=1) #eyo-style:Normal 
                     CVSS v2.0 Base Score Equations #slide #CI7130 
                         In CVSS v2.0, the equation defining the Base Score is 
                             $$\mu_{Base} = k_1 \cdot \mu_{Imp} + k_2 \cdot \mu_{Exp} - k_3$$
                         where $$k_1 = 0.71$$, $$k_2 = 0.47$$ and $$k_3 = 1.76$$ (rounded to two decimal places) assuming $$\mu_{Imp} \neq 0$$. 
                         The Impact subscore $$\mu_{Imp}$$ describes potential impact that an exploit has on the system:
                             $$\mu_{Imp} = k_4 \cdot \mu_{CIA}$$
                         where $$k_4 = 10.41$$ and 
                             $$\mu_{CIA} = 1 - (1 - \mu_C)(1 - \mu_I)(1 - \mu_A).$$
                         Here $$\mu_C$$, $$\mu_I$$ and $$\mu_A$$ are the impacts on the individual security requirements CIA.
                     CVSS v3.0 Base Score #slide #CI6280 
                         "CVSS Base Score = CVSS Impact + CVSS Exploitability"
                             The base score $$\mu_{B}$$ represents the intrinsic and fundamental characteristics of $$v$$ that are independent of time and specific user environments.
                             The Impact subscore $$\mu_{Imp}$$ describes potential impact that an exploit has on the system
                             The Exploitability subscore $$\mu_{Exp}$$ describes the means and ease of exploiting the vulnerability. 
                         Each of the two sub-metrics contribute in an additive fashion to the final numerical score, ranging from 0 to 10.
                     CVSS v4.0 Updates #slide
                         More granular
                         Deeper disclosure:
                             Temporal metrics: Clearer communication of expected impact over time.
                             Environmental metrics: Enhanced options for tailoring scores to specific contexts.
                         Streamlined scoring:
                             Calculator: Simplified interface for generating scores.
                             Documentation: Improved clarity and guidance for scoring.
                         Compared to previous versions:
                             CVSS v3: More comprehensive, nuanced, and adaptable scoring.
                             CVSS v2: Easier to understand and use, with improved accuracy.
                     Mini-Exercise: Understanding CVSS Scores #slide #CI7130 
                         Through this Mini-Exercise, you will better understand CVSS by analysing the scoring values for a given vulnerability.
                         (a) Find the CVSS v2 score of the famous Heartbleed vulnerability.
                             5
                         (b) Find also its string representation.
                             (AV:N/AC:L/Au:N/C:P/I:N/A:N). 
                         (c) Briefly sketch the meaning of two components of your choice in this vector notation and judge the credibility of this score.
                             For example:
                                 AV:N -- The access vector is through the network.
                                 C:P -- confidentiality is partially impacted upon. 
                             The Score of 5.0 seems somewhat low for this severe vulnerability.
                     Limitations #slide 
                         The main problem with vulnerability scoring is that two different vulnerabilities can have the same score, although they both have individual characteristics.
                         Whilst this is impossible to prevent in general, a careful design of the individual scoring functions should at least take this problem into account.
                         In the latest version CVSS 3, the scoring of vulnerabilities has improved -- e.g. some vulnerabilities are now scored higher than before.
                         We need a transition from a vulnerability-focused approach to a risk-based scoring system.
             Theoretical Concepts #h 
                 Random Oracle Model #slide 
                     A random oracle $$\mathcal O$$ is a deterministic function, mapping input into an output domain, following a uniformly random distribution. 
                     This can be used as a theoretical model for a range of cryptographic primitives:
                         Provably secure encryption algorithms [@Bellare1993]
                         True random number generators and secure hash functions [@Coron2000]
                         Define security for steganography [@Katzenbeisser], [@Hopper2002], [@Fischlin2016]
             Cryptographic Protocols and Techniques
                 Secret Sharing #h
                     WORKFLOWY
                     Shamir's Secret Sharing Scheme #h 
                         Motivation #slide 
                             Cryptography has given us strong encryption algorithms
                             Symmetric and asymmetric encryption standards are well-established and give reliable ways of protecting our data
                             However: relying only on encryption has also shortcomings
                             Main problem: key management and the underlying trust relationship 
                         Safeguarding a Cryptographic Key #slide  #CI7160 
                             Consider the task of storing a cryptographic key safely, especially in the context of mobile computing
                             We are facing a "chicken-and-egg" situation (why?)
                             We need a different, alternative cryptographic technique. 
                                 ![encryption-on-paper-with-key.jpg](https://www.dropbox.com/s/1sfl8794mjk37cp/encryption-on-paper-with-key.jpg?dl=1) #eyo-style:Normal 
                         Secret Sharing -- Idea #slide #CI7160 
                             We want to protect sensitive information (the "secret"). 
                             Idea behind secret sharing: divide secret into several pieces ("shares") and distribute them to recipients ("shareholders"). 
                             Thus we can protect information by distributing it amongst several parties. 
                             Developed in the late 80's, secret sharing is not a new technique, but it is still an active research area and new applications are emerging. 
                             Let's do a jigsaw puzzle!
                         Introduction #slide #arman 
                             In secret sharing schemes a secret is distributed among a set of users $$\mathcal{P}$$ in such a way that only some sets, the authorised sets, can recover it. 
                             Secret sharing schemes are useful for not trusting a single party e.g. two members of staff required to open a vault. 
                             Similar challenges can arise in other sensitive areas where a secret should be recovered only if certain users, the authorised sets, get together. 
                         Secret Sharing -- Concept #slide #CI7160 #CI7160 
                             The following terminology is used: given a __secret __$$s$$, a __dealer __will divide it into __shares __and send them to $$n$$ __shareholders __(or__ players__). 
                             We have a ($$t$$,$$n$$)-threshold scheme, if for $$1\le t\le n$$:
                                 The secret $$s$$ can be divided into $$n$$ shares. 
                                 The individual shares do not reveal $$s$$. 
                                 If (at least) $$t$$ shares are combined, they can reconstruct $$s$$. 
                             A $$(n,n)$$-threshold scheme is also referred to as __secret splitting__ (similar to RAID 0).
                             A $$(1,n)$$-threshold scheme represents $$n$$ backups for redundancy (similar to RAID 1)
                         Illustration: (3,4) Threshold Scheme -- Distribution #slide #CI7160 
                             ![ss-distribution.png](https://www.dropbox.com/s/my9wh1oqyhe36w8/ss-distribution.png?dl=1) #eyo-style:Normal 
                         Illustration: (3,4) Threshold Scheme -- Shared Secret #slide #CI7160 
                             ![ss-shared-secret.png](https://www.dropbox.com/s/cdxiyjal5o9vgm2/ss-shared-secret.png?dl=1) #eyo-style:Normal 
                         Illustration: (3,4) Threshold Scheme -- Dealer Combining #slide #CI7160 
                             ![ss-dealer-combining.png](https://www.dropbox.com/s/ufl1vzjmrc31742/ss-dealer-combining.png?dl=1 ) #eyo-style:Normal 
                         Illustration: (3,4) Threshold Scheme -- Player Combining #slide #CI7160 
                             ![ss-player-combining.png](https://www.dropbox.com/s/5vml3sihvfcwvya/ss-player-combining.png?dl=1 ) #eyo-style:Normal 
                         Secret Sharing -- Classical Schemes #slide  
                             The most well-known schemes are:
                                 Shamir: based on polynomial interpolation
                                 Blakley: solving linear system
                                 Asmuth-Bloom: modular techniques (Chinese remainder theorem)
                             We will present the Shamir scheme more in detail - it is simple and efficient, and yet secure
                         Shamir's Secret Sharing Scheme #slide #CI7160 #modified
                             Secret sharing schemes are generally using mathematical objects that allow sharing and reconstructing. 
                             The most well-known scheme is Shamir's scheme, based on polynomial interpolation and modular arithmetic.
                             The underlying idea of this scheme is to convert the secret $$s$$ to a polynomial $$f(x)$$ with a suitable degree and coefficients over the integers modulo a suitable prime number $$p$$. 
                                 The degree of $$f$$ is $$t-1$$. 
                                 The secret $$s$$ will be stored in $$f(0)$$ -- this is the constant term of $$f$$. 
                                 All other coefficients of $$f$$ are drawn at random. 
                                 So, $$f(x)=s+a_1x+a_2x^2+\cdots+a_{t-1}x^{t-1}$$.
                         Share Creation and Reconstruction of Secret #slide #CI7160 
                             Distribution of shares works by __evaluating__ $$f$$ modulo $$p$$:
                                 We share $$n$$ distinct points $$P_i(x_i, f(x_i))$$ (for $$(i=1,\ldots,n$$) amongst the $$n$$ players. 
                             Reconstruction of the secret is based on __interpolation__. 
                                 A polynomial $$f(x)$$ of degree $$t-1$$ is uniquely determined by $$t$$ different points. 
                                 Hence a coalition of $$t$$ players can reconstruct $$f$$, using interpolation. 
                                 Any set of $$t$$ distinct points will be valid. 
                             This implements all properties required for a $$(t,n)$$ threshold scheme. 
                             It is sufficient to know the constant term $$a_0$$.
                         Illustration: Shamir's Scheme #slide #CI7160 
                             ![ss-shamir-inefficient-illustration.png](https://www.dropbox.com/s/alottc1kdonfk2q/ss-shamir-inefficient-illustration.png?dl=1) #eyo-style:Normal 
                         Shamir's Scheme: Choice of Evaluation Points #slide #CI7160
                             If we are working with the integers modulo $$p$$, then the $$x_i$$ can simply be the values $$x_1=1$$, $$x_2=2$$, $$x_3=3$$...
                             The $$x_i$$ could also be computed from some unique information related to the players, e.g. using a secure hash function $$H$$, from an ID value: $$x_i = H(ID_i)$$.
                             This point generating algorithm could be made public. 
                             Hence there would be no need to actually send the $$x_i$$.
                             This would reduce the size of the data that needs distributing by 50\%!
                         Illustration: Space-Efficient Shamir #slide #CI7160
                             ![ss-shamir-illustration.png](https://www.dropbox.com/s/gqykalgmfrmgr15/ss-shamir-illustration.png?dl=1) #eyo-style:Normal 
                         Shamir's Scheme: Discussion #slide 
                             Security
                                 Shamir's scheme is a __perfect__ secret sharing scheme. 
                                 This means that no information about the initial secret is revealed to a coalition of less than the threshold number ($$t$$) of players. 
                             Space-Requirements
                                 When done naively, for each share we require twice the size of the secret $$s$$. 
                                 This can be reduced to a share size of $$|__s__|$$ e.g. by using a public evaluation point function. 
                             Computational Cost
                                 Polynomial evaluation can be done in the order of $$t$$ arithmetic operations. 
                                 The same holds for interpolation. 
                         Mini-Exercise #slide #CI7160 
                             Use Shamir's approach to create a (2,3)-threshold scheme in order to share the secret $$s=3$$. Proceed as follows: 
                                 Choose a suitable polynomial function $$f$$ and prime number $$p$$
                                 Select two distinct points on the graph of $$f$$
                                 Compute two shares that could be distributed to players
                             Sketch how they can be combined in order to reconstruct the secret again
                         Polynomial Interpolation #slide 
                             Goal: given $$(x_1, y_1),\ldots, (x_t, y_t)$$, how to explicitly construct a polynomial $$f$$ of degree $$t-1$$, satisfying $$f(x_i) = y_i$$ for all $$i$$?
                             We define the __Lagrange interpolation polynomial__ $$L_i(x)$$ of degree $$t-1$$ satisfying
                                 $$L_i(x_j) = 0$$ if $$i\neq j$$,
                                 $$L_i(x_j) = 1$$ otherwise.
                             We can then build the desired polynomial
                                 $$f(x) = y_1L_1(x) + \cdots + y_tL_t(x)$$.
                             We can state $$L_i(x)$$ explicity:
                                 $$L_{i}(x)=\prod_{1\le j \le t, i\neq j}\frac{x-x_i}{x_j-x_i}$$
                         Polynomial Interpolation -- Example #slide 
                             Example: let us fix $$t=3$$ and choose the points
                                 $$x_1=2$$, 
                                 $$x_2=5$$,
                                 $$x_3=-1$$.
                             Then:
                                 $$L_1(x) = \frac{(x-5)(x+1)}{(2-5)(2+1)} = -\frac{1}{9} (x-5)(x+1) = -\frac{1}{9} (x^2-4x-5)$$
                                 $$L_2(x) = \frac{(x-2)(x+1)}{(5-2)(5+1)} = \frac{1}{18} (x-2)(x+1) = \frac{1}{18}(x^2-x-2)$$
                                 $$L_3(x) = \frac{(x-2)(x-5)}{(-1-2)(-1-5)} = \frac{1}{18}(x-2)(x-5) = \frac{1}{18}(x^2-7x+10)$$
                         Polynomial Interpolation -- Example (cont.) #slide 
                             We can use this to construct a polynomial $$f$$ satisfying
                                 $$f(2) = -5$$
                                 $$f(5) = 4$$
                                 $$f(-1) = 4$$
                             Solution: $$f(x) = -5 L_1(x)+4 L_2(x)+4L_3(x) = [\cdots] = x^2-4x-1$$
                             Task: verify this!
                         Matrix Version #h
                             Principle #slide
                                 View the evaluation of Shamir polynomial $$f(x_i)$$ as vector multiplication:
                                     $$f(x_i) = (1, x_i , x_i^2, ..., x_i^{k-1}) \begin{pmatrix}s \\ a_1 \\ a_2 \\ \vdots \\ a_{k-1} \end{pmatrix}$$. 
                                 Hence, the following matrix equation determines all shares $$(x_i,y_i)=(x_i,f(x_i))$$ for $$i = 1,\ldots, n$$:
                                     $$\begin{pmatrix} 1 & x_1 & x_1^2 & \cdots & x_1^{k-1} \\ 1 & x_2 & x_2^2 & \cdots & x_2^{k-1} \\ \vdots & \vdots & \vdots & &\vdots \\ 1 & x_n & x_n^2 & \cdots & x_n^{k-1} \end{pmatrix} \begin{pmatrix} s \\ a_1 \\ a_2 \\ \vdots \\ a_{k-1} \end{pmatrix} = \begin{pmatrix} y_1 \\ y_2 \\ \vdots \\ y_{n} \end{pmatrix}$$. 
                             Vandermonde Matrix #slide 
                                 The special matrix in the previous equation is called a __Vandermonde__ matrix:
                                     $$V(x_1,...,x_n):= \begin{pmatrix} 1 & x_1 & x_1^2 & \cdots & x_1^{k-1} \\ 1 & x_2 & x_2^2 & \cdots & x_2^{k-1} \\ \vdots & \vdots & \vdots & &\vdots \\ 1 & x_n & x_n^2 & \cdots & x_n^{k-1} \end{pmatrix}$$.
                             Reconstruction of Secret #slide 
                                 This is possible if the associated Vandermonde matrix is square and invertible.
                                 Choose a coalition $$\{x_i,\ldots,x_{i_k}\}$$ of $$k$$ distinct points. 
                                 Then:
                                     $$\begin{pmatrix} s \\ a_1 \\ a_2 \\ \vdots \\ a_{k-1} \end{pmatrix} = \begin{pmatrix} 1 & x_1 & x_1^2 & \cdots & x_1^{k-1} \\ 1 & x_2 & x_2^2 & \cdots & x_2^{k-1} \\ \vdots & \vdots & \vdots & &\vdots \\ 1 & x_n & x_n^2 & \cdots & x_n^{k-1} \end{pmatrix}^{-1} \begin{pmatrix} y_1 \\ y_2 \\ \vdots \\ \\ y_{k-1} \end{pmatrix}$$. 
                             Shamir -- Compact Notation #slide 
                                 Given $$s$$ secret
                                 Shamir $$(k,n)$$ threshold secret sharing scheme:
                                     Define $$f(x)=s+\sum_{i=1}^{k-1}a_i x^i$$ where coefficients $$a_i$$ drawn randomly
                                     Choose distinct points $$(x_i,f(x_i))$$
                                 Reconstruct secret:
                                     Interpolate $$f$$
                                     $$s=f(0)$$
                         Proof of Correctness and Security #h 
                             Statement of Theorem #slide 
                                 Using the information-theoretical concept of entropy, Shamir's secret sharing scheme's correctness and perfect security property can be stated as follows: let $$C$$ be a coalition set of distinct points. Then one has:
                                     Shamir's scheme is correct: if $$|C|\ge k$$, then $$H(s|C)=0$$.
                                     The scheme is a perfect secret sharing scheme: if $$|C|< k$$, then $$H(s|C)=H(s)$$.
                             Information Theory #slide 
                                 Proofs are based on the concept of __entropy__, a notion developed by Shannon \cite{Shannon1948-eb}, as a tool for information theory 
                                 The entropy $$H$$ of a random variable $$X$$ is $$H(X)=\sum  p_i\log_{2}(p_i)$$
                                 We require the following random variables:
                                     $$S$$: the secret
                                     $$F_i$$: the value of $$f(i)$$ (part of $$i$$th share)
                                     $$Q_i$$: the coefficients of Shamir polynomial 
                             Entropy Properties #slide 
                                 The following properties will be used in the proof:
                                     $$H(X)\ge H(X|Y)$$ #ref:cond
                                     $$H(X,Y)=H(X)+H(Y| X)= H(Y)+H(X|Y)$$
                                     $$0\le H(X) \le \log_2|X|$$
                                     If $$H(Y|Z)=0$$ then $$H(X|Y)\ge H(X|Z)$$ #ref:this 
                                     If $$H(Y|Z)=0$$ then $$H(X|Y,Z)=H(X|Z)$$
                             Useful Identities #slide 
                                 We will also need the following entropy identities 
                                 They are specific to the construction of the Shamir secret sharing scheme:
                                     Due to the unique interpolation property of $$f$$, given $$k$$ distinct points, one has: $$H (Q_{0},\ldots ,Q_{k-1} |F_{i_{1}},\ldots ,F_{i_{k}})=0$$.
                                     Based on evaluation of $$f$$ we can uniquely determine the shares, hence: $$H (F_{i_{1}},\ldots ,F_{i_{k}}|Q_{0},\ldots ,Q_{k-1} )=0$$.
                                     Due to the definition of the Shamir polynomial, we know $$S$$ if we know $$f$$: $$H (S|Q_{0},\ldots ,Q_{k-1})=H (S|S,Q_1,\ldots ,Q_{k-1})=0$$. #ref:shamir 
                             Proof: Correctness #slide 
                                 Applying identity #ref:this with $$Y=Q_{0},\ldots ,Q_{k-1}$$ to the l.h.s. of #ref:shamir yields $$H (S|Q_{0},\ldots ,Q_{k-1}) \ge H (S |F_{i_{1}},\ldots ,F_{i_{k}})$$.
                                 Applying #ref:this to this again gives $$H (S |F_{i_{1}},\ldots ,F_{i_{k}})\ge H (S|Q_{0},\ldots ,Q_{k-1})$$.
                                 Hence $$H (S|Q_{0},\ldots ,Q_{k-1}) = H (S |F_{i_{1}},\ldots ,F_{i_{k}})$$.
                                 But this is 0, and hence $$H (S |F_{i_{1}},\ldots ,F_{i_{k}})=0$$.
                                 And then also $$0\le H (S |F_{i_{1}},\ldots ,F_{i_{t}})\le H (S |F_{i_{1}},\ldots ,F_{i_{k}}) =0$$ for $$t>k$$ due to #ref:cond which finishes the proof. 
                             Proof: Perfectness #slide
                                 $$H (S,F_{i_{1}},\ldots ,F_{i_{k-1}})=H(S,Q_{1},\ldots ,Q_{k-1})$$
                             INBOX
                                 Lemma  
                                     $$H (Q_{0},\ldots ,Q_{k-1} |F_0,F_{i_{1}},\ldots ,F_{i_{k-1}})=H(F_0,F_{i_{1}},\ldots ,F_{i_{k-1}})$$
                                     $$H (Q_{0},\ldots ,Q_{k-1} |F_0,F_{i_{1}},\ldots ,F_{i_{k-1}})=H(Q_{0},\ldots ,Q_{k-1})$$
                                 Proof
                                     Let $$y=V(x_1,...,x_n) f $$
                                     $$f=V(x_{i_1},...,x_{i_k})^{-1} y$$
                                     Its coefficient vector $$a$$ is $$a = \begin{pmatrix} s \\ a_1 \\ \vdots \\ a_{k-1} \end{pmatrix} = V(0,x_{i_1},...,x_{i_{k-1}})^{-1} \begin{pmatrix} s \\ y_{i} \\ \vdots \\ y_{i_{k-1}} \end{pmatrix}$$.
                                     $$a=V(x_{i_1},...,x_{i_k})^{-1} y$$
                                     $$H(f|x)=H(y)$$
                                     $$H(f|y)=H(x)$$ 
                                 Proof: Overview #slide 
                                     Let $$C$$ be a coalition set of points.
                                     We need to show:
                                         Correctness: $$H(s|C)=0$$ if $$|C|\ge k$$
                                         Perfect secret sharing scheme: $$H(s|C)=H(s)$$ if $$|C|< k$$
                         Proof of Correctness and Security (Version 2) #h 
                             Due to the unique interpolation property of $$f$$, given $$k$$ distinct points, one has: $$H (Q_{0},\ldots ,Q_{k-1} |F_{i_{1}},\ldots ,F_{i_{k}})=0$$.
                             If $$H(Y|Z)=0$$ then $$H(X|Y)\ge H(X|Z)$$ #ref:this 
                                 Applying identity #ref:this with $$Y=Q_{0},\ldots ,Q_{k-1}$$ yields $$H (S|Q_{0},\ldots ,Q_{k-1}) \ge H (S |F_{i_{1}},\ldots ,F_{i_{k}})$$.
                                     Applying #ref:this again gives $$H (S |F_{i_{1}},\ldots ,F_{i_{k}})\ge H (S|Q_{0},\ldots ,Q_{k-1})$$.
                                         Hence $$H (S|Q_{0},\ldots ,Q_{k-1}) = H (S |F_{i_{1}},\ldots ,F_{i_{k}})$$.
                                             But this is 0, and hence $$H (S |F_{i_{1}},\ldots ,F_{i_{k}})=0$$.
                                                 $$H(X)\ge H(X|Y)$$ #ref:that
                                                 And then also $$0\le H (S |F_{i_{1}},\ldots ,F_{i_{t}})\le H (S |F_{i_{1}},\ldots ,F_{i_{k}}) =0$$ due to #ref:that which finishes the proof. 
                             Entropy Properties #slide 
                                 The following properties will be used in the proof:
                                     $$H(X,Y)=H(X)+H(Y| X)= H(Y)+H(X|Y)$$
                                     $$0\le H(X) \le \log_2|X|$$
                                     If $$H(Y|Z)=0$$ then $$H(X|Y,Z)=H(X|Z)$$
                             Useful Identities #slide 
                                 We will also need the following entropy identities 
                                 They are specific to the construction of the Shamir secret sharing scheme:
                                     Based on evaluation of $$f$$ we can uniquely determine the shares, hence: $$H (F_{i_{1}},\ldots ,F_{i_{k}}|Q_{0},\ldots ,Q_{k-1} )=0$$.
                                     Due to the definition of the Shamir polynomial: $$H (S|Q_{0},\ldots ,Q_{k-1})=H (S|S,Q_1,\ldots ,Q_{k-1})=0$$.
                             Proof: Correctness #slide 
                             Proof: Perfectness #slide
                                 Lemma  
                                     $$H (Q_{0},\ldots ,Q_{k-1} |F_0,F_{i_{1}},\ldots ,F_{i_{k-1}})=H(F_0,F_{i_{1}},\ldots ,F_{i_{k-1}})$$
                                     $$H (Q_{0},\ldots ,Q_{k-1} |F_0,F_{i_{1}},\ldots ,F_{i_{k-1}})=H(Q_{0},\ldots ,Q_{k-1})$$
                             Proof
                                 Let $$y=V(x_1,...,x_n) f $$
                                 $$f=V(x_{i_1},...,x_{i_k})^{-1} y$$
                                 Its coefficient vector $$a$$ is $$a = \begin{pmatrix} s \\ a_1 \\ \vdots \\ a_{k-1} \end{pmatrix} = V(0,x_{i_1},...,x_{i_{k-1}})^{-1} \begin{pmatrix} s \\ y_{i} \\ \vdots \\ y_{i_{k-1}} \end{pmatrix}$$.
                                 $$a=V(x_{i_1},...,x_{i_k})^{-1} y$$
                                 $$H(f|x)=H(y)$$
                                 $$H(f|y)=H(x)$$ 
                             INBOX
                                 Proof: Overview #slide 
                                     Let $$C$$ be a coalition set of points.
                                     We need to show:
                                         Correctness: $$H(s|C)=0$$ if $$|C|\ge k$$
                                         Perfect secret sharing scheme: $$H(s|C)=H(s)$$ if $$|C|< k$$
                         Further Reading (and Watching..) #slide 
                             http://youtu.be/kkMps3X_tEE
                             
                     Applications #h #CI7160 
                         Cloud Security Scenario #slide #CI7160 
                             Consider a scenario where Alice has some confidential data, which she would like to store on a public cloud. 
                             However, she is using Dropbox, which does not offer end-to-end encryption. 
                             Hence she would like to implement the following security goals:
                                 Confidentiality versus the cloud provider (and external parties). 
                                 Availability (redundancy) in case of hard disk failure or unavailability of Dropbox. 
                         Cloud Security Scenario -- Solution #slide #CI7160 
                             Alice splits her data into several "pieces" and stores each on a different cloud (Dropbox, Box, Google Drive, OneDrive, iCloud)
                             This needs be done in such a way that none of the cloud providers can read the original information
                             Entire data can be restored from a subset of $$t$$ pieces
                             What is the redundancy of this architecture?
                         Applications of Secret Sharing #slide 
                             We review the use of secret Sharing for our initial scenarios:
                                 Safekeeping of cryptographic keys
                                     PGP client software uses a (5,3) secret sharing scheme to store the user's private key.
                         Octopus  
                     Advanced Secret Sharing Schemes #h #CI7160 
                         CI7160
                             Advanced Secret Sharing #eyo-style:Section #CI7160
                             Learning Objectives -- Advanced Secret Sharing #slide #CI7160 #CI7160_D3 #LObj
                                 Know the principle underlying Dealer-free Random Secret Sharing (RSS) #CI7160
                                 Understand the share distribution protocol #CI7160
                                 Discuss the use of Proactive Secret Sharing (PSS) for protecting long-lived secrets
                                 Be aware of the principle of Dynamic Secret Sharing
                                 Understand how to verify shares
                             Secret Sharing -- Advanced Requirements #slide #CI7160 
                                 When using secret sharing in real-world scenarios, there are many additional requirements in terms of security, robustness, flexibility, efficiency and scalability
                                 __Dealer-free__ (or __distributed__) secret sharing scheme -- no central dealer, players cooperate jointly
                                 __Verifiable secret sharing scheme__ -- protect against malicious dealers
                                 __Proactive secret sharing scheme__ -- update/change shares, maintain secret
                                 __Dynamic secret sharing scheme__ -- we can add or remove players (change $$n$$), and change the threshold $$t$$
                             Dealer-Free Random Secret Sharing (RSS) #slide #CI7160 #CI7160 
                                 Goal: mutually create and distribute shares of a random secret without the need for centralised dealer
                                 Ideal in peer-to-peer scenario where all players have equal capabilities
                                 Principle: each player $$P_i$$ creates random value and distributes its shares to all other players
                                 So, each player effectively acts as a dealer
                                 Final secret is the sum of the individual secrets
                             RSS Share Distribution Protocol #slide #CI7160 
                                 Stage 1: Creating and sending primary shares
                                     Each $$P_i$$ creates a random polynomial $$f_i(x)$$ of degree $$t-1$$
                                     So, for each player, $$s_i = f_i(0)$$ is her (partial) secret 
                                     $$P_i$$ sends the share $$f_i(j)$$ of $$s_i$$ to all other $$P_j$$,using a secure channel
                                 Stage 2: Receiving auxiliary shares
                                     Each $$P_i$$ receives $$f_j(i)$$ from all other $$P_j$$,using a secure channel
                                     The final share for $$P_i$$ is then $$f_1(i) + \ldots + f_n(i)$$
                                     Outcome: all parties share the random value $$f_1(0) + \ldots + f_n(0) = f(0)$$, although none of them know this value!
                             Mini-Exercise: RSS Role-play #slide-mini #CI7160 
                                 We will simulate the RSS protocol in an interactive role-play.
                                 Please form three groups within your class.
                                 We will then explain the rules and guide you along.
                                 
                             Ramp Secret Sharing Scheme #slide 
                                 Goal: be more space-efficient and store larger secrets (applications: cloud computing)
                                 A ramp secret sharing scheme is a particular type of secret sharing scheme that introduces a threshold structure with "ramp" properties
                                 Some subsets of participants can partially recover the secret, but not fully, unless they reach a higher threshold.
                                 Let there be $$n$$ participants $$P_1, P_2, \ldots, P_n$$.
                                 The secret $$S$$ is distributed among these participants as shares $$X_1, X_2, \ldots, X_n$$.
                             Thresholds:
                                 There are two thresholds, $$t_1$$ and $$t_2$$, where $$t_1 < t_2$$.
                                 Any subset of $$t_1$$ or fewer participants gains no information about the secret $$S$$. 
                                 This is formalized as $$I(S; X_{i_1}, X_{i_2}, \ldots, X_{i_{t_1}}) = 0$$ where $$\{ i_1, i_2, \ldots, i_{t_1} \}$$ is any subset of size $$t_1$$ or smaller.
                                 Any subset of $$t_2$$ or more participants can fully reconstruct the secret $$S$$. 
                                 This is expressed as $$H(S | X_{j_1}, X_{j_2}, \ldots, X_{j_{t_2}}) = 0$$ where $$\{ j_1, j_2, \ldots, j_{t_2} \}$$ is any subset of size $$t_2$$ or larger.
                             Partial Information for Intermediate Subsets #slide 
                                 For any subset of participants whose size is between $$t_1$$ and $$t_2$$, they may have partial information about the secret $$S$$. 
                                 In this range, the mutual information between the secret and the subset's shares is non-zero, but the entropy of the secret conditioned on these shares is still positive:
                                     $$0 < I(S; X_{k_1}, X_{k_2}, \ldots, X_{k_{m}}) < H(S)$$ and $$H(S | X_{k_1}, X_{k_2}, \ldots, X_{k_{m}}) > 0$$ where $$t_1 < m < t_2$$.
                             Information Theoretic Security #slide 
                                 The scheme is information-theoretically secure against coalitions of up to $$t_1$$ participants because the mutual information between the secret and the shares of any subset of size $$t_1$$ or less is zero.
                                 Information gained by subsets of participants between $$t_1$$ and $$t_2$$ participants is less than complete but more than nothing, reflecting the "ramp" nature of the scheme.
                             Share Size #slide 
                                 The share size typically grows as the total information distributed increases, especially if the scheme uses randomization or other techniques to manage the gradual leakage of information between the thresholds $$t_1$$ and $$t_2$$.
                             Summary
                                 
                             A Method #slide 
                                 We still use a polynomial as in Shamir's scheme
                                 However, rather than storing the secret in only one coefficient, we could also use all __t__ coefficients
                                 This would allow for a __t__-times larger secret as in Shamir
                                 However, a security analysis reveals that this will leak some information, so not a perfect secret sharing scheme
                                 We will not go into details, but this is current active research
                             Proactive Secret Sharing (PSS) #slide 
                                 Goal: prevent leakage of information in long-term secret sharing
                                 This could be caused by attacks on servers (aka players)
                                 Important application: key distribution in (wireless) sensor networks, MANETs
                                 Classic scheme: Herzberg
                                 Idea: refresh shares, but maintain same secret
                                 Advantage: attacker has to compromise t servers before refreshing period, instead during entire lifespan of system
                             Share Update -- Illustration #slide
                             Dynamic Secret Sharing (DSS) #slide 
                                 Goal: adapt to dynamic environment
                                     Change of number of players
                                     Change threshold value t
                                 Similar approach as in proactive scheme
                                 Idea: each player contributes to new shares
                                 However, not very efficient:
                                     Communication effort
                                     Re-sharing required
                             Discussion #slide 
                                 Protocol is not very efficient
                                 There are O(__n^__2) values to communicate
                                 Also there are some hidden flaws -- e.g. we need to guarantee that the degree of __f__ is guaranteed to be exactly __t__-1
                                 Finding a more efficient and robust solution is the topic of current research
                             Mobile Security Aspects #slide 
                                 VPSNs
                                     Relatively new concept (Conti et al, 2010)
                                     Goal: create a protected social network within a bigger carrier social network
                                     Information will be shared amongst users of the VPSN and is confidential w.r.t. social network provider
                                     Idea (Clarke et al, 2013): combine secret sharing and steganography
                                 Peer-to-Peer Networks
                                     P2P network: no infrastructure, all nodes are the same, decentralised network
                                     MANET (Mobile Ad-hoc Network): wireless links, spontaneous, self organising
                                     This makes it very difficult to have a CA (seems contradictory concept)
                                     Even if there was one, it would be easy to attack it and to compromise the system
                                     Create a distributed CA by using threshold cryptography (secret sharing) -- here, a private key is shared among several nodes
                             Herzberg's Scheme #slide 
                                 Idea: run share-renewal protocol:
                                     Each player $$P_i$$ chooses random update polynomial $$h_i(x)$$ with constant term 0
                                     $$P_i$$ updates all other players through a secure channel by sending $$h_i(j)$$
                                     $$P_i$$ receives $$h_j(i)$$ from all other $$P_j$$
                                     Player $$P_i$$ can then compute its new share as:
                                         $$siT+1 = siT + h1(i) +  + hn(i)$$
                                     All old data is then erased
                                 This is correct, robust and secret in the presence of passive adversaries
                             Strengthening the Protocol #slide 
                                 We also want to protect ourselves against active attackers
                                 They could tamper with the share updates
                                 Idea: create and send commitments of the hi
                                 The players can now check the validity
                                 Each Pi broadcasts either an accept message or an accusation
                                 Accusations will have to be resolved
                             DSS -- Increasing Number of Players #slide 
                                 Goal: increase n whilst keeping t
                                 This is the Group Joining Problem
                                 Problem: Pn+1 needs new share f(n+1)
                                 Assume Lagrange: $$f(x) = y_1L_1(x) + \cdots + y_tL_t(x)$$
                                 We have yi = f(i)
                                 But the f(i) are known by the Pi
                                 So, if Pn+1 contacts t nodes, it can compute its share, provided the Li can also be computed
                                 However: then Pn+1 would know Pi's share
                                 Solution: use PSS (Herzberg) to send new (refreshed) shares
                                 Note: more efficient non-interactive solution exists
                             Verifiable Secret Sharing (VSS) #slide 
                                 In a secret sharing scheme, each of several parties receive shares of a secret value and it may be important that those shares can be checked for correctness
                                 In a verifiable secret sharing scheme, the distribution of a secret is accompanied by commitments to the individual shares
                                 The commitments reveal nothing that can help a dishonest player, but the shares allow each individual party to check to see if their shares are correct
                             VSS -- Feldman Approach #slide 
                                 The dealer generates the polynomial $$f(x) = s + a_1x + \cdots + a_{t-1}x^{t-1}$$ (as in Shamir)
                                 Distributes shares $$f(x_i)$$ and creates commitments of coefficients $$a_k$$
                                 These are of the form $$c_k = g^{a_k}$$ where $$g$$ is a suitable value (also published)
                                 The commitments are broadcasted to all parties
                                 Players can now verify a share $$s_i$$ as they can compute $$g^{s_i}$$ themselves
                             Verification: How It Works #slide 
                                 The verification works as follows: $$P_i$$ computes $$g^{s_i}$$ and compares this value with
                                     $$g^{f(i)} = g^{a_0 + a_1^i + \cdots + a_{t-1}^{i^{t-1}}}$$
                                     $$= g^{a_0}\cdot g^{a_1^i} \cdot g^{a_2^{i^2}} \cdots g^{a_{t-1}^{i^{t-1}}}$$
                                     = $$c_0\cdot c_1^i \cdot c_2^{i^2} \cdots c_{t-1}^{i^{t-1}}$$
                                 If these values are the same, the share is correct
                                 Otherwise: either dealer cheated, or there was an error during transmission
                         Bivariate Secret Sharing #h
                             Introduction #slide #arman
                                 The secret is (part of) a bivariate polynomial $$f(x, y)$$.
                                 Let $$P_1, P_2,...,P_n$$ be players involved in the sharing scheme.
                                 We have the following definitions:
                                     Symmetric bivariate SS -- the polynomial $$f$$ is symmetric ($$f(x,y) = f(y,x)$$).
                                     Asymmetric BSS otherwise.
                                 The are several applications of BSS:
                                     Multi-secret sharing
                                     Key agreement
                                     Implementing advanced SS with special access structures
                             Matrix Notations #slide #arman
                                 Galois Field for prime $$p$$ - $$\mathbb{F}_p$$
                                 Principle: write $$f(x,y)$$ as a matrix $$F = ((a_{i,j}))$$ where $$f(x, y) = \sum^m_{i=0} \sum^m_{i=0} a_{ij} x^i y^j \pmod{p}$$.
                                 Create shares by evaluating $$f$$ at various points, e.g. $$f(x_i,y), f(x,y_i)$$ or $$f(x_i,y_i)$$. [Depending on application]
                                 Reconstruct $$f$$ by creating invertible Vandermonde matrix from a coalition of shares/players.
                             Multi-Secret Sharing #slide #arman
                                 Each Player receives $$g_i(y)=f(x_i, y)$$.
                                 Reconstruction of $$f(x,y)$$ is based on $$V(x_1, ...,x_n) \cdot F = \begin{bmatrix} \text{coeffs}_y(g_1) \\ \vdots \\ \text{coeffs}_y(g_m) \end{bmatrix}$$ and inverting $$V(x_{i_1}, ....,x_{i_k})$$.
                                 Similarly, the scheme could be using $$h_j(y)=f(x,y_j)$$: 
                                     $$F \cdot V(y_1,...,y_n)^t = \begin{bmatrix} \text{coeffs}_x(f(x,y)) \\ \vdots \\ \text{coeffs}_x(f(x,y_n)) \end{bmatrix}$$
                                 But this is not different to running multiple instances of Shamir SS.
                             Harn-Hsu's Bivariate Secret Sharing #h #arman 
                                 Share Creation #slide #arman
                                     $$t$$ secrets $$\{s_1, s_2, ... s_t\}$$ where $$s_r = f(r,0)$$
                                     $$f(x, y)$$ where $$x$$ and $$y$$ have degree $$t-1$$.
                                     Dealer computes $$f_i(x) = f(x,i),i = 1,2,...,n$$ and sends this result to the respective $$P_i$$ shareholder.
                                 Share Reconstruction #slide #arman
                                     $$t$$ Players $$\{P_1, ..., P_t\} \subset \{P_1, P_2, ... , P_n\}, t \leq n$$ can recover the secret.
                                     For secret a $$s_r$$ each player $$P_i \in \{P_1, ... , P_t\}$$ computes a value $$e_i = f_i(r) = f(r, i)$$.
                                     $$t$$ number of $$e$$ values are required to recover secret $$s_r$$.
                                     $$\sum^t_{i=1} (e_i \sum^t_{j=1, j \neq i} \frac{-j}{i - j})\pmod{p} = s_r$$
                                     Vandermonde $$V_{ij}$$ of dimension $$i,j$$ is inverted and transposed $$\hat{V_{ij}}$$, $$\hat{V_{ij}} = V_{ij}^{-1 \rightarrow T}$$.
                                     First column is taken where $$N = \hat{V_{1j}}$$
                                     $$\begin{bmatrix} e_{11} & \dots & e_{1n} \\ \vdots & & \vdots \\ e_{1n} & \dots & e_{rn} \end{bmatrix} \cdot N = \begin{bmatrix} s_1 \\ \vdots \\ s_r \end{bmatrix}$$
                             Tassa's Probabilistic Multipartite Scheme #h 
                             A Novel Deterministic Bipartite Scheme #h
                                 Introduction #slide #arman
                                 Linear Algebra #h 
                                     Notations #slide #arman 
                                         spec($$A$$) -- the spectrum (set of eigenvalues) of the matrix $$A$$.
                                         $$\otimes$$ -- the "Kronecker Product", defined as #todo 
                                         $$V({x_1,\ldots, x_n})$$ -- Vandermonde matrix with entries that are powers of $$x_1, ... , x_n$$.
                                         So:
                                             $$V({x_1,\ldots, x_n}) = \begin{bmatrix}1 & \cdots & 1 \\ x_1 & \cdots & x_n \\ x_{1}^2 & \cdots & x_{n}^2 \\ \vdots & & \vdots \\ x_{1}^{n-1} & \cdots & x_{n}^{n-1} \end{bmatrix}$$
                                     Sylvester Equation #slide #arman
                                         These are matrix equations $$AX - XB = C$$ where $$A$$ and $$B$$ are square matrices of order $$m$$ and $$n$$.
                                         Goal is to find the $$m$$ by $$n$$ matrix $$X$$.
                                         The following is a well-known fact:
                                             The sylvester equation admits a unique solution $$X$$, iff $$A$$ and $$B$$ have no eigenvalues in common.
                                             In this case, the solution is $$x = (I \otimes A - B^t \otimes I)^{-1} \cdot c$$ where $$x$$ and $$c$$ are the matrices $$X$$ and $$C$$ rearranged as single column vectors.
                                     Conjecture #slide #arman
                                         Informally:
                                             Vandermonde-matrices with pairwise different index sequences $$x_1, ..., x_n$$ and $$y_1, ... , y_m$$ have no eigenvalues in common.
                                         Formally:
                                             $$x = (x, ..., x_n), y = (y_1, ... , y_n)$$ and $$x_i \neq y_j (\forall i, j)\Leftrightarrow$$ spec($$V_x$$) $$\cap$$ spec($$V_y$$) = $$\emptyset$$.
                                 Properties #slide #arman
                                     There are two sets of players:
                                         $$\mathcal{P} = \{P_1, ..., P_n\}$$ and $$\mathcal{Q} = \{Q_1,...,Q_n\}$$
                                     Each set has associated thresholds $$k$$ and $$l$$.
                                     A coalition of at least $$k$$ players of $$P$$ and at least $$l$$ players of $$Q$$ can reconstruct the secret.
                                     Any coalition with less than these players do not gain (any? all?) information about the secret.
                                 Notations #slide #arman 
                                     Given a secret $$s$$, we create a bivariate polynomial $$f(x,y)$$ with $$\deg_x f = k-1$$ and $$\deg_y f = l-1$$.
                                     We set $$f(0,0) = s$$ and $$f(i,j)$$ is random $$(i,j \neq 0)$$.
                                     Furthermore, we form the matrix $$B := ((b_{ij}))$$ where $$1 \leq i \leq n, 1 \leq j \leq n$$, and 
                                         $$b_{ij} = \begin{bmatrix} 1 & x_i & \cdots & x_i^{k-1} \end{bmatrix} \cdot \begin{bmatrix} a_{0j} \\ a_{1j} \\ \vdots \\ a_{kj} \end{bmatrix} - \begin{bmatrix}a_{i0} & a_{i1} & \cdots & a_{il} \end{bmatrix} \cdot \begin{bmatrix} 1 \\ y_j \\ \vdots \\ y^{l-1}_j \end{bmatrix}$$.
                                         Here $$B = V_x A - A V_y$$. 
                                 Share Creation #slide #arman
                                     Each player $$P_i$$ has public value $$x_i$$.
                                     A public value $$y_j$$ is associated with $$Q_j$$.
                                     The shares distributed to the players in $$\mathcal{P}$$ and $$\mathcal{Q}$$ are as follows:
                                         $$P_i$$ receives the row vector $$\begin{bmatrix} b_{i0} & b_{i1} & \dots & b_{in} \end{bmatrix}$$.
                                         $$Q_j$$ receives the column vector $$\begin{bmatrix} b_{0j} \\ b_{1j} \\ \vdots \\ b_{nj} \end{bmatrix}$$.
                                 Share Reconstruction #slide #arman 
                                     In order to reconstruct $$f$$, a coalition of $$k$$ players $$\{P_{i_1},...,P_{i_k}\}$$ and $$l$$ players $$\{Q_{j_i}, ..., Q_{j_l}\}$$ proceed as follows:
                                         The first coalition constructs the matrix $$V{(x_{i_1},...,x_{i_k})}$$.
                                         The second coalition forms the matrix $$V^t{(y_{j_1}, ..., y_{j_l})}$$.
                                         Together, they build the matrix $$W(k,l) = \begin{bmatrix} b_{i_1,j_1} & b_{i_1,j_2} & \dots & b_{i,j_l} \\ b_{i_2,j_1} & b_{i_2,j_2} & \dots &b_{i_2,j_l} \\ \vdots & \vdots & \ddots & \vdots \\ b_{i_k,j_1} & b_{i_k,j_2} & \dots & b_{i_k,j_l}\end{bmatrix}$$. 
                                         They find the unique solution of the Sylvester equation $$V{(x_{i_1}, ..., x_{i_k})} F - F V^t{(y_{i_1}, ..., y_{i_l})} = W(k,l)$$.
                                 Example #h
                                     Parameters #slide 
                                         $$k = 2$$
                                         $$l = 3$$
                                         $$A = \begin{bmatrix}15 & 10 & 5\\1 & 2 & 3 \end{bmatrix}$$
                                         $$V{(x_1, x_2)} = \begin{bmatrix}1 & 1 \\1 & 2\end{bmatrix}$$, $$V{(y_1,y_2,y_3)}^T = \begin{bmatrix}1 & 1 & 1\\1 & 2 & 3 \\1 & 4 & 9\end{bmatrix}$$
                                     Share Creation #slide 
                                         Calculation of $$B = V{(x_1,x_2)} A - A V{(y_1,y_2,y_3)} = ((b_{ij}))$$:
                                             $$b_{1,1} = \begin{bmatrix}1 & 1\end{bmatrix} \begin{bmatrix}15 \\ 1 \end{bmatrix} - \begin{bmatrix}15 & 10 & 5 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix} = -14$$ 
                                             $$b_{2,1} = \begin{bmatrix} 1 & 2 \end{bmatrix} \begin{bmatrix} 15 \\ 1 \end{bmatrix} - \begin{bmatrix}1 & 2 & 3\end{bmatrix} \begin{bmatrix}1 \\ 1 \\ 1 \end{bmatrix} = 11$$
                                             $$b_{1,2} = \begin{bmatrix}1 & 1\end{bmatrix} \begin{bmatrix} 10 \\ 2 \end{bmatrix} - \begin{bmatrix}15 & 10 & 5\end{bmatrix} \begin{bmatrix} 1 \\ 2 \\ 4 \end{bmatrix} = -43$$
                                             $$b_{2,2} = \begin{bmatrix}1 & 2\end{bmatrix} \begin{bmatrix} 10 \\ 2\end{bmatrix} - \begin{bmatrix}1 & 2 & 3\end{bmatrix} \begin{bmatrix}1 \\ 2 \\ 4 \end{bmatrix} = -3$$
                                             $$b_{1,3} = \begin{bmatrix}1 & 1\end{bmatrix} \begin{bmatrix}5 \\ 3\end{bmatrix} - \begin{bmatrix}1 & 2 & 3\end{bmatrix} \begin{bmatrix}1 \\ 3 \\ 9\end{bmatrix} = -23$$
                                             $$b_{2,3} = \begin{bmatrix}1 & 2\end{bmatrix} \begin{bmatrix} 5 \\ 3\end{bmatrix} - \begin{bmatrix}1 & 2 & 3\end{bmatrix} \begin{bmatrix}1 \\ 3 \\ 9 \end{bmatrix} = -23$$
                                             $$\therefore B = \begin{bmatrix} -14 & -43 & -82 \\ 11 & -3 & -23 \end{bmatrix} = \begin{bmatrix} b_{1,1} & b_{1,2} & b_{1,3} \\ b_{2,1} & b_{2,2} & b_{2,3} \end{bmatrix}$$
                                     Secret Recovery #slide 
                                         Objective
                                             $$vec(A) = (I_l \otimes V{(x_1, x_2)} - V{(y_1, y_2, y_3)}^T \otimes I_k)^{-1} \cdot vec(B)^T$$
                                             $$vec(B) = \begin{bmatrix} b_{1,1} & b_{2,1} & b_{1,2} & b_{2,2} & b_{1,3} & b_{2,3}\end{bmatrix}$$
                                         Calculation
                                             $$vec(B) = \begin{bmatrix} -14 & 11 & -43 & -3 & -82 - 23\end{bmatrix}$$
                                             $$vec(A) = \begin{bmatrix} 0 & 1 & -1 & 0 & -1 & 0 \\ 1 & 1 & 0 & -1 & 0 & -1 \\ -1 & 0 & -1 & 1 & -4 & 0\\ 0 & -1 & 1 & 0 & 0 & -4\\-1 & 0 & -3 & 0 & -8 & 1 \\ 0 & -1 & 0 & -3 & 1 & -7\end{bmatrix}^{-1} \cdot \begin{bmatrix} -14 \\ 11 \\ -43 \\ -3 \\ -82 \\ -23\end{bmatrix} = \begin{bmatrix} 15 \\ 1 \\ 10 \\ 2 \\ 5 \\ 3 \end{bmatrix}$$
                         On Access Structures #h #arman 
                             Notations #slide #arman 
                                 Let denote $$\mathcal{P} =\{P_1, P_2, ...,P_n\}$$ be a set of parties.
                             Access Structures #slide #arman
                                 Given a set of players $$\mathcal{P} = \{{P}_1, \ldots , {P}_n\}$$, the family $$\Gamma \subset 2^\mathcal{P}$$ of __authorized sets__ is the __access structure__ of the secret sharing scheme.
                                 Example: for $$n=3$$ parties $$P_1 , P_2, P_3$$ that participate in a secret sharing scheme with threshold $$k=2$$, the authorised sets are $$\{P_1, P_2\}$$, $$\{P_1 , P_3\}$$, $$\{P_2, P_3\}$$ and $$\{P_1, P_2, P_3\}$$.
                                 A collection $$\Gamma \subseteq 2^\mathcal{P}$$ is __monotone__ if: $$\mathcal{V} \in \Gamma$$ and $$\mathcal{V} \subseteq \mathcal{W} \Rightarrow \mathcal{W} \in \Gamma $$.
                                 Usually, access structures are monotone collections.
                             Compartmented Access Structures #slide #arman 
                                 Denote $$\mathcal{C} = \{\mathcal{C}_1,...,\mathcal{C}_m \}$$ a partition of $$\mathcal{P}$$ into $$m$$ disjoint subsets, or __compartments__: $$\mathcal{P} = \bigcup^m_{i=1} \mathcal{C}_i$$.
                                 Let 
                                     $$t_i \in \mathbb{N}$$ ($$1 \leq i \leq m$$), and $$\sum^m_{i=1} t_i \le t \in \mathbb{N}$$,
                                     $$s_i \in \mathbb{N}$$ ($$1 \leq i \leq m$$), and $$\sum^m_{i=1} s_i \ge s \in \mathbb{N}$$. 
                                 A __compartemented access structure__ with __lower__ (__upper__ respectively) __bounds__ consists of all subsets containing at least $$t_i$$ (at most $$s_i$$) participants from $$C_i$$ for $$1 \leq i \leq m$$, and a total of at least $$t$$ ($$s$$ respectively) participants.
                                 Formally: 
                                     $$\Gamma = \{\mathcal{V} \subseteq \mathcal{P} : \exists \mathcal{W} \subseteq \mathcal{V}$$ such that $$|\mathcal{W} \cap \mathcal{C}_i | \geq t_i, 1 \leq i \leq m$$, and $$ |\mathcal{W}| = t \}$$.
                                     $$\Delta= \{\mathcal{V} \subseteq \mathcal{P} : \exists \mathcal{W} \subseteq \mathcal{V}$$ such that $$|\mathcal{W} \cap \mathcal{C}_i | \le s_i, 1 \leq i \leq m$$, and $$ |\mathcal{W}| = s \}$$.
                                 Original notion by @Simmons had $$\sum^m_{i=1} t_i = t $$, later generalised by @Brickell. 
                             Multipartite Access Structures #slide #arman 
                                 Let $$\Gamma \in 2^\mathcal{P}$$ be a compartmented access structure.
                                 An $$m$$-__partite__ (or __multipartite__) access structure on $$\mathcal{P}$$ with respect to partition $$\mathcal{C}$$ is any access structure that does not distinguish between members of the same compartment.
                                 Formally:
                                     Assume that for all permutations $$\pi : \mathcal{P} \rightarrow \mathcal{P}$$ such that $$\pi(\mathcal{C}_i) =\mathcal{C_i}\;(1 \leq i \leq m), \;\mathcal{V} \in \Gamma$$ if and only if $$\pi(\mathcal{V}) \in \Gamma$$. 
                                     Then $$\Gamma$$ is called $$m$$-__partite__ or __multipartite__ with respect to partition $$\mathcal{C}$$.
                                 Given any subset $$\mathcal{W} \subseteq \mathcal{U}$$, its __type__ with respect to partition (1) is the vector $$(t_1,...,t_m) \in \mathbb{N}^m $$, where $$t_i = |\mathcal{W} \cap \mathcal{C}_i |, 1 \leq i \leq m.$$
                             ARCHIVE
                                 INBOX 
                                     The set of elements of $$\mathcal{V}$$ are also elements of $$\mathcal{U}$$.
                                     There exists a set $$\mathcal{V}$$ such that the number of elements that are in common with set $$\mathcal{W}$$ and $$\mathcal{C}_i$$ is greater than $$t_i$$. 
                                         where $$\mathcal{C}_i$$ is a set of participants in a compartment and $$\mathcal{U}$$ is a set of all participants in all compartments?
                                     $$i$$ is not less than l or greater than $$m$$ and the number of elements in $$\mathcal{W}$$ is $$t$$. 
                                         where $$m$$ is the number of compartments and $$t$$ is the number of participants.
                                     So is subset of participants that are at least size $$t$$ ($$t$$ out of $$n$$?) which are authorised to recover their secret? 
                                 The sets in $$\Gamma$$ are called the authorised sets, and the sets not in $$\mathbb{A}$$ are called the unauthorised sets.
                                     An access structure (respectivily, monotonic access structure) is a collection (respectively, monotone collection) $$\Gamma$$ of non-empty subsets of $$\{P_1,P_2 ,..., P_n\}$$, i.e., $$\Gamma \subseteq 2^{\{P_1,P_2,...,P_n\}} \setminus \{\emptyset\}$$.
                         Secret Sharing Scheme with Pre-defined Shares #h 
                             The Scheme #slide 
                                 Define $$\mathcal{P}$$ as the set of players with pre-defined shares
                                 We assume $$|\mathcal{P}|= k-1$$ for now
                                 Protocol:
                                     Dealer $$D$$ sends the pre-defined shares $$(x_i,y_i)$$ to all $$P_i \in \mathcal{P}$$. 
                                     $$D$$ computes the share polynomial $$f(x)$$ using interpolation from:
                                         the pre-defined shares 
                                         the point $$(0,s)$$
                                     The dealer now sends the remaining $$n-k$$ shares $$f(j)$$ to all players $$j \not\in \mathcal{P}(D)$$.
                             Security Analysis #slide 
                                 We have the following theorem:
                                     Assume the points $$P_1(x_1,y_1),\ldots,P_{k-1}(x_{k-1},y_{k-1})$$ are pre-defined with distinct abscissae $$x_i$$ and uniformly random ordinates $$y_i$$. Then the scheme is a perfect secret sharing scheme. #theorem 
                                 Idea of proof: 
                                     We will show that the polynomial $$f$$ has uniformly random distributed coefficients. The claim then follows from the properties of Shamir's scheme. 
                             Proof #slide 
                                 The matrix $V$ is a Vandermonde-matrix
                                     $$V = \begin{pmatrix} 1 & x_1 & x_1^2 & \cdots & x_1^{k-1} \\ 1 & x_2 & x_2^2 & \cdots & x_2^{k-1} \\ \vdots & \vdots & \vdots & &\vdots \\ 1 & x_n & x_n^2 & \cdots & x_n^{k-1} \end{pmatrix}$$.
                                 We require the following random variables:
                                     $$X$$: the vector of $$x_i$$ 
                                     $$Y$$: the vector of $$y_i$$ 
                                     $$Q$$: the coefficients of Shamir polynomial
                                     $$V$$
                             Lemma #slide 
                                 Let $$\sigma$$ be a bijection. Then for any $$X$$
                                     $$H(\sigma(X))=H(X)$$.
                                 Proof:
                                     $$H(\sigma(X))\le H(X)$$ and $$H(\sigma^{-1}(X))\le H(X)$$ hence $$H(X)=H(\sigma^{-1}(\sigma(X)))\le H(\sigma(X))\le H(X)$$ from which the claim follows.
                             Proof #slide 
                                 We have $$Y=V(X)Q$$ and that $$V$$ is invertible due to the distinct $$x_i$$.
                                 It follows 
                                     $$H(Y|X)=H(V^{}(X)Q)=H(Q)$$ 
                                 due to the the lemma.
                                 Since $$Y$$ is random, $$H(Q)=H(Y|X)=H(Y)=\log_2|\mathbb{F}|^{k}$$ which finishes the proof. 
                             Discussion #slide 
                                 Variations:
                                     Dissemination
                                         Each $$P_i \in \mathcal{P}$$ sends a self-chosen share $$(x_i,y_i)$$ to dealer $$D$$, instead of receiving them.
                                         This might be beneficial, depending on the nature of the underlying communication channel
                                     We could also have $$|\mathcal{P}|< k-1$$
                                 Other interesting aspect: the use of this scheme for information hiding (steganography)
                             INBOX 
                                 hence $$Q=V^{-1}(X)Y$$ 
                                     $$H(Q|X)=H(V^{-1}(X)Y)=H(Y)$$ 
                                 Random Variables #slide 
                                     $$S$$: the secret
                                     $$F_i$$: the value of $$f(i)$$ (part of $$i$$th share)
                                     $$Q$$: the coefficients of Shamir polynomial 
                                     $$X_i$$: the abscissa $$x_i$$ of $$i$$th share $$(x_i,f(x_i))$$ 
                                     $$Y_i$$: the ordinate $$f(x_i)$$ of $$i$$th share $$(x_i,f(x_i))$$ 
                                 Entropy Properties #slide 
                                     $$H(X)\ge H(X|Y)$$
                                     $$H(X,Y)=H(X)+H(Y| X)= H(Y)+H(X|Y)$$
                                     $$0\le H(X) \le \log_2|X|$$
                                     If $$H(Y|Z)=0$$ then $$H(X|Y)\ge H(X|Z)$$
                                     If $$H(Y|Z)=0$$ then $$H(X|Y,Z)=H(X|Z)$$
                                 Useful Identities #slide 
                                     The following identities are specific to the construction of the Shamir secret sharing scheme:
                                         Due to the unique interpolation property of $$f$$, given $$k$$ distinct points, one has: $$H (Q_{0},\ldots ,Q_{k-1} |F_{i_{1}},\ldots ,F_{i_{k}})=0$$.
                                         Based on evaluation of $$f$$ we can uniquely determine the shares, hence: $$H (F_{i_{1}},\ldots ,F_{i_{k}}|Q_{0},\ldots ,Q_{k-1} )=0$$.
                                         Due to the definition of the Shamir polynomial: $$H (S|Q_{0},\ldots ,Q_{k-1})=H (S|S,Q_1,\ldots ,Q_{k-1})=0$$.
                                 Proof: Correctness #slide 
                                     Applying 4th identity with $$Y=Q_{0},\ldots ,Q_{k-1}$$ yields $$H (S|Q_{0},\ldots ,Q_{k-1}) \ge H (S |F_{i_{1}},\ldots ,F_{i_{k}})$$.
                                     Applying again gives $$H (S |F_{i_{1}},\ldots ,F_{i_{k}})\ge H (S|Q_{0},\ldots ,Q_{k-1})$$
                                     Hence $$H (S|Q_{0},\ldots ,Q_{k-1}) = H (S |F_{i_{1}},\ldots ,F_{i_{k}})$$
                                     Hence $$H (S |F_{i_{1}},\ldots ,F_{i_{k}})=0$$
                                     And also $$H (S |F_{i_{1}},\ldots ,F_{i_{t}})=0$$
                                 Proof: Perfectness #h 
                                     Lemma #slide 
                                         The following properties hold:
                                             $$H (Q_{0},\ldots ,Q_{k-1} |X_{i_{1}},\ldots ,X_{i_{k}})=H(Y_{i_{1}},\ldots ,Y_{i_{k}})$$
                                             $$H (Q_{0},\ldots ,Q_{k-1} |Y_{i_{1}},\ldots ,Y_{i_{k}})=H(X_{i_{1}},\ldots ,X_{i_{k}})$$
                                         Proof
                                             Let $$y=V(x_1,...,x_n) f $$
                                             $$f=V(x_{i_1},...,x_{i_k})^{-1} y$$
                                             Its coefficient vector $$a$$ is $$a = \begin{pmatrix} s \\ a_1 \\ \vdots \\ a_{k-1} \end{pmatrix} = V(0,x_{i_1},...,x_{i_{k-1}})^{-1} \begin{pmatrix} s \\ y_{i} \\ \vdots \\ y_{i_{k-1}} \end{pmatrix}$$.
                                             $$a=V(x_{i_1},...,x_{i_k})^{-1} y$$
                                             $$H(f|x)=H(y)$$
                                             $$H(f|y)=H(x)$$ 
                                 Dissemination Version #slide 
                                     **protocol** predefined_share_dissemination($$i, k$$):
                                         **if** $$i \in \mathcal{P}(D)$$ **then**
                                             // Node $$i$$ is pre-defining player for dealer. //
                                             **send** share $$(x_i,y_i)$$ to dealer $$D$$;
                                         **elif** $$i=D$$ **then**
                                             // Node $$i$$ is dealer. //
                                             **for all** $$i \in \mathcal{P}(l)$$ **do**
                                                 **receive** share $$(x_i,y_i)$$ from pre-defining player $$i$$;
                                             Compute share polynomial $$f(x) = V(0,x_{i_1},...,x_{i_{k-1}})^{-1} \begin{pmatrix} s \\ y_{i_1} \\ \vdots \\ y_{i_{k-1}} \end{pmatrix}$$;
                                             **send** shares $$f(j)$$ to all neighbours $$j \not\in \mathcal{P}(D)$$;
                                         **elif** $$i \not\in \mathcal{P}(D)$$ **then**
                                             // Node $$i$$ is not a pre-defining player for dealer. //
                                             **receive** share $$f(i)$$ from dealer;
                                         **fi**;
                                 **for all** $$j \in \mathcal{N}(l) \setminus \{{j_1},\ldots {j_d}\}$$ **do** 
                                     **send** share scalar $$f(l,j) = f(j, l) = f(x, l)|_{x=j} = v^\top\psi_{j}$$ to neighbour node $$j$$;
                                 **receive** share vector $$f(x,l) = \psi_l^\top M$$ from the dealer;
                         Shah Secret Share Dissemination Protocol #h 
                             Secret Share Dissemination -- Aim #slide
                                 Given: secret vector $$s^\top = [s_1, s_2,...,s_{d-k+1}]$$.
                                 Distribution of secret shares over an insecure channel is exposed to eavesdropping of nodes. 
                                 Dissemination i.e. "To disperse throughout" MW 
                                 This scheme allows participants to receive their intended share without others obtaining it.
                                 These shares can then proceed to be used as such in a Shamir's Secret Sharing Scheme $$(k,n)$$.
                                 Aim #slide #arman 
                                     Dissemination i.e. complete confidential dispersal of secret shares in a general network, avoiding eavesdropping of nodes. 
                                     This scheme allows participants to receive their intended share, avoiding eavesdropping of other nodes. 
                                     The shares can then be used as such, as in Shamir's $$(k,n)$$ secret sharing scheme.
                             Notations #slide
                                 $$\cdot^\top$$ -- transposed matrix or vector
                                 $$\mathbb{F}_q$$ -- finite field of characteristic $$q$$ where $$q > n$$
                                 $$k$$ -- number of different shares required to recover secret
                                 $$s$$ -- secret
                                 $$f(x)$$ -- share polynomial function
                                 $$\psi_{i}^{T} = [1,i,i^2,...,i^{d-1}]$$ -- encoding vector for node $$i$$
                                 $$\Psi$$ -- Vandermonde matrix of dimension $$n \times d$$ (each row being $$\psi_{i}^{T}$$)
                             Network and Secret Sharing Parameters #slide
                                 A vector containing $$(d-k+1)$$ secrets is subject to finite field $$\mathbb{F}_q$$.
                                 $$k$$ -- secret recovery threshold
                                 $$n$$ -- overall number of nodes/shares
                                 $$i$$ -- unique node index $$(1 \leq i \leq n)$$
                                 $$\mathcal{N}(j)$$ -- set of neighbours for any node $$j$$ $$(1 \leq j \leq n)$$
                                 $$d$$ -- parameter for propagating dealer property $$(d \ge k)$$.
                             Network Topology -- Conditions #slide
                                 A1 ($$k$$-connected-dealer): each node is either directly connected to the dealer or has at least $$k$$ vertex-disjoint paths from itself to the dealer.
                                     **Property 1** ($$k$$-connected-dealer) Out of $$n$$ participants, each is either directly connected to each other or have at least $$k$$ vertex-disjoint paths from itself to the dealer.
                                 A2 ($$d$$-propagating-dealer) The $$n$$ participants can be organised in the topology in an order such that every vertex is either directly connected to the dealer or $$d$$ nodes that make a path to it ($$d \geq k$$). 
                                 **Property 2** ($$k$$-propagating-dealer) The way the $$n$$ participants are organised in the topology is that every vertex is either directly connected to the dealer or $$k$$ nodes that make a path to it.
                                 Fact: $$d > k$$: increases communication efficiency 
                             Dealer -- Setup #slide 
                                 The dealer creates the symmetric bivariate polynomial $$f(x,y)$$ of degree $$d$$, where $$f(x,y)=\sum m_{ij}x^iy^j$$ and the symmetric matrix $$M=((m_{ij}))\in \mathbb{F}^{d\times d}$$ is defined as 
                                     $$M = \begin{pmatrix} s_a & r_a^\top & s_b^\top \\ r_a & R_b & R_c^\top \\ s_b & R_c & 0\end{pmatrix}$$ 
                                 where
                                     $$s_a = s_{d-k+1}$$, $$s_b = [s_1, ... , s_{d-k}]^\top$$,
                                     $$r_a \in \mathbb{F}^{(k - 1) \times 1}$$ is a vector of length $$(k - 1)$$,
                                     $$R_b \in \mathbb{F}^{(k - 1) \times (k - 1)}$$ is a symmetric random matrix with $$\frac{k(k - 1)}{2}$$ entries,
                                     $$R_c \in \mathbb{F}^{(d - k) \times (k - 1)}$$ is a random matrix with $$(d - k)(k - 1)$$ entries.
                             Dealer -- Share Creation #slide 
                                 $$\psi_{i}^\top = [1,i,i^2,\ldots,i^{d-k}]$$
                                 Share Polynomials/Vectors
                                     Create the share vectors $$f(i,y)=\psi_{i}^\top M$$ for any given node ID $$i$$.
                                 Share Scalars
                                     ...
                                 Observation:
                                     Due to symmetry of code matrix $$M$$: $$f(j,l)=\psi_j^\top M \psi_l = (\psi_j^\top M \psi_l)^\top= \psi_l^\top M^\top \psi_j = \psi_l^\top M \psi_j=f(l,j).$$
                             Node -- Share Dissemination #slide 
                             Share Dissemination Protocol #slide 
                                 **protocol** share_dissemination($$l, k, d,$$):
                                     // Node $$l$$ needs to send shares to all neighbours //
                                     **if** $$l=D$$ **then**
                                         // Node $$l$$ is dealer. //
                                         Create the code matrix $$M$$;
                                         **send** share vector $$f(x,j) = \psi_{j}^\top M$$ to all neighbours $$j \in \mathcal{N}(D)$$;
                                     **elif** $$l \in \mathcal{N}(D)$$ **then**
                                         // Node $$l$$ is direct neighbour of dealer. //
                                         **receive** share vector $$f(x,l) = \psi_l^\top M$$ from the dealer;
                                         **for all** $$j \in \mathcal{N}(l)$$ **do**
                                             **send** share scalar $$f(l,j) = \psi_{l}^\top M \psi_{j}$$ to neighbour node $$j$$;
                                     **else**
                                         // Now $$l \not\in \mathcal{N}(D)$$ -- node $$l$$ is not a direct neighbour of dealer. //
                                         **receive** share scalars $$f(j_i,l) = \sigma_{j_i}$$ $$(i=1,\ldots d)$$ from any $$d$$ neighbours $$j_1,\ldots,j_d$$;
                                         Compute share vector $$v = f(x, l) = \begin{pmatrix} \quad & \psi_{j_1}^\top & \quad \\ \quad & \vdots & \quad\\ \quad & \psi_{j_d}^\top & \quad \end{pmatrix}^{-1} \begin{pmatrix} \sigma_{j_1} \\ \vdots \\ \sigma_{j_d} \end{pmatrix}$$;
                                         **for all** $$j \in \mathcal{N}(l) \setminus \{{j_1},\ldots {j_d}\}$$ **do** 
                                             **send** share scalar $$f(l,j) = f(j, l) = f(x, l)|_{x=j} = v^\top\psi_{j}$$ to neighbour node $$j$$;
                                     **fi**;
                             Security Analysis #slide 
                                 Definitions #slide
                                     $$k$$-secret-recovery
                                         Any $$k$$ shares can recover the secret.
                                     $$(k - 1)$$-collusion-resistance
                                         No knowledge can be gained from $$k - 1$$ shares.
                                 Correctness #slide #arman 
                                     We have $$k$$-secret recovery:
                                 Security #slide #arman 
                                     We have $$(k - 1)$$-collusion resistance:
                             Applications #h 
                                 Self-organised p2p network of Bitcoin users
                             Extensions #h 
                                 Dealer-free Protocol #h 
                                 Addition of New Participant #slide 
                                     A participant that replaces the dealer
                                     Must be approved by $$d$$ existing participants.
                                     $$k$$ parameter is the threshold to recover the secret whilst $$d$$ is the threshold consensus to add a new participant.
                                     Handover share to another
                                         $$\begin{bmatrix} 1 & 2 & 4 \\ 1 & 3 & 9 \\ 1 & 4 & 16 \end{bmatrix}^{-1} \cdot \begin{bmatrix} \psi_1 M \psi_2^\top \\ \psi_1 M \psi_3^\top \\ \psi_1 M \psi_4^\top\end{bmatrix} = \psi_1 M$$
                             INBOX
                                 MBR Codes #slide 
                                     $$M$$
                                         Symmetric matrix that is a minimum bandwidth regeneration code.
                                         $$M = \begin{bmatrix} s_a & r_a^\top & s_b^\top \\ r_a & R_b & R_c^\top \\ s_b & R_c & 0\end{bmatrix}$$
                                             $$s_a = s_{d-k+1}$$
                                             $$r_a$$ is a $$((k - 1) \times 1)$$ is a vector of length $$(k - 1)$$.
                                             $$s_b = [s_1, ... , s_{d-k}]^\top$$
                                             $$R_b$$ is a $$(k - 1) \times (k - 1)$$ symmetric matrix with its $$\frac{k(k - 1)}{2}$$ entries populated by random values
                                             $$R_c$$ is a $$(d - k) \times (k - 1)$$ matrix with its $$(d - k)(k - 1)$$ entries populated by random values
                                     $$M$$ matrix symmetry
                                         $$\psi_j M \psi_l = \psi_l M \psi_j$$
                                         This allows nodes to pass on a regenerative code to a node.
                                         After enough aggregates of such code, the intended share is recovered.
                                 $$M$$ is a symmetric matrix that can be transposed. It contains an arrangement of vectors and matrices:
                                     $$s$$ contains the secret value.
                                     $$r_a$$ is a vector of random integers with length $$k-1$$.
                                     $$R_b$$ is a symmetric matrix of size $$(k-1)(k-1)$$ containing $$\frac{k(k-1)}{2}$$ random values.
                                     $$M = \begin{bmatrix} s & r_a^\top\\ r_a & R_b\end{bmatrix}$$
                                     For example a $$k = 3$$ matrix would look like:
                                         $$M = \begin{bmatrix} s & r_{a_1} & r_{a_2} \\ r_{a_1} & R_{b_{11}} & R_{bs2} \\ r_{a_2} & R_{bs2} & R_{b22}\end{bmatrix}$$
                                 4. Non-dealer neighbors can transmit further to other non-dealer neighbors
                                     In the same fashion as dealer recipients transmitting values by encoding $$\psi_{l}^\top M$$ with $$\psi_{j}$$ that is the other non-dealer neighbor $$j$$.
                                 Participant $$j$$ $$(1 \leq j \leq n)$$ has a set of neighbours given by $$\mathcal{N}(j)$$.
                                 Reconstruct $$\psi_{l}^\top M = \begin{bmatrix} \psi_{j1}^\top \\ \vdots \\ \psi_{jk}^\top \end{bmatrix}^{-1} \begin{bmatrix} \psi_{j1}^\top M \psi_{l} \\ \vdots \\ \psi_{jk}^\top M \psi_{l} \end{bmatrix}$$;
                                 Dissemination Algorithm #h 
                                     Parameters #s
                                         $$k$$ -- secret recovery threshold
                                         $$n$$ -- number of participants to obtain a share
                                         $$d$$ -- Condition 2's d-propagating-dealer
                                             $$d$$ $$(\geq k)$$
                                     Preamble #s
                                         A vector containing $$(d-k+1)$$ secrets is subject to finite field $$\mathbb{F}_q$$.
                                     Dealer Setup #s
                                         The dealer has functionality to produce the following:
                                             $$M$$
                                                 Symmetric matrix that is a minimum bandwidth regeneration code.
                                                 $$M = \begin{bmatrix} s_a & r_a^\top & s_b^\top \\ r_a & R_b & R_c^\top \\ s_b & R_c & 0\end{bmatrix}$$
                                                     $$s_a = s_{d-k+1}$$
                                                     $$r_a$$ is a $$((k - 1) \times 1)$$ is a vector of length $$(k - 1)$$.
                                                     $$s_b = [s_1, ... , s_{d-k}]^\top$$
                                                     $$R_b$$ is a $$(k - 1) \times (k - 1)$$ symmetric matrix with its $$\frac{k(k - 1)}{2}$$ entries populated by random values
                                                     $$R_c$$ is a $$(d - k) \times (k - 1)$$ matrix with its $$(d - k)(k - 1)$$ entries populated by random values
                                     Communication #h
                                         Dealer #s
                                             Identify each participant $$j \in \mathcal{N}(dealer)$$
                                             Compute $$\psi_{j}^\top M$$ where $$||\psi_{j}^\top M|| = d$$
                                                 The first element of this vector is a polynomial for a Shamir secret share. 
                                                 This element is the product of $$\psi_{j}^\top$$ with the first column of $$M$$ i.e. $$\begin{bmatrix} s_a \\ r_a \\ \end{bmatrix}$$
                                             Send the vectors to the relevant node $$j$$
                                         Participant $$l \in \mathcal{N}(dealer)$$ #s
                                             Receipt of $$\psi_{l}^\top M$$ is kept, already containing the intended share.
                                             Identify every participant $$j \in \mathcal{N}(l)$$.
                                             Compute $$\psi_{l}^\top M \psi_{j} = \sigma$$ 
                                             Send $$\sigma$$ to the relevant node $$j$$
                                         Participant $$l \not\in \mathcal{N}(dealer)$$ #s
                                             Memoisation of acquired $$\sigma$$ values and the respective node.
                                             Upon gathering $$d$$ number of $$\sigma$$ values, begin recovery of the intended share.
                                             $$\begin{bmatrix}\psi^\top_{i_1} \\ \vdots \\ \psi^\top_{i_d}\end{bmatrix}^{-1} \begin{bmatrix}\sigma_1 \\ \vdots \\ \sigma_d \end{bmatrix} = \psi_{l}^\top M$$
                                             Identify every participant $$j \in \mathcal{N}(l)$$.
                                             Compute $$\psi_{l}^\top M \psi_{j} = \sigma$$ 
                                             Send $$\sigma$$ to the relevant node $$j$$
                                         Participant $$j \in \mathcal{N}(l) \not\in \mathcal{N}(Dealer)$$ #s
                                             Upon attempting to communicate $$\sigma_j$$, ask node $$l$$ for approval.
                                             This prevents unnecessary communication. 
                 Secure Commitment Schemes and Zero-Knowledge Protocols (ZKPs) #h 
                     Secure Commitment Schemes #h 
                         Motivation #slide #proto #CI7100
                             A secure commitment scheme is a protocol implementing a game between Alice and Bob. 
                             Alice wants to reveal information in the future but keep it confidential for now. 
                             This means that Alice chooses a secret $$s$$ and only reveals it later
                             Bob is able to verify later that the revealed value is indeed the original secret
                             A commitment can represent the proof of this information whilst preserving the privacy. 
                             When it is revealed, the commitment will verify the revealed information.
                             An important additional feature of the protocol: both players do not necessarily have to trust each other (they might try to cheat). 
                         Motivation: Real-World Examples #slide 
                             Example 1
                                 A head-and-tail game (using a coin) between Alice and Bob
                             Example 2
                                 Peggy makes a bet that a certain person will win a race. 
                                 Before the race starts Peggy makes a commitment and sends it to Victor. 
                                 After the race has finished, Peggy can reveal who she thought was going to win which allows Victor to verify the truth.
                         Properties #slide #proto #CI7100
                             Protocol proceeds in two stages: commit($$x$$) and reveal($$x$$)
                             Alice executes the commit stage in order to commit to $$x$$
                             Later, she applies reveal in order to open the secret
                             Essential properties:
                                 Binding: Alice cannot change $$x$$ without being detected
                                 Hiding: Bob cannot learn $$x$$ before reveal
                         Ideal Commitment Model #slide #proto #CI7100
                             Use TTP, with which every user can communicate securely
                             Commit(x):
                                 Alice sends x to the TTP in a confidential and authenticated manner
                                 TTP creates nonce c and stores (c,x)
                                 TTP returns c to Alice
                             Reveal(x):
                                 Bob sends reveal command to TTP
                                 TTP publishes (c,x)
                             This is perfectly secure
                         Bit Commitment Using Hash Function  Basic Protocol #slide #proto #CI7100
                             Bit commitment scheme: $$x=b$$ is either 0 or 1
                             Alice wants to commit to a bit $$b$$ without revealing it to Bob
                             Why can she not simply send $$H(b)$$?
                             Protocol works as follows (assuming a secure channel):
                             Commit($$b$$):
                                 Alice generates a random bit-string $$R$$
                                 She creates message containing $$b$$ by forming $$m=(R,b)$$
                                 Alice now sends to Bob: $$H(m)$$
                             Reveal($$b$$):
                                 Alice sends $$m$$ to Bob
                                 Bob re-computes hash, checking it
                         Security of the Protocol #slide #proto #CI7100
                             Why is this binding?
                                 If Alice changes $$b$$, the output of the hash function will be different
                                 Due to collision-resistance, this will be detected
                             Why is this hiding?
                                 Bob only knows hash digest
                                 Due to pre-image attack resistance, he cannot access $$b$$
                         Bit Commitment Using Hash Function -- Strengthened Protocol #slide #proto #CI7100
                             Commit($$b$$):
                                 Bob creates random bit-string $$R_1$$ and sends it to Alice
                                 Alice also generates a random bit-string $$R_2$$
                                 She creates message containing $$b$$ by forming $$(R_1,R_2,b)$$
                                 Alice now sends $$H(R_1,R_2,b),R_1$$ to Bob, who records value 
                             Reveal($$b$$):
                                 Alice sends Bob: $$(R_1,R_2,b)$$
                                 Bob recomputes hash, checking it with recorded value
                         Protection Mechanisms #slide #proto #CI7100
                             We will explain the purpose of $$R_1$$ and $$R_2$$ (they are nonces or random coins)
                             Purpose of $$R_2$$: Hiding -- as in the previous basic protocol
                                 This gives protection for Alice's bit $$b$$
                                 Bob cannot invert $$H$$, so cannot deduce $$b$$
                             Purpose of $$R_1$$: Binding
                                 To strengthen Bob's protection
                                 Alice (or any other attacker) cannot find $$R_2'$$ with $$H(R_2, 0) = H(R_2, 1)$$ as in the previous protocol
                                 Even if she could, this forces the need for different collisions  in each protocol run
                         Applications #slide #proto #CI7100 
                             Secure commitment schemes are building blocks
                             They have applications for more advanced protocols
                                 A secure commitment scheme can help ensuring the correct outcome of a computation or protocol
                                 This is achieved by committing to some (crucial) intermediate parameters
                                 The security goals are initial sender data confidentiality and integrity. 
                                 Popular applications: verifiable secret sharing, zero-knowledge proofs
                     Zero-Knowledge Protocols #h 
                         Introduction #h 
                             ZKP Definition #slide 
                                 A __Zero-Knowledge Proof/Protocol__ (ZKP) is a method by which one party (the __prover__) can prove to another party (the __verifier__) that a given statement __S__ is true.
                                 Apart from the fact that the statement is indeed true, no other information must be conveyed.
                                 This is the main challenge, as it is trivial to e.g. prove that one possesses knowledge of certain information by simply revealing it.
                             ZKP as a Protocol #slide
                                 A good way to implement a ZKP is an asymmetric protocol, involving __Peggy__ (prover) and __Victor__ (verifier).
                                 This is usually done by Peggy computing proof a that __S__ is correct, and providing this to Victor.
                                 where Victor creates a challenge in order to verify it derived by their  respective secret values.
                                 Protocol can be __interactive__ or __non-interactive__.
                             ZKP Properties #slide
                                 There are 3 main properties:
                                     __Completeness__ -- if the statement is true, an honest prover will convince the verifier. The verifier will have confidence that the prover knows the information that they didn't reveal.
                                     __Soundness__ -- if the statement is false, the verifier will find out the prover is dishonest with a very high probability. So there cannot be an instance of a protocol run where false information can be verified by Victor.
                                     __Zero knowledge__ -- no extra information is revealed to the verifier.
                             ZKP Security #slide 
                                 ZKP Protocols are usually secure in terms of either 
                                     the RSA Prime-Multiplication Trapdoor function or 
                                     the Discrete Logarithm Problem 
                                 for classical computers. 
                                 They are potentially vulnerable to Schor's Algorithm/quantum computers.
                             Specific ZKP Example #slide 
                                 Peggy attempts to prove she knows $$x$$ to Victor but without revealing $$x$$ at any point.
                                 Here $$x$$ can represent any structured data, especially as it can be represented through a secure hash.
                                 This ZKP protocol effectively gives Victor access to a private version of the identity test function $$\mathsf{Id:x\to x}$$. 
                                 Victor verifies $$x = \mathsf{Id (x)}$$. 
                         Example Scenarios #h 
                             A Simple Interactive ZKP #slide 
                                 A: a very simple example: Peggy wants to convince Victor, that she possesses a certain key.
                                 Idea: rather than showing the key, she demonstrates that she can open the corresponding lock.
                                 This needs to be done with care so that the protocol remains zero-knowledge:
                                     Victor must not be able to see the key in a close up
                                     Otherwise, information can leak!
                                 Video illustrating this: [https://youtu.be/pfx2rcH2H9I](https://youtu.be/pfx2rcH2H9I)
                             Zero-knowledge Glassdoor #slide 
                                 Goal: two employees (Peggy and Victor) want to know whether they earn the same salary. 
                                 Or else a bank giving a loan. 
                                 They do not want to disclose how much money they get if their salaries are not the same.
                                 Approach:
                                     Peggy prepares envelopes, each labelled with some salary amounts (including one with her own). 
                                     Victor places notes in each (in Peggy's absence), with one "yes" and all others "no". 
                                     Peggy opens the envelope labeled with her salary (when Peggy is present) and reveals the note. 
                                 Remark: can Peggy or Victor cheat?
                             Non-Interactive ZKP: An Oriental Tale #slide 
                                 In the classic tale of Ali Baba and the Forty Thieves, the cave is used to demonstrate knowledge of the hidden secret, to a third party.
                                 The cave has two forks A and B which are at first glance a dead end. 
                                 ![Pasted image](https://dynalist.io/u/jbZ9pM1X4kRTsg1zTE5DTRw5) 
                                 The thieves are able to evade their pursuers by using a secret passphrase which opens a wall between A and B.
                                 One can demonstrate knowing this secret by having an observer at the fork flip a coin to decide which side the prover must appear from. 
                                 Each time this is tested, the chance of success by someone not knowing the secret is halved. 
                                 The randomisation is put in place in order to rule out collusion between the prover and verifier.
                                 Reference: [Jean-Jacques Quisquater, Louis Guillou, The Strange Cave of Ali Baba  (How to Explain Zero-Knowledge Protocols to Your Children)](http://pages.cs.wisc.edu/~mkowalcz/628.pdf)
                         Applications #h 
                             Sharing Criminal Evidence #slide
                                 Two different agencies (banks, or government institutions) share a record of customers
                                 They occasionally receive records about criminal allegations
                                 They want to compare evidence for a given, shared customer
                                 If the evidence is not the same, this should not be revealed
                                 In particular, this is useful if one of the agencies has not received any allegation.
                                 Here, a ZKP is the suitable solution!
                             Blockchain #slide 
                                 Idea: apply ZKP to transaction information
                                 This means that transactions can be validated, without knowing their content!
                                 This achieves a stronger version of encryption (which leaks information!)
                                 [A good article](https://blockheadtechnologies.com/zero-knowledge-proofs-a-powerful-addition-to-blockchain/)
                                 Z-Cash
                                     [ZK-SNARK](ZK-SNARK)
                                     [https://z.cash/technology/zksnarks/](https://z.cash/technology/zksnarks/)
                 Steganography #h 
             Dependability and Security #d #depend
             Security Architectures #h 
                 how about this for required outputs from each of the first, second and third stages:
                 1) Each bank processes every transaction to produce a signal, and share this with an auditor. 
                     From the data contained in the signal, it shall not be possible for any unauthorised entity to infer the 'to' or 'from' bank account, or sort code. For stage 1, the auditor would be unauthorised.
                     The amount and timestamp data will not be redacted at stage 1, i.e. the auditor is able to infer and use these elements of data about each transaction that it receives, in stage 2.
                 2) The auditor associates a probability of money-laundering to each transaction, and makes this information available to the banks. 
                     Note that the 'to' and 'from' account+sort codes are by necessity redacted. 
                     For each transaction, the auditor shall either i) disclose this associated data available only to the source bank, or ii) publish to the community of banks. both routes have their security advantages. Hybrid approaches may also be possible.
                     Note that the auditor may choose to only disclose/publish the transactions for which the probability exceeds a given value, i.e. those intended for inclusion in an SAR. This disclosure/publication activity then becomes in effect a request to reveal bank account+ sort code. 
                     It may also be possible for the auditor encrypt other aspects of the transaction, including the timestamp, amount,  and the probability of money-laundering. This way, only the source bank will be privy to these elements of data. This is especially relevant if route (ii) is chosen, but could also be useful for (i), i.e. for internal bank security. 
                 3) The auditor and banks work together to produce an SAR for each set of transactions with a sufficiently high probability of money-laundering. 
                     An SAR is defined as a list of transactions.
                     For each transaction, unless the 'from' bank has authorised the disclosure, the 'from' bank account+sort code is encrypted. Similarly, for each transaction, unless the 'to' bank has authorised the disclosure, the 'to' bank account+sort code is encrypted. 
                     An interactive workflow to request authorisation (and hence revelation) of plaintext bank account / sort code is suggested 
             Security Economics #h 
                 Learning Objectives #slide 
                 Introduction #slide #fix
                     Security Economics or Economics of Security ?
                          ![Pasted image](https://dynalist.io/u/FwaxcjYzw6bOr3GNZuGU_2ST) 
                     [Google Trends](https://trends.google.com/trends/explore?date=today%205-y&q=economics%20of%20security,security%20economics&hl=en-US)
                     [CyBOK: Security Economics Knowledge Guide](https://www.cybok.org/media/downloads/Security_Economics_KG_v1.0.0.pdf)
                 Security Economics Domain #slide
                     Aim: how can we design effective and cost-efficient security strategies and policies.
                     Combines economics theory with research in computer science and mathematics (optimisation).
                         Examines economic factors that drive the security industry.
                             (market for security products and services, and the impact of public policies and regulations on security) #wfe-ignore-item #note 
                         Seeks to understand the trade-offs between the costs of security measures and their benefits. 
                         Involves analysing the incentives and strategic decisions of various stakeholders, including attackers, defenders, and end-users.
                     As such, it contributes to the security of computer systems and networks. 
                 Economics of Security Topics #slide 
                     Financial analysis of security measures,
                     The economics of cybercrime,
                     Game theory in security.
                     The market for zero-day vulnerabilities, 
                     The role of insurance in cybersecurity. 
                 Financial analysis of security measures #h 
                     Return on Investment (ROI) and Cost-Benefit Analysis (CBA) #slide
                         Both are financial analysis methods, used to evaluate the financial impact of a proposed investment or project. 
                         Key differences between the two:
                             ROI is a simpler and more specific metric.
                             It focuses on the return on the investment.
                             CBA takes a broader view of the costs and benefits of the investment. 
                             It attempts to quantify both __tangible__ and __intangible__ (or "soft") costs and benefits.
                             Usually over a longer period of time. 
                         They can also be combined.
                     ROI -- Definition #slide 
                         ROI is a relative measure that calculates the net gain or loss from an investment or spending.
                         This provides a measure of the profitability of the investment.
                         The deeper meaning of ROI is the measurement of the efficiency of an investment. 
                         It takes into account both the benefits gained and the costs incurred, using a mathematic equation.
                     ROI -- Calculation #slide 
                         Informal equation: 
                             $$\text{ROI} = \frac{\text{benefits from investment} - \text{cost of investment}}{\text{cost of investment}}$$
                         Formal definition: 
                             Denote $$\rho$$ the ROI, $$b$$ and $$c$$ resp. the benefit and costs.
                             Then $$\rho:=\frac{b-c}{c}=\frac{b}{c}-1$$.
                         Hence, the ROI is calculated by 
                             1) Subtracting the initial investment from the expected total return (benefit) on the investment,
                             2) Dividing this by the initial investment. 
                     Investment Utility Function Definition #slide 
                         So, values $$\rho > 0$$ indicate that the returns exceed the costs of the investment.
                         Any return $$\mu < \rho$$ is a feasible return.
                         Another form sometimes used is the investment utility function
                             $$u(\lambda):=b-(\lambda+1)c-{b}$$.
                         One has
                             $$\rho+1=\frac{b}{c} \Longrightarrow u(\rho)=b-(\rho+1)c=0$$.
                         So we have for the investment utility function:
                             $$u(\mu) \ge 0$$ if $$\mu$$ is feasible and
                             the ROI is the maximal feasible value. 
                     Single Loss Expectancy (SLE) #slide 
                         The Single Loss Expectancy (SLE) is the monetary value expected for a single loss from a threat or risk.
                         The formula for SLE is: $$\text{SLE} = \text{AV} \times \text{EF}$$
                         Here:
                             the Asset Value (AV) is the estimated value of the asset at risk
                             the Exposure Factor (EF) is the percentage of the asset value that would be lost if the risk event occurs.
                     Annual Loss Expectancy (ALE) #slide 
                         The Annual Loss Expectancy (ALE) calculates the total expected loss from a single loss event, repeated throughout the year.
                         It can be defined as the product
                             $$\text{ALE}$$ = $$\text{SLE} \times \text{ARO}$$.
                         Here:
                             SLE is the monetary value expected from a single occurrence of a risk (see previous definition),
                             ARO is the number of times a risk is expected to occur in a year.
                         The ALE for $$n$$ assets can be defined as the sum of the individual ALEs:
                             $$\text{ALE} = \sum_{i=1}^{n} \text{SLE}_i \times \text{ARO}_i$$
                         Here $$\text{SLE}_i$$ is the Single Loss Expectancy, and $$\text{ARO}_i$$ is the Annual Rate of Occurrence for the $$i$$-th asset.
                     Mini-Exercise #slide 
                         You are the IT security manager of a small company that processes sensitive customer data. The company has recently experienced a security breach that resulted in the loss of 500 customer records. The company's CEO has asked you to provide a report on the breach's potential financial impact and recommend measures to prevent future incidents.
                         Each customer record has a value of $50. The company has experienced two similar security breaches in the past three years. Implementing security measures would cost $10,000 annually.
                         Tasks:
                             0. What are the costs and what are the benefits in this scenario?
                             1. Calculate the SLE.
                             2. Estimate the ARO.
                             3. Calculate the ALE.
                             4. Calculate the ROI of implementing security measures.
                             5. Plot the investment utility function.
                             6. Recommend suitable security measures.
                     Solution #slide 
                         The Single Loss Expectancy (SLE) of the security breach can be determined by estimating the cost of the loss that could result from a single incident: SLE = $50 x 500 = $25,000.
                         The Annualized Rate of Occurrence (ARO) of a security breach can be estimated by determining how often similar security breaches have occurred in the past: ARO = 2 / 3 = 0.67.
                         The Annual Loss Expectancy (ALE) can be calculated by multiplying the SLE by the ARO: ALE = $25,000 x 0.67 = $16,750.
                         To calculate the ROI of implementing security measures, divide the potential cost savings (ALE) by the cost of the security measures: ROI = ($16,750 - $10,000) / $10,000 = 0.675 or 67.5%.
                         Based on the ROI, it is recommended to implement the security measures as they would result in a positive return on investment. The company can consider measures such as enhancing access controls, implementing intrusion detection and prevention systems, and providing security awareness training to employees.
                     Research Insight -- MAEVA Framework #h 
                     Research Extensions: Multi-Returns of Multi-Security Investments #h #novel 
                         Motivation: Securing Logical Assets #slide 
                             We would like to apply the previous ideas to more complex assets.
                             A logical asset is a system, composed of several sub-systems. 
                             We examine a system $$a$$ with $$m>1$$ components $$a_1, \ldots, a_m$$.
                             Also, we might want to implement several security investments (controls/security policies).
                             Denote $$n>1$$ the number of these different types of security investments $$I_1, \ldots, I_m$$.
                             In the model, $$b_i$$ will be defined as the asset value of $$a_i$$ and $$c_i$$ as the costs for applying $$I_j$$ for $$i=1,\ldots,m$$ and $$j=1,\ldots,n$$.
                         Examples -- Illustration #slide 
                             ![Pasted image](https://dynalist.io/u/JRG-aJKxGNwECAUg7ItaUOtu) #eyo-style:Normal 
                         Security Investments for System 1 #slide 
                             Example for System 1: asset $$a$$ is a network with $$a_1$$ a firewall and $$a_2$$ an end-device (PC)
                             Assumption: there are no internal threats in the system.
                             Security inter-dependencies:
                                 If $$a_1$$ is secure, the overall system $$a$$ is secure (whether $$a_2$$ is secure or not, as it will not be compromised internally and is protected externally through $$a_1$$).
                                 If $$a_1$$ is not secure,  then $$a$$ is secure, as long as $$a_2$$ is secure.
                             We want to study the overall security achieved by the following security investments:
                                 $$I_1$$: Harden the firewall
                                 $$I_2$$: Patch the PC
                         Security Investments for System 2 #slide 
                             Example for System 2: a network consisting of two connected PCs $$a_1$$ and $$a_2$$.
                             They have different vulnerabilities and different asset values.
                             Security inter-dependencies:
                                 The system is secure, if both $$a_1$$ and $$a_2$$ are secure.
                                 But both assets are independent in terms of their security.
                             Study the security achieved by the following investments:
                                 $$I_1$$: Patch the PC $$a_1$$
                                 $$I_2$$: Patch the PC $$a_2$$
                         Multi-Asset Returns of (Single) Investment (M-ROI) #slide  #econ #security #VNM 
                             Let us consider an extension of the ROI concept to $$m$$ multiple assets, secured by the same investment.
                             Example for $$m=2$$: 
                                 Utility function for investment securing two assets:
                                     $$u(\lambda)= \begin{pmatrix} b_1 \\ b_2 \\  \end{pmatrix}-(\lambda+1)\begin{pmatrix} c_1 \\ c_2 \\ \end{pmatrix}\ge 0$$.
                                 This vector function does in general not have a value $$\rho$$ satisfying $$u(\rho)=\begin{pmatrix} 0 \\ 0 \\  \end{pmatrix}$$, so it is difficult to define ROI that way.
                         M-ROI Approach #slide 
                             Motivation: we could add the ROIs of the individual asset investments, but only if they are independent (see ALE for multiple assets)
                             Weighted asset selection vector $$x^\top = (x_1,x_2)$$ allows for distribution of allocated intensity:
                                 Denote $$\rho:=ROI(a_1,a_2)$$.
                                 Assume $$x^\top u(\rho)\ge 0$$ and solve for $$\rho$$.
                                 We require
                                     $$x^\top u(\rho)=x^\top\begin{pmatrix} b_1-c_1-\rho c_1 \\ b_2-c_2-\rho c_2 \end{pmatrix}\ge 0$$.
                                 This yields 
                                     $$ROI(a_1,a_2)=\rho \le \frac{x_1(b_1-c_1)+x_2(b_2-c_2)}{x_1c_1+x_2c_2}= \frac{x_1(b_1-c_1)}{x_1c_1+x_2c_2}+\frac{x_2(b_2-c_2)}{x_1c_1+x_2c_2}$$
                                     $$\le \frac{b_1-c_1}{c_1}+\frac{b_2-c_2}{c_2}=ROI(a_1)+ROI(a_2)$$.
                             Hence we could define 
                                 $$\rho:=\max \lambda$$  s.th. $$\exist x_1,x_2:x^\top u(\lambda)\ge 0$$.
                         Return of Multi-Investments (ROI-M) #slide 
                             This is an extension to $$n$$ multiple security investments made for the single asset.
                             Example for $$n=2$$: 
                                 Utility function for two investments, acting as overlapping controls
                                     $$u(\lambda)= \begin{pmatrix} b_1 & b_2 \\  \end{pmatrix}-(\lambda+1)\begin{pmatrix} c_1 & c_2 \\ \end{pmatrix}$$.
                         ROI-M Approach #slide 
                             There is a different parameters to optimise now:
                                 Weighted security control ("layered defense'') selection vector $$y = \begin{pmatrix} y_1 \\ y_2 \\  \end{pmatrix}$$.
                                 Minimise $$\lambda$$ over $$u(\lambda)y$$, the assignment of invested capital.
                                 Why? Consider the attacker's mind!
                             Economics context:
                                 Investment returns are produced goods.
                                 The production creates costs.
                                 These should be minimised.
                             Interpretation for security domain:
                                 Security investments can be done in several ways.
                                 The attacker wants them to be as ineffective as possible, potentially for a single (or small number of) assets.
                                 This creates maximal damage for the defending organisation.
                                 Hence the minimiser function can predict incoming attacks (principle of easiest attack).
                         Multi-Asset Returns of Multi-Investments (M-ROI-M) #slide 
                             Combine both extensions to model $$n$$ multiple investments made for each of the $$m$$ assets.
                             There are two parameters to optimise now:
                                 Maximise $$\lambda$$ over selection of covered assets
                                 Minimise $$\lambda$$ over assignment of security controls
                             One can show that these values are so-called equilibrium value of the Von Neumann economical growth model.
                         Generic M-ROI-M Model ($$m=2, n=2$$) #slide 
                             Asset selection vector $$x^\top = (x_1,x_2)$$.
                             Layered-defense vector ("security policy'') $$y = \begin{pmatrix} y_1 \\ y_2 \\ \end{pmatrix}$$.
                             Matrix ROI for asset consisting of two inter-dependent assets: 
                                 $$U(\lambda)= \lambda\begin{pmatrix} c_{11} & c_{12}\\ c_{21} & c_{22} \\ \end{pmatrix}-\begin{pmatrix} b_{11}-c_{11} & b_{12}-c_{12}\\ b_{21}-c_{21} & b_{22}-c_{22} \\ \end{pmatrix} =: \lambda C -B$$.
                             Definition of upper and lower ROI:
                                 $$\rho^+:=\max \lambda$$  s.th. $$\exist x:\,x^\top U(\lambda)\ge 0$$.
                                 $$\rho^-:=\min \lambda$$  s.th. $$\exist y:\,U(\lambda)y\ge 0$$.
                         Example 1 Revisited #slide 
                             Security Investments:
                                 If we use $$I_1$$ (harden firewall) then: 
                                     $$b=b_1 + b_2$$,
                                     $$c=c_1$$.
                                 If we use $$I_2$$ (patch PC) then: 
                                     $$b=b_2$$,
                                     $$c=c_2$$.
                             This is M-ROI-M Model with $$m=2, n=2$$, and
                                 $$U(\lambda)= \lambda\begin{pmatrix} c_{1} & c_{1}\\ c_{2} & c_{2} \\ \end{pmatrix}-\begin{pmatrix} b_{11}-c_{1} & b_{12}-c_{1}\\ b_{21}-c_{2} & b_{2}-c_{2} \\ \end{pmatrix}$$.
                         Example 2 Revisited #slide 
                             If we patch the PC $$a_1$$ then:
                                 $$b=b_1$$,
                                 $$c=c_1$$.
                             If we patch the PC $$a_2$$ then
                                 $$b=b_2$$,
                                 $$c=c_2$$.
                             If we patch both PCs $$a_1, a_2$$ then
                                 $$b=b_1+b_2$$,
                                 $$c=c_1+c_2$$.
                             This is M-ROI-M Model with $$m=2, n=2$$, and two independent assets:
                                 $$U(\lambda)= \lambda\begin{pmatrix} c_1 & 0\\ 0 & c_2 \\ \end{pmatrix}-  \begin{pmatrix} b_1-c_1 & 0\\ 0 & b_2-c_2 \\  \end{pmatrix}=(\lambda+1)\begin{pmatrix} c_1 & 0\\ 0 & c_2 \\ \end{pmatrix}-  \begin{pmatrix} b_1 & 0\\ 0 & b_2\\  \end{pmatrix}$$.
                         KNOWLEDGE #hh #wfe-ignore-item 
                 The Economics of Cybercrime #h #eyo-style:Section 
                     Introduction #slide 
                     The Model #slide 
                         Source: \cite{Anderson2013-nq}
                     Defender Cost #slide 
                         When an asset is attacked, there is damage/harm/loss, resulting in a cost
                         It might cost time and money to defend/repair an asset
                         There could also be other hidden costs
                         We will present a cost model, inspired by Anderson's taxonomy \cite{Anderson2013-nq} on the cost of cybercrime 
                         Approach: scaling up the notion of a "system": 
                             Society becomes organisation
                             People asset turns into a generic asset of organisation
                             Use of computers in society is mapped into business operations
                     Defender Cost Framework #slide 
                         We would like to quantify both tangible and intangible costs
                         Can distinguish between __direct __and__ indirect loss__ as well as __defence cost__
                             Direct losses:
                                 Replacing or repairing an asset
                             Indirect  losses:
                                 Loss of business
                                 Loss of reputation
                                 Fines
                             Defence cost: develop, deploy and maintain defence mechanisms
                     Defender Benefit #slide 
                         We usually get some "operational benefit" from a digital asset
                             This could be revenues (in a business organisation)
                             Individuals get benefits for their leisure activities, e.g. improved communications and information sharing
                         Question: how can we quantify this?
                         It might be reasonable to assume that this is proportional to the asset value
                         Could then be used for the cost-benefit analysis
                     Example -- Phishing #slide 
                         Direct losses
                             criminal revenue
                             time and effort to reset account credentials
                             secondary costs of overdrawn accounts (deferred purchases) lost attention and bandwidth caused by spam messages
                         Indirect losses
                             loss of trust in online banking
                             lost opportunity for banks to communicate via email efforts to clean-up PCs infected with malware
                         Defense costs
                             security products (spam filters, antivirus)
                             services for consumers (training) & industry (take-down) fraud detection, tracking, and recuperation efforts
                             law enforcement
                         Criminal revenue
                             sum of the money withdrawn from victim accounts
                             revenue to spammer for sending phishing mails
                 Game theory in security #h 
                 References #slide 
             Security Management #h 
                 MATURE FRAMEWORKS
                     OCTAVE (Operationally Critical Threat, Asset and Vulnerability Evaluation)
                         Overview
                             OCTAVE -- a well-documented, open security risk assessment methodology.
                             Set of tools, techniques and methods for risk-based information security strategic assessment and planning
                             Developed by Christopher Alberts at Carnegie Mellon University (CMU)
                             Published by Software Engineering Institute (SEI) at CMU in 1999
                             More information is available at the [CERT website](http://www.cert.org/octave/)
                         Characteristics
                             Philosophy/Vision
                                 Focuses on strategy
                                 Take into account the organisations needs
                             Risk Assessment:
                                 Top-down approach
                                 Threat-per-asset based
                                 Qualitative approach
                             Implementation:
                                 Flexible: Can be customized
                                 Self-directed: led by organisations employee
                         Variants
                             OCTAVE -- suitable for large organisations ( 300 employees)
                                 Phase 1: Build asset-based threat profiles 
                                     Process 1: Determine critical assets and how they are currently protected 
                                     Process 2: Identify security requirements for each critical asset. 
                                     Process 3: Identify organisational vulnerabilities within existing practices 
                                     Process 4: Create a Threat Profile for each critical asset 
                                         Asset (what is at risk)
                                             The (critical) asset that is potentially affected by the threat 
                                             Remember the asset categories: 
                                                 Data 
                                                 Software 
                                                 Hardware 
                                                 People 
                                         Actor (origin of the threat)
                                             OCTAVE distinguishes between the actors "nature" and "human" 
                                         Motive (reason for the attack) 
                                             Attackers might be classified according to his/her motive: 
                                                 Amateurs 
                                                 Script Kiddies
                                                 Geeks
                                                 White Hat (Ethical) Hackers 
                                                 Grey Hat Hackers 
                                                 Black Hat Hackers (Computer Criminals) 
                                         Access (how the asset is reached)
                                             An attack vector is a path or means by which the attacker can gain access to an asset 
                                             Attack vectors enable the exploitation of system vulnerabilities, including the human element. 
                                             Examples: 
                                                 A web interface with an XSS vulnerability  
                                                 An employee with a weak password 
                                         Outcome (damage likely to be caused)
                                             Outcome is one of the following: disclosure, modification, loss/destruction, interruption, or other 
                                             It is measured by the impact on the organisation -- the overall cost of losing an asset 
                                         Mini-Exercises: Threat Profile 
                                             For this exercise, you will review the latest developments concerning the ENISA (EU/Brexit InfoSec) vulnerability and create a threat profile of the most critical asset, relevant in this scenario.
                                             Reminder: a threat profile consists of the following attributes:
                                                 Asset (e.g. customer data, pc,)
                                                 Access (e.g. private/public network, web page)
                                                 Actor (Source of threat)
                                                 Internal (e.g. staff), External (e.g. hacker)
                                                 Motive (accidental, deliberate)
                                                 Outcome (Impact of asset e.g. data loss)
                                             Solutions
                                                 Threat 1: interception of confidential data/info by EU-internal attacker.
                                                     Asset:
                                                         Data in transit between a EU country and the UK.
                                                             criminal records
                                                             traveller information
                                                     Access:
                                                         COMPLICATED!
                                                     Actor:
                                                         Another member country of the EU
                                                     Motive (accidental, deliberate):
                                                         accidential
                                                     Outcome (disclosure, modification, loss/destruction, interruption, or other):
                                                         disclosure
                                                 Threat 2: interception of confidential data/info by attacker external to the EU-internal
                                                 Threat 3
                                                 :
                                                 :
                                                 :
                                                 :
                                                 :
                                                 Threat 1407
                                 Phase 2: Identify infrastructure vulnerabilities 
                                     Process 5: Identify network access paths and IT components related to critical assets 
                                     Process 6: Evaluate identified IT components 
                                 Phase 3: Develop security strategy and mitigation plans 
                                     Process 7: Conduct risk analysis 
                                         Goal: to identify and evaluate the impact of threats to critical assets 
                                         OCTAVE forms a risk profile by expanding the threat profile by two additional attributes:
                                             Impact description -- "The disclosure of the sensitive documents mean that our competitors know our trade secrets and might be able to come out with a competitive new product."
                                             Impact value -- usually chosen from {low, medium, high}, looking at impact areas such as:
                                                 Reputation/customer confidence
                                                 Life/health of customer
                                                 Fines/Legal penalties
                                                 Financial
                                                 etc
                                         Mini-Exercises: Risk Profile 
                                             Consider the threat profile from the previous exercise and complete it to a risk profile. 
                                                 Impact description:
                                                     Act of terrorism, committed in the EU with one nationality, and travelling back to UK with another nationality-passport and hence he/she is not arrested at the border.
                                                 Impact value:
                                                     Potentially high.
                                         Criticism: this approach is quite rudimentary and does not fully implement a risk analysis as we have introduced earlier. 
                                     Process 8: Develop protection strategy and mitigation plan 
                                         Information generated by Phases 1 and 2 are analysed to:
                                             Identify risks to critical assets - prioritise
                                             Develop protection strategies
                                             Develop mitigation plans
                                             Propose next steps
                                         Will need Senior Management approval
                             OCTAVE-S -- organisations  300 employees
                                 Developed in 2003 in response to needs of smaller organisations
                                 Meets same OCTAVE criteria but is adapted to more limited means and unique constraints of small organizations
                                     Small organisation with a simple hierarchical structure
                                     Small interdisciplinary analysis team (3-5 employees)
                                 Uses more streamlined processes and different worksheets, but produces the same type of results
                                 Includes a limited exploration of the computing infrastructure during Phase 2
                             OCTAVE Allegro -- focuses on information assets
                                 What is OCTAVE Allegro?
                                     Developed in 2007 due to the increased need to protect data
                                     Derived from earlier OCTAVE and OCTAVE-S methodologies.
                                     Unlike previous OCTAVE approaches, it focuses on information assets:
                                         Where they are stored, transported, and processed
                                         How they are used
                                         How they are exposed to threats, vulnerabilities, and disruptions as a result
                                 Consists of eight steps organized into four phases:
                                     Develop risk measurement criteria consistent with the organization's mission, goal objectives, and critical success factors.
                                     Create a profile of each critical information asset that establishes clear boundaries for the asset, identifies its security requirements, and identifies all of its __containers__.
                                     Identify threats to each information asset in the context of its containers.
                                     Identify and analyse risks to information assets and begin to develop mitigation approaches.
                         Strengths
                             Well-documented through published academic papers and freely available resources
                             Flexible as organisations may choose to implement portions that they find appropriate
                             Comprehensive and thorough
                             Strategic as it focuses on important and relevant risks
                             Cheap as it is self-led
                         Shortcomings
                             Needs extensive preparation and is complex when done correctly
                             Qualitative methodology means that OCTAVE does not allow for the mathematical modelling of risks
                             Risk Analysis is simplistic as done on a single asset and does not use any mathematical model
                     STRIDE and DREAD -- a (web) application security risk analysis framework, developed for Microsoft's threat modelling framework
                         STRIDE and DREAD are threat classification models originally designed for web application security.
                             Developed by Microsoft in 2005
                             Now also recommended by OWASP
                             Is top-down: focuses on threats (threat/risk modelling)
                             A simple approach
                             An iterative process
                         Illustration
                             ![](https://i-msdn.sec.s-msft.com/dynimg/IC101260.gif)
                             STRIDE is part of the bigger picture of threat modelling.
                         The STRIDE mnemonic conveniently covers most relevant threats to CIA.
                             ![](https://www.dropbox.com/s/5gnjyxyp95j87po/STRIDE.jpg?dl=1)
                         DREAD is a mnemonic that can be used for impact-assessing activity.
                             **D**amage -- how bad would an attack be?
                             **R**eproducibility -- how easy is it to reproduce the attack?
                             **E**xploitability -- how much work is it to launch the attack?
                             **A**ffected users -- how many people will be impacted?
                             **D**iscoverability -- how easy is it to discover the threat?
                         STRIDE proceeds in 4 steps.
                             Step 1. Create a list including all known threats, mapped against their impact.
                             Step 2. Rank threats by criticality (impact) and likelihood.
                                 For each threat, assign two numbers $$c$$ and $$l$$:
                                     $$c$$ -- criticality (10 is most severe)
                                     $$l$$ -- likelihood (10 is least likely to occur)
                                 Calculate overall risk as $$R = c/l$$.
                                 DREAD (and its successor alternatives) can be used to decide on criticality value $$c$$.
                                     When a given threat is assessed using DREAD, each category is given a rating. 
                                         Rating scales running from 0 to 10 are common -- for example, 10 for high, 5 for medium, 1 for low and 0 for none. 
                                         The sum of all ratings for a given exploit can be used to prioritize among different exploits.
                                     It was previously used at Microsoft and currently used by OpenStack and many other corporations but it was discovered that the ratings are not very consistent and subject to debate. 
                                     It was out of use at Microsoft by 2008.
                                     Discoverability Debate -- some security experts feel that including the "Discoverability" element as the last "D" rewards Security through Obscurity.
                                     Some organizations have either moved to a DREAD-D "DREAD minus D" scale (which omits Discoverability) or always assume that Discoverability is at its maximum rating.
                             Step 3. Select a mitigation technique or technology for each threat
                             Step 4. Start again (Step 1) as the project evolves
                         The main advantage of STRIDE is its simplicity and effectiveness.
                             STRIDE was originally designed for building secure web applications, whereas OCTAVE targets (information) security of an organisation.
                             Both frameworks are top-down, but the OCTAVE has a more formal approach for identifying critical assets and their vulnerabilities.
                             In OCTAVE, threat profiling is very generic, whereas the STRIDE acronym helps to identify relevant threat categories.
                             OCTAVE also lacks specific guidelines for risk analysis, STRIDE has developed the DREAD categorisation for threat outcomes.
                         Mini-Exercise
                             Choose a threat in a application-related area. 
                             Compare and contrast its OCTAVE threat and risk profiles and its STRIDE/DREAD classification.
                             Threat: Premature roll-out (deployment) of software with a security vulnerability.
                                 OCTAVE:
                                     Build threat profile....
                                         Actor
                                         Motive
                                             Negligence, Greed, Revenge
                                 STRIDE
                                     This threat is escaping the technology-focussed mnemonic, which does not cover the area of policies and procedures!
                         References
                             [https://en.wikipedia.org/wiki/STRIDE_(security)]
                             [https://msdn.microsoft.com/en-us/library/ee823878(v=cs.20).aspx] 
                             [https://en.wikipedia.org/wiki/DREAD_(risk_assessment_model)]
                     FAIR (Factor Analysis of Information Risk)
                     TARA (Threat Agent Risk Assessment) -- risk analysis methodology, part of Intels in-house security management framework
                     CORAS: Complex risk management framework, resulting from EU-project
                     NIST RMF -- risk management framework
                         Background
                             NIST RMF: National Institute of Standards &amp; Technology Risk Management Framework
                             RMF is a US national standard
                             Used by government organisations throughout the US
                             High-level framework for managing organisational risk
                             Contains a series of activities, organised in phases
                         NIST Risk Management Stages
                             Risk Framing
                                 Purpose: to produce a risk management strategy
                                 Establishes a foundation for managing risk and delineates the boundaries for risk-based decisions within organizations.
                                 Making explicit and transparent the risk perceptions that organizations routinely use in making both investment and operational decisions.
                                 Describes the environment in which risk-based decisions are made.
                             Risk Assessment
                                 Risk assessment is the process of identifying, estimating, analysing and prioritizing information security risks within the context of the organizational risk frame.
                                 Definition of Risk
                                     Risk is a measure of the extent to which an entity is threatened by a potential circumstance or event, and is typically a function of: 
                                         (i) the adverse impacts that would arise if the circumstance or event occurs;
                                         (ii) the likelihood of occurrence. 
                                     Information security risks are those risks that arise from the loss of confidentiality, integrity, or availability of information or information systems
                                 Approaches
                                     Assessment approach (e.g., quantitative, qualitative, or semi-qualitative), specifying the range of values those risk factors can assume during the risk assessment and how combinations of risk factors are identified/analyzed so that values of those factors can be functionally combined to evaluate risk
                                     Analysis approach (e.g., threat-oriented, asset/impact-oriented, or vulnerability-oriented), describing how combinations of risk factors are identified/analyzed to ensure adequate coverage of the problem space at a consistent level of detail.
                                     ![](https://www.dropbox.com/s/8oj1qy63icawnju/NIST%20Risk%20Framing.png?dl=1)
                                 Risk Assessment Stages and Purpose: 
                                     Risk Identification
                                         Identify critical assets
                                         Identify security requirements
                                         Identify threats and vulnerabilities
                                             threats to organizations (i.e., operations, assets, or individuals) or threats directed through organizations against other organizations or the Nation;
                                             vulnerabilities internal and external to organizations;
                                     Risk Analysis
                                         Assessing risk requires the careful analysis of threat and vulnerability information to determine both:
                                             the extent to which circumstances or events could adversely impact organizational operations (i.e., mission, functions, image, or reputation), organizational assets, individuals, other organizations, and the Nation.
                                             the likelihood that such circumstances or events or harm will occur.
                                     Risk Evaluation
                             Risk Response
                                 Addresses how organisations respond to risk, determined through a previous risk assessment.
                                 Response needs to be consistent, organisation-wide in accordance with the organizational risk frame by:
                                     (i) developing alternative courses of action for responding to risk;
                                         Security planning
                                     (ii) evaluating the alternative courses of action;
                                         Evaluating controls
                                     (iii) determining appropriate courses of action consistent with organizational risk tolerance;
                                         Selecting controls 
                                     (iv) implementing risk responses based on selected courses of action.
                                         Implementing controls
                                 Risk Response Matrix
                                     We can use the following table:
                             Risk Monitoring
                                 Addresses how organizations monitor risk over time. 
                                 The purpose of the risk monitoring component is to:
                                     (i) determine the ongoing effectiveness of risk responses (consistent with the organizational risk frame);
                                     (ii) identify risk-impacting changes to organizational information systems and the environments in which the systems operate;
                                     (iii) verify that planned risk responses are implemented and information security requirements are satisfied.
                             Illustration: Information and Communications Flows
                                 ![](https://www.dropbox.com/s/9zv3uqi572i762u/NIST%20RMF.png?dl=1)
                         Strengths
                             Widely accepted and approved, effectively a (national) standard
                             Improve information security by strengthening risk management processes
                             Encourage reciprocity among federal agencies
                             Is constantly being reviewed and updated
                             Commercial plug-in tools exist, that are compatible with the framework
                         Shortcomings
                             RMF is a document, not an automated tool  needs considerable additional work in-house
                             Complex  no light version for small organizations
                             Needs to be used competently
                             Difficult terminology used throughout framework
                         Example Standards
                             FIPS Publication 199 (Security Categorization)
                             FIPS Publication 200 (Minimum Security Controls)
                             NIST Special Publication 800-18 (Security Planning)
                             NIST Special Publication 800-30 (Risk Assessment)
                             NIST Special Publication 800-37 (System Risk Management Framework) 
                             NIST Special Publication 800-39 (Enterprise-Wide Risk Management)
                             NIST Special Publication 800-53 (Recommended Security Controls)
                             NIST Special Publication 800-53A (Security Control Assessment)
                             NIST Special Publication 800-59 (National Security Systems)
                             NIST Special Publication 800-60 (Security Category Mapping)
                     ISO/IEC 27000-series
                         Overview
                             Information Security Management Systems (ISMS) Family of international standards
                             Published by International Organization for Standardization (ISO) & International Electrotechnical Commission (IEC)
                             ISMS is a systematic approach for establishing, implementing, operating, monitoring, reviewing, maintaining and improving an organisations information security
                             Is an international Standard for security management
                             Consists of inter-related standards -- to date 23 standards available, 11 under development
                         ISMS Family of Standards Relationships
                             ![](https://www.dropbox.com/s/gavmrasd7widt0s/iso27000.jpg?dl=1)
                         Areas Covered
                             Information assets & relevant requirements identification
                             Risk Assessment & Treatment
                             Controls Selection & implementation
                             Monitor, maintain and improve the effectiveness of controls associated with assets
                         Selected Individual Standards
                             ISO/IEC 27000
                                 Part of a growing family of ISO/IEC Information Security Management System (ISMS) standards
                                 Assists organisations of all types and sizes to implement and operate an ISMS
                                 Provides introduction to the entire ISO/IEC 27000 family of ISMS standards
                                 Glossary of fundamental terms and definitions used throughout the ISO/IEC 27000 family
                             ISO/IEC 27005
                                 First version in 2008
                                 Replacement for the Management of Information & Communications Technology Security (MICTS) standards
                                 Steps:
                                     Risk Analysis
                                     Risk Identification
                                     Risk Estimation
                                     Risk Evaluation
                                     Risk Mitigation
                         Discussion
                             Advantages
                                 Framework is made out of (international) standards
                                 Supported by several other frameworks
                                 Flexibility in the choice of complementary low-level Risk Assessment method
                             Shortcomings
                                 Documentation is not free
                                 Highly complex
                                 Risk Analysis process is described at a very abstract level
                                 Third-party Risk Assessment method required in order to carry out a comprehensive Risk Assessment
                 Vulnerability Management
                     Vulnerability Assessment 
                     Vulnerability Scanning 
                     Vulnerability Patching 
                         Vulnerability Scoring
     Economics #h 
         Digital Economy #h 
         Absolutely! In a **digital economy**, these terms take on modern, technology-driven meanings:
             **Economy**  The digital economy encompasses all economic activities driven by digital technologies, such as online transactions, remote work, and data-driven business models, influencing global markets.
             **Sector**  The digital economy spans multiple sectors, including e-commerce, digital finance, online education, and cybersecurity, all contributing to innovation and economic growth.
             **Industry**  Digital industries include e-commerce, fintech, software development, social media, and cloud computing, all of which rely on digital infrastructure to operate.
             **Goods**  In the digital economy, goods can be physical (like smartphones and laptops) or digital (such as e-books, software, NFTs, and online courses).
             **Production**  Digital production involves coding software, creating digital content, developing AI models, or providing cloud-based services, often with lower physical resource requirements than traditional industries.
             **Cost**  Costs in the digital economy include cloud storage, software development, cybersecurity, and data management, often focusing on intellectual property and digital infrastructure rather than raw materials.
         The digital economy transforms traditional economic activities by prioritizing data, automation, and global connectivity, reshaping industries and business models.
     Mathematics #h
         Algebra #h
             #15-XX Linear and multilinear algebra; matrix theory
                 15Axx Basic linear algebra 
                     Vectors and Matrices for GT #slide #paper:order-2-barrier #paper:adv-learning #CYENS 
                         $$A, B$$ -- real matrices of dimension $$n\times m$$ #CYENS 
                         $$A, B$$ -- square, real matrices of dimension $$n$$ #paper:order-2-barrier #paper:adv-learning 
                         $$x, y$$ -- real column vectors #paper:order-2-barrier #CYENS 
                         $$x$$ -- real row vector #paper:order-2-barrier #paper:adv-learning #CYENS 
                         $$y$$ -- real column vector #paper:order-2-barrier #paper:adv-learning #CYENS 
                         All vectors will be column vectors and 
                         The row vector corresponding to $$x$$ will be written as $$^t\!x$$. #CYENS 
                         The symbol $$\ge$$ means each element in the vector is greater than the element in the other.
                         $$e$$ -- a column vector consisting only of entry 1. #paper:order-2-barrier #paper:adv-learning #CYENS 
                         $$E$$ -- the square matrix with all entries set to 1. #paper:order-2-barrier #paper:adv-learning 
                         The dimensions of $$x$$, $$y$$, $$e$$ and $$E$$ which will be clear from the context. #paper:order-2-barrier #paper:adv-learning 
                     Eigensysstems #h 
                         Standard #h 
                             The __spectrum__ $$\sigma(A)$$ is the set of eigenvalues of the matrix $$ A$$, and we denote $$\rho(A)$$ the __spectral radius__ of a matrix $$A$$, defined as $$\max \{|\lambda|: \lambda \in \sigma(A)\}$$.
                     Matrix pencils #15A22
                         Regular Matrix Pencils and their Eigensystems #slide
                             Notations -- GameSec #slide 
                                 $$A, B\in K^{n\times n}$$, $$K$$ a field of characteristic 0, $$\bar{K}$$ algebraic closure
                                 Regular matrix pencil $$A-\lambda B$$ with $$\text{rank}(B)=r\le n$$
                                 A __matrix pencil__ is an expression of the form $$A-\lambda B$$ where $$\lambda$$ is an indeterminate
                                 The matrix pencil $$A-\lambda B$$ is a __regular__ matrix pencil if the matrices $$A$$ and $$B$$ are square and the characteristic polynomial $$f(\lambda)=\det(A-\lambda B)$$ does not vanish identically: $$f(\lambda)  \not\equiv 0$$
                                 Otherwise, it is referred to as __singular__
                                 We have $$\deg(f) \le r$$.
                                 The concept of eigenvalues can be generalised to regular matrix pencils as follows: 
                                 __Left__ (__right__ respectively) __generalised eigenvectors__ with respect to the finite eigenvalue $$\mu$$ are nonzero solutions of the equation $$x^\top(A-\mu B)=0$$ (the equation $$(A-\mu B)y=0$$ respectively), where $$\mu$$ is a generalised eigenvalue. 
                                 If $$B=I$$, the finite eigenvalues are identified with the eigenvalues of $$A$$ in the usual sense. 
                             Definition #slide 
                                 $$A, B\in K^{n\times n}$$, $$K$$ a field of characteristic 0, $$\bar{K}$$ algebraic closure
                                 Regular matrix pencil $$A-\lambda B$$ with $$\text{rank}(B)=r\le n$$
                                 A __matrix pencil__ is an expression of the form $$A-\lambda B$$ where $$\lambda$$ is an indeterminate
                                 The matrix pencil $$A-\lambda B$$ is a __regular__ matrix pencil if the matrices $$A$$ and $$B$$ are square and the characteristic polynomial $$f(\lambda)=\det(A-\lambda B)$$ does not vanish identically: $$f(\lambda)  \not\equiv 0$$
                                 Otherwise, it is referred to as __singular__
                                 We have $$\deg(f) \le r$$.
                             Pencil Eigenvalues -- Definition #slide 
                                 The concept of eigenvalues can be generalised to regular matrix pencils as follows: 
                                     Consider the pairs $$(\beta,\alpha) \in \bar{K}\times\bar{K}$$ such that there exist $$0\neq y \in {\bar{K}}^n$$ verifying $$\beta Ay = \alpha By$$.
                                     Define the equivalence relation
                                         $$(\beta_1,\alpha_1) \sim (\beta_2,\alpha_2)\quad\Longleftrightarrow\quad \beta_1\alpha_2 -  \beta_2\alpha_1 = 0$$.
                                     We define the __spectrum__ $$\rho(A,B)$$ as $$(\bar{K}\times\bar{K})/\sim$$, the set of equivalence classes of $$\sim$$.
                                     This is the set of above pairs $$(\beta,\alpha)$$ modulo the equivalence relation $$\sim$$.
                                     The eigenvalues of the regular matrix pencil $$A-\lambda B$$ will be identified with the elements of $$\rho(A,B)$$.
                             Finite and Infinite Eigenvalues #slide 
                                 The values
                                     $$\left\{ \left. \lambda = \frac{\alpha}{\beta} \;\right|\;[(\beta, \alpha)] \in \rho(A,B), \beta \neq 0 \right\}$$
                                 are the __finite eigenvalues__ of the matrix pencil $$A-\lambda B$$.
                                 If $$[(0, 1)] \in \rho(A,B)$$, it is a representative of the __eigenvalue at infinity__. 
                                 The finite eigenvalues can be identified with the roots of $$f(\lambda) = \det(A-\lambda B)$$.
                                 The algebraic multiplicity of a finite eigenvalue is its multiplicity as a root of $$f$$.
                                 The integer $$d=n-\deg(P)$$ is the multiplicity of the eigenvalue at infinity.
                                 If $$B=I$$, the finite eigenvalues are identified with the eigenvalues of $$A$$ in the usual sense. 
                                 In this case and more generally if $$\det B \neq 0$$, the multiplicity of the eigenvalue at infinity is zero.
                                 Notations: depending on context, we will identify 
                             Eigenspaces and Eigenvectors #slide 
                                 __Left__ (__right__ respectively) __generalised eigenvectors__ with respect to the finite eigenvalue $$\mu$$ are nonzero solutions of the equation $$x^\top(A-\mu B)=0$$ (the equation $$(A-\mu B)y=0$$ respectively), where $$\mu$$ is a generalised eigenvalue. 
                                 "generalised"
                             References #slide 
                                 A good reference for more details on these concepts is the book by Gantmacher \cite{Gantmacher}.
                             INBOX
                                 Spectral Properties #slide 
                                     We denote the __spectrum__ of a regular matrix pencil, which may comprise of both finite eigenvalues and the eigenvalue at infinity, as $$\sigma(A-\lambda B)=\sigma^\circ(A-\lambda B)\cup\sigma^\infty(A-\lambda B)$$.
                                     (Generalised) eigenvalues: finite number of roots of $$f$$, and potentially infinity.
                                     Multiplicity 
                                     Then $$\sigma(A-\lambda I) =: \sigma(A)$$ the set of eigenvalues of the matrix $$A$$.
                                     We say that the spectrum is of __finite__, __infinite__ or __mixed__ type depending on whether the eigenvalues are finite, infinite, or both. 
                                     In the same way as an irreducible matrix has Irreducible matrix, regular matrix pencil
                                     left, right
                                     multiply by left/right
                                 The matrix pencil $$A-\lambda B$$ is a __regular__ matrix pencil if
                                     the matrices $$A$$ and $$B$$ are square and 
                                     $$\det(A-\lambda^* B)  \neq 0$$ for all but a finite number of values of $$\lambda^*$$
                                 Special Pencils for GT #slide #paper:order-2-barrier #paper:adv-learning
                                     We will be interested in matrices of the form $$A-\lambda = ((a_{ij}-\lambda))$$. #paper:adv-learning 
                                     Our preferred notation for these will be matrix pencil representation of the form $$A-\lambda E$$ where $$E$$ is defined as previously. #paper:adv-learning 
                                     It can be seen that for matrix pencils of this special form, under the assumption of regularity, there exists at the most one generalised real eigenvalue, with one corresponding left and right generalised eigenvector. #paper:adv-learning I
                                     n this case, the collection $${\mathcal E}_{A}=(\lambda^*,x,y)$$ of the generalised eigenvalue (if it exists), left and right eigenvectors  will be referred to as the __generalised eigensystem__ associated with the regular matrix pencil $$A-\lambda E$$. #paper:order-2-barrier #paper:adv-learning 
                                     All eigenvectors are assumed to be normalised in order to correspond to mixed strategies #paper:order-2-barrier 
                                     In the remainder of the paper, we will simply refer to __eigenvalues__ and __eigenvectors__, consistently omitting the term "generalised".
                                 Generalised Eigensystems for GT #slide #paper:order-2-barrier #paper:adv-learning
                                     A __generalised eigenvalue__  $$\lambda^*$$ of a regular matrix pencil is a value for which the determinant  $$\det(A-\lambda^* B)$$ vanishes. #paper:order-2-barrier #paper:adv-learning 
                                     These are actually only __finite__ ones, but this is sufficient for the purposes of application in game theory. #paper:order-2-barrier #paper:adv-learning 
                                     Case of regular matrix pencils: finite set, limited by rank of $$B$$ #paper:order-2-barrier
                                     More information about matrix pencils can be found in @ref:Gantmacher. #paper:order-2-barrier #paper:adv-learning 
                                     We remark about the case $$B=I$$ results in the standard concept of eigenvalues and eigenvectors. #paper:order-2-barrier #paper:adv-learning 
                     Special nonnegative matrices and pencils #h 
                         $$M$$-Matrices #h 
                             $$M$$-Matrix Definitions #slide 
                                 A matrix $$M \in \R^{n\times n}$$ is an M-matrix if (i) all off-diagonal entries are less than or equal to zero, and (ii) all principal minors of $M$ are positive.
                                 Non-singular $$M$$-Matrix: $$sI-B$$ where $$s>\rho(B)$$ and $$B\ge 0$$
                                 Singular $$M$$-Matrix: $$\rho(B)I-B$$ where $$B\ge 0$$
                             $$M$$-Matrix Equivalent Definitions #slide 
                                 There are many equivalent conditions 
                                     $$P$$ has only eigenvalues with positive real parts, and the PF property. This means $$-P$$ is a stable matrix. 
                             Nice Screenshot #slide 
                             ![M-Matrix.png](https://dynalist.io/u/rVI97f6vkh7U2xpcKxCPSEpk)
                         H-Matrix
                         $$P$$-Matrices #h 
                             Definition and Properties #slide 
                                 A square matrix A is a $$P$$-matrix if all its principal minors are positive.
                                 Every $$P$$-matrix is diagonally dominant.
                                 A matrix is irreducible if it is not similar to a block diagonal matrix.
                                 Every irreducible $$P$$-matrix is primitive.
                             History and Applications #slide 
                                 First study by Danzig \cite{Dantzig1967-zz}
                                 $$P$$-matrices arise in many fields such as economics, physics, and engineering.
                                 They are used in the study of linear complementarity problems, which are a class of optimization problems.
                                     The linear complementarity problem LCP(M,q) has a unique solution for every vector q if and only if M is a P-matrix.
                                 $$P$$-matrices are also used in the analysis of Markov chains, which are a stochastic model used in probability theory and statistical mechanics.
                                 In addition, $$P$$-matrices have applications in the study of partial differential equations and finite difference methods for solving them.
                         $$Q$$-Matrix
                         F-Matrix #EPF:FMat 
                         $$L$$-Matrix #slide 
                             Definition: $$A$$ is an $$L$$-matrix if the row-rank remains full for all matrices having the same sign pattern as $$A$$.
                         $$Z$$-Matrix #slide 
                             Definition: we have $$a_{ii}>0$$ for $$i=1,\ldots,n$$ and $$a_{ij}\le 0$$ for $$i\neq j$$. 
                             Any $$Z$$-matrix is also an $$L$$-matrix. 
                         F-Transformations #EPF:FTrans #h 
                             Definition #slide 
                                 The pencil $$D-\lambda C$$ is an $$F$$-pencil if there exists a unique, simple eigenvalue $$\lambda>0$$ of ($$C$$, $$D$$) with positive right and left eigenvectors $$x$$ and $$y$$, respectively. The quantities $$\lambda$$, $$x$$, and $$y$$ are called the $$F$$-eigenvalue and the right and left $$F$$-eigenvector of $$D-\lambda C$$, respectively.
                             Necessary Condition #slide 
                                 If $$d_{ii}>0$$ for all $$i\in I$$, and $$d_{ij}\le \lambda c_{ij}$$ for all $$i\neq j$$, then equalities hold in the definition of the von Neumann solutions (lag 0).
                                 If $$d_{ii}>0$$ for all $$i\in I$$, and $$d_{ij}< \lambda c_{ij}$$ for all $$i\neq j$$ for which $$c_{ij} >0$$, and if  $$C$$ is indecomposable, then
                                     $$x$$ and $$y$$ are positive and unique up to scalar multiplication
                                     $$\lambda$$ is a simple root of the characteristic equation $$f(\lambda) = \det(D-\lambda C) = 0$$
                                     No other eigenvalue of $$D-\lambda C$$ has a nonnegative right or left eigenvector.
                             Applications #slide 
                                 EPF-Theory
                                 Economics: von Neumann Growth Model
             Bilinear Algebra #h
                 Bilinear Forms #h 
                     Definition -- Bilinear form
                     A bilinear form on a real vector space V is a function $$B : V \times V \to R$$ mapping a pair of vectors to a real number, while satisfying 
             Linear Algebra #h 
                 Matrix Factorisation #h 
                     Introduction #slide 
                     Definition #slide 
                         $$B \in \R^{n\times n}$$
                         $$B=LR^\top$$ where $$L, R \in \R^{n\times m}$$ $$(m \le n)$$ is a factorisation of $$B$$
                         $$B=LR{}^\top$$ where $$L, R \in \R^{n\times r}$$ ($$r=\text{rank}(B)\le n$$) is a full rank-factorisation of $$B$$
                         The rank-factorisation is unique up to multiplication with a regular matrix $$P\in \R^{r\times r}$$. 
                         Can be computed efficiency, using Gaussian elimination \cite{Piziak1999-iu}. 
                         $$B=LR^\top$$ where $$L, R \in \R^{n\times m}$$ $$(m < n)$$ is a proper factorisation of $$B$$
                     References #h 
                         @ARTICLE{Piziak1999-iu,
                             title     = "Full Rank Factorization of Matrices",
                             author    = "Piziak, R and Odell, P L",
                             journal   = "Math. Mag.",
                             publisher = "Mathematical Association of America",
                             volume    =  72,
                             number    =  3,
                             pages     = "193--201",
                             year      =  1999
                             }
                 Matrix Equations #h
                     Notations #slide #arman 
                         spec($$A$$) -- the spectrum (set of eigenvalues) of the matrix $$A$$.
                         $$\otimes$$ -- the "Kronecker Product", defined as #todo  
                         $$V_{x_1,\ldots, x_n}$$ -- Vandermonde matrix with entries that are powers of $$x_1, ... , x_n$$.
                         So:
$$V_{x_1,\ldots, x_n} = \begin{bmatrix}1 & \cdots & 1 \\ x_1 & \cdots  & x_n \\ x_{1}^2 & \cdots & x_{n}^2 \\ \vdots & & \vdots \\ x_{1}^{n-1} & \cdots & x_{n}^{n-1} \end{bmatrix}$$
                     Sylvester Equation #slide #arman
                         These are matrix equations $$AX - XB = C$$ where $$A$$ and $$B$$ are square matrices of order $$m$$ and $$n$$.
                         Goal is to find the $$m$$ by $$n$$ matrix $$X$$.
                         Theorem.
                             The sylvester equation admits a unique solution $$X$$, iff $$A$$ and $$B$$ have no eigenvalues in common.
                             In this case, the solution is $$x = (I_m \otimes A - B_n^t \otimes I)^{-1} \cdot c$$ where $$x$$ and $$c$$ are the matrices $$X$$ and $$C$$ rearranged as single column vectors.
                     Conjecture #slide #arman
                         Informally:
                             Vandermonde-matrices with pairwise different index sequences $$x_1, ..., x_n$$ and $$y_1, ... , y_m$$ have no eigenvalues in common.
                         Formally:
                             $$x = (x, ..., x_n), y = (y_1, ... , y_n)$$ and $$x_i \neq y_j (\forall i, j)\Leftrightarrow$$ spec($$V_x$$) $$\cap$$ spec($$V_y$$) = $$\emptyset$$.
                 Matrix Theory #slide 
                     Submatrices #slide 
                         First Minor and Co-factor
                             The (__i__, __j__) or __first minor__ $$M_{i,j}$$ of the entry in the __i__th row and __j__th column is the determinant of the submatrix formed by deleting the __i__th row and __j__th column.
                             The (__i__, __j__) __cofactor__ $$C_{i,j}$$ is obtained by the minor as follows: $$ C_{i,j}=(-1)^{i+j}M_{i,j}$$. 
                         Principal Minor 
                             A principal minor is simply the determinant of a submatrix obtained from A when the same set of rows and columns are deleted.
             Solving Algebraic Equations 
                 The Cubic Equation #h 
                     Cardano's Formula #slide 
                         Famous Cardano's Formula (1545):
                             When wanting to solve $$x^3+px+q=0$$, one has
                                 $$x=\sqrt[3]{-\frac{q}{2}+\sqrt{\left(\frac{q}{2}\right)^2+ \left(\frac{p}{3}\right)^3}}+\sqrt[3]{-\frac{q}{2}-\sqrt{\left(\frac{q}{2}\right)^2+ \left(\frac{p}{3}\right)^3}}.$$
                         This formula can actually express up to 3 solutions.
                         We distinguish 3 cases depending on the value of the __discriminant__ $$D:=\frac{q^2}{4}+ \frac{p^3}{27}$$ as follows:
                             (i) $$D > 0$$,
                             (ii) $$D = 0$$,
                             (iii) $$D < 0$$.
                     Case (i): $$D > 0$$ #slide 
                     Case (ii): $$D = 0$$ #slide 
                     Case (iii): $$D < 0$$ #slide 
                     Example 1 #slide 
                     Example 2 #slide 
                     Example 3 #slide 
         Analysis 
         Basic Mathematics #h
             Mathematics #m #maths #maths-engage
                 #wfe-count:exx:0 #wfe-ignore-item #maths-engage #fix #solution 
                 Idea: self assessment https://workflowy.com/#/a323b354ee11
                 Topics #slide #maths-engage 
                     Delivered Maths Knowledge
                         Mathematical Objects, Operations and Algorithms
                         
                         Basic Computational Number Theory
                             Euler's Function
                             Fermat's Little Theorem and Euler's Theorem
                     Reading materials: A. Croft, R. Davidson, Foundation Maths, fifth or sixth edition, Pearson, ISBN-10: 1292170638, ISBN-13: 9781292170633
                 Maths Introduction #CI7100_LO1 #eyo-style:Section #maths-engage
                     Motivation #slide #maths-engage
                         Mathematics is seen as a "tough" subject, hence the need for good educational resources 
                         Aims of this lecture:
                             to improve your "Maths Engagement",
                             to provide a new way of delivery basic maths knowledge,
                             to be useful to students of a range of technical courses.
                         Target audience: 
                             If you had some prior exposure to maths, but you feel "out of touch"
                             If you would like to gain a quick overview of mathematics, useful for computer security/cryptography
                         We cannot cover everything of course, you should consult a good textbook to deepen your engagement 
                     Mathematical Syntax #slide #maths-engage
                         Symbols form an important part of the language of mathematics: __syntax__
                         Main difficulty: use of Greek letters, special symbols and typesetting conventions
                         Variables: 
                             $$a,b,c,\ldots y,z$$
                             $$\alpha, \beta, \gamma,\ldots,\omega$$
                             $$\bar{a}, \tilde{a}, \hat{a}, a_i, \tilde{a}_{ij}, \ldots$$
                         Operators:
                             $$+,\;-,\;\times,\; \cdot,\; :,\; /$$
                         Advanced Operators:
                             $$\sum,\prod, \sqrt{\cdot}$$
                     The Language of Maths (Semantics) #slide #maths-engage
                         Maths is like a language that you need to learn and practice, in order to make sense of
                         ![talkaboutmaths.jpeg](https://www.dropbox.com/s/cidmsxiaiqbynra/1_Nhgyg_QzFlL3uRsH0gorNw.jpeg?dl=1) #eyo-style:Normal 
                 Mathematical Objects #eyo-style:Section #maths-engage 
                     Learning Objectives #slide 
                         Understand the definition of integers and their representation using a number system
                         Be familiar with the structure of univariate polynomials over the integers
                         Appreciate the motivation behind introducing boolean numbers
                     Numbers #eyo-style:Subsection  #h 
                         Integers and Other Numbers #slide #maths-engage 
                             Almost most natural mathematical object
                             Numbers such as -333, -1, 0, 10, 2000,...
                             Mathematical symbol: $$Z$$
                             Union of positive and negative numbers, including 0
                             Good for computer arithmetic, if not too big
                             Other Numbers
                                 Rational Numbers (Fractions)
                                 Irrational Numbers
                                 Real Numbers
                                 Complex Numbers 
                         Number Systems #slide #maths-engage
                             Number system: a scheme to represent integers (or rationals) using digits
                             Traditionally humans have used the decimal system
                             Writing $$d$$ in a number system with basis $$b$$ means computing \[ d_{(b)} = d_{k}b^k + \ldots + d_{1}b + d_0 \quad (d_{i} \in \{0\ldots b-1\}) \]
                             Here $$b$$ is the __basis __and the $$d_i$$ the __digits__
                             Decimal system: $$b = 10$$
                             Binary: $$b = 2$$, hexadecimal: $$b = 16$$, ternary: $$b = 3$$
                             Can also represent fractions, using negative powers of $$b$$
                         Mini-Exercise  #wfe-count:ex #slide #maths-engage
                             Convert $$1010110_{2}$$ into decimal notation.
                             Write the integer 12 as a decimal, binary and ternary number.
                             Convert $$0.011_{2}$$ into decimal notation.
                             Write $$\frac{5}{8}$$ as a binary (optional: ternary) number.
                         Solutions: #slide #maths-engage #solution 
                             $$101 0110_{(2) }= 1\cdot 2^6+1\cdot 2^4+1\cdot 2^2+1\cdot 2^1= 64+16+4+2= 86_{(10) }$$
                             $$12= 12_{(10) }$$ (decimal number)
                             $$12=9+3=1\cdot 3^2+1\cdot 3^1+ 0\cdot 3^0= 110_{(3) }$$ (ternary number) 
                             $$12 =8+4=1\cdot 2^3+1\cdot 2^2+0\cdot 2^1 +0\cdot 2^0= 1100 _{(2) }$$ (binary number)
                             $$0.011_{(2) }=1\cdot 2^{-2}+1\cdot 2^{-3}=\frac{1}{4}+\frac{1}{8}=\frac{3}{8}_{(10) }$$
                             $$\frac{5}{8}=\frac{3}{8}+\frac{2}{8}= (\frac{1}{4}+\frac{1}{8}) +\frac{1}{4}=\frac{1}{8}+\frac{1}{2}=0.101_{(2) }$$
                                 ![mini-exercise-1.png](https://www.dropbox.com/s/a66nv0xf8hxli2v/maths-mini-1.png?dl=1) #eyo-style:Normal #solution #wfe-ignore-item 
                     Polynomials #eyo-style:Subsection  #h 
                         Polynomials #slide #maths-engage
                             Notation: $$f(x)   = \textstyle\sum_{i=0}^{d} a_i x^i\textstyle\in Z[x]$$
                                 $$d =\deg f$$ is the __degree__ of $$f$$
                                 $$a_i$$ are the __coefficients__
                                 $$Z[x]$$: the __ring__ of __univariate__ polynomials with coefficients in the integers
                             Example: $$f(x)=10x^2-5x+1$$ -- what is the degree of $$f$$ ? What are its coefficients?
                     Boolean Numbers #eyo-style:Subsection  #h 
                         Booleans -- Working with Zeros and Ones #slide #maths-engage
                             Fundamental truth values __false __and __true__ could be represented by integers: 0 and 1 
                             Benefits:
                                 Logical reasoning, used to describe real-life scenarios or for mathematical proofs, can be done numerically
                                 Very efficient with computers which use binary numbers internally
                                 Reason: easy to represent digit value of 0 or 1 in hardware
                     Summary #slide 
                         Understand the definition of integers and their representation using a number system
                         Be familiar with the structure of univariate polynomials over the integers
                         Appreciate the motivation behind introducing boolean numbers
                 Mathematical Operations #eyo-style:Section #h 
                     Learning Objectives  #slide 
                         Understand modular arithmetic
                         Know how to work with polynomials
                         Be familiar with the principles of Boolean Algebra
                     Integer Arithmetic #slide #maths-engage
                         We again consider integer numbers
                         We can perform __addition__, __subtraction__, __multiplication __and __division with remainder__
                         Examples for division with remainder:
                             10:5 = 2 since 10 = 2*5 + 0 (remainder 0)
                             19:2 = 9 since 19 = 9*2 + 1 (remainder 1)
                             23:5 = 4 since 23 = 4*5 + 3 (remainder 3)
                         We say that $$a$$ is divisible by $$b$$ if the division of $$a$$ by $$b$$ gives remainder 0
                         In the above example, 10 is divisible by 5
                     The Modulo Operation #eyo-style:Subsection  #h 
                         The Modulo Operation -- Definition #slide #maths-engage
                             Introducing $$a \bmod n$$: the modulo operation is defined as remainder of division of $$a$$ by $$n$$.
                             Example calculations:
                                 $$19 \bmod 5 = 4$$
                                 $$10 \bmod 5 = 0$$
                                 $$19 \bmod 2 = 1$$
                                 $$23 \bmod 5 = 3$$
                             Real world scenario: we know that 25h is the same as 1h -- the clock is counted modulo 24!
                         The Modulo Operation -- Notations #slide #maths-engage
                             Unfortunately, over time mathematicians have adopted different notations
                             __Functional notation__: $$b=\bmod(a,n)$$
                             Example: The input $$a=15$$ and $$n=4$$ gives the output $$b=3$$
                             __Equational notation__: $$a \equiv b \pmod{n}$$ means $$a \bmod n = b \bmod n$$
                             __Lazy mathematician's notation__: simply write $$a \equiv b $$ $$(n)$$
                             Examples:
                                 $$15\equiv 11 \pmod{4}$$
                                 $$4 \equiv 19 \equiv 24 \equiv -1$$ $$(5)$$
                         The Modulo Operation -- Properties #slide #maths-engage
                             You can use the Calculator in Windows to evaluate the mod function
                             Small numbers can be done without a tool
                             Additional Properties:
                                 $$a \bmod n$$ is always smaller than $$n$$
                                 $$a \bmod n=a$$ if $$a &lt; n$$
                                 $$a+k\cdot n \bmod n\equiv a \bmod n$$ (useful if $$a$$ is negative)
                                 $$a \bmod n\equiv b \bmod n$$ is equivalent to saying $$n$$ divides $$a - b$$ (Mathematician's preferred definition)
                         Mini-Exercise  #wfe-count:ex #slide #maths-engage
                             Compute
                                 $$17 \mod 5$$
                                 $$343 \mod 2$$
                                 $$0 \mod 77$$
                                 $$97 \mod 98$$
                                 $$98 \mod 97$$
                                 $$-4 \mod 6$$
                         Solutions: #slide #maths-engage 
                             $$17 \mod 5 = 2$$ \label{firstone}
                             $$343 \mod 2 = 1$$
                             $$0 \mod 77 = 0$$
                             $$97 \mod 98 = 97$$
                             $$98 \mod 97 = 1$$
                             $$-4 \mod 6 = 2$$
                             Alternative notations for \ref{firstone}:
                                 $$17 \mod 5 \equiv 2$$
                                 $$17 \equiv 2 \; \mod 5$$
                                 $$17 \equiv 2 \; (5)$$
                                 $$17 \equiv 2 \equiv 12 \; (5)$$
                                 $$\mod(17,5) = 2$$
                     Modular Arithmetic #eyo-style:Subsection  #h 
                         Modular Arithmetic #slide #maths-engage
                             We can perform addition, subtraction and multiplication modulo $$n$$
                             This confines results to range $$[0..n-1]$$ -- there is no "overflow"
                             Notation: $$a+b \bmod n$$ means $$(a+b) \bmod n$$
                             Similar for $$-$$ and $$\cdot$$, also use exponentiation (power raising)
                             Examples:
                                 $$7 + 5 = 2 \bmod 10$$
                                 Reason: $$7 + 5 = 12\;\;$$ and $$\;\;12 \bmod 10 = 2$$
                                 $$7\cdot 5 = 5 \bmod 10$$
                                 Reason: $$7 \cdot 5 = 35 \;\;$$ and $$\;\;35 \bmod 10 = 5$$
                                 $$7^5 = 16807 = 7 \bmod 10$$
                         Associativity of Modular Arithmetic #slide #maths-engage
                             An operation is __associative__, if brackets can be grouped freely (intermediate results can be computed in any order)
                             It is easy to see that normal addition, multiplication and exponentiation are associative: e.g. $$(1+3) + 4 = 1 + (3+4) = 8$$
                             This is correct for modular arithmetic as well!
                             Example: we want to compute $$(2^5)^2 \bmod 30$$.
                                 \begin{eqnarray*}(2^5 \bmod 30)^2 \bmod 30 & = & (32 \bmod 30)^2 \bmod 30 \\ & = & 2^2 \bmod 30 \\ & = & 4. \end{eqnarray*} #eyo-style:Normal 
                                 On the other hand, check that $$(2^5)^2 = 1024 = 4 \bmod 30$$.
                             Remark: this is used in the proof of correctness for the RSA algorithm
                         Mini-Exercise  #wfe-count:ex #slide #maths-engage
                             Compute:
                                 $$5+7$$ mod $$10$$
                                 $$1+1$$ mod $$2$$
                                 $$1-1$$ mod $$2$$
                                 $$4\cdot 7$$ mod $$27$$
                                 $$14^7 \bmod 13$$
                         Solutions: #slide #maths-engage 
                             $$5+7$$ mod $$10$$ $$= 12 \mod 10 = 2$$
                             $$1+1$$ mod $$2$$ $$= 2 \mod 2 = 0$$
                             $$1-1$$ mod $$2$$ $$= 0 \mod 2 = 0$$
                             $$4\cdot 7$$ mod $$27$$ $$= 28 \mod 27 = 1$$
                             $$14^7 \bmod 13=(14\bmod 13)^7= 1^7 \mod 13 = 1$$
                         Modular Arithmetic Tables #slide #maths-engage
                             A table can be used to illustrate arithmetic -- the entry in position $$(i,j)$$ is assigned to $$\;i+j \bmod n\;$$ (or $$\;i*j \bmod n)$$
                             For example, arithmetic mod 4 can be illustrated using the following tables:
                                 ![mod-arithmetic-tables.png](https://www.dropbox.com/s/zycghqhs0ol08vm/mod-arithmetic-tables.png?dl=1) #eyo-style:Normal 
                         Mini-Exercise  #wfe-count:ex #slide #maths-engage
                             Sketch tables for addition and multiplication mod 2. How could you express this using Boolean operations instead of modular arithmetic?
                         Solutions: #slide #maths-engage 
                             ![mini-exercise-7.png](https://www.dropbox.com/s/v3mvxo07n0vup5f/mini-exercise-7.png?dl=1) #eyo-style:Normal #solution
                     Working with Polynomials #eyo-style:Subsection #h 
                         Working with Polynomials #slide #maths-engage
                             Given $$f, g \in R[x]$$, we can perform addition, subtraction and multiplication
                             Given $$f, g \in R[x],$$ we can also divide $$f$$ by $$g$$ (with remainder): $$f = q \cdot g + r \; (\deg r < \deg g)$$
                             __Evaluation __of $$f(x)$$ at $$x=x_0$$: substitute $$x$$ for value $$x_0$$ and compute the resulting expression
                             __Interpolation__: reconstruction of a polynomial $$f$$ with degree $$d$$, using $$d+1$$ distinct points $$(x_i, f(x_i))$$
                         Mini-Exercise  #wfe-count:ex #slide #maths-engage
                             Given the polynomials $$f(x) = x^3-3x + 1$$ and $$g(x) = x - 1$$, compute
                                 $$f + g$$
                                 $$f - g$$
                                 $$fg$$
                                 $$f$$ divided by $$g$$
                             Factorise $$x^2+x-6$$. #wfe-ignore-item 
                         Solutions: #slide #maths-engage #solution 
                             $$f(x) = x^3-3x + 1$$, $$g(x) = x - 1$$
                             $$f+g= x^3-3x+x+1-1=x^3-2x$$
                             $$f-g=x^3-3x+1-(x-1)=x^3-3x+1-x+1= x^3-4x+2$$
                             $$fg= (x^3-3x+1) (x-1)=x^4-3x^2+x-x^3+3x-1=x^4-x^3-3x^2+4x-1$$
                         Mini-Exercise  #wfe-count:ex #slide #maths-engage
                             Given $$f(x) = 3x^2-4x+5$$, evaluate this polynomial at the points $$x_0=0$$, $$x_0=1$$ and $$x_0=2$$.
                             Perform interpolation using the points $$(1,1)$$ and $$(2,-3)$$ in order to compute a polynomial $$g$$ of degree 1, satisfying $$g(1)=1$$ and $$g(2)=-3$$.
                         Solutions: #slide #maths-engage #solution 
                             $$f(0)=5$$, $$f(1)=3-4+5=4$$, $$f(2) =12-8+5=9$$
                             Put $$g(x)=ax+b$$ and solve $$g(1)=1$$, $$g(2)=-3$$:
                                 $$a+b=1$$ (i) 
                                 $$2a+b=-3$$ (ii) 
                             $$\rightarrow$$ (i)-(ii): $$a=-3-1=-4$$, $$\rightarrow b=5$$
                             $$\rightarrow$$ $$g(x)=-4x+5$$
                                 ![mini-exercise-3.png](https://www.dropbox.com/s/9eymo9n15gly5lq/maths-mini-3.png?dl=1) #eyo-style:Normal #solution #wfe-ignore-item 
                     Boolean Algebra #eyo-style:Subsection #h 
                         Introducing Boolean Algebra #slide #maths-engage
                             Invented by George Boole (1854)
                             Idea: introduce operations on truth values. This maps logics into algebra.
                             The main logical operators are illustrated using the following __truth table__:
                             $$\begin{array}{| c |c|| c | c | c || c | c | c |} \hline x & y & \neg \; x & x \;\wedge\; y & x \;\lor\; y & x \oplus y & x \Rightarrow y & x \Leftrightarrow y \\ \hline 0 & 0 & 1 & 0 & 0 & 0 & 1 & 1 \\ 0 & 1 & 1 & 0 & 1 & 1 & 1 & 0 \\ 1 & 0 & 0 & 0 & 1 & 1 & 0 & 0 \\ 1 & 1 & 0 & 1 & 1 & 0 & 1 & 1 \\ \hline \end{array}$$ #eyo-style:Normal 
                             Example for $$\Rightarrow$$: $$x=$$ "It is raining."; $$y=$$ "The ground is wet".
                             More on [Wikipedia](https://en.wikipedia.org/wiki/Truth_table) #wfe-ignore-item 
                             Boolean Arithmetic can then be implemented for any binary number, by applying logical operations bit-wise.
                         Mini-Exercise  #wfe-count:ex #slide #maths-engage
                             Compute, by inserting leading 0s if needed:
                                 $$101101 \oplus 111$$
                                 $$101 \lor 1100$$
                                 $$11 \Rightarrow 01$$
                         Solutions: #slide #maths-engage #solution 
                             $$101101\oplus 111= 101101\oplus 000111= 101010$$
                             $$101\lor 1100= 0101\lor 1100= 1101$$
                                 ![mini-exercise-4.png](https://www.dropbox.com/s/6mlnv0z222izvxa/maths-mini-4.png?dl=1) #eyo-style:Normal #solution #wfe-ignore-item 
                             $$11 \Rightarrow 01=01$$
                     Summary #slide 
                         Understand modular arithmetic
                         Know how to work with polynomials
                         Be familiar with the principles of Boolean Algebra
                 Mathematical Algorithms #eyo-style:Section #fix 
                     Learning Objectives #slide 
                         Understand the concept of the Greatest Common Divisor
                         Be familiar with the Euclidean Algorithm
                         Know the definition of the Modular Inverse
                         Be able to use the Extended Euclidean Algorithm in order to compute the Modular Inverse
                     Computing the Greatest Common Divisor #eyo-style:Subsection  #h 
                         Greatest Common Divisor #slide #maths-engage
                             Definition: given two integers $$a$$ and $$b$$, their __greatest common divisor__ $$\gcd(a, b)$$ is the greatest integer dividing both $$a$$ and $$b$$.
                             Example: $$a = 28, \; b = 24 \Rightarrow \gcd(28, 24) = 4$$.
                             The gcd can be computed e.g. using prime factor decomposition: let $$a = p_1^{\alpha_1} \cdots p_n^{\alpha_n}$$ and $$b = p_1^{\beta_1} \cdots p_n^{\beta_n}$$ with $$\alpha_i, \beta_i\ge 0, p_i$$ prime.
                             It follows that then $$\gcd(a,b) = \prod p_i^{\min(\alpha_i,\beta_i)}$$.
                             We say that $$a$$ and $$b$$ are __co-prime__ if $$\gcd(a,b) = 1$$.
                         The Euclidean Algorithm #slide #maths-engage 
                             The __Euclidean Algorithm__ (EA) computes the greatest common divisor of two numbers.
                             Based on following __recursive__ identity:\[\gcd(a,b) = \gcd(b, a \bmod b)\]and $$\gcd(a, 0) = a$$ (__base case__). #fix 
                             We explain this using an example -- compute $$\gcd(80,45)$$:
                                 $$80: \color{orange}{45}  = 1$$ and $$80 - 1* \color{orange}{45}  =  \color{blue}{35}$$
                                 $$\color{orange}{45} : \color{blue}{35} = 1$$ and $$\color{orange}{45} - 1* \color{blue}{35} = \color{green}{10}$$
                                 $$\color{blue}{35}:\color{green}{10} = 3$$ and $$\color{blue}{35} - 3* \color{green}{10} =\color{red}{5}$$
                                 $$\color{green}{10} : \color{red}{5} = 2$$ and $$\color{green}{10} - 2* \color{red}{5} = \color{yellow}{0}\Rightarrow$$ algorithm terminates!
                             Solution: $$\gcd(80, 45) = \color{red}{5}$$
                             Reason: $$\gcd(80, 45)=\gcd(45, 35)=\cdots =\gcd(5, 0)=5$$.
                         Mini-Exercise  #wfe-count:ex #slide #maths-engage
                             (a) Compute the $$\gcd$$ of $$75$$ and $$28$$, using
                                 (i) Prime factor decomposition,
                                 (ii) The Euclidean algorithm.
                             (b) Find the greatest common divisor $$g$$ of $$799$$ and $$987$$.
                             (c) Optional: Find integers $$x$$ and $$y$$ such that $$799x + 987y = g$$.
                         Solutions: #slide #maths-engage 
                             ![mini-exercise-8.png](https://www.dropbox.com/s/0mekzxi3qs9w5vq/mini-exercise-8.png?dl=1) #eyo-style:Normal #solution
                     Computing the Modular Inverse #eyo-style:Subsection  #h 
                         Modular Inverse #slide #maths-engage 
                             Let $$a$$, $$n$$ be integers. The __inverse __of $$a$$ modulo $$n$$ is an integer $$x$$ such that $$a\cdot x \equiv 1 \bmod n$$.
                             Of course, then also $$x\cdot a \equiv 1 \bmod n$$.
                             We also write $$a^{-1} \bmod n$$ for the inverse.
                             Example:
                                 $$a = 3$$, $$n = 20$$.
                                 The inverse of $$a$$ modulo $$20$$ is $$x = 7$$ since $$3\cdot 7 = 21 \equiv 1 \bmod 20$$.
                                 Of course, also $$7\cdot 3 \equiv 1 \bmod 20$$.
                             Note: the inverse does not always exist. In fact, the inverse of $$a$$ exists $$\Longleftrightarrow \gcd(a,n)=1$$.
                             Importance for cryptography: computing RSA keys.
                         The Extended Euclidean Algorithm #slide #maths-engage 
                             How can inverse $$a^{-1}\bmod n$$ be computed?
                                 From multiplication table
                                 Try and error
                                 Extended Euclidean Algorithm
                             Using the extended version of Euclidean Algorithm (EEA):
                                 This computes $$u, v$$ such that $$ua + vb = \gcd(a, b)$$.
                                 If $$\gcd(a, b)=1$$: computes $$u$$ as modular inverse of $$a$$ mod $$b$$
                                 Proof: $$ua = 1-vb$$ so $$ua \equiv 1 \mod b$$
                             Example: 
                                 $$a = 3$$, $$b=20$$. 
                                 EEA computes $$u=7$$, $$v=-1$$ with $$7 \cdot 3 - 1 \cdot 20 = 1$$
                                 Hence: $$3^{-1} \equiv 7 \bmod{20}$$
                         The Extended Euclidean Algorithm -- Example #slide #maths-engage
                             Example: Compute modular inverse of $$29 \bmod 41$$
                             Step 1 (Euclidean Algorithm):
                                 $$41:29 = 1$$ and $$41 \color{red}{- 1} * 29 = 12$$
                                 $$29:12 = 2$$ and $$29 \color{orange}{- 2} * 12 = 5$$
                                 $$12:5 = 2$$ and $$12 \color{blue}{- 2} *5 = 2$$
                                 $$5:2 = 2$$ and $$5 \color{green}{- 2} * 2 = 1$$
                             Step 2 (Extended Euclidean Algorithm) -- redo EA operations on input (0, 1):
                                 $$0\color{red}{-1}*1 = -1$$
                                 $$1\color{orange}{-2}*(-1) = 3$$
                                 $$-1\color{blue}{-2}*3 = -7$$
                                 $$3\color{green}{-2}*(-7) = 17$$
                             Solution: $$29^{-1} \bmod 41 = 17$$. Exercise: verify this!
                         Mini-Exercise  #wfe-count:ex #slide #maths-engage
                             (a) Compute the modular inverse of 28 mod 75.
                             (b) Solve the following linear equations:
                                 (i) $$8x \equiv 1$$ (mod 13)
                                 (ii) $$6x \equiv 11$$ (mod 29)
                                 (iii) $$8x \equiv 7$$ (mod 11)
                         Solutions: #slide #maths-engage 
                             ![mini-exercise-9.png](https://www.dropbox.com/s/u6w3flmirszw43n/mini-exercise-9.png?dl=1) #eyo-style:Normal #solution
                     Summary #slide 
                         Understand the concept of the Greatest Common Divisor
                         Be familiar with the Euclidean Algorithm
                         Know the definition of the Modular Inverse
                         Be able to use the Extended Euclidean Algorithm in order to compute the Modular Inverse
                 Basic Number Theory #CI7100_LO1 #item2 #maths #eyo-style:Section #h 
                     Learning Objectives #slide 
                         Understand the importance of (computational) number theory for cryptography, and the RSA algorithm in particular.
                         Know the definition of a prime number and differentiate between the computational tasks of prime factorisation/primality testing.
                         Comprehend the definition of  Euler's Function.
                         Be familiar with Fermat's Little Theorem and Euler's Theorem, and their use for cryptography.
                     Number Theory #CI7100_LO1 #slide 
                         Number theory studies properties of the integers.
                         Founded by famous mathematicians such as Fermat, Gauss and Euler.
                         "Mathematics is the queen of the sciences, and number theory is the queen of mathematics" (Gauss).
                         Surprisingly difficult to prove even simple mathematical properties.
                         Believed to be without serious applications, before the invention of public key cryptography.
                         Our main interest: use of computational number theory for the RSA algorithm.
                     Prime Numbers #slide #maths-engage
                         Definition: __a prime number is any integer > 1 that is divisible only by itself and 1.__
                         Examples: $$2, 3, 5, 7, 11, 47, 1997, \ldots$$
                         It is easy to see that there is an infinite number of prime numbers. #blue 
                         Computers can decide relatively efficiently whether a given number is a prime number.
                         Integers that are not primes can be decomposed into smaller integers -- for example: $$12 = 4 \cdot 3$$
                         __Factorisation __of an integer: writing a given integer as product of prime numbers.
                             Every non-zero integer can be written __uniquely__ (up to sign) as product of prime numbers
                             Example: $$10 = 2\cdot 5,\;\; 12 = 2\cdot 2\cdot 3,\;\; 19 = 19$$
                         The problem of prime factorisation turns out to be a computationally very difficult problem.
                     Mini-Exercise  #wfe-count:ex #slide #maths-engage
                         Decompose into prime factors:
                             33
                             45
                             1001
                             2020
                     Solutions: #slide #maths-engage #solution 
                         $$33=3\cdot 11$$
                         $$45=3^2\cdot 5$$
                         $$1001=7\cdot 11\cdot 13$$
                         $$2020=2^2\cdot 5 \cdot 101$$
                     Euler's Function #slide #maths
                         Euler's function $$\phi(n)$$ plays an important role in computational number theory
                         Many properties and theorems relating to integers can be stated, involving this function.
                         Our main interest: use for the proof of correctness of the RSA algorithm.
                         For $$n > 1$$, $$\phi(n)$$ is the number of integers $$k \in \{ 1,\ldots, n-1 \}$$ that are co-prime to $$n$$
                         So, formally: 
                             $$ \phi(n) := \;\mid \{ k \in \{ 1,.., n-1 \} : \gcd(k, n) = 1 \} \mid. $$ #eyo-style:Normal 
                     Mini-Exercise  #wfe-count:ex #slide #maths
                         Compute $$\phi(15)$$. Tip: you need to successively examine all of the integers $$1, 2, \ldots, 14$$.
                     Fermat's Little Theorem and Euler's Theorem #slide #maths
                         These two related theorems state properties of repeated multiplication, when using modular arithmetic.
                         Fermat's Little Theorem: __if $$p$$ is prime and $$p \nmid a$$, then $$a^{p-1} \equiv 1 \: (\bmod p)$$__.
                         Application in cryptography:
                             Primality testing
                             Integer factorisation
                         Euler's Theorem: __if $$\gcd(a,n) = 1$$ then $$a^{\phi(n)} \equiv 1 \: (\bmod n)$$__.
                         Applications in cryptography:
                             RSA algorithm
                     Mini-Exercise  #wfe-count:ex #slide #maths
                         Verify Euler's Theorem for $$n=15$$ and $$a=2$$.
                         How are Euler's and Fermat's Theorem related? Hint: what is $$\phi(p)$$ for $$p$$ prime?
                         Prove that for $$p$$, $$q$$ prime and $$p \nmid a$$, $$q \nmid a$$, one has $$ a^{(p-1)(q-1)} \equiv 1 \pmod {pq}. $$ Hint: Use Euler's theorem and the fact that $$\phi(nm) = \phi(n) \phi(m)$$.
                     Solutions: Verify Euler's Theorem #slide
                         Euler's Theorem states that if $$\gcd(a,n) = 1$$ then $$a^{\phi(n)} \equiv 1 \: (\bmod n)$$.  
                         Here, with $$n=15$$ and $$a=2$$, $$\gcd(2,15) = 1$$, as they have no larger common divisors.  
                         We saw in the solution to Mini-Exercise 11 that $$\phi(15) = 8$$.  
                         Now  $$2^8 = 256$$ and $$256 = 17 \times 15 + 1$$, so $$2^{\phi(15)} \equiv 1 \: (\bmod 15)$$ and Euler's Theorem is verified for these two values.
                     Solutions: Euler's Theorem and Fermat's Theorem #slide
                         Consider integers $$a, p$$ with $$p$$ prime and $$p \nmid a$$.  
                         Then by Fermat's Little Theorem, $$a^{p-1} \equiv 1 \: (\bmod p)$$.  
                         Because $$p$$ is prime and $$p \nmid a$$ it must also be the case that $$\gcd(a,p) = 1$$.      What is $$\phi(p)$$?  Because for every positive integer $$m < p$$, $$\gcd(m,p) = 1$$, we must have $$\phi(p) = p - 1$$.  
                         Substituting $$\phi(p)$$ for $$p - 1$$ in the expression in Fermat's Little Theorem gives us $$a^{\phi(p)} \equiv 1 \: (\bmod p)$$, which is the expression in Euler's Theorem.  % EP bug
                     Solutions: cont. #slide
                         For $$p$$, $$q$$ prime and $$p \nmid a$$, $$q \nmid a$$,  $$ a^{(p-1)(q-1)} \equiv 1 \pmod {pq}$$
                         Recall from the last answer, we had $$\phi(p) = p-1$$.
                         So we can rewrite $$ a^{(p-1)(q-1)} = a^{\phi(p)\phi(q)} = a^{\phi(pq)}$$ using the hint.
                         Now $$\gcd(a, pq) = 1$$ because $$p \nmid a$$ and $$q \nmid a$$, so by Euler's Theorem, $$a^{\phi(pq)} \equiv 1 \pmod {pq}$$ as required.
                     Summary #slide 
                         Understand the importance of (computational) number theory for cryptography, and the RSA algorithm in particular.
                         Know the definition of a prime number and differentiate between the computational tasks of prime factorisation/primality testing.
                         Comprehend the definition of  Euler's Function.
                         Be familiar with Fermat's Little Theorem and Euler's Theorem, and their use for cryptography.
         Game Theory #h
             Theory #h
                 Introduction #h 
                     Symbols #slide 
                         $$G(\mathcal{P}, \mathcal{A}, \mathcal{S}, u)$$ -- game
                         $$\mathcal{P}$$ -- set of players
                         $$P_i \in \mathcal{P}$$ -- player $$i$$ 
                         $$\mathcal{A}$$ -- set of actions 
                         $$\mathcal{A}_i$$ -- set of actions of players $$P_i$$ 
                         $$a_i \in \mathcal{A}_i$$ -- a specific action of $$P_i$$
                         $$\mathcal{S}$$ -- strategy set 
                         $$\mathcal{S}_i \in \mathcal{S}$$ -- strategy set of $$P_i$$ (set)
                         $$s_i \in \mathcal{S}_i$$ -- a specific strategy of $$P_i$$ 
                         $$s$$ -- strategy profile of a game 
                         $$u$$ -- utility function 
                         $$b$$ -- benefit function 
                         $$c$$ -- cost function 
                     Notations and Definitions #slide 
                     Concepts in Game Theory #slide 
                         Game theory is "__the study of mathematical models of conflict and cooperation between intelligent rational decision-makers.__" [Wikipedia]
                         Important concepts:
                             Game Type
                             Players
                             Strategies
                             Utilities (payoffs)
                             Solving a game
                             Nash Equilibrium
                     Taxonomy #h 
                         Direct Games #slide 
                             Non-cooperative 
                                 Information of players
                                     Knowledge
                                         Complete information
                                         Incomplete information
                                     Awareness
                                         Perfect information 
                                         Imperfect information 
                                 Mode of playing
                                     Chronology 
                                         simultaneous 
                                         sequential 
                                     Frequency
                                         once
                                         repeated
                             Coalitional
                         Indirect Games
                 Bayesian Games #h 
                     Motivation #slide 
                         Incomplete information about the strategies and payoffs
                         In particular, one player has incomplete information about the other player.
                         Can be modelled by introducing Nature (a random value -- signal) as a player in the game 
                         This converts a game of incomplete information to a game of imperfect information
                     Notations #slide 
                         $$N$$ -- State of Nature #GT #bayes
                         $$A_i \in (A \times T)$$ -- action set of $$P_i$$, specified for specific types #GT #bayes 
                         $$a_i \in  (A \times T)$$ -- a specific action of $$P_i$$, specified for specific types #GT #bayes 
                         $$\theta_i \in \Theta$$ -- type of player $$P_i$$ (as a function of $$N$$) #GT #bayes 
                         $$p_i$$ -- probability distribution ("beliefs") over $$N$$, for the specific player $$P_i$$ #GT #bayes 
                     Overview #slide 
                         Non-Bayesian game: strategy profile is a NE iff every strategy in that profile is a best response to every other strategy
                         Our game: find Bayesian Nash Equilibria (BNE) 
                         Bayesian Games: Players maximise their expected payoffs
                     Basic Concepts #slide 
                         Bayesian are methods in probability and statistics named after Thomas Bayes. These methods include Bayesian Games which provides a new way for analysing incomplete information games. In such games, there is a certain belief with a known probability distribution
                         John Harsanyi developed a new theory for analysing games: Bayesian Games
                             "developing the highly innovative analysis of games of incomplete information, so-called Bayesian games"
                     Bayesian game consists of: #slide 
                         finite set N (the set of players)
                             each player has his own set of actions
                             each player has a finite set of signals and a signal function
                             each player has a prior belief
                             each player has a preference relation
                         finite set set of $$\Omega$$ (the set of states)
                         Bayesian Games (Games of Incomplete information) represents players' uncertainties about the game player
                     Bayesian Game -- Definition #slide
                         A Bayesian game can be represented as a tuple $$(N, A,\Theta, p, u)$$ where:
                             $$N$$ is a set of agents
                             $$A = A_1 \times\cdots \times A_n$$ where $$A_i$$ is the set of actions available to player $$i$$
                             $$\Theta = \Theta_1 \times\cdots \times \Theta_n$$ where $$\Theta_i$$ is the type space of player $$i$$
                             $$p : \Theta \rightarrow [0, 1]$$ is a common prior over types
                             $$u = (u_1, \cdots , u_n)$$, where $$u_i : A \times \Theta \rightarrow \R$$ is the utility function for player $$i$$
                     Two-Player Bayesian Game -- Definition #slide
                         A Two-Player Bayesian game can be represented as $$G(A,B, \Theta, p)$$ where:
                             $$\Theta$$ is the type space of the first player
                             $$A = A_1 \times\cdots \times A_n$$ where $$A_i$$ is the set of actions available to player $$i$$
                             $$u = (u_1, \cdots , u_n)$$, where $$u_i : A \times \Theta \rightarrow \R$$ is the utility function for player $$i$$
                             $$p : \Theta \rightarrow [0, 1]$$ is a common prior over types
                     Harsanyi-Transformation #slide 
                         John Harsanyi developed a theory for analysing Bayesian Games. 
                         Idea: convert game with uncertainty over strategies (types) into game with payoff uncertainty. 
                         Assume knowledge of probability distribution for types. 
                         This transforms a game of incomplete information into one of imperfect information. 
                         This can then solved with standard techniques. 
                         Disadvantage: the resulting game is of bigger size and hence more difficult to analyse.
                     Bayesian Nash Equilibrium (BNE) Types #slide 
                         __Pooling Equilibrium__: if the first player's best response is independent of any type. It remains the same, regardless of his belief in the type of Player 2.
                         __Separating Equilibrium__: if best response is different, depending on the type.
                     References #slide 
                         https://en.wikipedia.org/wiki/Bayesian_game
                 Bimatrix Games #h 
                     Notations #h 
                         Notations -- GameSec Paper #slide 
                             $$A$$ and $$B$$ -- real matrices of dimension $$m\times n$$. 
                             A bimatrix game is a two-person, non-zero sum finite game $$\mathcal{G}(A,B)$$ where 
                                 $$X$$ and $$Y$$ are the sets of strategies for the different players, #paper:order-2-barrier #paper:adv-learning 
                                 $$A:X\times Y \mapsto \mathbb{R}$$ is the payoff function for Player 1,  #paper:order-2-barrier #paper:adv-learning 
                                 $$B:X\times Y \mapsto \mathbb{R}$$ is the payoff function for Player 2.  #paper:order-2-barrier #paper:adv-learning 
                             The first (row) player plays a row action #paper:order-2-barrier #paper:adv-learning 
                             The second (column) player plays a column action #paper:order-2-barrier #paper:adv-learning 
                             $$x$$ and $$y$$ denote a pure or mixed strategy of the first and second player in the two-player bimatrix game
                             $$x^*$$ and $$y^*$$ are used for equilibrium strategies of these players. 
                             A strategy profile $$s=(x, y)$$ groups strategies of each player together. 
                             If the grouped strategies are in equilibrium, this strategy profile is written as $$s^*$$. 
                             An \textit{Nash Equilibrium strategy profile} is a strategy profile $$s^*=(x^*,y^*)$$ satisfying $$v_A=x^*Ay^* \ge  xAy^* \;\;\forall x$$ and $$v_B=x^*By^* \ge x^*By\;\;\forall y$$
                             Here, the strategies may be pure or mixed, and the corresponding NE is referred to as pure or mixed.
                             $$v=(v_A,v_B)$$ -- a (not necessarily unique) equilibrium value pair of a bimatrix game #paper:order-2-barrier #paper:adv-learning 
                         Notations -- Smart Energy Paper #slide 
                             $$x$$ and $$y$$ denote a pure or mixed strategy of the first and second player in the two-player bimatrix game
                             $$x^*$$ and $$y^*$$ are used for equilibrium strategies of these players. 
                             A strategy profile $$s=(x, y)$$ groups strategies of each player together. 
                             If the grouped strategies are in equilibrium, this strategy profile is written as $$s^*$$. 
                             An \textit{Nash Equilibrium strategy profile} is a strategy profile $$s^*=(x^*,y^*)$$ satisfying $$x^*Ay^* \ge  xAy^* \;\;\forall x,\quad x^*By^* \ge    x^*By\;\;\forall y$$
                             Here, the strategies may be pure or mixed, and the corresponding NE is referred to as pure or mixed.
                         Notations -- Raghaven #slide 
                             Following Raghaven, we denote the set of all equilibrium pairs for a given game by S, 
                             and if (x,y)e, let S(y) = {x: (x,y)e#}, T(x) = {y: (x,y)e). 
                             A subset $F of 8 is called completely mixed if each vector in each equilibrium pair in 2F is completely mixed.
                             A{. denotes the i-th row of A, A.j the ;-th column; similarly for B
                             MJCX) = {i: li > 0}, m^ix) = cardinality of M^x), and 
                             x0 -- the vector of m^ix components obtained by deleting the zero components of x. 
                             The corresponding meanings are assigned to Nx{y), n^y) and y0. 
                             Let M2(A, y) = {i: At.y' = max*Ak./}, N2(x, B) = {j: xB.j = maxkxB.k}.
                             (Vectors are regarded as row matrices, and a superscript t denotes transpose.)
                             It follows easily from the definitions (cf. [1; (2.3)], [3; Theorem 4]) that
                                 A strategy pair (x, y) is in & if and only if \ f Mt(x) s M2(A, y) and NM  N2(x, B). )
                     Basic Concepts and Terminologies #h
                         Bimatrix Game #slide #notation 
                             $$A$$ and $$B$$ -- real matrices of dimension $$m\times n$$. 
                             A bimatrix game is a two-person, non-zero sum finite game $$G=(X,Y,A,B)$$ where 
                                 $$X$$ and $$Y$$ are the sets of strategies for the different players, #paper:order-2-barrier #paper:adv-learning 
                                 $$A:X\times Y \mapsto \mathbb{R}$$ is the payoff function for Player 1,  #paper:order-2-barrier #paper:adv-learning 
                                 $$B:X\times Y \mapsto \mathbb{R}$$ is the payoff function for Player 2.  #paper:order-2-barrier #paper:adv-learning 
                             The first (row) player plays a row action #paper:order-2-barrier #paper:adv-learning 
                             The second (column) player plays a column action #paper:order-2-barrier #paper:adv-learning 
                         Strategies #slide #CYENS #notation 
                             $$x, y$$ -- strategies
                                 pure strategies #paper:order-2-barrier #paper:adv-learning 
                                 mixed strategies (probability vectors $$x,y \in {\mathbb R}^n$$ with $$0\le x_i\le 1$$, $$\sum_i x_i=1$$ and $$0\le y_i\le 1$$, $$\sum_i y_i=1$$) #paper:order-2-barrier #paper:adv-learning 
                             $$s=(x, y)$$ --  __strategy profile__, groups strategies of each player together. #paper:order-2-barrier 
                             Given a bimatrix game with payoff matrices $$A$$ and $$B$$, a __mixed strategy__ for Player 1 (the row player) is a real vector $$x$$ satisfying $$0\le x_i\le 1$$, with $$\sum x_i = 1$$. 
                             A mixed strategy for Player 2 (the column player) is a real vector $$y$$ satisfying the same properties. 
                             A __completely mixed strategy__ has all vector entries strictly greater than zero. 
                             The corresponding payoffs to Player 1 and Player 2 are $$^t{\!}xAy$$ and $$^t{\!}xBy$$ respectively. 
                         Best Response #slide 
                             $$\mathcal{BR}(y)$$ -- the set of __best responses__ to a strategy $$y$$ (the set of all strategies $$x$$ of Player 1 maximizing his expected payoff $$x^\top Ay$$).
                             Similarly a best response to $$x$$ is a strategy $$y\in \mathcal{BR}(x)$$ of Player 2 that maximizing her expected payoff $$x^\top By$$. 
                             #definition
                                 A Player 2 strategy $$y^*$$ is a __Nash equilibrium best response__ to a Player 1 strategy $$x$$ (denoted $$y^* \in \mathcal{BR}(x)$$ in the sequel) is a strategy $$y^*$$ satisfying $$ xBy^* \ge    xBy$$ for all other Player 2 strategy $$y$$.
                         Nash Equilibrium Strategies #slide #CYENS #notation 
                             #definition 
                                 A __Nash Equilibrium strategy__ $$(x^*,y^*)$$ satisfies: 
                                     $$ x^*Ay^* \ge  xAy^* \quad\forall x$$
                                     $$ x^*By^* \ge    x^*By\quad\forall y$$
                             A Nash equilibrium strategy is hence a strategy pair $$(x^*,y^*)$$ of mutual best responses: $$ x^* \in \mathcal{BR}(y^*) $$ and $$ y^* \in \mathcal{BR}(x^*) $$.
                              $$x^*,y^*$$ -- __Nash Equilibrium strategies__ of the game satisfying  
                                 $$ x^*Ay^* \ge  xAy^* \;\;\forall x,\quad x^*By^* \ge    x^*By\;\;\forall y$$. #wfe-style:Equation #paper:order-2-barrier #paper:adv-learning 
                             $$s^*=(x^*,y^*)$$ -- __Nash Equilibrium strategy profile __ 
                         Game Values #slide #notation 
                             $$v=(v_A,v_B)$$ -- a (not necessarily unique) equilibrium value pair of a bimatrix game #paper:order-2-barrier #paper:adv-learning 
                         Nash Equilibrium Types #slide 
                             NE strategies may be pure or mixed, and the corresponding NE is referred to as a pure or mixed NE. #paper:order-2-barrier #paper:adv-learning 
                             If all components of a strategy vector are non-negative, it is called a weakly completely mixed strategy. #paper:order-2-barrier
                             If all components of a strategy vectors are strictly positive, it is called a strictly completely mixed strategy. #paper:order-2-barrier
                             Depending on the type of completely mixed strategies involved in a NE, one has a __strict__ NE. Otherwise, the NE is __non-strict__.
                             Depending on the type of completely mixed strategies involved in a NE, one has a __strict__ NE. Otherwise, the NE is __non-strict__.
                             CHECK
                         A Best Response Lemma #h 
                             A Best Response Lemma #slide #CYENS 
                                 #lemma:best-response 
                                     If Player 1's mixed strategy $$x^*$$ is a best response to the (mixed) strategy $$y$$ of the other player, then, for each pure strategy $$e_i$$ such that $$x_i > 0$$, it must be the case that $$e_i$$ is itself a best response.  In particular, the payoff $$e_i Ay$$ must be the same for all such strategies.
                                 Note: an analogous lemma can be stated for Player 2, $$y^*$$ and $$x$$.
                             Proof (I) #slide #CYENS 
                                 Recap: due to $$x^* \in \mathcal{BR}(y^*)$$ we have $${}^t \!x^*Ay^*=v_{A}$$ and $${}^t \!xAy^*\le v_{A}$$ for all $$x$$. 
                                 Let us write $${}^t \!x^*= (x^*_{1},\ldots ,x^*_{i},\ldots ,x^*_{n})$$ and assume $$x^*_{i}\neq 0$$.
                                 Furthermore, denote $${}^t \!e_{i}= (\underbrace{0,\ldots ,0}_{i-1}, 1, 0,\ldots , 0)$$.
                                 It is clear that $${}^t \!e_{i}Ay^*\le v_{A}$$.
                             Proof (II) #slide #CYENS 
                                 Now assume $${}^t \!e_{i}Ay^*< v_{A}$$, minimal for all pure strategies. 
                                 Find $$j\neq i$$, $$x_{j}^*\neq 0$$ (such $$j$$ exists since $$x^*$$ is not pure) and define
                                     $${}^t \!\hat{x}={}^t \!x^*-x_i^* {\;}^t\! e_i+x_i^* {\;}^t\! e_j=(x^*_{1},\ldots ,0,\ldots ,x^*_{j}+x^*_{i},\ldots ,x^*_{n})$$.
                                 This is a mixed strategy as all components of strategy vector still add up to one.
                                 It follows
                                     $$^t\!\hat{x}Ay^*={}^t\!x^*Ay^*+x_{i}^*\overbrace{(^t\!e_{j}Ay^*-{}^t\!e_{i}Ay^*)}^{>0}>\,{}^t\! x^*Ay^*$$
                                 which is a contradiction. Hence we must have $${}^t \!e_{i}Ay^*= v_{A}$$. 
                                 An additional consequence is $${}^t \!x^*Ay^*\le v_{A}{}^t\!e$$. 
                                 Furthermore, since $${}^t \!e_{i}A$$ is the $$i$$th row of $$A$$,
                                     $$Ay^*= v_{A}e$$. 
                     Strategical Equivalence #h 
                         Motivation #slide 
                             Sometimes, two different games have the same strategic constraints 
                             This might not be directly obvious from the payoff functions 
                             But it can be seen from the relationship that exists between the two game matrices
                             This means that the Nash solution strategies coincide
                             But not necessarily the values
                             This is formalised with the concept of strategic equivalence
                         Notations #slide 
                             Let $$\mathcal{B}(I)$$ denote the set of payoff matrices with equal columns
                             This means a row $$R_i$$ has the only entry $$\alpha_i$$
                             This means $$S\in \mathcal{B}(I)\Longleftrightarrow S={\rm diag}(\alpha_1,\ldots,\alpha_m)\cdot E$$. 
                             Similarly denote $$\mathcal{B}(J)$$ for matrices of equal rows. 
                             This means matrices of the form $$T=E\cdot {\rm diag}(\beta_1,\ldots,\beta_m)$$
                         Strategical Equivalence -- Definition #slide 
                             #definition:strategic-equivalent 
                                 The games $$(A, B)$$ and $$(C,D)$$ are __strategically equivalent__ iff
                                     $$ \exists \lambda > 0 $$ such that $$C- \lambda A  \in \mathcal{B}(J) $$ or $$A$$ and $$C$$ are equivalently trival, and
                                     $$ \exists \mu> 0 $$ such that $$D- \mu B  \in \mathcal{B}(I) $$ or $$B$$ and $$D$$ are equivalently trival.
                             This means $$C=\lambda A+E\cdot {\rm diag}(\beta_1,\ldots,\beta_m)$$ and $$D=\mu B+ {\rm diag}(\alpha_1,\ldots,\alpha_m)\cdot E$$. 
                         NE Theorem #slide 
                             Assume the games $$G=G(A,B)$$ and $$\tilde{G}=G(\tilde{A},\tilde{B})$$ are strategically equivalent. Then any strategy profile $$s$$ is a Nash Equilibrium profile for $$G$$, iff it is one for $$\tilde{G}$$. 
                         Proof #slide 
                             One shows that best responses for any strategy coincide for both games. 
                             Let $$x^*\in {\mathcal{BR}}_G(y)$$ be a best response for $$y$$ in the game $$G$$. 
                             Hence $$x^*Ay\ge xAy$$ for all strategies $$x$$. 
                             But then
                                 $$x^*\tilde{A}y=x^*Ay+(\alpha_1,\alpha_2)y\ge xAy+(\alpha_1,\alpha_2)y=x\tilde{A}y\quad \forall x$$.
                             Thus $$x^*\in {\mathcal{BR}}_{\tilde{G}(y)}$$. 
                             Similarly for $$y^*\in {\mathcal{BR}}_G(x)$$.
                         Strategical Equivalence for 2x2 Games #slide 
                             The games $$G(A,B)$$ and $$\tilde{G}(\tilde{A},\tilde{B})$$ are said to be __strategically equivalent__ iff there exist real numbers $$\alpha_1, \alpha_2, \beta_1, \beta_2, \mu>0, \sigma>0$$ such that
                                 $$\tilde{A}=\mu {A}+\begin{pmatrix}  \alpha_1& \alpha_2\\\alpha_1 & \alpha_2 \\  \end{pmatrix}$$ and $$\tilde{B}=\sigma{B}+\begin{pmatrix}  \beta_1& \beta_1\\\beta_2 & \beta_2 \\  \end{pmatrix}$$.
                                     $$\Longleftrightarrow$$ $$A-\mu \tilde{A}=\begin{pmatrix}  \alpha_1& \alpha_2\\\alpha_1 & \alpha_2 \\  \end{pmatrix}$$ and $$B-\sigma\tilde{B}=\begin{pmatrix}  \beta_1& \beta_1\\\beta_2 & \beta_2 \\  \end{pmatrix}$$ 
                         Strategical Equivalence Transformation #slide 
                             For non-trivial games this means $$G \mapsto \tilde{G}$$ where
                                 $$\tilde{A}=\sigma A+E\; {\rm diag}(\beta_1,\ldots,\beta_m)$$ and
                                 $$\tilde{B}=\mu B+ {\rm diag}(\alpha_1,\ldots,\alpha_m)\; E$$. 
                     Algorithms for Solving Bimatrix Games #h
                         Introduction #slide 
                             A large body of research investigating the design of algorithms for solving bimatrix games exists. 
                             Most methods are based on linear techniques, an overview of such approaches is given e.g. in \cite{@Stengel2002}. 
                         Solving 2x2 Generic Bimatrix Games #h
                             Definition of Generic Game #slide #CYENS
                                 Consider the following generic bimatrix game in strategic normal form:
                                     $$\begin{array}{c|c|c}  &l &r \\ \hline u & a_{1}, a_{2} & b_{1}, b_{2} \\  \hline d &c_{1}, c_{2}& d_1,d_2  \end{array}$$
                                 To check the existence of a completely mixed-strategy equilibrium, we use a fundamental theorem due to Nash.
                             Best Response to (Row) Player 1 #slide #CYENS
                                 Suppose the row player plays $$u$$ with probability $$\alpha$$ and $$d$$ with probability $$1-\alpha$$.
                                 He uses a mixed strategy $$\sigma=\alpha u+(1-\alpha)d$$.
                                 Then, if the column player uses both $$l$$ and $$r$$ in the mixed equilibrium best response, we have seen (Best Response Lemma) that they must both have the same payoff $$v_B$$.
                                 The payoff to $$l$$ against $$\sigma$$ is $$\alpha{a_2}+(1-\alpha)c_{2}$$, and the payoff to $$r$$ against $$\sigma$$ is $$\alpha b_{2}+(1-\alpha)d_2$$. 
                                 Equating these two, we find $$\alpha=\dfrac{d_2-c_2}{d_2-b_2+a_2-c_2}$$.
                             Best Response to (Column) Player 2 #slide #CYENS 
                                 This follows sthe same reasoning, assuming the column player uses the strategy $$\tau=\beta l +(1-\beta)r$$ (that is, plays $$l$$ with probability $$\beta$$). 
                                 Then, if the row player uses both $$u$$ and $$d$$, they must both have the same payoff against $$\beta$$. 
                                 The payoff to $$u$$ against $$\beta$$ is $$\beta a_{1} +(1-\sigma)b_{1}$$, and the payoff to $$d$$ against $$\sigma$$ is $$\beta c_{1}+ (1 -\beta)d_1$$. 
                                 Eventually we find 
                                     $$\beta=\dfrac{d_1-b_1}{d_1-b_1+a_1-c_1}.$$
                             Discussion #slide #CYENS  
                                 For this to make sense, the denominator must be nonzero, and the right-hand side must lie between zero and one. 
                                 Note that the __column__ players strategy is determined by the requirement that __row__ players two strategies be equal.
                             References
                                 [https://oyc.yale.edu/sites/default/files/mixed_strategies_handout_0_0.pdf](https://oyc.yale.edu/sites/default/files/mixed_strategies_handout_0_0.pdf)
                 Matrix Games #h 
                     Basic Concepts and Terminologies #h  
                         Notations and Definitions #slide
                             $$A$$ -- square, real matrix of dimension $$n$$
                             $$x, y$$ -- strategies, can be:
                                 pure strategies
                                 mixed strategies (probability vectors $$x,y \in {\mathbb R}^n$$ with entries summing up to 1: $$0\le x_i\le 1$$, $$\sum_i x_i=1$$ and $$0\le y_i\le 1$$, $$\sum_i y_i=1$$)
                             $$v=v(A)$$ -- the unique value of the game
                              $$x^*,y^*$$ -- optimal solutions of the game
                                 $$x^*Ay^*=v$$
                                 $$xAy^* \le v^- \;\forall x$$
                                 $$x^* Ay \ge v^+ \;\forall y$$ 
                             Let $$x$$ be an optimal strategy for Player 1. 
                             Then any $$i$$ for which $$x_i=0$$ is called an inactive strategy. 
                         Matrix Games #slide
                             These are two-person, zero-sum finite games $$G=(X,Y,A)$$ where 
                                 $$X$$ and $$Y$$ are the sets of strategies for the different players 
                                 $$A:X\times Y \mapsto {\mathbb R}$$ is the payoff function. 
                             We use a matrix to represent the payoff function
                             The first (row) player plays a row action 
                             The second (column) player plays a column action
                             Zero-sum game: one player wins what the other player loses
                         Lower and Upper Value #slide #definition #deconstruct:equilibrium 
                             We denote 
                                 $$v^{-}(A):=\max_x \min_y xAy$$ the __lower value__ of the matrix game $$G(A)$$. 
                                 $$v^{+}(A):= \min_y \max_x xAy $$ the __upper value__ of the game. 
                             Using elementary mathematics, it can be seen that $$v^{-} \le v^{+}$$.
                             Min-max Theorem (due to von Neumann): 
                                 In the setting of a matrix game, these two values can be seen to be the same: $$v^- = {v^+}$$.
                                 Proof: non-trivial. 
                         Value and Optimal Solutions #slide #deconstruct:equilibrium 
                             We can hence define the __value__ of the game uniquely by $$v(A):=\max_x \min_y xAy = \min_y \max_x xAy $$.
                             Any strategy $$x^*, y^*$$ satisfying $$x^*Ay^* = v$$ is called __optimal__. 
                             There may be several such $$x^*, y^*$$.
                             They are a __mutual best response__ pairs.
                         Specialisation of Nash Equilibrium Concept #slide
                             Often, NE are not mentioned in the context of zero-sum games.
                             We say that $$(x^*, y^*)$$ is a NE strategy profile iff
                                 $$\forall x: \; xAy^* \le x^*Ay^* = v^-$$ 
                                 $$\forall y: \; x^* Ay \ge x^*Ay^* = v^+$$ 
                             Note that one can show for zero-sum games that any combination of different optimal strategies yields an equilibrium strategy. 
                         Best Response #slide
                             Any player will want to maximise their payoff, which means 
                                 maximising $$xA$$ if $$x$$ is Player 1's strategy,
                                 minimising $$Ay$$ if $$y$$ is Player 2's strategy. 
                             With their best response, a player will want to maximise what she gets from the other player's move.
                                 The best response for Player 1 is to assume maximum damage caused by the other player, and then to try mitigating this as much as possible: $$ \max_x \min_y xAy =: v^{-}$$. 
                                 The best response for Player 2 is to assume Player 1 seeks maximum gain, and then to limit this as much as possible: $$\min_y \max_x xAy =: v^{+}$$.
                         Equalizer  Formulation Using Best Responses #slide 
                         Principle of Indifference (Player 1) #slide 
                             The following can be seen as a result of the Best Response Lemma for bimatrix games:
                             Lemma. #lemma 
                                 If $$x^*$$ is an optimal solution for Player 1 and $$x^*_{i}>0$$ (i.e. $$i$$ is an active strategy), then every optimal solution $$y^*$$ for Player 2 satisfies
                                 $$(\underbrace{0,\ldots,0}_{i-1},1,\underbrace{0,\ldots,0}_{n-i-1}) Ay^*=\text{row}_{i}(A)y^* = v^-$$.
                                 For any other index $$k$$ with $$x_k^*=0$$ one has $$\text{row}_{k}(A)y^* < v^-$$.
                             Hence we have $$Ay^*=v^-e-b$$ where $$b\ge 0$$.
                         Principle of Indifference (Player 2) #slide 
                             A similar statement holds for an optimal solution $$y^*$$ for Player 2. 
                             Lemma. #lemma 
                                 If $$y^*$$ is an optimal solution for Player 2 and $$y_{i}>0$$ (i.e. $$j$$ is an active strategy), then every optimal solution $$x^*$$ for Player 1 satisfies
                                 $$x^*A(\underbrace{0,\ldots,0}_{j-1},1,\underbrace{0,\ldots,0}_{m-j-1}) =x^*\text{col}_{j}(A) = v^+$$.
                                 For any other index $$k$$ with $$x_k^*=0$$ one has $$x^*\text{col}_{k}(A) > v^+$$.
                             Hence we have $$x^*A=v^+e+b$$ where $$b\ge 0$$.
                         Value -- Discrete Definition #slide 
                             Starting with $$v^-(A):=\max_x \min_y xAy$$ we use the Principle of Indifference: $$v^-(A):=\max_x x\text{col}_{i}(A)$$
                             Similar for $$ \min_y \max_x xAy $$.
                         Further Structure #slide
                         Inactive Strategies #slideValue -- 
                         Slack-free Solutions #slide 
                         Dominance #slide 
                         The Trivial Case #slide 
                         Two-Action Case #slide
                     Algorithms for Solving Matrix Games #h 
                         LP
                         Double Description Approach #h 
                         Computational Geometry Approach #h 
                             Let P be an n-rowed matrix whose columns are nonzero vectors in real Euclidean m-space, R m. 
                             Tbe set of all nonnegative linear combinations of the columns of P is a cone which is called a polyhedral (or finitely generated) cone. 
                             The matrix P is called a generating matrix for the cone. 
                             A positive operator on a cone is a linear transformation which maps the cone into itself. 
                             Motivation #slide 
                                 It turns out that a natural setting for properties such as those stated in the last two theorems is that of regular matrix pencils, their associated (generalised) eigenvalues and eigenvectors. 
                                 expressed as generalised eigenvectors of an associated regular matrix pencil.  
                                 A zero-sum matrix game can be directly solved if $$\deg(\det A - \lambda E) > 0$$, i.e. the matrix polynomial vanishes identically in $$\lambda$$. 
                                 The following theorem generalises Shapley's theorem as it is also valid for $$v=0$$ and at the same time it improves Weil's theorem as it characterises the value of the same game (rather than a different one).
                             Rays #slide
                                 A ray is inside a (pointed) cone
                                 An extreme ray helps spanning a cone
                             Ordered Profiles #slide 
                                 Using a renaming of strategies, we can achieve that
                                     The rows of $$A$$ are ordered in (not necessarily strictly) decreasing value of their min-values
                                     We say that $$A$$ has ordered maximin profile
                                 Equally, we can arrange that
                                     The columns are of increasing max-values
                                     This is an ordered minimax profile 
                             Simultaneously Ordered Profiles #slide 
                                 We can even arrange for both profiles to be ordered simultaneously 
                                 In particular, if the maximin value equals the minimax, this then implies that the element at the top left equals the value $$v$$ of the game.
                             Maximin-Reduced Matrices #slide 
                                 Definition
                                     We say that the game $$\mathcal{G}(A)$$ (the matrix $$A$$) is maximin-reduced iff all submatrices of $$A$$ have an ordered maximin-profile. 
                             Strategically Equivalence #slide
                             Block-Structure Lemma I #slide 
                                 Lemma
                                     Assume the matrix is of the form
                                         $$A=\begin{pmatrix} \tilde{A} & \mu e  \end{pmatrix}$$. 
                                     Then we have $$v(A)\le \mu$$. If
                                         $$A=\begin{pmatrix} A\\ \mu ^\top\!e\end{pmatrix}$$
                                     then $$v(A)\ge \mu$$.
                             Proof of  Lemma I #slide 
                                 if all entries of A less than mu -> dominance. 
                                 otjerwise mu is lower bound as is minimal entry. 
                             Block-Structure Lemma II #slide 
                                 Note that both parts of the previous lemma can arise simultaneously.
                                 Lemma
                                     Assume
                                         $$A=\begin{pmatrix} \tilde{A}& \mu e\\ \mu ^\top\!e& \mu\end{pmatrix}$$.
                                     Then $$v(A)=\mu$$.
                                 This can also be seen directly from Saddle Point theorem.
                             Proof of  Lemma II #slide 
                             Affine-Relation Lemma #slide 
                                 Lemma
                                 If $$A$$ has two rows $$r_{i_1},r_{i_2}$$ of the form $$r_{i_1}=\alpha r_{i_2}+\beta$$ $$(\alpha\neq 1, \beta\neq 0)$$, at least one of them is an inactive strategy. Similar for two columns.
                                 Proof
                         Linear Algebra Approach #h
                             Direct Matrix Approach #slide 
                                 Direct properties 
                                     There is little stated about such direct relationship in the literature. 
                                         The results of \cite{@Weil1968} and \cite{ShapleySnow1950} [#todo @luluwah Find citation], applicable to matrix games, were the initial inspiration for the work in this Section and Theorem \ref{} is a generalisation. Theorem \ref{} then extends this to bimatrix games. The work in \cite{bimatrix}, although not using the concept of matrix pencils, #todo 
                             Motivation #slide 
                                 Starting point of our investigation was the observation that there are sufficient condition for the existence of optimal strategies and value of zero-sum games, expressed in terms of algebraic properties of the game matrix $$A$$.  % 
                             An Old Theorem #slide 
                                 Theorem [Shapley, 1950] Assume the square matrix $$A$$ is nonsingular and $$e^\top A^{-1}e \neq 0$$. Then the game with matrix $$A$$ has value $$v(A)=v=1/e^\top A^{-1}e$$ and optimal strategies $$x=ve^\top A^{-1}$$ and $$y=vA^{-1}e$$, provided both $$x$$ and $$y$$ are nonnegative. #theorem
                             Discussion #slide 
                                 The proof of this theorem only requires elementary algebra
                                     , and is a special case of our proof of Theorem \ref{}. #note
                                 This result computes the game value, provided $$v \neq 0$$
                                  And some assumptions that do not seem too restrictive. % #todo 
                             A More Recent Theorem #slide 
                                 #theorem:weil-theorem Weil, 1968] If $$A$$ has the real eigenvalue $$\lambda$$ corresponding to nonnegative eigenvectors $$x$$ and $$y$$, then $$v(A-\lambda I)=0$$ and $$x$$, $$y$$ are optimal for the game $$A-\lambda I$$.   #theorem
                                     mailto:Roman.Weil@ChicagoBooth.edu #note
                             Discussion #slide 
                                 Whilst this theorem might be applicable more often than the previous, it does mostly compute the value of a different game. 
                             Overview #slide 
                                 Goal: compute value $$v$$ and optimal solutions $$x^*, y^*$$ directly from properties of the game matrix $$A$$
                                 Few approaches:
                                     "Entscheidungsverfahren" for game value and completely mixed solutions (Kaplanski, 195x)
                                     Active submatrix (Shapley & Snow, 19xx), refined in (Karlin, 19xx) -- approach for computing solutions in exponential time
                                     Interesting relation to eigensystems (Weil) but without algorithmic application
                                 Considered being replaced by modern LP algorithms nowadays 
                             Incomplete Algorithm #slide 
                                 **algorithm** matrix_game_solve_incomplete($$A$$)
                                     **if** $$({e^T{\rm adj}( A)e}\neq 0)$$ **then**
                                         $$v := \frac{\det(A)} {e^T{\rm adj}( A)e}$$;
                                         **if** $$\neg (e^T{\rm adj}( A)= 0 \wedge {{\rm adj}( A)e}=0)$$ **then**  
                                             $$x:=\frac{e^T{\rm adj}(A)} {e^T{\rm adj}( A)e}$$
                                             $$y:=\frac{{\rm adj}(A)e} {e^T{\rm adj}( A)e}$$
                                             **if** $$x\ge 0$$ **and** $$y\ge 0$$ **then** **return**($$v$$, $$x$$, $$y$$);
                                         **fi**; 
                                     **fi**; 
                                     **return**(FAIL);
                                 **end**;
                             Complete Algorithm #slide 
                                 **algorithm** matrix_game_classic_solve_complete($$A$$)
                                     sols $$:= \emptyset$$
                                     **for all** submatrices $$\bar{A}$$ of $$A$$ **do**
                                         temp $$:=$$ matrix_game_solve_incomplete$$(\bar{A})$$
                                         **if** temp $$\neq$$ FAIL:
                                             $$(x,y,{v}) := $$ temp; 
                                             **if** check_solutions$$(A,x,y,{v})$$ **then** sols $$:=$$ sols $$\cup$$ temp
                                     **end**
                                     **return** sols;
                                 **end**
                             Discussion #slide 
                             INBOX
                                 **if** $$\neg ({\rm adj}( A)e= 0 \wedge {e^T{\rm adj}( A)e}=0)$$ **then**  
                                 else // $$\det A = 0$$ //
                                     **if** $$A$$ has non-negative left and right nullspace $$x,y$$:
                                         **return**($$x$$, $$y$$, $$0$$)
                                     **elif** $$\exists \mu:\det(A +\mu)\neq 0$$:
                                         $$(x,y,\tilde{v}):=$$ matrix_game_classic_solve$$(A+\mu)$$
                                         **return**($$x$$, $$y$$, $$\tilde{v}-\mu$$)
                                     **elif** $$\not \exists \mu:\det(A +\mu)\neq 0$$:
                                         return(FAIL)
                                 
                                     **if** $$(\exists a:\det(A +a)\neq 0 \wedge {e^T{\rm adj}( A+a)e}\neq 0)$$ **then**
                     Matrix Games and Generalised Eigensystems #h 
                         Regular Matrix Games #slide
                             #definition A square matrix game $$G(A)$$ is called  __regular__ iff $$P(\lambda):=A-\lambda E$$ is a regular matrix pencil.
                             We denote $$c(\lambda)=\det(A-\lambda E)\not\equiv 0$$ the __characteristic polynomial__. 
                             If $$c(\mu)=0$$, $$\mu$$ is an eigenvalue corresponding to left and right eigenvectors $$x_\mu$$ and $$y_\mu$$ of $$P_A$$.
                             We also say that $$\mu$$ is the eigenvalue of the game. 
                             Note: we can have $$\mu=\infty$$.
                             Question: how does the value of the game $$v(A)$$ relate to $$\mu$$?
                         VALUE OF GAME
                         INBOX #h
                             Definition #slide 
                                 https://math.stackexchange.com/questions/2115713/coefficient-of-characteristic-polynomial-as-sum-of-principal-minors
                             Note that rank of $$A$$ is then $$n-1$$.
                             If the game is completely mixed we can compute a strategic equivalent transformation $$T$$ such that the new completely mixed game has a pure optimal solution.
                             
                         Dominance #slide 
                         Matrix Transformations #slide
                 Signalling Games #h 
                     Definition #slide 
                         Simple type of a dynamic Bayesian game. 
                         It is a game with two players, called the sender and the receiver: 
                             The sender can have one of several types. The sender's type $$t$$, determines the payoff function of the sender. It is the private information of the sender - it is not known to the receiver.
                             The receiver has only a single type, so by the assumption of common priors, their payoff function is known to both players.
                     Game Play #slide 
                         The game has two steps:
                             The sender plays in the first step. They can play one of several actions, which are called __messages__. The set of possible messages is $$\mathcal M = \{m_1, m_2, m_3,\ldots, m_j\}$$.
                             The receiver plays in the second step, after viewing the sender's message. The set of possible actions is $$\mathcal A= \{a_1, a_2, a_3,\ldots, a_j\}$$.
                         The two players receive payoffs dependent on the sender's type, the message chosen by the sender and the action chosen by the receiver
                 Stackelberg Games #h 
                     In a Stackelberg game, one player (the leader) moves first, and all other players (the followers) move after him.
                     Stackelberg competition
                         Two firms (N = 2)
                         Each firm chooses a quantity sn  0
                         Cost of producing sn : cn sn
                         Demand curve:
                             Price=P(s1 +s2)=ab(s1 +s2)  Payoffs:
                             Profit=n(s1,s2)=P(s1 +s2)sn cn sn
                                 Stackelberg competition
                         In Stackelberg competition, firm 1 moves before firm 2.
                         Firm 2 observes firm 1s quantity choice s1, then chooses s2.
                     Stackelberg competition
                         We solve the game using backward induction.
                         Start with second stage: Given s1, firm 2 chooses s2 as
                         s2 = arg maxs2  S2 2(s1, s2)
                         But this is just the best response R2(s1)!
                         
                             Best response for firm 2
                         Recall the best response given s1:
                         Differentiate and solve: So:
                         
                             Firm 1s decision
                         Backward induction:
                         Maximize firm 1s decision, accounting for
                         firm 2s response at stage 2.
                         Thus firm 1 chooses s1 as
                         s1 = arg maxs1  S1 1(s1, R2(s1))
                         
                             Firm 1s decision
                         Define tn = (a - cn)/b.
                         If s1  t2, then payoff to firm 1 is:
                         If s1 > t2, then payoff to firm 1 is:
                         
                             Firm 1s decision
                         For simplicity, we assume that 2c2 a+c1
                         This assumption ensures that
                         is strictly decreasing for s1 > t2.
                         Thus firm 1s optimal s1 must lie in [0, t2].
                         
                             Firm 1s decision
                         If s1  t2, then payoff to firm 1 is:
                         
                             Firm 1s decision
                         If s1  t2, then payoff to firm 1 is:
                         
                             Firm 1s decision
                         If s1  t2, then payoff to firm 1 is:
                         Thus optimal s1 is:
                     Stackelberg equilibrium
                         So what is the Stackelberg equilibrium?
                         Must give complete strategies: s1* = (a - 2c1 + c2)/2b
                         s2*(s1) = (t2/2 - s1/2)+
                         The equilibrium outcome is that
                         firm 1 plays s1*, and firm 2 plays s2*(s1*).
                     Comparison to Cournot
                         Assume c1 = c2 = c.
                         In Cournot equilibrium:
                         (1)s1 =s2 =t/3.
                         (2) 1 = 2 = (a - c)2/(9b). In Stackelberg equilibrium:
                         (1) s1 = t/2, s2 = t/4.
                         (2) 1 = (a - c)2/(8b), 2 = (a - c)2/(16b)
                     Comparison to Cournot
                         So in Stackelberg competition:
                         -the leader has higher profits
                         -the follower has lower profits
                         This is called a first mover advantage.
                         
                             Stackelberg competition: moral
                         Moral:
                         Additional information available can lower a players payoff,
                         if it is common knowledge that the player will have the additional information.
                         (Here: firm 1 takes advantage of knowing firm 2 knows s1.)
                 Stochastic Games #h 
                     Background and Context #slide 
                         Security Games
                     Overview #h 
                     Small Taxonomy #slide 
                         Stochastic Game: transition function depends on the history 
                         Stochastic Games #slide 
                             A dynamic game that involves probabilistic transitions through several states of the system
                             Has a start state: players choose actions and receive a payoff that depends on the current state of the game
                             Then the game transitions into a new state, with a probability based upon players actions and the current state
                         Finite Stochastic Games #slide 
                             In these games, there are a finite number of players and a finite number of states. 
                             The outcome of the game depends on the actions taken by the players and the probability of transitioning from one state to another.
                         Continuous Stochastic Games #slide 
                             In these games, the state space is continuous, 
                             and the outcome of the game depends on the actions taken by the players and the probability of transitioning from one state to another.
                         Markov Decision Processes (MDPs) #slide 
                             MDPs can be seen as a special case of stochastic games
                             There is only one player, 
                             Outcome of the game depends only on:
                                 the player's actions 
                                 the probability of transitioning from one state to another.
                         Partially Observable Markov Decision Processes (POMDPs) #slide 
                             POMDPs are a more general form of MDPs
                             The state of the game is not directly observable
                             However it can be inferred from the observations made by the player.
                         Markov Games #slide 
                             Linear Markov Game: transition function depends only on the current state 
                             Extend the concept of Markov decision processes (MDPs) to the multiplayer setting
                             Multiple agents interact with each other in a shared environment
                             Actions affect not only the immediate reward but also the state of the environment, which influences future rewards.
                             New state does not depend on previous history though
                             Competitive Game: 2 player Zero Sum Markov Game
                         States #slide 
                             Like in an MDP, the state of a Markov game satisfies the Markov property, meaning that the current state captures all relevant information about the past history of the game. However, in a Markov game, each agent's action affects not only the immediate reward but also the transition function, which determines the probability distribution over the next state given the current state and joint actions of all agents.
                         Bayesian Games #slide 
                             In Bayesian games, the players have incomplete information about the state of the game, 
                             and the state of the game is determined by a random variable.
                         Evolutionary Games #slide 
                             In these games, the players are not rational decision-makers, but instead follow simple rules that determine their behavior. 
                             The outcome of the game is determined by the frequency of each player's behavior in the population.
                         Repeated Games #slide 
                             In these games, the players interact repeatedly over time
                             The outcome of the game depends on the history of previous interactions.
                         Stochastic Differential Games #slide 
                             These games are a more general form of stochastic games in which the state space evolves continuously over time, 
                             and the outcome of the game depends on the players' actions and the stochastic differential equations that govern the evolution of the state space.
                     Notations -- GameSec #slide 
                         We assume A dynamic game states of which changes over time 
                         A game different in each state 
                         Simultaneous actions of players A function describes the dynamic evolution of the system w.r.t the simultaneous plays and the state 
                         When the evolution function is random it is a stochastic game. 
                     Static 2-Player Zero-Sum Stochastic Games #h
                         Information Models #slide 
                             Perfect Information 
                                 In Step $$t$$, the players know all actions, states and rewards until Step $$t  1$$. 
                             Closed Loop 
                                 All players know the the current state of the game.
                         Mathematical Model #slide 
                             Dimensions:
                                 Number of players (2)
                                 Number of strategies per player
                                 Number of game stages
                                 Number of states
                             Maps:
                                 Payoff map $$G: \mathcal{P} \times  \mathcal{S} \times S  \rightarrow \R$$
                                 State transition map $$T: \mathcal{P} \times  \mathcal{S} \times S \rightarrow {S}$$
                         SHAPLEY STOPPING GAME
                             Model Motivation #slide 
                                 First description of stochastic game in seminal paper
                                 Stochastic Repeated Matrix Game 
                                 Maps:
                                     Payoff map $$G: \mathcal{P} \times  \mathcal{S} \rightarrow \R$$ is the same irrespective of current state
                                     State transition map $$T: \mathcal{P} \times  \mathcal{S} \times S \rightarrow {S}$$ depends linearly on chosen strategy and given state, hence a bilinear map
                             Description #slide 
                                 The same game $$G$$ proceeds in steps according to transition probabilities $$0\le s_{ij}\le 1$$
                                 If row player choose a strategy $$i$$ and column player chooses $$j$$, then 
                                     the game stops with probability $$s_{ij}$$
                                     the game continues with probability $$1-s_{ij}$$
                                 The state transition function is linearly depending on both players' strategies 
                                 Hence it is a function bilinear in the strategies
                             States and Transitions #slide 
                                 There are two states: play and stop.
                                 One is transient, the other absorbing.
                                 Transition matrix $$P$$ is encoding map 
                                     $$T: \mathcal{X}\times S \times \mathcal{Y} \rightarrow S$$, $$(x^\top,s,y) \mapsto T(x^\top,s,y):=x^\top Py$$.
                             Strategic State Transition Diagram #slide 
                                 ![Pasted image](https://dynalist.io/u/U5kmS8j_Y7NSIxSgU5Qh6an5) 
                             Stage Games #slide 
                             Payoffs #slide  
                             Playing the Game #slide 
                                 Define $$s=\min_{i,j} s_{ij}$$
                                 Hence, probability that game does not stop after $$t$$ steps is $$P(\text{"More than t steps"})\le (1-s)^t$$
                                 So game finishes in finite number of steps
                                 Payoffs accumulate throughout game
                                 Defining the bound $$M=\max | a_{ij} |$$ we find a bound for the expected payoff as
                                     $$M + (1-s)M + (1-s)^2M + \cdots = M/s$$.
                             Stationary Solutions #slide 
                                 Assume we play the same strategy $$(x^\top, y)$$ and repeat with probability $$p=x^\top P y$$
                                 The probability that the state after $$k$$ iterations is still "play" is $$p^k$$
                                 The probability that the game stops in the $$k$$th iteration is $$p^{k-1}(1-p)$$
                                 The overall payoff is $$u=\sum_i x^\top A yp^i$$
                                 $$v=\sum_i x^\top P^i y$$
                                 The strategy leading to this is $$(x^\top P^k, P^ky)$$
                         MARKOV GAME
                             Stochastic Markov Matrix Game #slide 
                                 States progress from $$s_i$$ to $$s_j$$ according to transition probabilities $$0\le s_{ij}\le 1$$
                                 They follow a linear Markov model with transition matrix $$S$$
                                 Game $$G_k$$ proceeds in state $$k$$
                             Model #slide 
                                 Maps:
                                     Payoff map $$G: \mathcal{S} \times S  \rightarrow \R$$ corresponds to definition of a stage game $$G(s)$$
                                     State transition map $$T:  \mathcal{S} \times S \rightarrow {S}$$ is linear, independent of player and strategies
                             States and Transitions #slide 
                             Stage Games #slide 
                             Payoffs #slide  
                             Playing the Game #slide 
                                 If row player choose a stationary Equilibrium strategy $$x_k^*$$ and column player chooses $$x_j^*$$, then they receive corresponding payoffs $$v_k$$ and $$w_k$$
                                 Payoffs accumulate throughout game
                             Solving the Game #h 
                                 Stationary Solutions #slide 
                                 Value of Game #slide 
                                 Best Response #slide 
                         INTERCONNECTED SYSTEM GAME
                             Model Motivation #slide 
                                 Maps:
                                     Payoff map $$G: \mathcal{P} \times  \mathcal{S} \times S  \rightarrow \R$$
                                     State transition map $$T: \mathcal{P} \times  \mathcal{S} \times S \rightarrow {S}$$
                             Description #slide 
                             States and Transitions #slide 
                             Stage Games #slide 
                             Payoffs #slide  
                             Playing the Game #slide 
                                 If row player choose a stationary Equilibrium strategy $$x_k^*$$ and column player chooses $$x_j^*$$, then they receive corresponding payoffs $$v_k$$ and $$w_k$$
                                 Payoffs accumulate throughout game
                             Solving the Game #h 
                                 Stationary Solutions #slide 
                                 Value of Game #slide 
                                 Best Response #slide 
                         TWO-STAGE REPEATED GAME
                             Repeated Games #h 
                                 Maps:
                                     Payoff map $$G: \mathcal{P} \times  \mathcal{S} \times S  \rightarrow \R$$
                                     State transition map $$T: \mathcal{P} \times  \mathcal{S} \times S \rightarrow {S}$$
                                 Definition #slide 
                                     An [extensive form game](https://en.wikipedia.org/api/rest_v1/page/mobile-html/Extensive_form_game) that consists of a number of repetitions of some base game (called a stage game). 
                                     The stage game is usually one of the well-studied [2-person games](https://en.wikipedia.org/api/rest_v1/page/mobile-html/List_of_games_in_game_theory). 
                                     Repeated games capture the idea that a player will have to take into account the impact of his or her current action on the future actions of other players; this impact is sometimes called his or her reputation.  
                                     Single stage game or single shot game are names for non-repeated games.
                                 Repeated Games #h 
                                     Stochastic Games #slide 
                                         We now look at repeatedly playing these games $$G_1$$ and $$G_2$$. 
                                         We will define some stopping conditions to prevent an infinite duration. 
                                         This yields __stochastic games__, as introduced by (Shapley, 1953). 
                                         Let us focus on repeating $$G_1$$ first. 
                                     The Stochastic Game  $$G^*_1$$ #slide
                                         Consider the stopping matrix $$S=\begin{pmatrix} 1& s\\ s &1  \\  \end{pmatrix}$$ where $$0<s < 1$$. 
                                         There will be a finite sequence $$i=1,\ldots,N$$ of the __stage-game__ $$G^*_1$$. 
                                         The players decide on their strategies $$x_i$$ and $$y_i$$
                                         The payoffs of each stage are added
                                         After a stage, the game stops if:
                                             The system can trust a cooperative Wizard
                                             The system detects a non-cooperative Wizard
                                         Otherwise, it continues with probability $$1-s$$
                                     Game Analysis -- Questions #slide 
                                         What are the NEs?
                                         As a parameter of $$s$$?
                                         Good values for $$s$$?
                                         How do we interpret mixed strategies?
                                         Run simulation -- mixed strategies.
                                     Previous Work #slide 
                                         Shapley has shown that in the case of a matrix game (zero-sum, $$B=-A$$), there is a unique value $$v$$.
                                         One can obtain this from a rational form $$v := \min_x \max_y \frac{xAy}{xSy}$$.
                                         (Von Neumann, 1937) and (Loomis, 1946) have first shown the existence and uniqueness of this value.
                                         (Thompson & al) connect linear algebra concepts to the structure of optimal solutions.
                                         More recent work? On bimatrix (non-zero sum) case?
                                     Our Approach #slide 
                                         Following Thompson, we consider the matrix pencil $$P(\lambda)=A-\lambda S$$.
                                         Concepts: generalised characteristic polynomial, eigenvalues and eigenvectors.
                                         A fundamental result is due to Thompson et al.
                                             https://dynalist.io/d/LEdIn-fQiooRnQn8D-7fFHVC#z=YSp1OMYk8Zhb6qGinGLbhdKe #wfe-ignore-item
                     Rational Games #h 
             Security Games #h 
                 Introduction #slide #IARIA
                     Security games model interaction between players:
                         attacker(s)
                         defender(s)
                     They assume that players are:
                         rational
                         non-cooperative 
                     All players seek to maximise their payoff (utility) functions.
                     Our context: two-player, non-zero-sum complete information games.
                 Notations and Definitions #slide 
                     Players
                         $$\mathcal{P} = \{\mathcal{A}, \mathcal{D}\}$$ where
                             $$\mathcal{A}$$ -- attacker #notation
                             $$\mathcal{D}$$ -- defender #notation
                     Strategies
                         $${\mathcal S}_\mathcal{A}$$ -- strategy set/space of attacker #GT 
                         $${\mathcal S}_\mathcal{D}$$ -- strategy set/space of defender #GT 
                         $$s_\mathcal{A} \in {\mathcal S}_\mathcal{A}$$ -- strategy of attacker (pure or mixed)
                         $$s_\mathcal{D} \in {\mathcal S}_\mathcal{D}$$ -- strategy of defender (pure or mixed)
                         $$s = (s_\mathcal{A}, s_\mathcal{D})$$ where $$s_\mathcal{A} \in {\mathcal S}_\mathcal{A}$$ and $$s_\mathcal{D} \in {\mathcal S}_\mathcal{D}$$: strategy profile where strategies are chosen from strategy spaces
                     Utility Functions
                         $$u_\mathcal{A}$$ -- attacker's utility function #notation 
                         $$u_\mathcal{D}$$ -- defender's utility function #notation 
                 Complete Information Security Games #slide #IARIA 
                     Introduction #slide #IARIA 
                         Complete information security games assume mutual knowledge of strategies, by both the attacker and defender. 
                         In real-world scenarios, this could correspond to a situation where the attacker might be able to gain some knowledge. 
                         For example, through:
                             insider information
                             information leakage
                             reconnaissance
                         The defender might be aware of potential attackers and their motivation through security assessment and risk analysis. 
                     Massive 2-Player Complete Information Security Games #h 
                         Motivation #slide 
                             Game-theoretic models that are motivated by real-world scenarios.
                             Constraints in defense budget can be taken into account.
                             Big security games are usually non-zero-sum games.
                             Typically, they have 2 players but a large number of actions.
                             A compact notation helps with efficiently storing and solving the game.
                         Notations #slide 
                             Let us fix some notations:
                                 $${\mathcal T} = \{t_1,\ldots,t_n\}$$ -- set of __targets__ (assets under attack),
                                 $${\mathcal R} = \{r_1,\ldots,r_m\}$$ -- set of __resources__, covering $$m \leq n$$ targets (implementing controls),
                             Example: Case Study 1
                                 $$\{t_1,\ldots,t_n\}$$ -- targeted YouTube channels ($$n=31,000,000$$),
                                 $$\{r_1,\ldots,r_m\}$$ -- YouTube employees ($$m \ll n$$).
                         Strategies -- Attacker #slide 
                             The attacker can choose between __pure__ or __mixed__ strategies.
                                 Pure strategy space:
                                     $$s_A= {\mathcal T}$$ -- the set of targets,
                                 Mixed strategy space:
                                     $$s_A= \{(q_1,q_2,\ldots q_n )\}$$ where $$0 \le q_j \le 1 $$ and $$\sum q_j=1 $$ represents the probability of attacking target $$t_i$$. 
                             Example: Case Study 1
                                 The attacker can choose random YouTube channels as his targets, using an automated script. This implements a mixed strategy.
                         Strategies -- Defender #slide 
                             $${\mathcal S}$$ -- set of __feasible schedules__, representing specific allocations of resources to cover targets (respecting a finite budget constraint).
                             There are $$d={n \choose m}$$ such feasible schedules.
                             Pure strategy:
                                 This is a feasible schedule $$s_D \in {\mathcal S}$$, covering $$m$$ out of $$n$$ targets.
                                 Notation: $$s = \langle i_1,i_2,\ldots i_n \rangle$$  ($$i_j \in \{0, 1\}$$, $$\sum i_j = m$$).
                                     $$s \subset {\mathcal T}$$ ($$|s| = m$$) -- set notation  #wfe-ignore-item 
                             Mixed strategy:
                                 $$s_D = ( p_1,p_2,\ldots p_d )$$ where $$0 \le p_j \le 1$$ are probabilities of using a feasible schedule.
                                 This induces a __coverage vector__ $$c = \langle c_{1},\ldots, c_{n} \rangle$$, expressing the probability of protection for each of the targets.
                         Utilities #slide 
                             Compact notations: utility per use/attack of $$t_i$$
                                 $$u_D^c(t_i)$$ -- defender's utility when target $$t_i$$ is covered by at least one resource,
                                 $$u_D^u(t_i)$$ -- defender's utility for uncovered target $$t_i$$,
                                 $$u_A^c(t_i)$$ -- attacker's utility for a covered target $$t_i$$,
                                 $$u_A^u(t_i)$$ -- attacker's utility, when $$t_i$$ is uncovered.
                             $$u_D^c(t_i) - u_D^u(t_i) = 0$$ if $$t_i$$ is not attacked.
                         Assumptions/Properties #slide
                             Applying resources to a target benefits the defender and hurts the attacker:
                                 $$\Delta u_D(t_i) := u_D^c(t_i) - u_D^u(t_i) > 0$$ -- the defender's utility reduction due to loss of coverage on attack,
                                 $$\Delta u_A(t_i) :=  u_A^u(t_i)-u_A^c(t_i) > 0$$ -- the attacker's utility gain when attacked target not covered.
                             These assumptions are realistic, for the considered scenario.
                         Example: Case Study 1 #slide 
                             YouTube Game in sparse notation:
                             Using bimatrix game notation, we have:
                                 $$A=\begin{pmatrix} 7 & 1 & 3 & 0 \\ 3& 5 & 3 & 0 \\ 3& 1 & 4 & 0 \\ 3& 1 & 3 & 3 \\ \end{pmatrix}$$, $$B=\begin{pmatrix} 0 & 4 & 5 & 3 \\ 1& 1 & 5 & 3 \\ 1 &  4& 0 & 3 \\ 1& 4 & 5 & 2 \\ \end{pmatrix}$$ #eyo-style:Normal 
                         Example (continued) #slide 
                             The unique NE solution $$(x^*, y^*) $$ to this game is: $$x^*= (0, 0.39, 0.43, 0.17)$$ and $$y^*= (0, 0.16, 0.63, 0.21 )$$.
                             The corresponding expected payoffs are 2.68 and 2.83.
                             These are coverage vectors, from which suitable feasible schedules can be computed.
                         References #slide 
                             Kiekintveld, C., Jain, M., Tsai, J., Pita, J., Ordez, F., and Tambe, M. (2009). Computing Optimal Randomized Resource Allocations for Massive Security Games. Proceedings of The 8th International Conference on Autonomous Agents and Multiagent Systems, 1, 689696. https://doi.org/http://dl.acm.org/citation.cfm?id=1558108
                             Korzhyk, D., Yin, Z., Edu, Z., Kiekintveld, C., Conitzer, V., and Tambe, M. (2011). Stackelberg vs. Nash in Security Games: An Extended Investigation of Interchangeability, Equivalence, and Uniqueness. Journal of Artificial Intelligence Research, 41, 297327. Retrieved from https://www.jair.org/media/3269/live-3269-5686-jair.pdf
                     Public Good $$n$$-Player Security Games #h
                         Economics and Security Games - Basic Equations #slide 
                             $$p$$ - Exogenous probability of attack
                             Expected utility function of defender under attack with probability $$p$$ is $$u = b - p \cdot c_a - c_d$$ where $$c_a$$ is the cost due to assets under attack and $$c_d$$ is the defense cost.
                             More specifically, $$u = b - p (1 - \sigma(\gamma)) L - \kappa(\gamma)$$
                         CLOUD PROVIDER DECISION-MAKING SECURITY GAMES #decision
                     Strategic 2-Player Complete Information Security Games #h 
                         Disadvantages of Big Games #slide 
                             Unrealistic to be adopted due to large number of NEs 
                             Lack of analytical insight into solution structure
                             Computationally hard
                             Leads to small security games
                         Strategic 2-Player Security Games #slide 
                             Strategic security games are smaller versions and specialisations of the massive 2-player security games.
                             Motivation for their use in modelling security scenarios:
                                 They are insightful for theoretical analysis as they can be solved explicitly
                                 They are suitable for certain specific real-world scenarios, e.g. 
                                     Security assessment, as risk analysis mostly considers single asset at a time
                                     Vulnerability scoring, as a game-theoretic version of CVSS, as only deals with one vulnerability at the time
                             Analysis is inspired by typical considerations in game theory, e.g. for the famous Prisoner's Dilemma.
                         Utility, Cost and Benefit Functions  #slide 
                             $$u_D = b_D - c_D$$ 
                                 $$b_D$$ -- operational benefit 
                                 $$c_D = c_l + c_d$$ -- loss due to attack and cost of defense 
                             $$u_A = b_A - c_A$$ 
                                 $$b_A$$ -- benefit of the attacker
                                 $$c_A$$ -- cost of the attacker 
                         Single-Target Games #h 
                             Attack-Defence Game #h #single-target 
                                 Motivation #slide 
                                     Single-target game: we only consider one target. The focus is on the single asset that has a vulnerability.
                                     Most simple attacker defender scenario.
                                         Rows corresponds to the strategies available to the defender.
                                         Columns are the attacker's strategies.
                                     Strategies:
                                         $$S_\mathcal{D} = \{$$defend, not defend$$\} = \{s_d, s_{-d}\}$$ 
                                         $$S_\mathcal{A} = \{$$ attack, not attack $$\} = \{s_a, s_{-a}\}$$ 
                                 Payoff Notations #slide 
                                     $$c_{d}$$ -- the defense cost
                                     $$l_{d}$$ -- the defender's loss from an attack
                                     $$c_{a}$$ -- the attacker's cost
                                     $$r_{a}$$ -- the reward (benefit) of the attacker from an attack.
                                     Assumptions:
                                         __Principle of Adequate Protection__: $$c_{d} <l_{d}$$
                                         __Principle of Easiest Attack__: $$c_{a} < l_{d}$$
                                         The winner gets it all: $$r_{a} = l_{d}$$
                                 Game Description  #slide 
                                     $$G(\mathcal{D},\mathcal{A})$$  Payoff Matrix:
                                         $$\begin{array}{ | c | c | c| } \hline \mathcal{D} \downarrow \mathcal{A}\rightarrow & s_a & s_{-{a}} \\ \hline s_d &  - c_d, - c_a&  -c_d,  0 \\ \hline s_{-{d}} &  -l_d,  r_a- c_a &  0,  0 \\ \hline\end{array}$$ #eyo-style:Normal 
                                 Game Analysis #slide
                                     **Theorem 1**. The security game $$G(\mathcal{D},\mathcal{A})$$ has no pure Nash Equilibrium.
                                     **Proof**: By inspecting the game.
                                     **Theorem 2**. A mixed Nash Equilibrium strategy pair $$(x_\mathcal{D}^,x_\mathcal{A}^)$$ is obtained, where $$p^=1-c_{a}/r_{a}$$ and $$q^=c_{d}/l_{d}$$ are the probability of defense and attack respectively. The resulting expected payoffs, in this case, are $$u_{d}^=c_{d}$$ and $$u_{a}^=0$$.
                                     **Proof**: Following Nash.
                                 References #slide
                                     __Strategically zero-sum games: The class of games whose completely mixed equilibria cannot be improved upon__ - International Journal of Game Theory, 1978, Volume 7, Number 3-4, Page 201 - H. Moulin, J. -P. Vial #wfe-ignore-item 
                                     Maghrabi, L., Pfluegel, E., Al-Fagih, L., Graf, R., Settanni, G., & Skopik, F. (2017). Improved software vulnerability patching techniques using CVSS and game theory. In 2017 International Conference on Cyber Security and Protection of Digital Services, Cyber Security 2017. Institute of Electrical and Electronics Engineering, https://doi.org/10.1109/CyberSecPODS.2017.8074856
                                 SA Game
                                     $$\begin{array}{ | c | c | c| } \hline \mathcal{D} \downarrow \mathcal{A}\rightarrow & s_a & s_{-{a}} \\ \hline s_d &  - d, - a&  -d,  0 \\ \hline s_{-{d}} &  -I,  G- a &  0,  0 \\ \hline\end{array}$$ #eyo-style:Normal 
                             AD Game with Reward #h #single-target 
                                 Motivation #slide 
                                     Most simple scenario
                                     We only consider one target
                                     Assume complete protection by defense
                                     We add a reward for the attacker, wether he decides to attack or not, because he pushes the defender to spend a cost to proctect his assets.
                                 Notations #slide 
                                     $$t$$ -- target (an asset $$a$$) 
                                     $$c^{\mathcal{D}}$$ -- the defense cost
                                     $$l^{\mathcal{D}}$$ -- the defender's loss from an attack
                                     $$c^{\mathcal{A}}$$ -- the attacker's cost
                                     $$l^{\mathcal{D}}$$ -- the benefit of the attacker.
                                     $$r$$ -- the reward for the atacker
                                     Strategies
                                         $$S_\mathcal{D} = \{defend, not\ defend\} = \{s_d, s_{-d}\}$$ 
                                         $$S_\mathcal{A} = \{attack, not\ attack\} = \{s_a, s_{-a}\}$$ 
                                 Assumptions #slide
                                     Principle of Adequate Protection : $$c^{\mathcal{D}} <l^{\mathcal{D}}$$
                                     Principle of Easiest Attack : $$c^{\mathcal{A}} < l^{\mathcal{D}}$$
                                 Utility Matrix #slide #utility 
                                     $$\begin{array}{ | c | c | c | }  \mathcal{D} \downarrow \mathcal{A}\rightarrow & s_a & s_{-{a}} \\ s_d &  - c^{\mathcal{D}}, r- c^{\mathcal{A}}&  -c^{\mathcal{D}},  r\\  s_{-{d}} &  -l^{\mathcal{D}},  l^{\mathcal{D}}- c^{\mathcal{A}} &  0,  0 \end{array}$$  #normal
                                 Equilibrium Analysis #slide [2]
                                     There is one optimal Mixed NE Strategy
                                         $$x^{*} = \frac{l^{\mathcal{D}}-c^{\mathcal{A}}}{l^{\mathcal{D}}} = 1 - \frac{c^{\mathcal{A}}}{l^{\mathcal{D}}}$$
                                         $$y^{*} = \frac{c^{\mathcal{D}}}{l^{\mathcal{D}}}$$
                                     The corresponding optimal expected utilities are:
                                          $$s^{*}_d = -c^{\mathcal{D}} $$
                                         $$s^{*}_a =  \frac {{l^\mathcal{D}}^2 r - l^\mathcal{D} r c^\mathcal{A}} {{l^\mathcal{D}}^2 } = r - \frac {r c^\mathcal{A}}{l^\mathcal{D}}$$ 
                                     The game is strategically zero-sum [1] #todo
                                 References #slide #todo 
                                     [1] - __Strategically zero-sum games: The class of games whose completely mixed equilibria cannot be improved upon__ - International Journal of Game Theory, 1978, Volume 7, Number 3-4, Page 201 - H. Moulin, J. -P. Vial
                                     [2] - Maghrabi, L., Pfluegel, E., Al-Fagih, L., Graf, R., Settanni, G., & Skopik, F. (2017). Improved software vulnerability patching techniques using CVSS and game theory. In 2017 International Conference on Cyber Security And Protection Of Digital Services, Cyber Security 2017. Institute of Electrical and Electronics Engineers Inc. https://doi.org/10.1109/CyberSecPODS.2017.8074856
                             SECURITY-LEVEL GAME #h #single-target 
                                 Motivation #slide 
                                 Notations #slide 
                                     Strategies
                                         Defend with controls $${\gamma}_1$$ or $${\gamma}_2$$
                                         Attack or not attack
                                         Strategy Spaces
                                             $${\mathcal S}_D = \{defend, not\ defend\} = \{s^{d}_D, s^{-d}_D\}$$
                                             $${\mathcal S}_A = \{attack, not\ attack\} = \{s^{a}_A, s^{-a}_A\}$$
                                 Utility Matrix #slide #utility
                                     $$\begin{array}{  c | c | c  }  \mathcal{D} \downarrow \mathcal{A}\rightarrow & s_a & s_{-{a}} \\ s_{\sigma_1}&  - c_1^{\mathcal{D}}-(1-\sigma_1)l^{\mathcal{D}}     ,(1-\sigma_1)l^{\mathcal{D}}  - c^{\mathcal{A}}&  -c_1^{\mathcal{D}},  0 \\  s_{\sigma_2}& - c_2^{\mathcal{D}}-(1-\sigma_2)l^{\mathcal{D}}  ,  (1-\sigma_2)l^{\mathcal{D}}- c^{\mathcal{A}} &  -c_2^{\mathcal{D}},  0 \end{array}$$
                                 Assumptions #slide
                                     #todo comapre the sigma and cost
                                 Equilibrium Analysis #slide 
                                     Optimal Mixed NE Strategies
                                         $$x^{*} = \frac{c^\mathcal{A} - (1 - \sigma_2 )l^\mathcal{D}}{(\sigma_2 - \sigma_1)l^\mathcal{D}} $$
                                         $$y^{*} = \frac{c^\mathcal{D}_1 - c^\mathcal{D}_2}{(\sigma_1 - \sigma_2)l^\mathcal{D}}$$
                                     Optimal Expected Utilities 
                                          $$s^{*}_d = \frac{c^\mathcal{D}_1 (\sigma_1 \sigma_2 +\sigma_2 - \sigma_1 - {\sigma_2}^2) + c^\mathcal{D}_1 (\sigma_1 \sigma_2 + \sigma_1 - \sigma_2 - {\sigma_1}^2)}{(\sigma_1-\sigma_2)^2} $$
                                         $$s^{*}_a = 0 $$ 
                                 Discussion #slide 
                                 References #slide 
                         Two-Target Games #h #
                             RESOURCE ALLOCATION (SEARCH) GAME #h
                                 Motivation
                                     a game with a restricted budget
                                     the utility compagny want to decide where to spend it
                                     type of game that is more realistic nowadays
                                 ********Notations******** 
                                     $$t_1, t_2$$ -- targets (asset $$a_1$$ and $$a_2$$)
                                     $$r$$ -- resource, covering either $$t_1$$ or $$t_2$$ 
                                     $$c^\mathcal{D}_{t_1}, c^ \mathcal{D}_{t_2}$$ -- the defense cost
                                     $$c^\mathcal{A}_{t_1}, c^ \mathcal{A}_{t_2}$$ -- the attack cost
                                     $$l^\mathcal{D}_{t_1}, l^ \mathcal{D}_{t_2}$$  -- the defender's loss from an attack
                                     $$l^\mathcal{D}_{t_1}, l^ \mathcal{D}_{t_2}$$  -- the benefit of the attacker
                                     Strategies
                                         $$S_\mathcal{D} = \{{defend }\; t_1, {defend }\; t_2\} = \{s^\mathcal{D}_{t_1}, s^\mathcal{D}_{t_2}\}$$
                                          $$S_\mathcal{A} = \{{attack}\; t_1, {attack}\; t_2\} = \{s^\mathcal{A}_{t_1},s^\mathcal{A}_{t_2}\}$$
                                 Utility Matrix #slide #utility [1]
                                     $$\begin{array}{ c | c | c }  \mathcal{D} \downarrow \mathcal{A}\rightarrow & s^\mathcal{A}_{t_1} & s^\mathcal{A}_{t_2} \\ \hline s^\mathcal{D}_{t_1} &  - c^{\mathcal{D}}_{t_1}, - c^{\mathcal{A}}_{t_1}&  -c^{\mathcal{D}}_{t_1} -l^ \mathcal{D}_{t_2},  -c^{\mathcal{A}}_{t_2} +l^ \mathcal{D}_{t_2} \\   \hline s^\mathcal{D}_{t_2} &  -c^{\mathcal{D}}_{t_2} -l^ \mathcal{D}_{t_1},  - c^{\mathcal{A}}_{t_1} + l^{\mathcal{D}}_{t_1} &  -c^{\mathcal{D}}_{t_2},  -c^{\mathcal{A}}_{t_2} \end{array}$$
                                 Equilibrium Analysis #slide  [1]
                                     There is one optimal Mixed NE Strategy #todo compare with Italian paper
                                         $$x^{*} = \frac{l^\mathcal{D}_{t_1} + c^\mathcal{A}_{t_2} - c^\mathcal{A}_{t_1}}{l^\mathcal{D}_{t_1} + l^\mathcal{D}_{t_2}}$$
                                         $$y^{*} = \frac{l^\mathcal{D}_{t_2} + c^\mathcal{D}_{t_1} - c^\mathcal{D}_{t_2}}{l^\mathcal{D}_{t_1} + l^\mathcal{D}_{t_2}}$$
                                     The corresponding optimal expected utilities are:
                                          $$s^{*}_d = \frac {l^\mathcal{D}_{t_1}   l^\mathcal{D}_{t_2} (c^\mathcal{D}_{t_1}+c^\mathcal{D}_{t_2} +l^\mathcal{D}_{t_1}+l^\mathcal{D}_{t_2}  ) + c^\mathcal{D}_{t_1}{l^\mathcal{D}_{t_1} }^2 +  c^\mathcal{D}_{t_2} {l^\mathcal{D}_{t_2} }^2}{-(l^\mathcal{D}_{t_1}+l^\mathcal{D}_{t_2})^2} $$
                                         $$s^{*}_a = \frac {l^\mathcal{D}_{t_1}  l^\mathcal{D}_{t_2} (c^\mathcal{A}_{t_1}+c^\mathcal{A}_{t_2} -l^\mathcal{D}_{t_1}-l^\mathcal{D}_{t_2}  ) + c^\mathcal{A}_{t_1}{l^\mathcal{D}_{t_2} }^2 +  c^\mathcal{A}_{t_2}{l^\mathcal{D}_{t_1} }^2}{-(l^\mathcal{D}_{t_1}+l^\mathcal{D}_{t_2})^2}  $$
                                 References #slide 
                                     [1] - Gianini, G., Cremonini, M., Rainini, A., Cota, G. L., & Fossi, L. G. (2015). A game theoretic approach to vulnerability patching. In 2015 International Conference on Information and Communication Technology Research, ICTRC 2015 (pp. 8891). Institute of Electrical and Electronics Engineers Inc. https://doi.org/10.1109/ICTRC.2015.7156428
                             BIG GAME SPECIALISATION #h 
                                 Motivation
                                     a two-target game with one ressource
                                 Notations
                                     $$U^d_c(t_i)$$ -- the defense cost for the covered target $$t_i$$.
                                     $$U^d_u(t_i)$$ -- the defense cost for the uncovered target $$t_i$$.
                                     $$U^a_c(t_i)$$ -- the attack cost for the covered target $$t_i$$.
                                     $$U^a_u(t_i)$$ -- the attack cost for the uncovered target $$t_i$$.
                                     Strategies
                                         $$S_\mathcal{D} = \{{defend }\; t_1, {defend }\; t_2\} = \{s^\mathcal{D}_{t_1}, s^\mathcal{D}_{t_2}\}$$
                                          $$S_\mathcal{A} = \{{attack}\; t_1, {attack}\; t_2\} = \{s^\mathcal{A}_{t_1},s^\mathcal{A}_{t_2}\}$$
                                 Utility Matrix #slide #utility [1]
                                     $$\begin{array}{ c | c | c }  \mathcal{D} \downarrow \mathcal{A}\rightarrow & s^\mathcal{A}_{t_1} & s^\mathcal{A}_{t_2} \\ s^\mathcal{D}_{t_1} &  U^d_c(t_1), U^a_c(t_1)&  U^d_u(t_2), U^a_u(t_2)  \\  s^\mathcal{D}_{t_2} &  U^d_u(t_1), U^a_u(t_1)&  U^d_c(t_2), U^a_c(t_2)\end{array}$$
                                 Equilibrium Analysis #slide  [1]
                                     There is one optimal Mixed NE Strategy 
                                         $$x^{*} = \frac{U^a_c(t_2)-U^a_u(t_1)}{U^a_c(t_2)-U^a_u(t_1) + U^a_c(t_1)-U^a_u(t_2) }$$
                                         $$y^{*} = \frac{U^d_c(t_2)-U^d_u(t_2)}{U^d_c(t_2)-U^d_u(t_2) + U^d_c(t_1)-U^d_u(t_1)}$$
                                     The corresponding optimal expected utilities are:
                                          $$s^{*}_d =  $$
                                         $$s^{*}_a =  $$
                         Alpcan et al IDS Game #h 
                             Strategies #slide 
                                 Attacker
                                     $$a$$ attack
                                     $$-a$$ not attack
                                 Defender
                                     $$d$$ intensified monitoring
                                     $$-d$$ default response (no major defence)
                             Payoffs #slide 
                                 Player $$\mathcal{D}$$ (defender) payoffs
                                     $$\alpha_c$$ -- gain from detecting the attack
                                     $$\alpha_m$$ -- cost of missing the attack
                                     $$\alpha_f$$ -- cost of a false alarm 
                                 Player $$\mathcal{A}$$ (attacker)  payoffs
                                     $$\beta_c$$ -- cost of detection penalty
                                     $$\beta_s$$ -- benefit from undetected attack (reward)
                             Strategic Normal Form #slide 
                                 Game $$\mathcal{G}(\alpha, \beta)$$:
                                     $$\begin{array}{ c | c | c }  \mathcal{D} \downarrow \mathcal{A}\rightarrow & {a} & \mathcal{-a}  \\\hline  {d}&  {\alpha}_c , -{\beta}_c & -{\alpha}_f , 0\\\hline  {{-d}} &  -{\alpha}_m, {\beta}_s  & 0,0 \end{array}$$ #eyo-style:Normal 
                             Analysis #slide 
                                 Let $$0\leq {p}\leq{1}$$ and $$0\leq {q}\leq{1}$$.
                                 Furthermore:
                                     $$p$$ and $$(1-p)$$ be the probability for the attack/not attack actions
                                     $$q$$ and $$ (1-q)$$ be those for the defend/not defend actions
                             NE Solutions #slide 
                                 Each game possesses one unique mixed NE solution $$(p^{*},1-p^{*})$$ and $$(q^{*},1-q^{*})$$:
                                     $${p}^{*}=\frac{\alpha_f}{\alpha_f+\alpha_c+\alpha_m}$$ 
                                     $${q}^{*}=\frac{\beta_s}{\beta_c+\beta_s}$$ 
                                 Corresponding equilibrium values:
                                     $${p}^{*}\alpha_c +(1-{p}^{*})(-\alpha_f) = - {p}^{*}\alpha_m  =\frac{-\alpha_f\alpha_m}{\alpha_f+\alpha_c+\alpha_m}$$
                                     $${q}^{*}(-\beta_c) +(1-{q}^{*})\beta_s =  {q}^{*}(0) +(1-{q}^{*})(0) = 0$$
                             References #slide 
                                 [1] T. Alpcan & T. Basar, 2011, Network Security -- A Decision and Game-Theoretic Appraoch, Cambridge University Press 
                     INBOX
                         For the special case of security games as introduced in \cite{@Kiekintveld2009}, more specialised methods have been developed.
                         , exploiting properties specific to these types of games and reducing the bimatrix game to a matrix (zero-sum) game \cite{@Korzhyk2011a}. Other transformation techniques are given in \cite{}. By relaxing the assumption of algebraic independence of  the matrices $$A$$ and $$B$$, algorithmic game analysis is simplified. In \cite{}, the authors show how to compute optimal Nash Equilibria if the game matrices are linked by an affine transformation. [ #todo More recent refs] The notion of strategical equivalence as defined in \cite{@Moulin1978} can also be characterised in terms of algebraic relations however it does not seem applicable to arbitrary security games \cite{@Korzhyk2011a}. 
                 Bayesian Security Games #h 
                     Bayesian we must say that the Defender for example knows his type, chosen by the Nature, and he selects his best response; then the Attacker uses a prob dist over Defenders types plays his best response. 
                 Stochastic Security Games #h 
                     Notations #slide 
                         Security Games
                         Stochastic Games
             Specific Example Games #h 
                 Chicken Game #slide
                 Coordination Game #slide 
                     
                 Hawk & Dove Game #slide
                 Inspection Game #slide
                 Prisoner Dilemma #slide 
                     Non-cooperative game (Selfish players/agents) #slide 
                         2 Rational Players
                         How non-cooperative and they cooperate to be silent?
                         Strategies for prisoners:
                             Betray and testify that the other committed the crime
                             Cooperate with the other prisoner by remaining silent
                             Prisoners cannot choose to reward or punish their partner other than the prison sentences they get
                     Payoffs #slide 
                         THIS
                             If both players cooperate (C), they each receive a payoff of -1.
                             If one cooperates (C) and the other defects (D), the cooperator receives -3 while the defector receives 0.
                             If both defect (D), they each receive -2.
                         OR
                             If prisoners betray each other, both will serve 2 years in prison
                             If prisoner A betrays prisoner B but B remains silent, A will be set free and B will serve 3 years in prison
                             If A and B both remain silent, both of them will only serve 1 year in prison
                     Strategic Normal Form #slide 
                         $$\begin{array}{|c|c|c|}\hline \mathcal{P}_1 \downarrow \mathcal{P}_2\rightarrow& \text{cooperate} (C) & \text{defect} (D) \\\hline \text{cooperate} (C) & (-1, -1) & (-3, 0) \\\hline \text{defect} (D) & (0, -3) & (-2, -2) \\\hline \end{array}$$
                     Generalised PD #slide 
                         $$\begin{array}{|c|c|c|}\hline \mathcal{P}_1 \downarrow \mathcal{P}_2\rightarrow& \text{cooperate} (C) & \text{defect} (D) \\\hline \text{cooperate} (C) & (R,R) & (S,T) \\\hline \text{defect} (D) & (T,S) & (P,P) \\\hline \end{array}$$
                         $$T>R>P>S$$
                         $$2R>T+S$$
                 Search Games #slide
                 Sheriff's Dilemma #h
                     A Sheriff's Dilemma #slide 
                         A sheriff is faces an armed suspect and they each must(simultaneously) decide whether to shoot the other or not,and :
                         \begin{itemize}
                         \item the suspect is either a criminal with a probability $$\pi$$ or not with probability 1 - $$\pi$$
                         \item the sheriff would rather shoot if the suspect shoots,but not if the suspect does not
                         \item the criminal would rather shoot even if the sheriff does not, as the criminal would be caught if does not shoot
                         \item the innocent suspect would rather not shoot even if the sheriff shoots.
                         \end{itemize}
                         We are facing a bayesian game were sheriff doesn't possess full information about his oponnent. In particular,the criminal possess a \textit{private information} that the sheriff should take into account when forming expectation about how the criminal would behave. To analyse the interesting Dilemma, we begin with a class of games of incomplete infor-
                         mation (i.e. games where at least one player is uncertain about another players payoff func-
                         tion) that are the analogue of the normal form games with complete information:Bayesian
                         games.
                         The payoffs are as following :
                         \[\ Mat_{Bad\_suspect} = \bordermatrix{~ &amp; Shoot &amp; Not \cr
                             Shoot &amp; 0,0 &amp; 2,-2 \cr
                                 Not &amp; -2,-1 &amp; -1,1 \cr}\]
                         \[\ Mat_{Good\_suspect} = \bordermatrix{~ &amp; Shoot &amp; Not \cr
                             Shoot &amp; -3,-1 &amp; -1,-2 \cr
                                 Not &amp; -2,-1 &amp; 0,0 \cr}\]
                         For a good suspect(innocent) that shoots the sheriff would have a better payoff of $$-1$$ if he shoots(it's a negative payoff because we are shooting an inoncent), otherwise he would be killed and get payoff of $$-2$$. The best payoff would not shooting for both.
                         For the bad suspect(guilty),the sheriff would rather shoot if the suspect shoots and that's best payoff for both $$(0,0)$$. In the case the criminal does not shoot he would be taken to jail and gets a payoff of $$-1$$ and the sheriff gets a payoff of $$1$$ for capturing the criminal.
                     Pure strategy Bayesian Nash Equilibrium analysis
                         This type of incomplete games are so difficult to solve and people has been stuck for many years. However, John C. Harsanyi proposed a method that allowed one to transform the game of incomplete information into a game of imperfect information(good news is that we can solve games of imperfect information)which could then be analyzed with standard techniques. In brief,the\textbf{Harsanyi transformation} include a variable called \textit{Nature} that determines the suspect's type (Good or guilty), transforming the incomple information of sheriff about the suspect into imperfect information about the move by \textit{Nature}.
                         %\begin{figure*}[tbph]
                         %\begin{center}
                         %\includegraphics[width=10cm,height=6cm]{harsanyi.png}
                         %\caption{ The Harsanyi-Transformed Game}
                         %\end{center}
                         %\end{figure*}
                         As stated, Nature moves first and chooses the guilty suspect with probability of $$\pi$$ and the good suspect with a probability of $$1- \pi$$ . All the sheriff knows is the probability of him being of one type or another. It is quite important to note that here sheriff's beliefs are
                         \textit{common knowledge}. That means that suspect knows what he believes his type to be, and he knows that he knows, and so on. This is important because suspect will be optimizing given what he thinks sheriff will do, and his behavior depends on these beliefs. We can now apply the Nash equilibrium solution concept to this new game. HarsanyisBayesian Nash Equilibrium(or simply Bayesian Equilibrium) is precisely the Nash equilibrium of this imperfect-information representation of the game. The bayesian Nash equilibrium will be a triple of strategies: one for the suspect of the guilty type, another for suspect of the good type, and one for the sheriff. In equilibrium, no deviation should be profitable.
                         We denote $$S$$ for \textit{Shoot} and $$\overline{S}$$ for \textit{Not shoot}. The suspect's pure strategies are \textsc{\{$$SS$$,$$S\overline{S}$$,$$\overline{S}S$$,$$\overline{S}\overline{S}$$\}}. Where the first component of each pair tells what to do if guilty and the second what to do if innocent. Sheriff has only two pure strategies \textsc{\{$$S$$,$$\overline{S}$$\}}. The resulting payoff matrix is shown as following:
                             \[\bordermatrix{~ &amp; S &amp; \overline{S} \cr
                                 SS &amp; 0.p-3.(1-\pi),0.p-1.(1-\pi) &amp; 2.\pi-1.(1-\pi),-2.\pi-2.(1-\pi) \cr
                                     S\overline{S} &amp; 0.p-2.(1-\pi),0.p-1.(1-\pi) &amp; 2.\pi-0.(1-\pi),-2.\pi-0.(1-\pi) \cr
                                     \overline{S}S &amp; -2.\pi-3.(1-\pi),-1.\pi-1.(1-\pi) &amp; -1.\pi-1.(1-\pi),1.\pi-2.(1-\pi) \cr
                                     \overline{S}\overline{S} &amp; -2.\pi-2.(1-\pi),-1.\pi-1.(1-\pi) &amp; -1.\pi+0.(1-\pi),1.\pi+0.(1-\pi) \cr
                                         } \]
                             \[=\bordermatrix{~ &amp; S &amp; \overline{S} \cr
                                 SS &amp; -3.(1-\pi),-(1-\pi) &amp; 2.\pi-(1-\pi),-2 \cr
                                     S\overline{S} &amp; -2.(1-\pi),-(1-\pi) &amp; 2.\pi,-2.\pi\cr
                                     \overline{S}S &amp; -2.\pi-3.(1-\pi),-1 &amp; -1,\pi-2.(1-\pi) \cr
                                     \overline{S}\overline{S} &amp; -2,-1&amp; -\pi,\pi\cr
                                         } \]
                         We see that $$S\overline{S}$$ strictly dominate all the three strategies $$\{SS,\overline{S}S,\overline{S}\overline{S}\}$$. We can eliminate all this three strategies and keep the dominant one.
                         \[\bordermatrix{~ &amp; S &amp; \overline{S} \cr
                             S\overline{S} &amp; -2.(1-\pi),-(1-\pi) &amp; 2.\pi,-2.\pi\cr
                                 } \]
                         This reducted strategic form means that either the sherrif shoots or not the best response would be shooting if bad suspect and not shooting if good suspect $$S\overline{S}$$. This can be seen obviously from the two payoff matrix where shooting is a dominant strategy for the bad suspect and likewise not shooting for the good suspect.
                         However,sherrif's optimal strategy depends on his prediction about the suspect. In fact, if the suspect choose his his optimal strategy which is $$S\overline{S}$$, the best response that maximise the profit is: $$max(-(1-\pi),-2.\pi)$$ which depends on the value of $$\pi$$. Hence, sherrifs's optimal response is shooting if $$\pi&gt;1/3$$ , not shooting if $$\pi&lt;1/3$$ and random strategy if $$\pi=1/3$$. This is logic since a nature that has a higher probability of being bad supect exceeding $$1/3$$ should be shot.
                         Summarizing the results, we have the folowing Nash equilibria( We remind that the bayesian Nash Equilibrium is a triple of strategies):
                         \begin{itemize}
                         \item if $$\boldsymbol{\pi&gt;1/3}$$, then \textbf{\{Shooting if bad suspect,not shooting if good suspect,and sherrif shoots\}} is a BNE
                         \item if $$\boldsymbol{\pi&lt;1/3}$$, then \textbf{\{Shooting if bad suspect,not shooting if good suspect,and sherrif don't shoot\}} is BNE
                         \item if $$\boldsymbol{\pi=1/3}$$, then \textbf{\{Shooting if bad suspect,not shooting if good suspect,and sherrif radomely shoots or not\}} is BNE
                         \end{itemize}
                     Mixed strategy Bayesian Nash Equilibrium analysis
                         As to obtain the mixed strategies, we have to make another kind of analysis and try to replicate the three BNE obtained before. Assume the probabilities of playing each action are as shown in the matrices below. $$y$$ is the probability Sheriff plays $$Shoot$$ (not conditional on the matrix since this is an information Sheriff does not have), $$x$$ is the probability suspect plays $$Shoot$$
                         if he is guilty and z is the probability suspect plays $$shoot$$ if he is good).
                         $$ \matrix{\mbox{Guilty}&amp;y&amp;1-y\\x &amp; 0,0 &amp; 2,-2\\1-x&amp; -2,-1 &amp; -1,1}   \qquad \qquad \qquad \qquad
                         \matrix{\mbox{Good}&amp;y&amp;1-y\\z&amp; -3,-1 &amp; -1,-2\\1-z&amp; -2,-1 &amp; 0,0}$$
                         \subsubsection{Suspect best response}
                         \begin{itemize}
                         \item The suspect's best response if he is guilty: \\
                         He would rather choose chooting if the expected payoff of shooting exceed the expected payoff of not shooting. Since this strategy is dominant, whatever the sheriff plays ($$y \in [0,1]$$), shooting for suspect is the optimal strategy ($$x=1$$). We conclude that:\\
                         \Rmnum{1)} $$y \in [0,1] \Rightarrow
                         x=1$$
                         \item The suspect's best response if he is good: \\
                         Same as before, we conclude that \\
                         \Rmnum{2)} $$y \in [0,1] \Rightarrow
                         z=0$$
                         \item The sheriff's best response: \\
                         We recall that sheriff does not know wich type the suspect is, assigning a probability of $$\pi$$ to be guilty or not). The sheriff would play $$Shoot$$ instead of $$Not Shoot$$ ($$y=1$$) if: \\
                         $$\pi[0.x-1.(1-x)]+(1-\pi)[-1.z -1.(1-z)] &gt; \pi[-2.x+1.(1-x)]+(1-\pi)[-2.z +0.(1-z)] $$
                         $$\Leftrightarrow \pi(x-1)-(1-\pi) &gt; \pi(-3.x+1)-2.(1-\pi).z $$ \\
                         $$\Leftrightarrow 4.\pi.x &gt; \pi+1 + 2.(\pi-1).z $$
                         Wich can be summarized as : \\
                         \Rmnum{3)} $$4.\pi.x &gt; \pi+1 + 2.(\pi-1).z \Rightarrow y=1 $$ \\
                         \Rmnum{4)} $$4.\pi.x &lt; \pi+1 + 2.(\pi-1).z \Rightarrow y=0 $$ \\
                         \Rmnum{5)} $$4.\pi.x = \pi+1 + 2.(\pi-1).z \Rightarrow y \in [0,1] $$ \\
                         \subsubsection{Mixed equilibria}
                         We have to found the mixed strategies \{$${x^\star,y^\star,z^\star}$$\} that verifie all the five conditions above.
                         \textbf{Possible Case 1:} \\
                         If $$y^\star \in [0,1] $$, it means that $${x^\star = 1}$$ from \Rmnum{1} and $$z^\star= 0$$ from \Rmnum{2}. From \Rmnum{5},we can see that in order $$y^\star$$ belongs to the interval between 0 and 1 it should be the case : $$4.\pi.x = \pi+1 + 2.(\pi-1).z $$. By subtituting the values of $${x^\star}$$ and $${z^\star}$$. We found that $$\pi=1/3$$. This supports the third pure Nash equilibrium that we found before \textbf{\{Shooting if bad suspect,not shooting if good suspect,and sherrif radomely shoots or not\}}.
                         \textbf{Possible Case 2:} \\
                         If sheriffs choose to shoot, wich means $$y^{\star}=1$$. We have to make sure that the condition \Rmnum{3} hold. Since $$y^{\star}=1 \in [0,1] $$, $${x^\star = 1}$$ from \Rmnum{1} and $$z^\star= 0$$ from \Rmnum{2}. So all the three condition gives $$\pi&gt;1/3$$. This supports the third pure Nash equilibrium that we found before \textbf{\{Shooting if bad suspect,not shooting if good suspect,and sherrif shoots\}}.
                         \textbf{Possible Case 3:} \\
                         If sheriffs choose not to shoot, wich means $$y^{\star}=1$$. We have to make sure that the condition \Rmnum{4} hold. Since $$y^{\star}=0 \in [0,1] $$, $${x^\star = 1}$$ from \Rmnum{1} and $$z^\star= 0$$ from \Rmnum{2}. So all the three condition gives $$\pi&lt;1/3$$. This supports the third pure Nash equilibrium that we found before \textbf{\{Shooting if bad suspect,not shooting if good suspect,and sherrif don't shoot\}}.
                         We found that there is only pure strategies in our dilemma's case. This is du to the existence of dominant strategies for suspect.
                         \end{itemize}
                 Stag Game #slide
             NOVEL
                 INBOX
                     
                     Weakly Strategical Equivalence #slide 
                         Do not require $$\sigma$$ and $$\mu$$ to be positive. 
                     Algebraic Equivalence #slide 
                         Pencil Similarity + Affine Subs
                 INBOX
                     if convex combination of rows and columns leads to a matrix with saddle point => that's the value #novel 
                     Classical Non-Cooperative Game Theory #GT
                         Introduction #h
                             Motivation
                                 Why Game Theory?
                                 Originally, it used to analyse real games mathematically
                                 In general, it is used to model scenarios where participants have competing interests
                                 "Game theory provides a way of predicting consequences if several people are making decisions at the same time, and if the outcome depends on the decisions of the others"
                                 Game Theory
                                     A multi-person (multi-decision-taker? because we have individuals, group or machine) decision scenarios as games
                                     Each player chooses actions which result in the best rewards for self, while anticipating the rational actions from other players
                                     Matehmatical study of interaction among independent, self-interested agents
                                     Applied to economics (main area), political science, biology, psychology, linguistics and computer science
                             History
                             Basic Concepts and Terminology
                                 Game
                                     Strategic interactions between opposing or cooperating interests
                                     Includes constraints of and payoffs for potential actions
                                 Player
                                     Basic entity in a game which makes choices for actions
                                     Can be an individual, group of individuals or a machine making a decision (Decision-maker)
                                     Special type of player: chance player (Called nature in the signalling games)
                                 Action
                                     A move within a game
                                     Actual actions might be open or hidden from other players
                                 Strategies
                                     A complete plan of actions in all possible situations throughout the game
                                     A complete set of actions a player will follow in a game
                                     A strategy must be complete, defining an action in every contingency, including those that may not be attainable in equilibrium." (http://www.gametheory.net/dictionary/Strategy.html)
                                     Types:
                                         Pure Strategy: a unique action is taken in a single situation
                                         Mixed Strategy: a probability distribution for all possible actions in a situation
                                         Dominant Strategy
                                         Security Strategy
                                             http://www.eprisner.de/MAT109/Sequential.html
                                         Totally mixed strategy: important for equilibrium refinement
                                     Strategy set
                                     Solution concept/Strategy Profile(?): how the game will be played by employing the best possible strategies and what the outcomes might be
                                 Payoff/Utility (u): utility, cost and benefit functions 
                                     Outcomes to a player for a given action which combines the cost and benefits within the game
                                     Might be positive or negative
                                     Often represented as a matrix
                                     Usually, defined as $$u = b - c$$
                                         Benefit (b):
                                             Reward that a player gains through his actions
                                         Cost (c):
                                             Loss that a player experiences through his actions
                                 Game Representation
                                     Normal (Strategic) Form (Matrix)
                                         Combination sets of choices (moves, strategies) associated with outcomes represented in a matrix showing each players payoff for each combination(Rewrite)
                                         Normal form game can be represented in $$(\mathcal{P}, \mathcal{A}, u)$$
                                     Extensive Form (Dynamic/tree-diagram) (Review) AHP paper?
                                         Represented as a tree diagram
                                 Consequence function
                                     Each action has an associated consequence
                                 Preference relation
                                     Complete relation on the set of consequences
                                     Models the preference of each player in the game
                                 Game Characteristics
                                     Ability to Work as a Team
                                         Cooperative (Coalitional) Game
                                             Ability to form binding commitments between players
                                             Allows communications between players
                                             Maximizes joint payoff
                                             Focuses on the game at large
                                         Non-cooperative Game
                                             Ability to model detailed situations which produces accurate results
                                             Maximizes own payoff
                                             Useful for attacker-defender scenarios
                                         Both types can be combined ?
                                             Non-cooperatrive game < cooperative
                                     Payoff Correlation
                                         Zero-sum
                                             Payoffs of one player are the negative of the payoffs of the other player
                                             One player wins if and only if the other player loses
                                             Example: chess
                                             If best responses of both players coincide, they are optimal. Value of the game?
                                             Fair game
                                         Non-zero sum
                                             Is a competition
                                             One player wins
                                         Constant-sum
                                             Payoffs of the two players always add up to a constant no what strategy is used
                                             Example: squash
                                     Number of Players
                                         Most GT models treat the case of 2 players
                                         This is often sufficient for attacker/defence scenarios (as in Computer Security)
                                         Situation far more complicated if more than 2 players
                                         There is some literature on 3-player models with applications to non-security domains
                                         Main problem: Complexity of the computation of equilibrium
                                     Number of Rounds in a Game
                                         Static/Strategic/Simultaneous/One-shot Game
                                             Each player has a private plan of actions
                                             All players decision are made simultaneously
                                             Is an Imperfect information game
                                             Is a Finite Game
                                         Dynamic/Extensive/Sequential/Hierarchical Game
                                             Has more than one stages/shots/moves/rounds in each of which the players can consider their action
                                             E.g. Two-shot Game
                                             Is a sequential-move game and players choose their strategies in sequence
                                             Can have infinite number of stages, in which case it is Infinite Game
                                             Otherwise, it is a finite game
                                         Finite vs. Infinite Games
                                             Finite number of rounds: Finite game, otherwise it is an infinite game
                                     Observability of Actions
                                         Perfect Information Game
                                             Each player is aware of the actions of all other players that have already taken place
                                             Example: tic-tac-toe, chess
                                         Imperfect Information Game
                                             At least one player is not aware of the actions of at least one other player that have taken place
                                             Example: Card game Bridge, poker
                                     Knowledge of Strategies
                                         Complete Information Game
                                             Every player knows the strategies and payoffs of all players in the game
                                             But not necessarily all the actions
                                         Incomplete Information Game
                                             At least one player is unaware of the possible strategies and payoffs for at least one of the other players
                                             This introduces uncertainty
                                             Popular models:
                                                 e.g. Bayesian Games
                                     Taxonomy 
                                         Diagrams from PPT Slides!
                                     Uncertainty
                                         There are two sources of uncertainty
                                             Uncertainty about the preferences or capabilities of an opponent (Incomplete Information)
                                             Uncertainty about the previous actions of other players (Imperfect Information)
                                             However, incomplete information can be converted into imperfect information
                                 Equilibriums
                                     Nash Equilibrium
                                         it is a fundamental concept and most used solution concept in game theory
                                         Named after John Forbes Nash, Jr.
                                         it involves a minimum of two players and each player is assumed to know the equilibrium strategies of other players and no player gain if the player's own strategy is changed
                                         Steady state condition of a game
                                         No player changes strategy because it will lower his payoffs given that all other players are following the prescribed strategy
                                         No player can improve their utility through a "unilateral" change of strategy
                                         Does not specify how steady state is reached
                                         Only useful for non-cooperative games
                                         Formal Definition of NE 
                                             Let $$(S, f)$$ be a game with $$n$$ players, where $$S_i$$ is the strategy set for player $$i$$
                                             $$S=S_1 \times S_2 \times \dotsb \times S_n$$ is the set of [[Strategy (game theory)|strategy profiles]]
                                             $$f(x)=(f_1(x), \dotsc, f_n(x))$$ is its payoff function evaluated at $$x \in S$$. 
                                             Let $$x_i$$ be a strategy profile of player $$i$$ and $$x_{-i}$$ be a strategy profile of all players except for player $$i$$. 
                                             When each player $$i \in \{1, \dotsc, n\}$$ chooses strategy $$x_i$$ resulting in strategy profile $$x = (x_1, \dotsc, x_n)$$ then player $$i$$ obtains payoff $$f_i(x)$$. 
                                             Note that the payoff depends on the strategy profile chosen, i.e., on the strategy chosen by player $$i$$ as well as the strategies chosen by all the other players. 
                                             A strategy profile $$x^* \in S$$ is a Nash equilibrium (NE) if no unilateral deviation in strategy by any single player is profitable for that player, that is:$$\forall i,x_i\in S_i : f_i(x^*_{i}, x^*_{-i}) \geq f_i(x_{i},x^*_{-i}).$$
                                             When the inequality above holds strictly (with &gt; instead of &ge;) for all players and all feasible alternative strategies, then the equilibrium is classified as a ''strict Nash equilibrium''. If instead, for some player, there is exact equality between $$x^*_i$$ and some other strategy in the set $$S$$, then the equilibrium is classified as a ''weak Nash equilibrium''.
                                         Types of NE
                                             Pure NE
                                             Mixed NE
                                         Existence of Nash equilibrium:
                                             Not every strategic game has a NE (e.g. Matching Pennies Game)
                                         Bayesian Nash Equilibrium BNE
                                             Same as NE?
                                             How is it computed?
                                             Pure and mixed?
                                     Sequential
                                     Competitive
                                     Correlated
                                     Evolutionary
                                     Stackelberg
                             Game Types
                         Complete Information Games #h
                             References #slide 
                         Incomplete (Asymmetric) Information Games #h
                             BAYESIAN
                                 https://en.wikipedia.org/wiki/Bayesian_game
                                 Motivation
                                     Incomplete information about the strategies and payoffs
                                         In particular, one player has incomplete information about the other player.
                                         Can be modelled by introducing Nature as a player in the game (Nature is a random value (signal))
                                         What Nature refer to ? The behaviour of a player ? #coline 
                                     uncertainty?
                                         imperfect information game?
                                         What does it mean and how is it related to Nature?
                                         Harsanyi invented the trick of converting games of incomplete information to games of imperfect information, by introducing nature as an additional player
                                 Basic Concepts
                                     Bayesian are methods in probability and statistics named after Thomas Bayes. These methods include Bayesian Games which provides a new way for analysing incomplete information games. In such games, there is a certain belief with a known probability distribution
                                     John Harsanyi developed a new theory for analysing games: Bayesian Games
                                         "developing the highly innovative analysis of games of incomplete information, so-called Bayesian games"
                                     Bayesian game consists of:
                                         finite set N (the set of players)
                                             each player has his own set of actions
                                             each player has a finite set of signals and a signal function
                                             each player has a prior belief
                                             each player has a preference relation
                                         finite set set of $$\Omega$$ (the set of states)
                                     Bayesian Games (Games of Incomplete information) represents players' uncertainties about the game player
                                         Uncertainty is presented within a set using probability distribution of the game played
                                 Bayesian Probability
                                 Bayes Nash Equilibrium
                             SIGNALLING
                                 Asymmetric incomplete information games  #r
                                 Signalling is a way for an agent to communicate his type under adverse selection @Rasmusen2007
                                 A two-player game where one of the players has incomplete information (Asymmetric information game)
                                 Extensive game
                                 __Nature__ selects a game to be played according to a <u>commonly known distribution</u>
                                 Sequential game
                                     Player 1 is informed on the selected game and chooses an action
                                     Then, player 2 chooses an action knowing player 1's action but not knowing the Nature's choice
                                 2 players --&gt; Sender (S) and Receiver (R)
                                     Player 1 (Cloud)
                                         knows what __Nature__ chooses
                                         Then he chooses an action (knows which game is played)
                                         will choose his message? action or message?
                                     Player 2 (Client)
                                         Does not know the Nature's action and chooses an action (incomplete information)
                                         His action depends entirely on the game being played and that player 1 will play his **dominant strategy (e.g. in which case we have equilibrium)**
                                 Expected Payoff
                                 Questions
                                     Would our game be a screening game because cloud makes decision on behalf of the user and the cloud might not be trusted (depending on trust degree $$T$$)?
                                     Which assumptions can we remove in an extended model?
                                     Signalling Game
                                         Abstract of paper: "Type of the attacker"
                                         In Section 3.1, generic relationships between the utility functions are derived for the AD-game (such as $$D_{21} \ge D_{11}$$) without defining the specific cost and benefit functions. This is possible although the game is a simultaneous (one-shot) game because??
                                         What is a Successful attack in Table 2?
                                         After the one-shot AD-game, the service provider will know whether he is been attacked or not
                                         Signalling game is a communication game
                                         What are the different types of attackers?
                                     What is the timeline of the nested game? (Attacker-Cloud Game and User-Cloud Game)
                             Screening Game
                                 1st stage signalling then 2nd Screening?? #review 
                                 Screening game https://en.wikipedia.org/wiki/Screening_game 
                         Nested Games #h
                     An intersection of $$d$$ half-planes in $$R^d$$ is generically a point
                     Application to Single-Target Bayesian CVSS Game
                         \label{single-target-section}
                         Goal of this section is to apply the algebraic framework developed in the previous section to a bimatrix Bayesian vulnerability patching game. The analysis in order to analyse this game. This will provide the equations needed for the vulnerability scoring functions introduced in the next section. #signpost
                         \subsection{Bayesian Game} % #h2 
                             The loss $$l^{\mathcal{A}}$$ in the defender's utility function is due to the attack impact, exploiting the vulnerability $$v$$ and affecting the asset's CIA security requirements. 
                             This can be modelled as follows, using the CVSS CIA impact subscores and value components of the asset $$a$$:
                             $$l^{\mathcal{D}}(a) =\vec{\mu}_{Imp} \cdot \vec{V}(a) = \mu_{Imp, C} \cdot V_C(a) + \mu_{Imp, I} \cdot V_I(a) + \mu_{Imp, A} \cdot V_A(a).$$ @asset-loss-definition
                             asset and values are know to system admin
                             \subsection{Defender Types} % #h2 
                                 The goal in this section is to make our previous CVSS game more suitable for real-world scenarios, by introducing information asymmetry. 
                                 Equation @equation shows that we have to impose the condition $$0 \leq 1 - \frac{\alpha}{L \cdot \mu_E} \leq 1 \Longleftrightarrow 0\le \frac{\alpha}{L} \le  \mu_E$$ in order to ensure that $$p^*$$ can be used as a probability in the mixed Nash equilibrium strategy.
                             [TODO: design Bayesian game and compute Optimal Mixed BNE Strategies and Optimal Expected Utilities]
         Decision Making #h
             Understanding Pareto Optimality: From Multi-Criteria Optimisation to Game Theory: A comparative exploration of efficiency and dominance across contexts #h 
                 Multi-Criteria Optimisation  The Basics #slide
                     Many real-world problems involve multiple conflicting objectives.
                     Examples:
                         Design: Minimize weight, maximize strength
                         Finance: Maximize return, minimize risk
                     Goal: Identify trade-offs between objectives.
                 Pareto Optimality (Multi-Criteria Optimisation) #slide
                     Definition: A solution is Pareto optimal if no other feasible solution improves one objective without worsening at least one other.
                     Formal (minimisation case): Let $$f: X 
                 Visualising the Pareto Front #slide
                     The Pareto front consists of all Pareto optimal solutions in objective space.
                     Represents the best trade-offs between competing objectives.
                     Often visualised in 2D with dominated points below the curve.
                 Partial Orders and Pareto Dominance #slide
                     Pareto dominance defines a partial order on $$\mathbb{R}^k$$: $$u \prec v \iff (\forall i,\ u_i \leq v_i) \land (\exists j,\ u_j < v_j)$$
                     This relation is:
                         Reflexive
                         Antisymmetric
                         Transitive
                     Pareto optimal points are the maximal elements under this partial order.
                 Bimatrix Games  Setup #slide
                     Two players, each with a finite set of strategies.
                     Each strategy profile $$(s_1, s_2)$$ results in a payoff pair: $$(u_1(s_1, s_2),\ u_2(s_1, s_2)) \in \mathbb{R}^2$$
                     Each component represents one players utility.
                     Payoffs are evaluated jointly in $$\mathbb{R}^2$$.
                 Pareto Optimality in Bimatrix Games #slide
                     Definition: A strategy profile is Pareto optimal if no other profile improves one players payoff without reducing the others.
                     Formal: $$
                 Example  Prisoner's Dilemma #slide
                     Payoff matrix:
                     $$\begin{array}{c|c|c}&    \ext{Cooperate (C)} &    \ext{Defect (D)} \\\hline \ext{Cooperate (C)} & (3,3) & (0,5)\\\hline \ext{Defect (D)} & (5,0) & (1,1)\end{array}$$
                     (C, C) = (3, 3) is Pareto optimal.
                     (D, D) = (1, 1) is a Nash equilibrium, but not Pareto optimal.
                     Shows conflict between equilibrium and efficiency.
                 Comparing the Two Contexts #slide
                     Summary table:
                     $$
                     \begin{array}{|l|l|l|}
                     \hline
                         extbf{Aspect} &     extbf{Multi-Criteria Optimisation} &     extbf{Bimatrix Games} \
                     \hline
                         ext{Agents} &     ext{Single decision-maker} &     ext{Two strategic players} \
                         ext{Space} & \mathbb{R}^k\     ext{(objectives)} & \mathbb{R}^2\     ext{(payoffs)} \
                         ext{Trade-offs} &     ext{Among objectives} &     ext{Between players} \
                         ext{Dominance} &     ext{One solution dominates another} &     ext{One outcome dominates another} \
                         ext{Partial order} &     ext{Over internal objectives} &     ext{Over joint outcomes} \
                         ext{Outcome type} &     ext{Optimal solution} &     ext{Efficient strategy profile} \
                     \hline
                     \end{array}
                     $$
                 Key Takeaways #slide
                     Pareto optimality reflects non-dominance in both frameworks.
                     In multi-objective optimisation: trade-offs occur within one agents goals.
                     In games: trade-offs occur between independent agents.
                     Both rely on partial orders to define efficiency and non-dominance.
             ightarrow \mathbb{R}^k$$. A solution $$x^* \in X$$ is Pareto optimal if $$
             ot\exists x \in X : f_i(x) \leq f_i(x^*)\\forall i,\     ext{and } f_j(x) < f_j(x^*)     ext{ for some } j$$.
             ot\exists (s_1', s_2') : u_i(s_1', s_2') \geq u_i(s_1, s_2)\forall i,\     ext{with strict inequality for some } i$$
                 Reflects mutual efficiency  no free lunch between players.
             
         Interpolation #h 
             Bivariate Interpolation #h 
                 Vandermonde Matrix #slide 
                     The special matrix in the previous equation is called a __Vandermonde__ matrix:
                         $$V(x_1,\ldots,x_n):= \begin{pmatrix} 1 & x_1 & x_1^2 & \cdots & x_1^{k-1} \\ 1 & x_2 & x_2^2 & \cdots & x_2^{k-1} \\ \vdots & \vdots & \vdots & &\vdots \\ 1 & x_n & x_n^2 & \cdots & x_n^{k-1} \end{pmatrix}$$.
                 Vandermonde Matrix -- Factorisation #slide 
                     Interesting factorisation properties:
                         $$V(x) = V_L(x) V_R(x)$$ 
                     Here
                         $$V_L(x) = $$
                         $$ V_R(x) =$$
                 Sampling and Interpolation #slide 
                     Given $$f(x,y) = \displaystyle \sum^m_{i=1} \sum^n_{j=1} a_{ij} x^i y^j \in \mathbb{F}_p[x,y]$$, we evaluate (sample) as
                         $$f(x_i,y_j) = b_{ij} \in \mathbb{F}_p$$.
                     This can be written as $$V(x_1,\ldots,x_m) A V(y_1,\ldots,y_n) = B$$. 
                     Hence if $$n=m$$, the coefficient matrix $$A$$ is square and can be computed as
                         $$A=V^{-1}(x_1,\ldots,x_n) B V^{-1}(y_1,\ldots,y_n)$$
                     if $$x_i\neq x_j$$ and $$y_i\neq y_j$$.
                     Note: if $$f$$ is symmetric, then so will be the matrices $$A$$ and $$B$$. 
         Optimisation
             Asymptotic Linear Programming #h
             Linear Programming #h
                 Introduction #slide 
                 LP Standard Canonical Form #slide 
                     A standard form of the LP is to choose $$y_1,\ldots,y$$, to maximize
                         $$ c_1y_1 + \cdots + c_ny$$, 
                     subject to the constraints
                         $$a_{11}y_1 + \cdots + a_{1n}y_n \le b_1$$
                           $$\vdots$$
                         $$a_{m1}y_1 + \cdots + a_{mn}y_n \le b_m$$
                     and $$b_i\ge 0$$, $$y_j \ge 0$$ for $$ i = 1,\ldots,m$$ and $$ j = 1,\ldots,n$$.
                     In compact notation this is:
                         MAX $$c^T y$$  ST $$Ay\le b$$ and $$y\ge 0$$. 
                 LP Augmented Canonical Form #slide #simplex:augmented 
                     Idea: convert the system of inequality constraints into a system of equations, subject to some positivity conditions.
                     The __augmented canonical__ form of the LP is: 
                         Find $$y_1,\ldots,y_n$$ to maximise
                             $$z= c_1y_1 + \cdots + c_ny+d$$
                         subject to the constraints
                             $$a_{11}y_1 + \cdots + a_{1n}y_n + {\hat{y}}_1= b_1$$,
                               $$\vdots$$
                             $$a_{m1}y_1 + \cdots + a_{mn}y_n+ {\hat{y}}_{m}= b_m$$
                         where $$y_j \ge 0$$ for $$ j = 1,\ldots,n$$ and $${\hat{y}}_j \ge 0$$ for $$ j = 1,\ldots,m$$.
                     The $$\hat{y}_j$$ are called the __slack variables__ or __basic solutions__. 
                 The Revised Simplex Method #h
                     Using Matrix Notation #slide 
                         The augmented/canonical form contains a linear system which can be expressed using matrices:
                             $$\max z := c^\top x+d:$$
                                 $$ Ax+\hat{x}=b \,\land \, z-c^\top x=d \Longleftrightarrow $$
                                 $$\begin{pmatrix}  0& A&I\\  1 & -c^\top&0\\ \end{pmatrix}\begin{pmatrix}  z\\ x  \\  \hat{x}  \\   \end{pmatrix}=\begin{pmatrix}   b  \\ d  \\ \end{pmatrix}$$. 
                         Here, $$x$$ contains the __non-basic solutions__ and $$\hat{x}$$ the __basic solutions__.
                         A __feasible solution__ is any solution $$\begin{pmatrix} x \\ \hat{x}\end{pmatrix}$$, satisfying the constraints.
                     Main Idea #slide 
                         Denote the system during a step of iteration $$k$$ as:
                             $$\begin{pmatrix}  0& {A}_{{k}}&I\\  1 & -{c}^\top_{{k}}&0\\ \end{pmatrix}\begin{pmatrix} z\\ x_{{k}} \\  \hat{x}_{{k}}  \\  \end{pmatrix}=\begin{pmatrix} {b}_{{k}}  \\  {d}_{{k}} \\  \end{pmatrix}$$.
                         Successive left-multiplication with matrix $$R_{{k+1}}$$ implements row-operations, increasing the value of $$z$$:
                             $$\begin{pmatrix}  0& {A}_{{k+1}}&I\\  1 & -{c}^\top_{{k+1}}&0\\ \end{pmatrix}=R_{{k}}\begin{pmatrix}  0& {A}_{{k}}&I\\  1 & -{c}^\top_{{k}}&0\\ \end{pmatrix}$$,
                             $$\begin{pmatrix} {b}_{{k+1}}  \\  {d}_{{k+1}} \\  \end{pmatrix}=P_{{k}}\begin{pmatrix} {b}_{{k}}  \\  {d}_{{k}} \\  \end{pmatrix}$$.
                     Initialisation and Termination #slide #simplex:exit 
                         We start with $$b_0=b, d_0=0$$ and put $$x_{0} =0$$ and $$\hat{x}_{0}=b_0$$, satisfying the lower block-row. #simplex:init
                         Iterations terminate once the row-vector $$-{c}^\top_{k}$$ is nonnegative. 
                         Reason:
                             Maximising $$z_k= {d}^\top_{k}+{c}^\top_{k} x_k$$ and $${c}^\top_{k} \leqq 0$$ is solved by $$x_k=0$$. 
                         Hence:
                             $$z= {d}_k$$ is the optimal value.
                             $$(x,\hat{x})=(0,\hat{x}_{{k}})$$ is a feasible solution for the augmented system
                             CORRECT THIS:, hence of the original LP.  
                     Pivot-Step #slide #simplex:pivot 
                         In this step, subject to some assumptions, fix a row index $$i$$ and column index $$j$$. 
                         Denote the $$j$$th column of a matrix $$A$$ as $$\text{col}(A,j)$$.
                         Assume we can form $$R$$ non-singular such that $$R \;\text{col}(A,j) =  e_i $$.
                         Multiplying the entire system of linear equations by $$R$$ on the left allows swapping the non-basic variable $$x_j$$ and basic variable $$\hat{x}_i$$.
                     Determining $$i$$ and $$j$$ #slide 
                         In this step, a suitable row index $$i$$ and column index $$j$$ need to be found. 
                         The previous operation increases $$z$$, provided the $$i$$th entry of the vector $$R\tilde{b}$$ is greater than zero. 
                         This is equivalent to stating 
                             $$\exist i: b/a_{ij} > 0$$
                         We then chose $$i := \argmax_i \{ b/a_{ij} \}$$.
                     New System #slide 
                         After a Pivot-Step, the new system is
                     Non-Degeneracy #slide 
                         
                     LP Method versus LP Algorithm #slide 
                         The method does not specify how the pivoting strategy should be
                         Different authors have suggested different algorithms:
                             Random
                             Maximal 
                             Block
                     Performance of Algorithm #slide 
                         Certain assumptions need to be made to guarantee termination 
                         Generally they hold true
                         Complexity is exponential in the worst case but linear for most practical applications 
                     ARCHIVE
                         $$RA_j = \begin{pmatrix} \tilde{A}_1 & e_i &\tilde{A}_2   \end{pmatrix}$$
                         $$\tilde{A} = RA = \begin{pmatrix} \tilde{A}_1 & \begin{array}{c} 0_{i-1} \\ e_i \\ 0_{n-i}   \end{array} &\tilde{A}_2   \end{pmatrix}$$
                         $$A = \begin{pmatrix} A_{1\ldots j-1} & A_j &A_{j+1\ldots n}   \end{pmatrix}$$.
                 The Dual Simplex Method #h
                     Dual Linear Programs #h 
                         Dual Linear Optimisation Problem -- Definition #slide 
                             Find $$x,y$$: #deconstruct:equilibrium
                                 $$\min c^\top y$$  subject to $$Ay\ge b$$ and $$y\ge 0$$. 
                                 $$\max   x^\top b$$  subject to $$x^\top A\le c^\top$$ and $$x\ge 0$$. 
                             Strong Duality Theorem:
                                 Denote $$v^{+} := \min c^\top y,v^{-}:=\max x^\top b$$.
                                 The following theorem holds:
                                 #theorem: $$v^{-}=v^{+}$$.
                         Artificial Basic Variables #slide #simplex:augmented 
                             Introducing artificial basic variables $$\hat{x}, \hat{y}$$:
                                 $$\min v^+=c^\top y+d$$  subject to $$Ay+\hat{y}= b$$ and $$y, \hat{y}\ge 0$$. 
                                 $$\max  v^-=x^\top b+d$$  subject to $$x^\top A= \hat{x}^\top + c^\top$$ and $$x, \hat{x}\ge 0$$. #todo 
                                 $$v^+= c_1y_1 + \cdots + c_ny_n$$
                                 $$v^-= x_1b_1 + \cdots + x_nb_n$$
                         Augmented Canonical Form #slide #simplex:augmented 
                             The __canonical__ form of the Dual LP uses the algebraic constraints
                                 $$a_{11}y_1 + \cdots + a_{1n}y_n + \hat{y}_1= b_1$$,
                                   $$\vdots$$
                                 $$a_{m1}y_1 + \cdots + a_{mn}y_n+ \hat{y}_{m}= b_m$$
                             and
                                 $$x_1a_{11} + \cdots + x_ma_{m1} + c_1= \hat{x}_1$$,
                                   $$\vdots$$
                                 $$x_1a_{1n} + \cdots + x_ma_{mn} + c_n= \hat{x}_n$$
                             as well as the non-negativity constraints
                                 $$x_j,\hat{x}_j \ge 0$$  for $$ j = 1,\ldots,m$$,
                                 $$y_j,\hat{y}_j \ge 0$$  for $$ j = 1,\ldots,n$$,
                     Different Views and Presentations #h 
                         Revised Simplex: Matrix-Vector Notation #slide #simplex:augmented 
                             $$Ay+\hat{y}=b \,\land \, z=d-c^\top y \Longleftrightarrow \begin{pmatrix}  0& A&I\\  1 & c^\top&0\\ \end{pmatrix}\begin{pmatrix}  z\\ y  \\  \hat{y}  \\   \end{pmatrix}=\begin{pmatrix}   b  \\ d  \\ \end{pmatrix}$$
                             $$x^\top A-\hat{x}=-c \,\land \, z=-d-x^\top b \Longleftrightarrow \begin{pmatrix}  z& x^\top  &  \hat{x}^\top \end{pmatrix}\begin{pmatrix}  0& 1\\A& b\\-I & 0 \end{pmatrix}=\begin{pmatrix}   -c  & -d  \end{pmatrix}$$. 
                         Tableau Notation #slide 
                             Tableau notation originally by \cite{Danzig}, reviewed in \cite{Balinski1969-xt} for dual simplex method
                             This contains all involved parameters and encodes their relationships in a compact form:
                                 $$ \begin{array}{c|ccc|c|c} & \hat{y}_1 & \cdots & \hat{y}_n &  1   \\ \hline x_1 & a_{11} & \cdots &  a_{1n}& b_1 &  -y_1 \\  \vdots & \vdots &  & \vdots & \vdots &  \vdots  \\  x_m & a_{m1} & \cdots &  a_{mn}& b_m &   -y_m \\ \hline 1 & c_1 & \cdots  & c_n &   d & v^+\\ \hline & \hat{x}_1 & \cdots & \hat{x}_n &  v^-\end{array} $$
                         View as Linear Matrix Pencil Equation #slide 
                         View as Matrix Game #slide 
                             Game between row and column player
                             Row player wants to maximise her benefit $$x^\top A$$
                             Column player wants to minimise her benefit $$Ay$$
                             Von Neumann
                     The Method #h 
                         Initialisation #slide #simplex:init 
                             We start with a basic solution: 
                                 $$\hat{v}=\frac{1}{c^\top b}$$, $$\hat{x}^\top=c^\top$$, $$\hat{y}=b$$.
                             We can see that $$(\hat{v},\hat{x}^\top, \hat{y})$$ is a generalised eigensystem of $$I-\lambda {bc^\top}$$.
                             This will only give feasible solutions, if $$b \geqq 0$$ or $$c \geqq 0$$.
                         Reduction Step #slide 
                         Termination #slide #simplex:exit 
                             Criterium: $$b \geq 0$$ and $$c^\top \geq 0$$.
                             Maximising $$z_k= {d}^\top_{k}+{c}^\top_{k} x_k$$ and $${c}^\top_{k} \leqq 0$$ is solved by $$x_k=0$$. 
                             The iterations terminate with $$x=x_{{k}}=0$$ and $$\hat{x}=\hat{x}_{{k}}$$ if $$\tilde{c}^\top\leqq 0$$, 
                             Note that since $${v}=\frac{1}{c^\top A^{-1}b}>0$$,
                             
                              we can assume $${v}>0$$, $$A>0$$ and hence $$A^{-1}>0$$.
                              $${x}^\top=c^\top A^{-1}$$, $${y}=A^{-1}b$$, $$x$$ and $$y$$ are feasible.
                             Furthermore $$\hat{x} = 0$$ and $$\hat{y} = 0$$.
                             or with $$\hat{x}_{{k}}=0$$ if $$A^{-1}b\geqq 0$$. #lemma 
                 Applications of Linear Programming #h
                     Solving Matrix Games #h 
                         Problem Statement #slide 
                             Let us consider the game problem from Player Is point of view. 
                             Applying the Principle of Indifference, our goal is to now maximise $$v(x)=\min_{j\in\{1..m\}}xA_j$$ where 
                                 $$A_j$$ corresponds to column $$j$$ of $$A$$,
                                 $$x=(x_1 \ldots x_n)$$ is the set of mixed strategies.
                             He wants to choose $$x_1,\ldots,x_m$$ to maximize @NE-zero-sum-x:ref  subject to the constraint $$ x \in X^*$$. 
                             This is subject to the constraints
                                 $$\sum_{i=1}^{n}x_i = 1$$
                                 $$x_i \ge 0 $$ for $$i = 1,\ldots,n$$
                             This becomes the mathematical program: 
                                 Choose $$x_1,\ldots,x_m$$ to maximize
                                     $$\min_{1 \le j\le n}\sum_{i=1}^{m} x_ia_{ij}$$ #equation
                                 subject to the constraints
                                     $$x_1 + \ldots + x_m = 1 $$
                                 and
                                     $$ x_i \ge 0$$ for $$i = 1,\ldots,m$$.
                             The objective function is not a linear function of the $$x$$s because of the $$\min$$ operator, so this is not a linear program. 
                             However, it can be changed into a linear program through a trick. 
                         Approach 1 #h 
                             The Reduction #slide 
                                 Add one new variable $$v$$ to Player Is list of variables
                                 Restrict it to be less than the objective function: $$v \le \min_{1 \ge j \ge n}\sum_{i=1}^{m} p_ia_{ij} $$
                                 Try to make $$v$$ as large as possible subject to this new constraint.  The problem becomes:
                                     Maximize $$v$$
                                     Subject to constraints :
                                         $$v - \sum_{i=1}^{m}p_ia_{ij}\le 0$$ for $$j = 1,\ldots,n$$
                                         $$\sum_{i=1}^{m}p_i = 1$$
                                         $$p_i \ge 0 $$ for $$i = 1,\ldots,m$$
                             LP in Matrix Notation #slide 
                                 This can be written also using a matrix product:
                                 Maximize $$ f = \tilde{c}^t\tilde{x}$$ subject to $$\tilde{A}\tilde{x} \le \tilde{b} $$ where
                                     $$\tilde{c} = \begin{bmatrix} 0 \\ \vdots\\0\\1 \end{bmatrix}$$, $$\tilde{x} = \begin{bmatrix} x^t \\v \end{bmatrix}$$ 
                                 and
                                     $$\tilde{A}=\begin{pmatrix} -A^t & e \\ e^t& 0 \\  -e^t& 0   \end{pmatrix}$$ , $$\tilde{b} = \begin{bmatrix}0\\1\\-1 \end{bmatrix}$$
                                 and $$\tilde{x} \ge 0$$. 
                             Proof  #slide 
                                 We have $$ \tilde{c}^t\tilde{x}   = \begin{bmatrix} 0 &.&.&0&1 \end{bmatrix} \begin{bmatrix} x^t \\v \end{bmatrix}  = v$$ so maximizing $$f$$ is the same as maximizing $$v$$ which is our objective:
                                     $$\tilde{A}\tilde{x}  =\begin{pmatrix} -A^t & \begin {matrix} 1 \\ . \\ . \\ 1 \end{matrix} \\ \begin{matrix} 1 &. &.&1 \end{matrix} & 0 \\  \begin{matrix} -1 &. &.&-1 \end{matrix} & 0   \end{pmatrix}  \begin{bmatrix} x^t \\v \end{bmatrix} = \begin{bmatrix}- \sum_{i=1}^{n}p_ia_{i1} + v \\ \vdots \\- \sum_{i=1}^{n}p_ia_{im} +v \\ \sum_{i=1}^{n}p_i \\ -\sum_{i=1}^{n}p_i\end{bmatrix}  $$
$$ \tilde{A}\tilde{x} \le \tilde{b} \Leftrightarrow v - \sum_{i=1}^{n}p_ia_{ij}\le 0 , j \in [|1 \ldots m|] ;\sum_{i=1}^{n}p_i \le 1 ;  -\sum_{i=1}^{n}p_i \le -1$$
$$\Leftrightarrow  v - \sum_{i=1}^{n}p_ia_{ij}\le 0 , j \in [|1 \ldots m|] ;\sum_{i=1}^{n}p_i = 1$$ 
                             Example #slide
                                 Consider the game matrix $$ A = \begin{pmatrix}1 & 2 \\ 3 & 4 \end{pmatrix}$$. 
                                 We set 
                                     $$\tilde{x} = \begin{bmatrix} p_1 \\p_2 \\v \end{bmatrix}$$, $$\tilde{c} = \begin{bmatrix} 0 \\0\\1 \end{bmatrix}$$ 
                                 and obtain 
                                     $$\tilde{A}=\begin{pmatrix} -1 & -3 &1 \\-2&-4&1\\1&1&0\\-1&-1&0 \end{pmatrix}$$, $$\tilde{b} = \begin{bmatrix} 0 \\0\\1\\-1 \end{bmatrix}$$.
                         Approach 2 #h 
                             Simplification #slide 
                                 We can achieve $$v >0$$ by adding some constant $$c$$ that is at least equal to the maxmin of the matrix.
                                 We perform a change of variable:
                                     $$x' = (x'_1,\ldots,x'_m)$$ where $$x'_i = {x_i}/{v}$$ for $$i =1,\ldots,m$$. 
                                 Maximizing $$v$$ is the same as minimizing $$\sum_{i=1}^{m}x'_i = \frac{1}{v}$$ subject to constraints $$1 \le \sum_{i=1}^{m}x_i'a_{ij}$$ for $$j = i,\ldots,n$$.
                             Linear Program Formulation #slide 
                                 Linear Program for Player 1:
                                     Minimize $$xe_m^\top=\sum_{i=1}^{m}x_i$$.
                                     Subject to constraints :
                                         $$xA \ge e^\top_m$$
                                         $$x\ge 0$$ 
                             Obtaining the Solutions #slide 
                                 We have $$\sum_{i=1}^{m}x_i = 1 $$ which implies that $$\sum_{i=1}^{m}x'_i = \frac{1}{v}$$. 
                                 Unwinding the formulation back to our original variables, we find the optimal strategy X for player I and the value of the game as follows:(the minimum objective is denoted $$ z_1^{*}$$)
                                 $$v(A) = \frac{1}{\sum_{i=1}^{m}p'_{i}}=\frac{1}{z_1^*}$$ and $$p_i=p'_i . v(A)$$ 
                                 After the optimum solution is obtained, the true value of the game is obtained by subtracting that constant.   
                             DUAL
                                 Dual LP #slide
                                     Maximimize :  $$z_2=c.q'=c^\top q'=q' c^\top$$
                                     ST:
$$Aq' \le  c;\quad q'\ge 0$$
                                     Where:
$$q= \begin{bmatrix} q'_1 \\ \vdots \\q'_m\end{bmatrix}$$ , $$c = e_m^\top = \begin{bmatrix} 1 \\\vdots \\1 \end{bmatrix}$$ 
                                 Player 2: Finding $$y^*$$ #slide 
                                     Similarely for the player 2:
$$Value_{game}(A) = \frac{1}{\sum_{i=1}^{m}q'_{i}}=\frac{1}{z_2^*}$$ and $$q_i=q'_i . value(A)$$
                                     Player 2's problem is the dual of the player 1.
                                     Duality Theorem:
                                         For any primal dual pair of linear programs, if either has an optimal solution, then both have optimal solutions, and their optimal objective function values are equal.
                                         .   This means that we are guarenteed that $$z_1^* = z_2^*$$
                             An Example #h
                                 Step 1 #slide 
                                     Use the Simplex method on Minimax to find solution of the game with matrix: $$A=\begin{pmatrix} -2 & 1 & 0 \\ 2 & -3 & -1 \\ 0 & 2 & -3  \end{pmatrix}$$
                                     Then:
                                         $$\begin{pmatrix} -2 & 1 & 0 \\ 2 & -3 & -1 \\ 0 & 2 & -3  \end{pmatrix}$$ $$\begin{matrix} -2 \\ -3\\ -3\end{matrix}$$ $$\begin{matrix} maxmin \le v\\ \\ \end{matrix}$$  
$$\begin{matrix} & 2 &  & 2 & &0 \end{matrix}$$
$$\begin{matrix} &  &   &  & &minmax \ge v\end{matrix}$$
                                 Example (cont.) #slide 
                                     We can deduce that $$ -2 \le v \le  0 $$ . 
                                     It is possible that value of the game may be negative or zero, thus the constant $$c>2$$ is added to all the elements of matrix 
                                     Let $$C = 2$$, add this value to all the elements of the matrix. The resultant matrix is : $$\begin{pmatrix} 0 & 3 & 2 \\ 4 & -1 & 1 \\ 2 & 4 & -1  \end{pmatrix}$$
                                 Example (cont.) #slide 
                                     Player 1's linear program is: 
                                         Minimize $$z_1 = p'_1+p'_2+p'_3= \frac{1}{v}$$ 
                                     Subject to : 
$$0p'_1+4p'_2+2p'_3 \ge 1$$
$$3p'_1-1p'_2+4p'_3 \ge 1$$
$$2p'_1+1p'_2-1p'_3 \ge 1$$
$$p'_i \ge 0 $$ , for $$  i=1,2,3$$
                                 Example (cont.) #slide 
                                     After finding $$p'_i$$'s,we will set :
                                         $$\tilde{v} = \frac{1}{p'_1+p'_2+p'_3}=\frac{1}{z_1^*}$$
                                         $$p_i=p'_i \tilde{v}  $$  for $$  i=1,2,3 $$ 
                                         $$v =  \tilde{v} - C $$
                                     The simplex Method is part of all standard Minimax and Mathematical software, so we will solve the linear programs using Minimax. 
                                     For player I we use the Maxima commands:
                     INBOX
                         Formulation as LP #slide 
                             We can use a Piecewise-linear Maximization where the equivalent LP is (We note $$v(x)$$ simply $$v$$) :
                                 Subject to :
$$xA_j \le v$$   ,for $$  j \in  [| 1 \ldots m|]$$ 
$$\sum_{i=1}^{n}p_i = 1$$
$$p_i \ge 0 $$ for $$i = 1,\ldots,n$$
                         INBOX
                             Example (cont.) #slide 
                                 Note that not all entries in $$\tilde{b}$$ are positive.
                                 The modified version of the simplex algorithm is applicable (9.4). 
                                 We choose the last negative entry in the column $$\tilde{b}$$ which is
                 Glossary #h 
                      ![Pasted image](https://dynalist.io/u/0Ma1XII8HDup4leh93nAZR7U) 
             Multi-Criteria (MC2) Linear Programming #h
                 Definition #slide 
                     A standard form of the LP is to choose $$x_1,\ldots,x_n$$, to maximize
                         $$ c_1x_1 + \cdots + c_nx_n$$, 
                     subject to the constraints
                         $$a_{11}x_1 + \cdots + a_{1n}x_n \le b_1$$
                           $$\vdots$$
                         $$a_{m1}x_1 + \cdots + a_{mn}x_n \le b_m$$
                     and
                         $$x_j \ge 0$$  for $$ j = 1,\ldots,n$$.
                     In compact notation this is:
                         MAX $$c^T x$$  ST $$Ax\le b$$ and $$x\ge 0$$. 
                 Dual Linear Optimisation Problem -- Definition #slide 
                     Find $$x,y$$: #deconstruct:equilibrium
                         $$\min c^\top y$$  subject to $$Ay\ge b$$ and $$y\ge 0$$. 
                         $$\max   x^\top b$$  subject to $$x^\top A\le c^\top$$ and $$x\ge 0$$. 
                     Strong Duality Theorem:
                         Denote $$v^{+} := \min c^\top y,v^{-}:=\max x^\top b$$.
                         The following theorem holds:
                         #theorem: $$v^{-}=v^{+}$$.
                 MC2 Linear Program #slide 
                     MC2 Problem:
                         Consider
                             "$$\max C^\top y+d$$" subject to "$$Ay\le B$$" and $$y\ge 0$$ ($$d>0$$). 
                         This means
                             $$\exist\, x,y^0\ge 0:\; z=x(C^\top y + d)$$ maximal s.t. $$Ay \le By^o,\; y\ge 0$$.
                         Here:
                             Multiple objectives: $$C$$
                             Multiple constraints: $$B$$
         Probability Theory
             LINEAR MARKOV
                 Linear Markov Models #slide 
                     Markov modeling belongs to the area of mathematics known as probability theory. 
                     It is a mathematical technique used to model systems that change over time and whose future behavior depends only on their present state, not on their past history.
                     Markov models are based on Markov processes, which are stochastic models that assume that the future state of a system depends only on its present state and not on its past. 
                     Stochastic process where future states depend linearly on current state
                     Can be represented by a transition matrix
                 Markov processes -- Transition Matrix #slide 
                     They are often represented using a state transition matrix, where each element of the matrix represents the probability of transitioning from one state to another in a single time step.
                 State Concepts
                     There are various notations and concepts associated with Markov models, including state spaces, transition probabilities, steady-state probabilities, initial state distributions, and absorbing states. 
                 Types #slide 
                     Additionally, various types of Markov models exist, such as discrete-time Markov chains, continuous-time Markov chains, hidden Markov models, and Markov decision processes, each with its own unique characteristics and applications.
                 Properties of Linear Markov Models #slide 
                     Time-homogeneous: Transition matrix is constant over time
                     Markovian: Future states only depend on current state, not on past history
                     Stationary: A stationary distribution exists and can be found by solving a linear system of equations
                     Can model a wide range of phenomena, from stock prices to weather patterns to genetic mutations
                 Stationary State #slide 
                     Note that in some cases, the stationary distribution may not exist or may be a mixture of multiple distributions, in which case the long-run behavior of the Markov chain may be more complicated.
                     A stationary state exists for a linear Markov model if and only if the transition matrix has a unique left eigenvector corresponding to the eigenvalue $$1$$, where the left eigenvector is defined as a row vector that satisfies the equation $$\pi P = \pi$$.
                     Here, $$\pi$$ represents the stationary distribution and $$P$$ represents the transition matrix. 
                     The elements of $$\pi$$ represent the long-run probabilities of being in each state of the Markov chain.
                     Stationary distribution exists if all eigenvalues of transition matrix are less than 1 in magnitude
                 Transition Matrix #slide 
                     In order for the stationary distribution to exist, the transition matrix must also be irreducible and aperiodic. 
                     A matrix is irreducible if it is possible to reach any state from any other state in a finite number of steps. 
                     A matrix is aperiodic if the period of each state is $$1$$, which means that it is not possible to get stuck in a cycle of visiting the same set of states repeatedly.
                     If the transition matrix satisfies these conditions, then the stationary distribution can be found by solving the linear system of equations:
                     $$\pi P = \pi$$ ($$\sum_{i}\pi_i = 1$$)
                     where the second equation enforces the normalization condition that the probabilities add up to $$1$$.
                 Markov Chain Monte Carlo (MCMC) methods can be used to sample from stationary distribution
         Von Neumann Growth Model #h Unique
             INBOX
                 The **von Neumann growth model** is an economic model that describes long-term economic expansion based on productive processes and resource allocation. It connects closely to the general economic terminology we discussed:
                 **Economy**  The von Neumann model represents an economy as a system of interdependent industries where production processes determine economic expansion. The model focuses on achieving a balanced growth rate for the entire economy.
                     **Industry**  The model assumes multiple industries that produce different goods using various production techniques. Each industry contributes to overall economic growth through efficient resource utilization.
                     **Sector**  Different economic sectors interact in the von Neumann model, with some sectors producing raw materials, others manufacturing capital goods, and others providing consumer products. Their interdependence drives economic expansion.
                         **Goods**  Goods in this model include both consumer and capital goods, which industries produce using available resources. Capital goods (such as machines and tools) are particularly important, as they enable further production.
                         **Production**  A key aspect of the von Neumann model is that production relies on inputs (resources and capital) to generate outputs. The model assumes that production functions exhibit constant returns to scale, meaning that output increases proportionally with input.
                         **Cost**  The model incorporates the idea of efficiency, where industries must minimize costs by optimizing input use. It assumes that resources flow to the most productive sectors, ensuring maximum economic growth.
                 In summary, the von Neumann growth model uses mathematical principles to explain how industries, goods, production, and costs interact to drive long-term economic growth. It highlights the importance of efficient resource allocation and technological progress in sustaining economic expansion.
             Background and Motivation of the von Neumann Growth Model #h 
                 The **von Neumann economic growth model** explains how economies optimize resource allocation and technological progress to achieve sustainable expansion, ensuring efficient use and potential **reuse** of goods in a cyclical economic system. #slide
                 Origins #slide #teaching #research 
                     Introduced by John von Neumann in 1937 \cite{}.
                     Initially presented as a mathematical theory of economic growth.
                     Published formally in "A Model of General Economic Equilibrium" in 1945-46 \cite{}.
                     Inspired by early studies on balanced economic expansion and Walrasian general equilibrium theory \cite{}.
                 Basic Economics Terminology #slide 
                     Societies consume resources and capital to produce, distribute, and reuse goods. 
                     Here's how they relate to each other:  
                         economy,
                         sector, 
                         industry, 
                         goods, 
                         production,
                         cost,
                         resources,
                         capital.
                     Societies operate within an **economy**, where different **sectors** (such as agriculture, manufacturing, and technology) consist of various **industries** that produce and distribute **goods**. 
                     These industries rely on **resources** (such as raw materials, labor, and energy) and **capital** (such as machinery, infrastructure, and investments) to drive **production**. 
                     The **cost** of production, including labor and materials, influences pricing and market dynamics. 
                 Economy, Sectors and Industries #slide 
                     Economy is the broader system that encompasses all industries, businesses, and activities related to the production, distribution, and consumption of goods and services. 
                     It includes everything from agriculture and manufacturing to technology and finance.  
                     Sector refers to a broad division of the economy that groups related industries together, such as the agriculture sector, manufacturing sector, or service sector, each contributing to overall economic activity in different ways.
                     Industry refers to a specific sector of the economy that produces goods or services. For example, the automobile industry produces cars, while the textile industry makes clothing.  
                 Goods, Production and Cost #slide 
                     Goods are physical products that industries produce for consumption or further use. These can range from consumer goods (like clothing and electronics) to capital goods (like machinery used in production).  
                     Production is the process of creating goods and services. It involves using resources such as labour, raw materials, and technology to transform inputs into finished products. The efficiency and scale of production influence the overall performance of industries and the economy.  
                     Cost represents the expenses incurred during production, including raw materials, labour, machinery, and overhead. The cost of production affects pricing, profitability, and competitiveness within an industry and the economy as a whole.  
                 Motivation #slide #teaching #research 
                     Goal: to maximise the growth levels of production, while minimising associated costs.
                         Understanding the dynamics of economic growth:
                             How can economies achieve sustained growth under resource constraints?
                         Capturing production interdependencies:
                             Focuses on the relationships between sectors and goods in an economy.
                     Providing an idealized framework:
                         Assumes perfectly efficient allocation of resources and production.
                         Serves as a foundation for more complex, real-world models.
                     Applications 
                         Economics
                         Game Theory
                         ECONOMICS
                             iNTEREST RATE
                             eXPANSION RATE
             Economy Introductory Example #slide #teaching 
                 Economy modeled as $$n$$ sectors and $$m$$ goods:
                     Sectors: represent industries, production processes or activities.
                     Goods: they are outputs of sectors and also used as inputs.
                 Input-Output Relationships:
                     Input $$m\times n$$ matrix $$ A $$: Specifies how much of each good is consumed by each sector.
                     Output $$m\times n$$ matrix $$ B $$: Specifies how much of each good is produced by each sector.
                 Assumptions:
                     No good can be produced out nothing: $$\text{col}_j(A)>0$$.
                     No activity produces nothing: $$\text{row}_i(B)>0$$.
             Types of Economies #slide 
                 Open: $$m > n$$ 
                 Closed: $$m \le n$$ 
                 Circular: $$m = n$$ 
             Growth Rate  #slide #teaching 
                 Inequality:
                     $$            (1 + g) A x \leq B x$$
                     where:
                         $$ g $$: Growth rate of the economy.
                         $$ x $$: Vector of production levels for each sector.
                 Interpretation:
                     Sectors produce outputs that must meet or exceed their inputs scaled by growth.
                     The goal is to find the maximum $$ g $$ that satisfies the inequality.
             Background #slide 
                 Value and Optimal Solutions of Matrix Games
                 NE Equilibrium Solutions of Bimatrix Games
             Motivation #slide 
                 Definition is complex
                 Several forms
                     ![Pasted image](https://dynalist.io/u/XUx-YcxqNUgc4E5_yBkhj1cu) 
                 This also effects the structure of equilibria
                      ![Pasted image](https://dynalist.io/u/iTJFbZCLzHcBahM6ckl9qqav) 
                      ![Pasted image](https://dynalist.io/u/pF6fmz3n_Q5BiwnBynCBffA8) 
             Original Economics Definition #slide #teaching #research
                 In the original context of mathematical economics \cite{Neumann1945-ab}:
                     Definition of Von Neumann __balanced growth path__: $$(\alpha,x)$$ such that $$\alpha$$ is maximal subject to $$x^\top(B-\alpha A) \ge 0$$.
                         $$\alpha$$: expansion factor
                         $$x$$: intensity vector
                     Definition of Von Neumann __price problem__: $$(\beta,p)$$ such that $$\beta$$ is minimal subject to $$(B-\alpha A)p \le 0$$.
                         $$\beta$$: interest factor
                         $$p$$: price vector
                 One makes the following assumption: $$A+B>0$$.
                 The result is then, that at least one such solution exist, and that it holds $$0<\beta\le \alpha$$.
             Min-Max Definition #slide 
                 In Game-theoretic context \cite{}:
                 $$(\alpha,x)$$ such that $$\alpha$$ is maximal subject to $$(A-\alpha B)x \ge 0$$.
                 $$(\beta,p)$$ such that $$\beta$$ is minimal subject to $$p(A-\alpha B) \le 0$$.
                 Assumption: $$A+B>0$$.
                 Results:
                     Solutions exist.
                     It holds $$0<\beta\le \alpha$$.
             Generalised Definition #slide 
                 A triplet $$(x, y,\lambda)$$, with $$x\geqq0$$, $$y\geqq 0$$, $$\lambda > 0$$, is a __generalised equilibrium solution__ for the von Neumann technology VNM($$A, B$$) if it satisfies the following system:
                     $$x^\top A \geqq \lambda x^\top B$$,
                     $$Ay \leqq \lambda By$$.
                 So we do not need $$x^\top Ay> 0$$. 
             Active Sub-pencil Definition #slide 
                 Thompson et al \cite{Thompson1971-or} show that 
                 This generalises results by Shapley, see also Karlin's book, for game theory
             Equality Definition #slide 
                 A quadruplet $$(x, y, \alpha, \beta)$$, $$x\geqq 0$$, $$y \geqq 0$$, $$\alpha \neq 0$$, $$\beta \neq 0$$ is an __equilibrium solution__ for the von Neumann model VN$$(B, A)$$ if it satisfies the following system:
                     $$ x^\top A  \ge  \alpha x^\top B$$,
                     $$ x^\top A y= \alpha  x^\top By$$,
                     $$ Ay \le \beta By$$,
                     $$ x^\top Ay = x^\top \beta By $$,
                     $$x^\top Ay > 0$$.
             Pencil Notation #slide 
                 We can re-write the above inequalities using matrix pencil notation:
                     $$ x^\top (A  - \alpha B)\ge 0$$,
                     $$ x^\top (A - \alpha  B)y = 0$$,
                     $$ (A  -\beta B)y\le 0 $$,
                     $$ x^\top (A - \beta B)y = 0$$,
                     $$x^\top Ay > 0$$.
             Simplification #slide 
                 Lemma: If $$(\bar{x}, \bar{y}, \bar{\alpha} ,\bar{\beta})$$ is an equilibrium solution, then $$\bar{\alpha}=\bar{\beta}>0$$.
                 Proof:
                     $$0<\bar{x}^\top A\bar{y}= \alpha\bar{x}^\top B\bar{y}=\beta\bar{x}^\top B\bar{y}$$
                      ![Pasted image](https://dynalist.io/u/KY41W0xBeMdX3mvJ9H06H-cj) 
             Simplified Definition #slide 
                 A triplet $$(x, y,\lambda)$$, with $$x\geqq0$$, $$y\geqq 0$$, $$\lambda > 0$$, is an equilibrium solution for the von Neumann technology VNM($$A, B$$) if it satisfies the following system:
                     $$x^\top A \geqq \lambda x^\top B$$,
                     $$Ay \leqq \lambda By$$,
                     $$x^\top Ay> 0$$. 
             Pencil Perturbation Definition #slide 
             Assumptions #slide 
                 Von Neumann et al: $$A+B>0$$
                 Thompson et al: $$xAy > 0$$
                 Us: $$\det(A-\lambda B) \neq 0$$ and $$\det(A^{ij}-\lambda B^{ij}) > 0$$
             Various Model Assumptions #slide 
             Main Theorem #slide #teaching 
             Sufficient Conditions #slide 
                 Background: concept of $$F$$-transformation (or "$$F$$-pencil")
             F-Transformation (Drandakis) #slide 
                 Context and Details
                 If the input and output transformation of a von Neumann production system is an $$F$$-transformation, the von Neumann maximal growth factor $$\rho$$ is the F-eigenvalue, and $$z$$, $$p$$ are the (unique) right and left F-eigenvectors of $$D-\lambda C$$ (\cite{Drandakis1966-nv}).
             Basic Estimates #slide 
                 One has
                     $$\rho \le (\sum a_{ij})/(\sum b_{ij})=\sum a_{ij}/(\sum b_{ij})\le \sum (a_{ij}/b_{ij})$$ (\cite{})
                 Precise result if we have an F-Transformation:
             Rank-1 Models #h 
                 LP Equivalence Theorem #slide 
                     Consider the model VNM($$B,A$$) where $$B=uv^\top \geqq 0$$.
                     We refer to this as a rank-1 VN model.
                     It is known in the literature \cite{Bidard2000-jr}, that such a model is equivalent to a linear program.
                     Theorem: the rank-one model VNM($$uv^\top,A$$) with maximal growth factor $$\lambda>0$$ is equivalent to the linear program LP($$v^\top, A, u$$) with optimal value $$\lambda^{-1}$$. #theorem 
                 Proof #slide 
                     $$\Longrightarrow$$" 
                         We start with $$\lambda$$ maximal such that $$\exists x^\top: x^\top(A-\lambda uv^\top)\geqq 0$$.
                         Define $$\tilde{x} := \frac{x^\top}{\lambda x^\top u}$$.
                         Then $$\tilde{x}u=\frac{x^\top u}{\lambda x^\top u}=\lambda^{-1}$$ is minimal, such that $$\tilde{x}^\top(A-\lambda uv^\top)=\tilde{x}^\top A-v^\top \geqq 0$$.
                         This means that the linear program LP($$u, A, v^\top$$) is solved by $$\tilde{x}^\top$$ with value $$\lambda^{-1}$$.
                     "$$\Longleftarrow$$" 
                         Assume $${x}^\top$$ is a solution of the linear program LP($$u, A, v^\top$$) with value $$\mu^{}$$.
                         This means $$\mu := x^\top u$$ is minimal such that $$x^\top A-v^\top\geqq 0$$.
                         One has $$v^\top=\frac{x^\top u}{x^\top u}v^\top = \frac{1}{x^\top u}x^\top uv^\top = \mu^{-1}x^\top uv^\top \geqq 0$$. 
                         Hence $$x^\top(A-\mu^{-1} uv^\top)\geqq 0$$ and $$\lambda:=\mu^{-1}$$ is a maximal growth factor for VNM($$uv^\top,A$$).
                 Equilibrium Solutions #slide 
                 Weak and Strong Duality #slide 
                 Example #slide 
                     Consider LP$$(A,b,c)$$ where
                         $$A=\begin{pmatrix} 1 & 3 & -1 \\ 0 & 1 & 1 \\ 3 & 1 & 0 \\  \end{pmatrix},\quad b=\begin{pmatrix} 6 \\ 4 \\ 7 \\  \end{pmatrix},\quad^tc=\begin{pmatrix} 5&2&1  \\  \end{pmatrix}$$.
                     This example is given in \cite{Fer} and its value and primal and dual optimal solutions are
                         $$v=\frac{3}{47},\quad {}^tx=\begin{pmatrix} 0&1&5/3  \\  \end{pmatrix},\quad y=\begin{pmatrix} 7/3\\0\\4  \\  \end{pmatrix}$$.
                     Then $$D={}^tc\,b=\begin{pmatrix} 30&12&6 \\ 20&8&4 \\ 35&14&7 \\  \end{pmatrix}$$ and we consider the pencil $$A-\lambda D$$.
                 Active Sub-pencil #slide 
                     Deleting the first row and second column, corresponding to the zero components of the optimal solutions, the sub-pencil 
                         $$\hat{A}-\lambda \hat{D}=\begin{pmatrix}  0 & 1 \\ 3 & 0 \\  \end{pmatrix}-\lambda \begin{pmatrix}  20&4 \\ 35&7 \\  \end{pmatrix} $$
                     is obtained.
                     One verifies that
                         $$\mathcal{E}(\hat{A}-\lambda \hat{D})=\left[\hat{v}=\frac{47}{3},\quad {}^t\hat{x}=\begin{pmatrix} 1&5/3  \\  \end{pmatrix},\quad \hat{y}=\begin{pmatrix} 7/3\\4  \\  \end{pmatrix}\right]$$
                             
                     is a generalised positive eigensystem.
                 Pencil Perturbation #slide 
                     Furthermore, $${}^t\hat{x}()=$$
                     The pencil perturbation
                          
                     yields the pencil
                          
                     The generalised eigensystem of the perturbed pencil is
                         
                 Algorithm #slide 
                     **algorithm** Von_Neumann_rank_one_solve_incomplete$$(A)$$
                         **if** $$({e^T{\rm adj}( A)e}\neq 0)$$ **then**
                             $$v := \frac{\det(A)} {e^T{\rm adj}( A)e}$$;
                             **if** $$\neg (e^T{\rm adj}( A)= 0 \wedge {{\rm adj}( A)e}=0)$$ **then**  
                                 $$x:=\frac{e^T{\rm adj}(A)} {e^T{\rm adj}( A)e}$$
                                 $$y:=\frac{{\rm adj}(A)e} {e^T{\rm adj}( A)e}$$
                                 **if** $$x\ge 0$$ **and** $$y\ge 0$$ **then** **return**($$v$$, $$x$$, $$y$$);
                             **fi**; 
                         **fi**; 
                         **return**(FAIL);
                     **end**;
             Novel Results #slide 
                 Rank-$$k$$ VN Models 
                 2x2 Strategic VN Models 
             Algorithmic Treatment #h 
                 Overview #slide 
                     Thompson and Weil show that equilibrium solutions correspond to generalised eigensystems of submatrices of the matrix pencil
                     Leads to exhaustive search algorithm
                     Another approach is based on evaluations of the pencil at various points
                     This is basis for iterative algorithms 
                 Exhaustive Search Approach #h
                     Algorithm (I) #slide 
                         **algorithm** Von_Neumann_submatrix_solve($$A$$)
                             sols $$:= \emptyset$$;
                             **for all** square pencil submatrices $$\bar{A}-\lambda\bar{B}$$ of $$A-\lambda B$$ **do**
                                 temp $$:=$$ max_gen_eigen_system$$(\bar{A},\bar{B})$$;
                                 **if** temp $$\neq \emptyset$$ **then**
                                     $$(\bar{x},\bar{y},\bar{v}) := $$ temp; 
                                     **if** is_equilibrium_solution$$(\bar{v},{x},{y},A,B)$$ **then** sols $$:=$$ sols $$\cup$$ temp;
                             **return** sols;
                         **end**;
                     Algorithm (II) #slide 
                         max_gen_eigen_system$$(\bar{A},\bar{B})$$
                         **algorithm** is_equilibrium_solution$$(\bar{v},\bar{x},\bar{y},A,B)$$
                             **if** $$\bar{x}\ge 0\wedge\bar{x}(A-\bar{v}B)\ge 0\wedge \bar{y}\ge 0\wedge(A-\bar{v}B)\bar{y}\ge 0$$ **then**
                                 **return** __true__
                             else
                                 **return** __false__;
                         **end**;
                 Iterative Solving of Game #slide 
                     Thompson and Hamburger 
                     Bose
                 Numerically stable algorithms #slide 
                 Novel Algorithms
             Novel Digital Knowledge Work Productivity Model #h #novel
                 Suitability for Model: Digital Productivity as a Circular Economy #h 
                     Introduction #slide 
                         Circular economy:
                             Focuses on minimizing waste and maximizing resource reuse within a closed-loop system.
                         Digital productivity:
                             Refers to the effective use of digital tools, platforms, and processes to create value.
                     Digital productivity exhibits traits of a circular economy #slide 
                         Reuse of digital resources:
                             Digital tools, software, and platforms can be reused indefinitely without degradation.
                             Example: Open-source software reused and adapted across industries.
                         Knowledge as a renewable resource:
                             Knowledge work outputs (e.g., reports, analyses) can be reused as inputs for future projects.
                             Example: Insights from one project informing strategic decisions for others.
                         Low marginal cost of replication:
                             Digital goods (e.g., software, data, reports) can be duplicated at almost zero cost.
                     Conclusion #slide 
                         Digital productivity can be partially seen as a circular economy:
                             Strengths:
                                 The reuse and low-cost replication of digital resources align with circular principles.
                             Limitations:
                                 Energy use and hardware waste are significant barriers to full circularity.
                             Future direction:
                                 Emphasizing green computing and sustainable digital practices can help bridge the gap.
                         Challenges in achieving circularity 
                             Digital waste:
                                 Obsolete hardware, e-waste, and outdated systems contribute to resource inefficiency.
                             Energy consumption:
                                 Data centers and cloud computing require significant energy, impacting sustainability.
                             Security and obsolescence:
                                 Older digital systems may become vulnerable, limiting their long-term reusability.
                 Von Neumann Growth Model for Knowledge Work Scenario #h 
                     Goal #slide 
                         To apply the VNM to a digital productivity scenario where knowledge workers are assigned to projects, working on tasks. 
                         The goal is to maximise productivity output based on a suitable assignment of intensities, while minimising the required salaries.
                     Model Definition #slide 
                         Input matrix: represents the amount of each task required to produce a unit of project output
                             Each row accumulates the extent to which a specific task is required for the various projects
                             Each column specifies the involved tasks for a specific project
                         Output matrix: represents the goods (tasks) produced by each project:
                         Intensity and Price Levels: Worker Allocations and Costs
                             $$w=(w_1,w_2)$$ where $$w_1, w_2$$ are the time and effort (productivity or depth level) allocated to the projects 1 and 2. 
                     Equilibrium Solutions #slide 
                     Benefits #slide 
                     Example #h 
                         Model Setup -- Technological Production #slide 
                             Sectors: knowledge work projects (matrix columns)
                                 Project 1: Focuses on strategic planning.
                                 Project 2 (matrix rows): Focuses on operational research.
                             Goods: knowledge work tasks
                                 Task 1: Report Writing (e.g., creating strategic or operational reports).
                                 Task 2: Data Analysis (e.g., processing data for decision-making).
                             Intensity vector: allocated efforts/workers
                                 This is  $$w=(w_1,w_2)$$ where $$w_1, w_2$$ are the time and effort (productivity or depth level) allocated to the projects 1 and 2. 
                         Input Matrix #slide 
                             Consider the following matrix:
                                 $$A = \begin{bmatrix} 2 & 1 \\ 1 & 3 \end{bmatrix}.$$
                             Project 1 requires 2 units of Report Writing and 1 unit of Data Analysis.
                             Project 2 requires 1 unit of Report Writing and 3 units of Data Analysis.
                         Output Matrix #slide 
                             Consider the following matrix:
                                 $$B = \begin{bmatrix} 4 & 1 \\ 2 & 3 \end{bmatrix}.$$
                             Project 1 produces 4 units of Report Writing and 2 units of Data Analysis.
                             Project 2 produces 1 unit of Report Writing and 3 units of Data Analysis.
                         Growth Condition #slide 
                             The growth inequality
                                 $$(1 + g) x^\top A  \leq x^\top B$$
                             where $$g>0$$ and $$ x = \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} $$ represents the production levels of Project 1 and Project 2.
                         Solve for Growth Rate #slide 
                             Expand the growth inequality into two conditions:
                             1. For Project 1:
                                 $$            (1 + g)(2x_1 + x_2) \leq 3x_1 + x_2.$$
                             2. For Project 2:
                                 $$            (1 + g)(x_1 + 2x_2) \leq x_1 + 3x_2.$$
                             Solving these yields:
                             $$        g^* = 0.5 \quad \text{(50\% maximum growth rate)}.$$
                         Equilibrium Production Levels #slide 
                             At the maximum growth rate $$ g^* $$, equilibrium production levels satisfy:
                             $$        x_1 = 2 \quad \text{(output from Project 1)}, \quad x_2 = 1 \quad \text{(output from Project 2)}.$$
                         Model Setup -- Economical Pricing #slide 
                             Dual price vector:
                                 $$        p = \begin{bmatrix} p_1 \\ p_2 \end{bmatrix},$$
                                 where $$ p_1 $$ is the value per unit of Report Writing and $$ p_2 $$ is the value per unit of Data Analysis.
                         Interpretation #slide 
                             Inputs ($$ A $$): Project 1 relies more on Report Writing, while Project 2 relies more on Data Analysis.
                             Outputs ($$ B $$):Project 1 emphasizes producing reports; Project 2 emphasizes producing data insights.
                             Maximum Growth Rate ($$ g^* $$):
                                 The tasks can grow at a maximum rate of 50\%, given the balance of inputs and outputs.
                             Equilibrium Values:
                                 Project Outputs: Project 1 should produce twice as much as Project 2.
                                 Task Values: Report Writing is valued twice as much as Data Analysis.
                     Discussion #slide 
             Novel AI-Enhanced Digital Knowledge Work Productivity Model #h #novel 
                 Goal: to enhance the digital productivity scenario with AI tools. #slide
             ECONOMICS #hh 
             Stochastic
             Security Economics: Definition of Multi-Asset Multi-ROI #h #novel 
                 Goal: to extend the definition of return of security investment to a multiple asset multiple investment scenario. #slide
             Application to Network Security #h 
                 Setting #slide #teaching 
                     A fascinating adaptation of the von Neumann growth model! 
                     Goal: 
                         to apply the model for investing in security measures for a system with interdependent assets and multiple security controls. 
                         This should maximise the cost-benefit utility for the organisation running the system while minimising the financial damage inflicted by an attacker.
                     Let's map the network security scenario to the model's framework:
                         Considering two sectors = LAN and DMZ
                         Networked appliances as goods
                         Security benefits minus deployment costs minus loss of asset value as the utility.
                 Example: A 2x2 Highly Interconnected System #slide #teaching 
                     Model Parameters:
                         Input matrix $$ A $$: Represents resources required for production.
                         Output matrix $$ B $$: Represents resources produced by production.
                         Let
                             $$        A = \begin{bmatrix} 1 & 1 \\ 1 & 1 \end{bmatrix}, \quad         B = \begin{bmatrix} 2 & 1 \\ 1 & 2 \end{bmatrix}.$$
                     Interpretation:
                         Input Matrix $$ A $$:
                             Every unit of output from any sector requires 1 unit of every input.
                         Output Matrix $$ B $$:
                             Sector 1 produces 2 units of Good 1 and 1 unit of Good 2.
                             Sector 2 produces 1 unit of Good 1 and 2 units of Good 2.
                 Example: Independent System #slide #teaching
                     A matrix AA with all entries equal to 1 reflects a system of **uniform interdependence and balanced resource usage**, 
                     which has strong symmetry but also potential vulnerabilities if outputs fail to exceed inputs.
                 Production Model #slide #teaching 
             WATER RESOURCE MANAGEMENT  #hh
             CA
             Markov+Bilinear+Security
                 State Transitions #slide 
                     ![Pasted image](https://dynalist.io/u/L7qeIgCxFCJEAsajwBc3QSsf) 
                 Transition Matrices #slide 
                     These are
                         $$D=\begin{pmatrix}  d_{11}&d_{12} \\ d_{21} &d_{22}  \\  \end{pmatrix}$$
                         $$A=\begin{pmatrix}  a_{11}&a_{12} \\ a_{21} &a_{22}  \\  \end{pmatrix}$$
                     Written as linear matrix pencil: $$D-\lambda A$$.